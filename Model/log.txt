[20] train loss: 351.0867004394531, train metric: 272.4383544921875, lr: 0.0009994393913075328
[40] train loss: 16.29847526550293, train metric: 37.24787902832031, lr: 0.0009969500824809074
[60] train loss: 4.208664894104004, train metric: 10.511611938476562, lr: 0.000992479850538075
[80] train loss: 2.353236675262451, train metric: 7.73241662979126, lr: 0.000986046390607953
[100] train loss: 1.917643427848816, train metric: 7.433781623840332, lr: 0.0009776754304766655
[120] train loss: 2.6090269088745117, train metric: 8.00448226928711, lr: 0.0009674003813415766
[140] train loss: 1.452107310295105, train metric: 6.694370746612549, lr: 0.0009552621049806476
[160] train loss: 1.6080207824707031, train metric: 6.373427391052246, lr: 0.0009413089719600976
[180] train loss: 1.3886709213256836, train metric: 6.031280517578125, lr: 0.0009255966870114207
[200] train loss: 3.1707372665405273, train metric: 11.834915161132812, lr: 0.00090818788157776
[220] train loss: 1.1114543676376343, train metric: 5.337376594543457, lr: 0.0008891518809832633
[240] train loss: 1.3993592262268066, train metric: 5.741065979003906, lr: 0.0008685645880177617
[260] train loss: 1.1302287578582764, train metric: 4.896233558654785, lr: 0.0008465081336908042
[280] train loss: 0.8939223289489746, train metric: 4.6216630935668945, lr: 0.0008230703533627093
[300] train loss: 0.7907061576843262, train metric: 4.59163761138916, lr: 0.0007983447285369039
[320] train loss: 2.4706270694732666, train metric: 7.238276481628418, lr: 0.0007724298629909754
[340] train loss: 1.700251817703247, train metric: 13.24365234375, lr: 0.0007454289589077234
[360] train loss: 3.281209707260132, train metric: 16.681900024414062, lr: 0.0007174497004598379
[380] train loss: 2.3853201866149902, train metric: 11.790061950683594, lr: 0.00068860367173329
[400] train loss: 0.821880578994751, train metric: 4.673244953155518, lr: 0.0006590057746507227
[420] train loss: 2.386974811553955, train metric: 10.2017822265625, lr: 0.0006287740543484688
[440] train loss: 6.700322151184082, train metric: 18.406173706054688, lr: 0.000598029000684619
[460] train loss: 4.240921497344971, train metric: 14.932937622070312, lr: 0.0005668931407853961
[480] train loss: 0.7648816704750061, train metric: 4.0780534744262695, lr: 0.0005354906315915287
[500] train loss: 23.298402786254883, train metric: 37.5135498046875, lr: 0.0005039466777816415
[520] train loss: 9.610654830932617, train metric: 24.025482177734375, lr: 0.0004723869787994772
[540] train loss: 1.0247188806533813, train metric: 4.659956932067871, lr: 0.0004409373505041003
[560] train loss: 0.806948184967041, train metric: 5.13520622253418, lr: 0.0004097231721971184
[580] train loss: 5.41206693649292, train metric: 13.48175048828125, lr: 0.000378868862753734
[600] train loss: 228.2538299560547, train metric: 111.96234893798828, lr: 0.00034849741496145725
[620] train loss: 18.766357421875, train metric: 25.392562866210938, lr: 0.0003187299007549882
[640] train loss: 4.757693290710449, train metric: 25.102928161621094, lr: 0.0002896849764510989
[660] train loss: 1.1034119129180908, train metric: 5.352813720703125, lr: 0.0002614784170873463
[680] train loss: 0.9448823928833008, train metric: 4.757434844970703, lr: 0.00023422270896844566
[700] train loss: 1.0772318840026855, train metric: 4.9244794845581055, lr: 0.00020802643848583102
[720] train loss: 1.0847810506820679, train metric: 5.441412448883057, lr: 0.00018299407383892685
[740] train loss: 0.8097434639930725, train metric: 4.686760425567627, lr: 0.00015922538295853883
[760] train loss: 0.7137410640716553, train metric: 4.716812610626221, lr: 0.00013681512791663408
[780] train loss: 3.3057475090026855, train metric: 9.996427536010742, lr: 0.00011585262109292671
[800] train loss: 3.1854445934295654, train metric: 14.872390747070312, lr: 9.999999747378752e-05
[820] train loss: 1.2072259187698364, train metric: 7.227171897888184, lr: 9.999999747378752e-05
[840] train loss: 2.5880398750305176, train metric: 7.471667289733887, lr: 9.999999747378752e-05
[860] train loss: 4.5487775802612305, train metric: 20.315025329589844, lr: 9.999999747378752e-05
[880] train loss: 1.8411672115325928, train metric: 10.047065734863281, lr: 9.999999747378752e-05
[900] train loss: 1.128923773765564, train metric: 5.581714630126953, lr: 9.999999747378752e-05
[920] train loss: 0.9934713840484619, train metric: 5.076651573181152, lr: 9.999999747378752e-05
[940] train loss: 4.410301685333252, train metric: 11.899020195007324, lr: 9.999999747378752e-05
[960] train loss: 16.823226928710938, train metric: 24.365131378173828, lr: 9.999999747378752e-05
[980] train loss: 7.284621715545654, train metric: 18.823989868164062, lr: 9.999999747378752e-05
[1000] train loss: 4.212631702423096, train metric: 8.08483600616455, lr: 9.999999747378752e-05
[1020] train loss: 1.5423164367675781, train metric: 7.164054870605469, lr: 9.999999747378752e-05
[1040] train loss: 1.0258039236068726, train metric: 5.219627380371094, lr: 9.999999747378752e-05
[1060] train loss: 1.2212612628936768, train metric: 6.204444885253906, lr: 9.999999747378752e-05
[1080] train loss: 1.5917601585388184, train metric: 6.054145812988281, lr: 9.999999747378752e-05
[1100] train loss: 7.589622974395752, train metric: 12.19700813293457, lr: 9.999999747378752e-05
