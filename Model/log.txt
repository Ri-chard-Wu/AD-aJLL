[5] train loss: 15.816348791122437, train metric: 25.402267456054688, lr: 0.0010000000474974513
[10] train loss: 26.577974319458008, train metric: 42.15365505218506, lr: 0.000999937648884952
[15] train loss: 41.92828845977783, train metric: 46.02592849731445, lr: 0.0009997508022934198
[20] train loss: 12.76169753074646, train metric: 27.204341888427734, lr: 0.0009994393913075328
[25] train loss: 19.442317485809326, train metric: 16.741861820220947, lr: 0.000999003415927291
[30] train loss: 13.821960926055908, train metric: 16.653684616088867, lr: 0.0009984431089833379
[35] train loss: 41.16061496734619, train metric: 49.44654655456543, lr: 0.0009977585868909955
[40] train loss: 29.07087993621826, train metric: 33.51018142700195, lr: 0.0009969500824809074
[45] train loss: 74.35979557037354, train metric: 81.72664260864258, lr: 0.0009960177121683955
[50] train loss: 36.381829261779785, train metric: 55.99087619781494, lr: 0.0009949617087841034
[55] train loss: 10.942613124847412, train metric: 36.86475372314453, lr: 0.0009937823051586747
[60] train loss: 7.287559628486633, train metric: 48.55435848236084, lr: 0.000992479850538075
[65] train loss: 9.035590887069702, train metric: 68.1701602935791, lr: 0.0009910546941682696
[70] train loss: 6.007007002830505, train metric: 29.127527236938477, lr: 0.0009895070688799024
[75] train loss: 131.52794647216797, train metric: 86.23439025878906, lr: 0.0009878375567495823
[80] train loss: 57.86509418487549, train metric: 59.9161491394043, lr: 0.000986046390607953
[85] train loss: 31.107518672943115, train metric: 41.09825325012207, lr: 0.0009841341525316238
[90] train loss: 8.507930278778076, train metric: 29.0318603515625, lr: 0.00098210119176656
[95] train loss: 1.9120767414569855, train metric: 7.4125494956970215, lr: 0.0009799482068046927
[100] train loss: 13.063540697097778, train metric: 26.18838405609131, lr: 0.0009776754304766655
[105] train loss: 6.52100682258606, train metric: 18.63905143737793, lr: 0.000975283735897392
[110] train loss: 5.438933491706848, train metric: 13.448259353637695, lr: 0.0009727735887281597
[115] train loss: 2.889966607093811, train metric: 19.07467746734619, lr: 0.0009701455710455775
[120] train loss: 27.62217664718628, train metric: 23.457804679870605, lr: 0.0009674003813415766
[125] train loss: 2.7592151761054993, train metric: 22.00766086578369, lr: 0.0009645387181080878
[130] train loss: 4.421252012252808, train metric: 12.790173530578613, lr: 0.0009615612798370421
[135] train loss: 5.2491302490234375, train metric: 13.75578784942627, lr: 0.0009584688232280314
[140] train loss: 20.719159603118896, train metric: 24.98292827606201, lr: 0.0009552621049806476
[145] train loss: 61.4785270690918, train metric: 62.86329936981201, lr: 0.0009519418817944825
[150] train loss: 171.06877517700195, train metric: 101.79414939880371, lr: 0.0009485090849921107
[155] train loss: 121.11682891845703, train metric: 81.09304618835449, lr: 0.0009449644712731242
[160] train loss: 26.39287042617798, train metric: 48.230732917785645, lr: 0.0009413089719600976
[165] train loss: 5.998861312866211, train metric: 30.97486686706543, lr: 0.0009375435183756053
[170] train loss: 16.876221656799316, train metric: 29.59933853149414, lr: 0.0009336689836345613
[175] train loss: 21.32568359375, train metric: 37.191436767578125, lr: 0.0009296864154748619
[180] train loss: 14.253100395202637, train metric: 21.950143814086914, lr: 0.0009255966870114207
[185] train loss: 8.050397396087646, train metric: 31.864295959472656, lr: 0.0009214009623974562
[190] train loss: 8.034408688545227, train metric: 15.747489929199219, lr: 0.0009171001729555428
[195] train loss: 19.548715353012085, train metric: 25.134541988372803, lr: 0.000912695424631238
[200] train loss: 13.991087675094604, train metric: 20.80959177017212, lr: 0.00090818788157776
[205] train loss: 6.408532619476318, train metric: 25.46127700805664, lr: 0.0009035785333253443
[210] train loss: 2.731111466884613, train metric: 17.553234100341797, lr: 0.0008988686604425311
[215] train loss: 18.036152839660645, train metric: 38.50557994842529, lr: 0.0008940593688748777
[220] train loss: 16.739876747131348, train metric: 63.400875091552734, lr: 0.0008891518809832633
[225] train loss: 65.7225923538208, train metric: 78.04140853881836, lr: 0.0008841473609209061
[230] train loss: 21.531896591186523, train metric: 72.9482250213623, lr: 0.0008790471474640071
[235] train loss: 11.752768993377686, train metric: 23.41126251220703, lr: 0.0008738524629734457
[240] train loss: 7.901718258857727, train metric: 19.31583595275879, lr: 0.0008685645880177617
[245] train loss: 17.61846351623535, train metric: 31.379575729370117, lr: 0.0008631848613731563
[250] train loss: 13.27307677268982, train metric: 20.267874240875244, lr: 0.0008577146218158305
[255] train loss: 4.429019331932068, train metric: 24.09250545501709, lr: 0.0008521552663296461
[260] train loss: 15.698249101638794, train metric: 23.189302444458008, lr: 0.0008465081336908042
[265] train loss: 60.78868389129639, train metric: 65.76680374145508, lr: 0.0008407746208831668
[270] train loss: 58.17193794250488, train metric: 54.700876235961914, lr: 0.0008349561830982566
[275] train loss: 17.008629322052002, train metric: 24.546403884887695, lr: 0.0008290542755275965
[280] train loss: 6.942800760269165, train metric: 17.553964614868164, lr: 0.0008230703533627093
[285] train loss: 8.906984567642212, train metric: 63.61150646209717, lr: 0.0008170059300027788
[290] train loss: 9.123887538909912, train metric: 22.68814182281494, lr: 0.0008108624606393278
[295] train loss: 16.28989005088806, train metric: 20.97536325454712, lr: 0.0008046415750868618
[300] train loss: 17.97536039352417, train metric: 31.7938175201416, lr: 0.0007983447285369039
[305] train loss: 16.710469245910645, train metric: 27.810163497924805, lr: 0.0007919735508039594
[310] train loss: 11.42015552520752, train metric: 25.384042739868164, lr: 0.000785529613494873
[315] train loss: 12.130991458892822, train metric: 25.593278884887695, lr: 0.0007790144882164896
[320] train loss: 12.196213245391846, train metric: 20.19169807434082, lr: 0.0007724298629909754
[325] train loss: 8.468672752380371, train metric: 26.02397632598877, lr: 0.0007657773094251752
[330] train loss: 8.396203398704529, train metric: 19.704158782958984, lr: 0.0007590585155412555
[335] train loss: 4.846131682395935, train metric: 22.572330474853516, lr: 0.0007522751693613827
[340] train loss: 19.736526012420654, train metric: 21.634871006011963, lr: 0.0007454289589077234
[345] train loss: 2.2570353150367737, train metric: 27.337976455688477, lr: 0.0007385215722024441
[350] train loss: 1.4749104976654053, train metric: 10.729077339172363, lr: 0.0007315547554753721
[355] train loss: 0.9511120468378067, train metric: 6.9347909688949585, lr: 0.0007245301967486739
[360] train loss: 14.559854745864868, train metric: 17.851271152496338, lr: 0.0007174497004598379
[365] train loss: 37.391855239868164, train metric: 29.532007217407227, lr: 0.0007103150128386915
[370] train loss: 10.025510787963867, train metric: 30.62518882751465, lr: 0.0007031279383227229
[375] train loss: 16.535701274871826, train metric: 22.583730697631836, lr: 0.0006958902231417596
[380] train loss: 11.843269109725952, train metric: 49.04385280609131, lr: 0.00068860367173329
[385] train loss: 4.070814073085785, train metric: 8.384300231933594, lr: 0.0006812700885348022
[390] train loss: 8.44075334072113, train metric: 22.227871894836426, lr: 0.0006738913943991065
[395] train loss: 10.360606670379639, train metric: 21.78089141845703, lr: 0.0006664693355560303
[400] train loss: 5.500168204307556, train metric: 12.157946586608887, lr: 0.0006590057746507227
[405] train loss: 4.4323378801345825, train metric: 18.64262294769287, lr: 0.0006515025743283331
[410] train loss: 4.626105427742004, train metric: 20.34034538269043, lr: 0.0006439616554416716
[415] train loss: 2.6095943450927734, train metric: 8.932334899902344, lr: 0.0006363848224282265
[420] train loss: 22.494836807250977, train metric: 23.16918134689331, lr: 0.0006287740543484688
[425] train loss: 15.32086443901062, train metric: 21.179651737213135, lr: 0.0006211311556398869
[430] train loss: 9.302764892578125, train metric: 25.414477348327637, lr: 0.0006134580471552908
[435] train loss: 3.0667735934257507, train metric: 23.232988357543945, lr: 0.0006057567079551518
[440] train loss: 6.179784417152405, train metric: 46.34772300720215, lr: 0.000598029000684619
[445] train loss: 82.33995628356934, train metric: 60.68246841430664, lr: 0.0005902768461965024
[450] train loss: 56.32071304321289, train metric: 75.00441932678223, lr: 0.0005825021653436124
[455] train loss: 25.17603302001953, train metric: 36.86006164550781, lr: 0.0005747069953940809
[460] train loss: 26.631292819976807, train metric: 40.90539360046387, lr: 0.0005668931407853961
[465] train loss: 26.79929208755493, train metric: 36.17364692687988, lr: 0.0005590626387856901
[470] train loss: 30.4978346824646, train metric: 50.6810417175293, lr: 0.0005512174102477729
[475] train loss: 21.328869342803955, train metric: 22.317550659179688, lr: 0.0005433594342321157
[480] train loss: 27.18396282196045, train metric: 38.054521560668945, lr: 0.0005354906315915287
[485] train loss: 44.88814067840576, train metric: 29.39807891845703, lr: 0.0005276130395941436
[490] train loss: 69.53532218933105, train metric: 56.07485580444336, lr: 0.0005197285208851099
[495] train loss: 43.37171268463135, train metric: 27.576316356658936, lr: 0.0005118390545248985
[500] train loss: 10.313676595687866, train metric: 20.468168258666992, lr: 0.0005039466777816415
[505] train loss: 6.330544710159302, train metric: 13.356063842773438, lr: 0.0004960533115081489
[510] train loss: 4.0876305103302, train metric: 35.033002853393555, lr: 0.00048816093476489186
[515] train loss: 9.632839441299438, train metric: 22.78261375427246, lr: 0.00048027149750851095
[520] train loss: 23.30104351043701, train metric: 23.956867218017578, lr: 0.0004723869787994772
[525] train loss: 10.136366128921509, train metric: 21.288009643554688, lr: 0.00046450935769826174
[530] train loss: 15.928508281707764, train metric: 29.57303810119629, lr: 0.00045664055505767465
[535] train loss: 11.064826726913452, train metric: 40.39960193634033, lr: 0.00044878257904201746
[540] train loss: 4.736236572265625, train metric: 13.770608901977539, lr: 0.0004409373505041003
[545] train loss: 8.881405353546143, train metric: 24.765031814575195, lr: 0.0004331068485043943
[550] train loss: 2.722711443901062, train metric: 30.251489639282227, lr: 0.00042529302299953997
[555] train loss: 1.9237282574176788, train metric: 16.42015838623047, lr: 0.00041749782394617796
[560] train loss: 5.770387768745422, train metric: 25.835796356201172, lr: 0.0004097231721971184
[565] train loss: 13.731873512268066, train metric: 32.83571720123291, lr: 0.0004019710177090019
[570] train loss: 2.6665648221969604, train metric: 19.142266273498535, lr: 0.00039424331043846905
[575] train loss: 5.980700135231018, train metric: 20.48589515686035, lr: 0.00038654194213449955
[580] train loss: 6.227442026138306, train metric: 12.588891744613647, lr: 0.000378868862753734
[585] train loss: 32.49715852737427, train metric: 30.56784152984619, lr: 0.00037122596404515207
[590] train loss: 33.12199068069458, train metric: 44.978965759277344, lr: 0.0003636151668615639
[595] train loss: 31.513829231262207, train metric: 42.09787082672119, lr: 0.0003560383338481188
[600] train loss: 9.581734895706177, train metric: 22.376230239868164, lr: 0.00034849741496145725
[605] train loss: 15.111876964569092, train metric: 24.15059757232666, lr: 0.0003409942437428981
[610] train loss: 16.85664939880371, train metric: 29.407514572143555, lr: 0.0003335306828375906
[615] train loss: 8.559166550636292, train metric: 24.07090663909912, lr: 0.00032610862399451435
[620] train loss: 1.7163599729537964, train metric: 11.782093048095703, lr: 0.0003187299007549882
[625] train loss: 3.5478233098983765, train metric: 13.621733665466309, lr: 0.0003113963466603309
[630] train loss: 5.907562971115112, train metric: 10.648586511611938, lr: 0.0003041097952518612
[635] train loss: 3.85812771320343, train metric: 8.198896884918213, lr: 0.00029687208007089794
[640] train loss: 25.642040729522705, train metric: 23.459246158599854, lr: 0.0002896849764510989
[645] train loss: 21.017714500427246, train metric: 20.10044813156128, lr: 0.0002825502888299525
[650] train loss: 19.59751558303833, train metric: 19.928531646728516, lr: 0.0002754697925411165
[655] train loss: 14.554710149765015, train metric: 18.248526573181152, lr: 0.00026844526291824877
[660] train loss: 8.47577178478241, train metric: 19.013469696044922, lr: 0.0002614784170873463
[665] train loss: 4.99938702583313, train metric: 9.62098240852356, lr: 0.0002545710594858974
[670] train loss: 38.35053539276123, train metric: 32.28974533081055, lr: 0.00024772481992840767
[675] train loss: 22.574119091033936, train metric: 52.675490379333496, lr: 0.00024094148830045015
[680] train loss: 2.4348281919956207, train metric: 34.30920124053955, lr: 0.00023422270896844566
[685] train loss: 5.439193606376648, train metric: 16.576190948486328, lr: 0.00022757015540264547
[690] train loss: 21.473491191864014, train metric: 19.399078369140625, lr: 0.00022098551562521607
[695] train loss: 17.065211296081543, train metric: 18.626526355743408, lr: 0.00021447039034683257
[700] train loss: 5.799856424331665, train metric: 25.39294719696045, lr: 0.00020802643848583102
[705] train loss: 4.135862350463867, train metric: 28.88546657562256, lr: 0.00020165526075288653
[710] train loss: 34.89825105667114, train metric: 23.483896732330322, lr: 0.00019535842875484377
[715] train loss: 45.84857654571533, train metric: 28.842237949371338, lr: 0.0001891375140985474
[720] train loss: 9.400726318359375, train metric: 14.774829864501953, lr: 0.00018299407383892685
[725] train loss: 3.390699625015259, train metric: 10.01750373840332, lr: 0.0001769296359270811
[730] train loss: 4.120306670665741, train metric: 14.544233322143555, lr: 0.00017094572831410915
[735] train loss: 2.093430757522583, train metric: 15.578536033630371, lr: 0.00016504382074344903
[740] train loss: 16.023229837417603, train metric: 18.176167964935303, lr: 0.00015922538295853883
[745] train loss: 10.009409070014954, train metric: 23.82289695739746, lr: 0.0001534918847028166
[750] train loss: 4.864754319190979, train metric: 15.59912109375, lr: 0.0001478447375120595
[755] train loss: 9.665632963180542, train metric: 23.463850021362305, lr: 0.0001422853529220447
[760] train loss: 3.6171849966049194, train metric: 12.537403106689453, lr: 0.00013681512791663408
[765] train loss: 10.181565761566162, train metric: 14.181215763092041, lr: 0.00013143540127202868
[770] train loss: 5.77065908908844, train metric: 10.993262529373169, lr: 0.00012614754086825997
[775] train loss: 2.6127843856811523, train metric: 14.350982666015625, lr: 0.00012095284910174087
[780] train loss: 1.156878501176834, train metric: 6.52185595035553, lr: 0.00011585262109292671
[785] train loss: 25.139923095703125, train metric: 22.176323890686035, lr: 0.0001108481374103576
[790] train loss: 3.867454946041107, train metric: 14.618386268615723, lr: 0.00010594063496682793
[795] train loss: 1.8083370923995972, train metric: 25.909900665283203, lr: 0.0001011313361232169
[800] train loss: 2.3352062702178955, train metric: 35.46425437927246, lr: 9.999999747378752e-05
[805] train loss: 15.995360374450684, train metric: 28.71763801574707, lr: 9.999999747378752e-05
[810] train loss: 35.186964988708496, train metric: 24.328158855438232, lr: 9.999999747378752e-05
[815] train loss: 13.038055062294006, train metric: 41.48709058761597, lr: 9.999999747378752e-05
[820] train loss: 3.593654453754425, train metric: 26.45610523223877, lr: 9.999999747378752e-05
[825] train loss: 6.5186649560928345, train metric: 23.097026824951172, lr: 9.999999747378752e-05
[830] train loss: 9.74294137954712, train metric: 13.114931344985962, lr: 9.999999747378752e-05
[835] train loss: 9.393120050430298, train metric: 12.871333837509155, lr: 9.999999747378752e-05
[840] train loss: 8.83010721206665, train metric: 16.865297317504883, lr: 9.999999747378752e-05
[845] train loss: 1.251644253730774, train metric: 17.590516090393066, lr: 9.999999747378752e-05
[850] train loss: 1.083905667066574, train metric: 17.25469398498535, lr: 9.999999747378752e-05
[855] train loss: 1.6717898845672607, train metric: 7.379651188850403, lr: 9.999999747378752e-05
[860] train loss: 3.812428116798401, train metric: 9.198572158813477, lr: 9.999999747378752e-05
[865] train loss: 19.702703952789307, train metric: 19.194395542144775, lr: 9.999999747378752e-05
[870] train loss: 17.438040733337402, train metric: 18.493010997772217, lr: 9.999999747378752e-05
[875] train loss: 17.335121154785156, train metric: 17.766362190246582, lr: 9.999999747378752e-05
[880] train loss: 1.7788532972335815, train metric: 15.68920612335205, lr: 9.999999747378752e-05
[885] train loss: 7.531710505485535, train metric: 20.688081741333008, lr: 9.999999747378752e-05
[890] train loss: 42.34078645706177, train metric: 37.56599044799805, lr: 9.999999747378752e-05
[895] train loss: 7.431371331214905, train metric: 10.860036849975586, lr: 9.999999747378752e-05
[900] train loss: 5.519688725471497, train metric: 21.490636825561523, lr: 9.999999747378752e-05
[905] train loss: 3.3612247109413147, train metric: 19.00522804260254, lr: 9.999999747378752e-05
[910] train loss: 11.770565032958984, train metric: 15.080850601196289, lr: 9.999999747378752e-05
[915] train loss: 19.778205394744873, train metric: 18.63769245147705, lr: 9.999999747378752e-05
[920] train loss: 20.87360429763794, train metric: 20.314724445343018, lr: 9.999999747378752e-05
[925] train loss: 1.0125142335891724, train metric: 8.488926887512207, lr: 9.999999747378752e-05
[930] train loss: 28.498642921447754, train metric: 24.80270481109619, lr: 9.999999747378752e-05
[935] train loss: 30.145398139953613, train metric: 21.438549518585205, lr: 9.999999747378752e-05
[940] train loss: 32.81411361694336, train metric: 24.56463384628296, lr: 9.999999747378752e-05
[945] train loss: 3.3489726781845093, train metric: 11.904770851135254, lr: 9.999999747378752e-05
[950] train loss: 5.520325064659119, train metric: 16.7723331451416, lr: 9.999999747378752e-05
[955] train loss: 2.3563170433044434, train metric: 11.326986312866211, lr: 9.999999747378752e-05
[960] train loss: 15.166050672531128, train metric: 31.778146743774414, lr: 9.999999747378752e-05
[965] train loss: 7.221261739730835, train metric: 11.183898448944092, lr: 9.999999747378752e-05
[970] train loss: 14.993146181106567, train metric: 29.39911460876465, lr: 9.999999747378752e-05
[975] train loss: 6.463994145393372, train metric: 19.198598861694336, lr: 9.999999747378752e-05
[980] train loss: 3.0648974776268005, train metric: 11.346296310424805, lr: 9.999999747378752e-05
[985] train loss: 10.09221625328064, train metric: 18.311189651489258, lr: 9.999999747378752e-05
[990] train loss: 8.56883454322815, train metric: 14.061480045318604, lr: 9.999999747378752e-05
[995] train loss: 0.9685205668210983, train metric: 8.62117862701416, lr: 9.999999747378752e-05
[1000] train loss: 1.5727274119853973, train metric: 7.621103644371033, lr: 9.999999747378752e-05
[1005] train loss: 5.5089263916015625, train metric: 10.155813932418823, lr: 9.999999747378752e-05
[1010] train loss: 6.119696855545044, train metric: 17.712417602539062, lr: 9.999999747378752e-05
[1015] train loss: 1.6989289224147797, train metric: 15.640410423278809, lr: 9.999999747378752e-05
[1020] train loss: 2.4657119512557983, train metric: 33.238529205322266, lr: 9.999999747378752e-05
[1025] train loss: 13.095475912094116, train metric: 31.804625511169434, lr: 9.999999747378752e-05
[1030] train loss: 40.84546613693237, train metric: 30.25370979309082, lr: 9.999999747378752e-05
[1035] train loss: 9.375904321670532, train metric: 13.109748363494873, lr: 9.999999747378752e-05
[1040] train loss: 4.5045822858810425, train metric: 36.36889171600342, lr: 9.999999747378752e-05
[1045] train loss: 9.723838806152344, train metric: 24.485532760620117, lr: 9.999999747378752e-05
[1050] train loss: 8.037983417510986, train metric: 11.95175576210022, lr: 9.999999747378752e-05
[1055] train loss: 8.073400139808655, train metric: 12.003724813461304, lr: 9.999999747378752e-05
[1060] train loss: 9.24356460571289, train metric: 14.81471061706543, lr: 9.999999747378752e-05
[1065] train loss: 1.9926494359970093, train metric: 17.794830322265625, lr: 9.999999747378752e-05
[1070] train loss: 1.116297870874405, train metric: 14.89845085144043, lr: 9.999999747378752e-05
[1075] train loss: 1.5782066583633423, train metric: 7.229468822479248, lr: 9.999999747378752e-05
[1080] train loss: 1.2141550779342651, train metric: 7.332758784294128, lr: 9.999999747378752e-05
[1085] train loss: 15.86660099029541, train metric: 17.71325922012329, lr: 9.999999747378752e-05
[1090] train loss: 18.311396598815918, train metric: 18.626101970672607, lr: 9.999999747378752e-05
[1095] train loss: 18.428512573242188, train metric: 18.64281702041626, lr: 9.999999747378752e-05
[1100] train loss: 9.999834060668945, train metric: 14.244659423828125, lr: 9.999999747378752e-05
[1105] train loss: 3.8812054991722107, train metric: 12.429048538208008, lr: 9.999999747378752e-05
[1110] train loss: 14.871794939041138, train metric: 16.912137985229492, lr: 9.999999747378752e-05
[1115] train loss: 20.1328706741333, train metric: 18.522074699401855, lr: 9.999999747378752e-05
[1120] train loss: 3.0391339659690857, train metric: 15.373732566833496, lr: 9.999999747378752e-05
[1125] train loss: 3.254923105239868, train metric: 18.343957901000977, lr: 9.999999747378752e-05
[1130] train loss: 3.974315881729126, train metric: 10.826566457748413, lr: 9.999999747378752e-05
[1135] train loss: 21.752111434936523, train metric: 20.12642765045166, lr: 9.999999747378752e-05
[1140] train loss: 19.465913772583008, train metric: 19.881147861480713, lr: 9.999999747378752e-05
[1145] train loss: 1.6694818437099457, train metric: 8.474688410758972, lr: 9.999999747378752e-05
[1150] train loss: 2.5469289124011993, train metric: 9.041461110115051, lr: 9.999999747378752e-05
[1155] train loss: 39.667946338653564, train metric: 26.804203987121582, lr: 9.999999747378752e-05
[1160] train loss: 32.60522127151489, train metric: 23.141550540924072, lr: 9.999999747378752e-05
[1165] train loss: 3.120568573474884, train metric: 18.622414588928223, lr: 9.999999747378752e-05
[1170] train loss: 6.668979644775391, train metric: 18.128124237060547, lr: 9.999999747378752e-05
[1175] train loss: 1.2629622519016266, train metric: 8.63537311553955, lr: 9.999999747378752e-05
[1180] train loss: 7.132242321968079, train metric: 21.371326446533203, lr: 9.999999747378752e-05
[1185] train loss: 39.696452140808105, train metric: 30.301316261291504, lr: 9.999999747378752e-05
[1190] train loss: 3.663776993751526, train metric: 12.564815521240234, lr: 9.999999747378752e-05
[1195] train loss: 9.737413883209229, train metric: 24.32176399230957, lr: 9.999999747378752e-05
[1200] train loss: 0.8122928291559219, train metric: 6.997068762779236, lr: 9.999999747378752e-05
[1205] train loss: 5.351263642311096, train metric: 16.003644943237305, lr: 9.999999747378752e-05
[1210] train loss: 9.985273838043213, train metric: 14.568111896514893, lr: 9.999999747378752e-05
[1215] train loss: 2.1699676513671875, train metric: 9.130073547363281, lr: 9.999999747378752e-05
[1220] train loss: 1.0050362795591354, train metric: 11.291723251342773, lr: 9.999999747378752e-05
[1225] train loss: 1.035600557923317, train metric: 6.834773421287537, lr: 9.999999747378752e-05
[1230] train loss: 21.413954734802246, train metric: 21.907098293304443, lr: 9.999999747378752e-05
[1235] train loss: 2.3123472332954407, train metric: 12.512019157409668, lr: 9.999999747378752e-05
[1240] train loss: 1.523640215396881, train metric: 24.242863655090332, lr: 9.999999747378752e-05
[1245] train loss: 3.6376516222953796, train metric: 27.777414321899414, lr: 9.999999747378752e-05
[1250] train loss: 17.795574188232422, train metric: 17.885392665863037, lr: 9.999999747378752e-05
[1255] train loss: 19.30143165588379, train metric: 18.605087280273438, lr: 9.999999747378752e-05
