[5] train loss: 5.827322043478489, train metric: 19.298811048269272, lr: 0.0010000000474974513
[10] train loss: 37.50794592499733, train metric: 22.478154838085175, lr: 0.000999937648884952
[15] train loss: 24.77516060322523, train metric: 24.453787446022034, lr: 0.0009997508022934198
[20] train loss: 11.13463643193245, train metric: 15.061609923839569, lr: 0.0009994393913075328
[25] train loss: 20.644297800958157, train metric: 16.777653872966766, lr: 0.000999003415927291
[30] train loss: 19.92570661008358, train metric: 27.000977754592896, lr: 0.0009984431089833379
[35] train loss: 33.36940950900316, train metric: 31.374654233455658, lr: 0.0009977585868909955
[40] train loss: 12.799414053559303, train metric: 36.75468289852142, lr: 0.0009969500824809074
[45] train loss: 107.22191256284714, train metric: 32.35677444934845, lr: 0.0009960177121683955
[50] train loss: 13.11123513430357, train metric: 44.089255571365356, lr: 0.0009949617087841034
[55] train loss: 11.982558578252792, train metric: 41.54656085371971, lr: 0.0009937823051586747
[60] train loss: 26.86110793799162, train metric: 21.51895120739937, lr: 0.000992479850538075
[65] train loss: 47.83717876672745, train metric: 29.579492330551147, lr: 0.0009910546941682696
[70] train loss: 10.277145504951477, train metric: 35.230823278427124, lr: 0.0009895070688799024
[75] train loss: 29.9456075578928, train metric: 26.54310667514801, lr: 0.0009878375567495823
[80] train loss: 62.91710764169693, train metric: 21.777683973312378, lr: 0.000986046390607953
[85] train loss: 21.63777267932892, train metric: 26.2484347820282, lr: 0.0009841341525316238
[90] train loss: 14.988931328058243, train metric: 29.053200602531433, lr: 0.00098210119176656
[95] train loss: 38.968439280986786, train metric: 26.414100170135498, lr: 0.0009799482068046927
[100] train loss: 48.42962555587292, train metric: 31.441792249679565, lr: 0.0009776754304766655
[105] train loss: 42.41165933012962, train metric: 23.78871387243271, lr: 0.000975283735897392
[110] train loss: 40.7603869587183, train metric: 16.878379076719284, lr: 0.0009727735887281597
[115] train loss: 35.434680581092834, train metric: 18.53997939825058, lr: 0.0009701455710455775
[120] train loss: 27.416134729981422, train metric: 20.762726604938507, lr: 0.0009674003813415766
[125] train loss: 16.731961980462074, train metric: 15.898349642753601, lr: 0.0009645387181080878
[130] train loss: 34.00209130346775, train metric: 34.51891702413559, lr: 0.0009615612798370421
[135] train loss: 9.282552644610405, train metric: 25.195821285247803, lr: 0.0009584688232280314
[140] train loss: 72.83838585019112, train metric: 27.045847475528717, lr: 0.0009552621049806476
[145] train loss: 223.40822106599808, train metric: 41.719038009643555, lr: 0.0009519418817944825
[150] train loss: 6.560092352330685, train metric: 29.905772864818573, lr: 0.0009485090849921107
[155] train loss: 134.3384709507227, train metric: 42.17052799463272, lr: 0.0009449644712731242
[160] train loss: 6.992936491966248, train metric: 29.856783092021942, lr: 0.0009413089719600976
[165] train loss: 34.92339859157801, train metric: 30.287652671337128, lr: 0.0009375435183756053
[170] train loss: 24.210453435778618, train metric: 27.013220012187958, lr: 0.0009336689836345613
[175] train loss: 9.298185124993324, train metric: 23.45807582139969, lr: 0.0009296864154748619
[180] train loss: 34.827373676002026, train metric: 31.394968509674072, lr: 0.0009255966870114207
[185] train loss: 30.87605132162571, train metric: 24.038734138011932, lr: 0.0009214009623974562
[190] train loss: 11.162338800728321, train metric: 25.413916289806366, lr: 0.0009171001729555428
[195] train loss: 41.52223088592291, train metric: 22.447842717170715, lr: 0.000912695424631238
[200] train loss: 45.553347796201706, train metric: 23.482550114393234, lr: 0.00090818788157776
[205] train loss: 13.08619900047779, train metric: 41.99757045507431, lr: 0.0009035785333253443
[210] train loss: 22.21868083626032, train metric: 31.328283548355103, lr: 0.0008988686604425311
[215] train loss: 26.66458074748516, train metric: 30.85223138332367, lr: 0.0008940593688748777
[220] train loss: 43.48789124190807, train metric: 31.718161284923553, lr: 0.0008891518809832633
[225] train loss: 9.1025510430336, train metric: 37.992413848638535, lr: 0.0008841473609209061
[230] train loss: 17.329125359654427, train metric: 20.030162811279297, lr: 0.0008790471474640071
[235] train loss: 37.23178616166115, train metric: 21.39793911576271, lr: 0.0008738524629734457
[0] train loss: 6833053.617036057, train metric: 13126.231211242675, lr: 0.0009949617087841034
[0] train loss: 241322.5, train metric: 1354.8934326171875, lr: 0.0009949617087841034
[0] train loss: 35461364.0, train metric: 7884.634765625, lr: 0.0009949617087841034
[0] train loss: 239539.921875, train metric: 779.670654296875, lr: 0.0009949617087841034
[0] train loss: 614753344.0, train metric: 27360.509765625, lr: 0.0009949617087841034
[0] train loss: 12253489.0, train metric: 6768.8076171875, lr: 0.0009949617087841034
[1] train loss: 97076.5625, train metric: 1456.1544189453125, lr: 0.0009776754304766655
[0] train loss: 310419767951360.0, train metric: 38014536.0, lr: 0.00096276612021029
[1] train loss: 535.0977783203125, train metric: 168.00115966796875, lr: 0.0008510327897965908
[2] train loss: 197.08612060546875, train metric: 116.15437316894531, lr: 0.0006827404722571373
[3] train loss: 150.0726318359375, train metric: 98.36346435546875, lr: 0.00048500468255952
[4] train loss: 111.6917724609375, train metric: 67.13912963867188, lr: 0.0002896849764510989
[5] train loss: 164.98150634765625, train metric: 102.37415313720703, lr: 0.00012825157318729907
[0] train loss: 987600453632.0, train metric: 2739076.0, lr: 0.00096276612021029
[1] train loss: 241.95693969726562, train metric: 152.48155212402344, lr: 0.0008510327897965908
[2] train loss: 104.279541015625, train metric: 71.12077331542969, lr: 0.0006827404722571373
[3] train loss: 89.49620056152344, train metric: 54.68601989746094, lr: 0.00048500468255952
[4] train loss: 70.80645751953125, train metric: 42.15190124511719, lr: 0.0002896849764510989
[5] train loss: 63.51316833496094, train metric: 47.874595642089844, lr: 0.00012825157318729907
[6] train loss: 148.60760498046875, train metric: 78.58516693115234, lr: 9.999999747378752e-05
[7] train loss: 79.98214721679688, train metric: 43.36308288574219, lr: 0.0009991005063056946
[8] train loss: 127.68916320800781, train metric: 72.92587280273438, lr: 0.0009471045923419297
[9] train loss: 184.83792114257812, train metric: 88.28639221191406, lr: 0.0008230703533627093
[10] train loss: 45.06443405151367, train metric: 44.12432861328125, lr: 0.0006469824584200978
[11] train loss: 137.3675079345703, train metric: 62.34891891479492, lr: 0.00044721245649270713
[12] train loss: 56.16985321044922, train metric: 44.61443328857422, lr: 0.0002559476706665009
[13] train loss: 53.20270538330078, train metric: 40.855133056640625, lr: 0.00010400506289443001
[14] train loss: 48.475685119628906, train metric: 36.85120391845703, lr: 9.999999747378752e-05
[15] train loss: 32.3458251953125, train metric: 34.60039520263672, lr: 0.0009953988483175635
[16] train loss: 46.57887649536133, train metric: 45.77602005004883, lr: 0.0009288769797421992
[0] train loss: nan, train metric: nan, lr: 0.00096276612021029
[0] train loss: 533559022452736.0, train metric: 30144004.0, lr: 0.0009913494577631354
[0] train loss: 9316.4345703125, train metric: 327.8740234375, lr: 0.00096276612021029
[1] train loss: 344.27276611328125, train metric: 162.6826934814453, lr: 0.0008510327897965908
[2] train loss: 417.1195373535156, train metric: 141.43624877929688, lr: 0.0006827404722571373
[3] train loss: 212.428955078125, train metric: 116.60992431640625, lr: 0.00048500468255952
[4] train loss: 149.0785675048828, train metric: 87.11189270019531, lr: 0.0002896849764510989
[5] train loss: 259.998046875, train metric: 113.34952545166016, lr: 0.00012825157318729907
[6] train loss: 267.5498962402344, train metric: 134.92959594726562, lr: 9.999999747378752e-05
[7] train loss: 181.79617309570312, train metric: 95.56214904785156, lr: 0.0009991005063056946
[8] train loss: 299.73223876953125, train metric: 141.86077880859375, lr: 0.0009471045923419297
[9] train loss: 380.3538513183594, train metric: 112.73429870605469, lr: 0.0008230703533627093
[10] train loss: 191.63807678222656, train metric: 78.2537841796875, lr: 0.0006469824584200978
[11] train loss: 384.28240966796875, train metric: 142.2404022216797, lr: 0.00044721245649270713
[12] train loss: 321.81768798828125, train metric: 143.36119079589844, lr: 0.0002559476706665009
[13] train loss: 242.52276611328125, train metric: 108.0171890258789, lr: 0.00010400506289443001
[14] train loss: 232.87899780273438, train metric: 111.31364440917969, lr: 9.999999747378752e-05
[15] train loss: 179.82894897460938, train metric: 101.5040283203125, lr: 0.0009953988483175635
[16] train loss: 266.77825927734375, train metric: 125.16899871826172, lr: 0.0009288769797421992
[17] train loss: 166.97122192382812, train metric: 93.24765014648438, lr: 0.0007932536536827683
[18] train loss: 209.5859375, train metric: 104.9936294555664, lr: 0.0006103807827457786
[19] train loss: 292.2377014160156, train metric: 150.00035095214844, lr: 0.0004097231721971184
[20] train loss: 199.2758331298828, train metric: 95.09625244140625, lr: 0.0002236111176898703
[21] train loss: 232.3019256591797, train metric: 132.8987579345703, lr: 9.999999747378752e-05
[22] train loss: 244.7681884765625, train metric: 110.34135437011719, lr: 9.999999747378752e-05
[23] train loss: 261.7647705078125, train metric: 101.87411499023438, lr: 0.0009888538625091314
[24] train loss: 270.31787109375, train metric: 127.7552490234375, lr: 0.00090818788157776
[25] train loss: 387.5590515136719, train metric: 147.49185180664062, lr: 0.0007617538794875145
[26] train loss: 228.38897705078125, train metric: 121.37728881835938, lr: 0.000573145633097738
[27] train loss: 250.06349182128906, train metric: 108.51663208007812, lr: 0.0003727520233951509
[28] train loss: 204.82122802734375, train metric: 97.1974868774414, lr: 0.0001928608544403687
[29] train loss: 148.3687744140625, train metric: 96.09786224365234, lr: 9.999999747378752e-05
[30] train loss: 226.41702270507812, train metric: 128.49685668945312, lr: 9.999999747378752e-05
[31] train loss: 215.79855346679688, train metric: 122.88676452636719, lr: 0.0009795031510293484
[32] train loss: 326.4179992675781, train metric: 139.65403747558594, lr: 0.0008851559832692146
[33] train loss: 263.188720703125, train metric: 104.80563354492188, lr: 0.000728751765564084
[0] train loss: 215.3929443359375, train metric: 82.6767578125, lr: 0.00096276612021029
[0] train loss: 2578.446044921875, train metric: 83.72673034667969, lr: 0.00096276612021029
[0] train loss: 3801.18701171875, train metric: 115.74539947509766, lr: 0.00096276612021029
[0] train loss: 5608.5400390625, train metric: 143.7079315185547, lr: 0.00096276612021029
[1] train loss: 19757.46875, train metric: 202.23309326171875, lr: 0.0008510327897965908
[2] train loss: 13177.671875, train metric: 177.930419921875, lr: 0.0006827404722571373
[3] train loss: 1127.9315185546875, train metric: 140.7557373046875, lr: 0.00048500468255952
[4] train loss: 1487.87451171875, train metric: 100.7864990234375, lr: 0.0002896849764510989
[5] train loss: 2270.94482421875, train metric: 152.2640380859375, lr: 0.00012825157318729907
[6] train loss: 14094.890625, train metric: 179.59732055664062, lr: 9.999999747378752e-05
[7] train loss: 1877.4620361328125, train metric: 133.2800750732422, lr: 0.0009991005063056946
[8] train loss: 20111.046875, train metric: 186.5418701171875, lr: 0.0009471045923419297
[9] train loss: 11320.78125, train metric: 128.92555236816406, lr: 0.0008230703533627093
[10] train loss: 1084.4661865234375, train metric: 69.26760864257812, lr: 0.0006469824584200978
[11] train loss: 15395.787109375, train metric: 173.2589874267578, lr: 0.00044721245649270713
[12] train loss: 12481.375, train metric: 188.376953125, lr: 0.0002559476706665009
[13] train loss: 2117.418212890625, train metric: 122.72919464111328, lr: 0.00010400506289443001
[14] train loss: 979.8682861328125, train metric: 120.195068359375, lr: 9.999999747378752e-05
[15] train loss: 1175.118896484375, train metric: 106.43638610839844, lr: 0.0009953988483175635
[16] train loss: 1670.897705078125, train metric: 160.8753662109375, lr: 0.0009288769797421992
[17] train loss: 1164.51171875, train metric: 108.10114288330078, lr: 0.0007932536536827683
[18] train loss: 11252.84765625, train metric: 123.98918914794922, lr: 0.0006103807827457786
[19] train loss: 11628.044921875, train metric: 175.0076904296875, lr: 0.0004097231721971184
[20] train loss: 2150.3994140625, train metric: 119.70768737792969, lr: 0.0002236111176898703
[21] train loss: 2529.96630859375, train metric: 155.7174530029297, lr: 9.999999747378752e-05
[22] train loss: 1962.1390380859375, train metric: 140.2693634033203, lr: 9.999999747378752e-05
[23] train loss: 964.3178100585938, train metric: 118.60186767578125, lr: 0.0009888538625091314
[24] train loss: 16195.8408203125, train metric: 164.01144409179688, lr: 0.00090818788157776
[25] train loss: 13825.095703125, train metric: 157.5517578125, lr: 0.0007617538794875145
[26] train loss: 1441.3515625, train metric: 119.71729278564453, lr: 0.000573145633097738
[27] train loss: 2045.009521484375, train metric: 109.23771667480469, lr: 0.0003727520233951509
[28] train loss: 12937.4833984375, train metric: 117.85612487792969, lr: 0.0001928608544403687
[29] train loss: 10838.884765625, train metric: 126.13470458984375, lr: 9.999999747378752e-05
[30] train loss: 2722.28564453125, train metric: 151.98878479003906, lr: 9.999999747378752e-05
[31] train loss: 12287.18359375, train metric: 146.12464904785156, lr: 0.0009795031510293484
[32] train loss: 10329.837890625, train metric: 163.71566772460938, lr: 0.0008851559832692146
[33] train loss: 4037.949951171875, train metric: 109.74244689941406, lr: 0.000728751765564084
[34] train loss: 1582.949462890625, train metric: 98.4555892944336, lr: 0.0005354906315915287
[35] train loss: 2109.29638671875, train metric: 99.62367248535156, lr: 0.00033651123521849513
[36] train loss: 10939.44140625, train metric: 164.05809020996094, lr: 0.00016387341020163149
[37] train loss: 8791.94921875, train metric: 122.99308776855469, lr: 9.999999747378752e-05
[38] train loss: 4834.7626953125, train metric: 165.44943237304688, lr: 9.999999747378752e-05
[39] train loss: 18835.8203125, train metric: 193.77755737304688, lr: 0.0009674003813415766
[40] train loss: 3859.40673828125, train metric: 110.99945068359375, lr: 0.0008599135326221585
[41] train loss: 1179.6572265625, train metric: 113.34475708007812, lr: 0.0006944367196410894
[42] train loss: 10647.240234375, train metric: 157.58018493652344, lr: 0.0004976319614797831
[43] train loss: 2341.39013671875, train metric: 123.08865356445312, lr: 0.00030120875453576446
[44] train loss: 1785.84912109375, train metric: 142.2840118408203, lr: 0.00013681512791663408
[45] train loss: 8031.521484375, train metric: 143.57077026367188, lr: 9.999999747378752e-05
[46] train loss: 8467.201171875, train metric: 146.26136779785156, lr: 0.0009996984153985977
[47] train loss: 2335.84912109375, train metric: 113.04031372070312, lr: 0.0009526149951852858
[48] train loss: 1099.60009765625, train metric: 112.320556640625, lr: 0.0008326053502969444
[49] train loss: 2930.769775390625, train metric: 150.78353881835938, lr: 0.0006590057746507227
[50] train loss: 12047.212890625, train metric: 132.7223358154297, lr: 0.00045978688285686076
[51] train loss: 9906.4580078125, train metric: 122.59768676757812, lr: 0.0002670472313184291
[52] train loss: 9766.490234375, train metric: 131.75779724121094, lr: 0.00011184131290065125
[53] train loss: 1582.1983642578125, train metric: 117.62171173095703, lr: 9.999999747378752e-05
[54] train loss: 1926.901611328125, train metric: 108.56061553955078, lr: 0.0009969500824809074
[55] train loss: 23556.162109375, train metric: 134.42532348632812, lr: 0.000935231801122427
[56] train loss: 9660.359375, train metric: 145.625244140625, lr: 0.0008033882477320731
[57] train loss: 10448.53515625, train metric: 122.0776596069336, lr: 0.0006226621917448938
[58] train loss: 751.6341552734375, train metric: 86.70608520507812, lr: 0.00042217259760946035
[59] train loss: 9915.052734375, train metric: 119.89457702636719, lr: 0.00023422270896844566
[60] train loss: 1132.048095703125, train metric: 95.75823974609375, lr: 9.999999747378752e-05
[61] train loss: 1358.9583740234375, train metric: 114.47114562988281, lr: 9.999999747378752e-05
[62] train loss: 1192.0009765625, train metric: 144.22714233398438, lr: 0.0009913494577631354
[63] train loss: 903.3802490234375, train metric: 129.61570739746094, lr: 0.0009153506834991276
[64] train loss: 20597.701171875, train metric: 200.20230102539062, lr: 0.0007724298629909754
[65] train loss: 1273.15966796875, train metric: 134.77560424804688, lr: 0.0005856145871803164
[66] train loss: 1307.3028564453125, train metric: 135.6593475341797, lr: 0.0003850049979519099
[67] train loss: 908.5799560546875, train metric: 122.82878875732422, lr: 0.00020292359113227576
[68] train loss: 12732.375, train metric: 137.74267578125, lr: 9.999999747378752e-05
[69] train loss: 20561.712890625, train metric: 189.35044860839844, lr: 9.999999747378752e-05
[70] train loss: 1706.5009765625, train metric: 164.1533660888672, lr: 0.0009829289047047496
[71] train loss: 946.3782958984375, train metric: 130.98165893554688, lr: 0.0008930856711231172
[72] train loss: 676.9739379882812, train metric: 134.95419311523438, lr: 0.0007399078458547592
[73] train loss: 1346.865234375, train metric: 118.99113464355469, lr: 0.0005480756517499685
[74] train loss: 894.9769287109375, train metric: 136.6943359375, lr: 0.00034849741496145725
[75] train loss: 9759.2568359375, train metric: 159.86871337890625, lr: 0.00017332953575532883
[76] train loss: 1626.6429443359375, train metric: 119.21061706542969, lr: 9.999999747378752e-05
[77] train loss: 10051.6484375, train metric: 139.83250427246094, lr: 9.999999747378752e-05
[78] train loss: 2083.535888671875, train metric: 101.1479263305664, lr: 0.0009717364446260035
[79] train loss: 11929.0732421875, train metric: 182.04244995117188, lr: 0.0008685645880177617
[80] train loss: 1220.113525390625, train metric: 132.76492309570312, lr: 0.000706008926499635
[81] train loss: 12275.880859375, train metric: 168.9962158203125, lr: 0.0005102607537992299
[82] train loss: 2891.8193359375, train metric: 130.627197265625, lr: 0.00031285933800973
[83] train loss: 1017.229736328125, train metric: 113.40367889404297, lr: 0.00014561037824023515
[84] train loss: 1392.599365234375, train metric: 147.47244262695312, lr: 9.999999747378752e-05
[85] train loss: 21784.37890625, train metric: 171.06565856933594, lr: 0.0009999775793403387
[86] train loss: 1092.965576171875, train metric: 86.93109893798828, lr: 0.0009578365716151893
[87] train loss: 1576.7947998046875, train metric: 93.70553588867188, lr: 0.0008419281803071499
[88] train loss: 12697.451171875, train metric: 186.78662109375, lr: 0.0006709276349283755
[89] train loss: 11950.6376953125, train metric: 161.94970703125, lr: 0.0004723869787994772
[90] train loss: 9680.9208984375, train metric: 130.67591857910156, lr: 0.0002782953670248389
[91] train loss: 756.7124633789062, train metric: 112.42323303222656, lr: 0.00011992520740022883
[92] train loss: 8996.927734375, train metric: 154.89007568359375, lr: 9.999999747378752e-05
[93] train loss: 999.0313720703125, train metric: 81.98521423339844, lr: 0.0009981842013075948
[94] train loss: 8345.412109375, train metric: 178.59893798828125, lr: 0.0009413089719600976
[95] train loss: 2123.364501953125, train metric: 127.9847640991211, lr: 0.0008133292431011796
[96] train loss: 901.6604614257812, train metric: 94.55230712890625, lr: 0.0006348653114400804
[97] train loss: 1619.667724609375, train metric: 144.0233917236328, lr: 0.0004346716741565615
[98] train loss: 22023.669921875, train metric: 208.13336181640625, lr: 0.0002450038446113467
[99] train loss: 11719.39453125, train metric: 161.46670532226562, lr: 9.999999747378752e-05
[100] train loss: 1030.9407958984375, train metric: 143.05038452148438, lr: 9.999999747378752e-05
[101] train loss: 973.6431884765625, train metric: 93.1113510131836, lr: 0.0009935316629707813
[102] train loss: 1741.68505859375, train metric: 140.4556884765625, lr: 0.0009222485241480172
[103] train loss: 10850.697265625, train metric: 186.48358154296875, lr: 0.0007829319802112877
[104] train loss: 604.9608154296875, train metric: 112.9071044921875, lr: 0.000598029000684619
[105] train loss: 19152.177734375, train metric: 171.0867919921875, lr: 0.0003973313432652503
[106] train loss: 5926.53125, train metric: 123.30509948730469, lr: 0.0002131758665200323
[107] train loss: 860.326904296875, train metric: 90.57086181640625, lr: 9.999999747378752e-05
[108] train loss: 9562.0595703125, train metric: 174.454345703125, lr: 9.999999747378752e-05
[109] train loss: 13772.544921875, train metric: 201.64324951171875, lr: 0.000986046390607953
[110] train loss: 826.771240234375, train metric: 113.57737731933594, lr: 0.0009007646003738046
[111] train loss: 1162.023193359375, train metric: 131.30633544921875, lr: 0.0007509108982048929
[112] train loss: 1055.5701904296875, train metric: 115.53387451171875, lr: 0.000560629996471107
[113] train loss: 1197.5687255859375, train metric: 143.06509399414062, lr: 0.0003605802485253662
[114] train loss: 1030.7568359375, train metric: 102.5650634765625, lr: 0.00018299407383892685
[115] train loss: 1394.051513671875, train metric: 112.16250610351562, lr: 9.999999747378752e-05
[116] train loss: 11866.2939453125, train metric: 177.26455688476562, lr: 9.999999747378752e-05
[117] train loss: 2107.2958984375, train metric: 104.6898193359375, lr: 0.0009757715743035078
[118] train loss: 10473.36328125, train metric: 171.226806640625, lr: 0.0008769805426709354
[119] train loss: 2328.381591796875, train metric: 148.01136779785156, lr: 0.0007174497004598379
[120] train loss: 322.4961853027344, train metric: 109.80318450927734, lr: 0.0005228830268606544
[121] train loss: 20548.970703125, train metric: 143.4866485595703, lr: 0.0003246293345000595
[122] train loss: 10985.4365234375, train metric: 176.93678283691406, lr: 0.00015463172167073935
[123] train loss: 1041.137451171875, train metric: 122.37226867675781, lr: 9.999999747378752e-05
[124] train loss: 909.65966796875, train metric: 122.946533203125, lr: 9.999999747378752e-05
[125] train loss: 1419.5673828125, train metric: 122.21566772460938, lr: 0.00096276612021029
[126] train loss: 2827.81396484375, train metric: 122.72370147705078, lr: 0.0008510327897965908
[127] train loss: 1331.68896484375, train metric: 150.1373748779297, lr: 0.0006827404722571373
[128] train loss: 9957.1640625, train metric: 126.45150756835938, lr: 0.00048500468255952
[129] train loss: 8389.1552734375, train metric: 170.583984375, lr: 0.0002896849764510989
[130] train loss: 650.5184326171875, train metric: 113.79061889648438, lr: 0.00012825157318729907
[131] train loss: 10943.30078125, train metric: 123.90174102783203, lr: 9.999999747378752e-05
[132] train loss: 680.461669921875, train metric: 107.53258514404297, lr: 0.0009991005063056946
[133] train loss: 10499.8154296875, train metric: 152.85775756835938, lr: 0.0009471045923419297
[134] train loss: 10795.38671875, train metric: 127.32583618164062, lr: 0.0008230703533627093
[135] train loss: 1185.779052734375, train metric: 154.8922882080078, lr: 0.0006469824584200978
[136] train loss: 18649.296875, train metric: 205.37474060058594, lr: 0.00044721245649270713
[137] train loss: 1267.95068359375, train metric: 109.90104675292969, lr: 0.0002559476706665009
[138] train loss: 618.3381958007812, train metric: 128.59564208984375, lr: 0.00010400506289443001
[139] train loss: 10918.2646484375, train metric: 156.058349609375, lr: 9.999999747378752e-05
[140] train loss: 1491.122314453125, train metric: 139.58544921875, lr: 0.0009953988483175635
[141] train loss: 2087.586181640625, train metric: 131.66561889648438, lr: 0.0009288769797421992
[142] train loss: 1292.155029296875, train metric: 148.0160675048828, lr: 0.0007932536536827683
[143] train loss: 727.635009765625, train metric: 125.90789031982422, lr: 0.0006103807827457786
[144] train loss: 1273.3294677734375, train metric: 106.36405944824219, lr: 0.0004097231721971184
[0] train loss: 11956.287109375, train metric: 88.58533477783203, lr: 0.00096276612021029
[1] train loss: 1.1538210416348573e+27, train metric: 27705582026752.0, lr: 0.0008510327897965908
[2] train loss: nan, train metric: nan, lr: 0.0006827404722571373
[3] train loss: nan, train metric: nan, lr: 0.00048500468255952
[4] train loss: nan, train metric: nan, lr: 0.0002896849764510989
[5] train loss: nan, train metric: nan, lr: 0.00012825157318729907
[0] train loss: nan, train metric: 106.3369140625, lr: 0.00096276612021029
[0] train loss: 609.493896484375, train metric: 107.85441589355469, lr: 0.00096276612021029
[1] train loss: 921.9994506835938, train metric: 161.07763671875, lr: 0.0008510327897965908
[2] train loss: 570.091064453125, train metric: 126.52494812011719, lr: 0.0006827404722571373
[3] train loss: 1770.380859375, train metric: 110.39631652832031, lr: 0.00048500468255952
[4] train loss: 924.4244384765625, train metric: 92.58663940429688, lr: 0.0002896849764510989
[5] train loss: 711.2783203125, train metric: 112.223876953125, lr: 0.00012825157318729907
[6] train loss: 1512.5986328125, train metric: 146.92361450195312, lr: 9.999999747378752e-05
[7] train loss: 565.1412963867188, train metric: 97.71495056152344, lr: 0.0009991005063056946
[8] train loss: 575.845703125, train metric: 152.30499267578125, lr: 0.0009471045923419297
[9] train loss: 624.6773071289062, train metric: 102.1199722290039, lr: 0.0008230703533627093
[10] train loss: 361.916259765625, train metric: 74.11367797851562, lr: 0.0006469824584200978
[11] train loss: 493.7043151855469, train metric: 132.26612854003906, lr: 0.00044721245649270713
[12] train loss: 539.2325439453125, train metric: 145.2286834716797, lr: 0.0002559476706665009
[13] train loss: 275.0314025878906, train metric: 93.85943603515625, lr: 0.00010400506289443001
[14] train loss: 763.3526611328125, train metric: 108.78825378417969, lr: 9.999999747378752e-05
[15] train loss: 698.7122802734375, train metric: 121.09025573730469, lr: 0.0009953988483175635
[16] train loss: 790.744140625, train metric: 129.7235107421875, lr: 0.0009288769797421992
[17] train loss: 321.1824951171875, train metric: 83.18086242675781, lr: 0.0007932536536827683
[18] train loss: 872.8951416015625, train metric: 107.65665435791016, lr: 0.0006103807827457786
[19] train loss: 1633.54150390625, train metric: 150.99609375, lr: 0.0004097231721971184
[20] train loss: 389.11767578125, train metric: 84.62627410888672, lr: 0.0002236111176898703
[21] train loss: 683.7025756835938, train metric: 121.66679382324219, lr: 9.999999747378752e-05
[22] train loss: 591.23291015625, train metric: 126.23021697998047, lr: 9.999999747378752e-05
[23] train loss: 569.305908203125, train metric: 104.38154602050781, lr: 0.0009888538625091314
[24] train loss: 751.0565185546875, train metric: 134.410888671875, lr: 0.00090818788157776
[25] train loss: 903.733154296875, train metric: 137.88027954101562, lr: 0.0007617538794875145
[26] train loss: 633.612548828125, train metric: 99.27275848388672, lr: 0.000573145633097738
[27] train loss: 428.4219665527344, train metric: 101.08584594726562, lr: 0.0003727520233951509
[28] train loss: 628.5953979492188, train metric: 101.11064147949219, lr: 0.0001928608544403687
[29] train loss: 285.0658264160156, train metric: 94.8870849609375, lr: 9.999999747378752e-05
[30] train loss: 436.5359802246094, train metric: 137.27099609375, lr: 9.999999747378752e-05
[31] train loss: 528.4855346679688, train metric: 127.36737823486328, lr: 0.0009795031510293484
[32] train loss: 841.5126342773438, train metric: 150.88229370117188, lr: 0.0008851559832692146
[33] train loss: 1109.665771484375, train metric: 104.49490356445312, lr: 0.000728751765564084
[34] train loss: 1535.0252685546875, train metric: 83.2448501586914, lr: 0.0005354906315915287
[35] train loss: 519.8746948242188, train metric: 93.4354476928711, lr: 0.00033651123521849513
[36] train loss: 2780.50732421875, train metric: 139.95758056640625, lr: 0.00016387341020163149
[37] train loss: 1412.4111328125, train metric: 106.70681762695312, lr: 9.999999747378752e-05
[38] train loss: 1043.697998046875, train metric: 136.76927185058594, lr: 9.999999747378752e-05
[39] train loss: 376.42425537109375, train metric: 157.07717895507812, lr: 0.0009674003813415766
[40] train loss: 1277.1214599609375, train metric: 84.01322174072266, lr: 0.0008599135326221585
[0] train loss: 1458.294921875, train metric: 139.37376403808594, lr: 0.00096276612021029
[1] train loss: 843.3384399414062, train metric: 89.392333984375, lr: 0.0008510327897965908
[2] train loss: 1302.4022216796875, train metric: 204.554443359375, lr: 0.0006827404722571373
[3] train loss: 759.560791015625, train metric: 141.56871032714844, lr: 0.00048500468255952
[4] train loss: 719.6641845703125, train metric: 124.29762268066406, lr: 0.0002896849764510989
[5] train loss: 558.7030029296875, train metric: 132.9709014892578, lr: 0.00012825157318729907
[6] train loss: 532.303955078125, train metric: 120.52627563476562, lr: 9.999999747378752e-05
[7] train loss: 698.129150390625, train metric: 99.77029418945312, lr: 0.0009991005063056946
[8] train loss: 885.032958984375, train metric: 67.48401641845703, lr: 0.0009471045923419297
[9] train loss: 582.959716796875, train metric: 89.71174621582031, lr: 0.0008230703533627093
[10] train loss: 766.177001953125, train metric: 106.07037353515625, lr: 0.0006469824584200978
[11] train loss: 809.096435546875, train metric: 111.3557357788086, lr: 0.00044721245649270713
[12] train loss: 310.89080810546875, train metric: 120.09083557128906, lr: 0.0002559476706665009
[13] train loss: 367.3428039550781, train metric: 195.33885192871094, lr: 0.00010400506289443001
[14] train loss: 439.636962890625, train metric: 85.39452362060547, lr: 9.999999747378752e-05
[15] train loss: 494.2032165527344, train metric: 105.954833984375, lr: 0.0009953988483175635
[16] train loss: 346.5750732421875, train metric: 129.96188354492188, lr: 0.0009288769797421992
[17] train loss: 475.2774353027344, train metric: 163.7425079345703, lr: 0.0007932536536827683
[18] train loss: 360.1864013671875, train metric: 83.05357360839844, lr: 0.0006103807827457786
[19] train loss: 826.2279052734375, train metric: 118.62898254394531, lr: 0.0004097231721971184
[20] train loss: 245.44369506835938, train metric: 78.44384765625, lr: 0.0002236111176898703
[21] train loss: 173.213134765625, train metric: 49.07530212402344, lr: 9.999999747378752e-05
[22] train loss: 627.9024658203125, train metric: 120.54055786132812, lr: 9.999999747378752e-05
[23] train loss: 1583.6004638671875, train metric: 141.54823303222656, lr: 0.0009888538625091314
[24] train loss: 233.03660583496094, train metric: 159.99273681640625, lr: 0.00090818788157776
[25] train loss: 928.7191162109375, train metric: 139.09393310546875, lr: 0.0007617538794875145
[26] train loss: 327.7774963378906, train metric: 93.11186981201172, lr: 0.000573145633097738
[27] train loss: 258.7032470703125, train metric: 106.10558319091797, lr: 0.0003727520233951509
[28] train loss: 350.43017578125, train metric: 105.81827545166016, lr: 0.0001928608544403687
[29] train loss: 1346.4375, train metric: 113.08456420898438, lr: 9.999999747378752e-05
[30] train loss: 464.4974365234375, train metric: 72.82723999023438, lr: 9.999999747378752e-05
[31] train loss: 232.8736572265625, train metric: 137.0380859375, lr: 0.0009795031510293484
[32] train loss: 317.3052673339844, train metric: 111.74909973144531, lr: 0.0008851559832692146
[33] train loss: 1280.3333740234375, train metric: 171.64889526367188, lr: 0.000728751765564084
[34] train loss: 383.84033203125, train metric: 79.2214126586914, lr: 0.0005354906315915287
[35] train loss: 585.7860107421875, train metric: 114.3958740234375, lr: 0.00033651123521849513
[36] train loss: 296.08978271484375, train metric: 98.42303466796875, lr: 0.00016387341020163149
[37] train loss: 1439.65966796875, train metric: 90.7083740234375, lr: 9.999999747378752e-05
[38] train loss: 1006.4176635742188, train metric: 144.33706665039062, lr: 9.999999747378752e-05
[39] train loss: 3213.552734375, train metric: 167.4227752685547, lr: 0.0009674003813415766
[40] train loss: 348.20086669921875, train metric: 101.13890075683594, lr: 0.0008599135326221585
[41] train loss: 1289.1461181640625, train metric: 81.15442657470703, lr: 0.0006944367196410894
[42] train loss: 517.9497680664062, train metric: 105.33428955078125, lr: 0.0004976319614797831
[43] train loss: 638.6292114257812, train metric: 160.45571899414062, lr: 0.00030120875453576446
[44] train loss: 873.9466552734375, train metric: 107.6335220336914, lr: 0.00013681512791663408
[45] train loss: 383.0947265625, train metric: 115.70289611816406, lr: 9.999999747378752e-05
[46] train loss: 1375.819580078125, train metric: 103.79963684082031, lr: 0.0009996984153985977
[47] train loss: 648.873291015625, train metric: 104.92060852050781, lr: 0.0009526149951852858
[1] train loss: 2470.1328125, train metric: nan, lr: 0.0007999999797903001
[1] train loss: 856.09228515625, train metric: nan, lr: 0.0009996984153985977
[2] train loss: 659.610595703125, train metric: nan, lr: 0.0009981842013075948
[3] train loss: 489.7607421875, train metric: nan, lr: 0.0009953988483175635
[4] train loss: 507.57330322265625, train metric: nan, lr: 0.0009913494577631354
[5] train loss: 496.76824951171875, train metric: nan, lr: 0.000986046390607953
[6] train loss: 323.50823974609375, train metric: nan, lr: 0.0009795031510293484
[7] train loss: 436.60394287109375, train metric: nan, lr: 0.0009717364446260035
[8] train loss: 1177.781494140625, train metric: nan, lr: 0.00096276612021029
[9] train loss: 698.6101684570312, train metric: nan, lr: 0.0009526149951852858
[10] train loss: 594.72900390625, train metric: nan, lr: 0.0009413089719600976
[11] train loss: 330.8190002441406, train metric: nan, lr: 0.0009288769797421992
[12] train loss: 628.2061767578125, train metric: nan, lr: 0.0009153506834991276
[13] train loss: 302.1744384765625, train metric: nan, lr: 0.0009007646003738046
[14] train loss: 414.1829528808594, train metric: nan, lr: 0.0008851559832692146
[15] train loss: 214.64495849609375, train metric: nan, lr: 0.0008685645880177617
[16] train loss: 258.90966796875, train metric: nan, lr: 0.0008510327897965908
[17] train loss: 284.7532043457031, train metric: nan, lr: 0.0008326053502969444
[18] train loss: 486.11737060546875, train metric: nan, lr: 0.0008133292431011796
[19] train loss: 389.9259033203125, train metric: nan, lr: 0.0007932536536827683
[20] train loss: 1107.417724609375, train metric: nan, lr: 0.0007724298629909754
[21] train loss: 398.70440673828125, train metric: nan, lr: 0.0007509108982048929
[22] train loss: 273.24224853515625, train metric: nan, lr: 0.000728751765564084
[23] train loss: 350.7142028808594, train metric: nan, lr: 0.000706008926499635
[24] train loss: 431.01922607421875, train metric: nan, lr: 0.0006827404722571373
[25] train loss: 738.4190063476562, train metric: nan, lr: 0.0006590057746507227
[26] train loss: 545.730712890625, train metric: nan, lr: 0.0006348653114400804
[27] train loss: 314.92138671875, train metric: nan, lr: 0.0006103807827457786
[28] train loss: 448.8348388671875, train metric: nan, lr: 0.0005856145871803164
[29] train loss: 161.20166015625, train metric: nan, lr: 0.000560629996471107
[30] train loss: 1128.9910888671875, train metric: nan, lr: 0.0005354906315915287
[31] train loss: 699.6245727539062, train metric: nan, lr: 0.0005102607537992299
[32] train loss: 676.1558227539062, train metric: nan, lr: 0.00048500468255952
[33] train loss: 228.53634643554688, train metric: nan, lr: 0.00045978688285686076
[34] train loss: 611.1231689453125, train metric: nan, lr: 0.0004346716741565615
[35] train loss: 1015.1951904296875, train metric: nan, lr: 0.0004097231721971184
[36] train loss: 1511.5970458984375, train metric: nan, lr: 0.0003850049979519099
[37] train loss: 761.776123046875, train metric: nan, lr: 0.0003605802485253662
[38] train loss: 1296.9154052734375, train metric: nan, lr: 0.00033651123521849513
[39] train loss: 708.8717041015625, train metric: nan, lr: 0.00031285933800973
[40] train loss: 1507.85205078125, train metric: nan, lr: 0.0002896849764510989
[41] train loss: 526.8424072265625, train metric: nan, lr: 0.0002670472313184291
[42] train loss: 616.9586181640625, train metric: nan, lr: 0.0002450038446113467
[43] train loss: 563.23828125, train metric: nan, lr: 0.0002236111176898703
[44] train loss: 656.11376953125, train metric: nan, lr: 0.00020292359113227576
[45] train loss: 966.9122924804688, train metric: nan, lr: 0.00018299407383892685
[46] train loss: 264.1784973144531, train metric: nan, lr: 0.00016387341020163149
[47] train loss: 1363.62890625, train metric: nan, lr: 0.00014561037824023515
[48] train loss: 248.72091674804688, train metric: nan, lr: 0.00012825157318729907
[49] train loss: 593.727294921875, train metric: nan, lr: 0.00011184131290065125
[50] train loss: 666.0210571289062, train metric: nan, lr: 9.999999747378752e-05
[51] train loss: 249.25723266601562, train metric: nan, lr: 9.999999747378752e-05
[52] train loss: 1207.0328369140625, train metric: nan, lr: 9.999999747378752e-05
[53] train loss: 344.797607421875, train metric: nan, lr: 9.999999747378752e-05
[54] train loss: 358.71893310546875, train metric: nan, lr: 9.999999747378752e-05
[55] train loss: 670.7227783203125, train metric: nan, lr: 9.999999747378752e-05
[56] train loss: 1601.75537109375, train metric: nan, lr: 9.999999747378752e-05
[57] train loss: 726.8394775390625, train metric: nan, lr: 9.999999747378752e-05
[58] train loss: 1301.178955078125, train metric: nan, lr: 9.999999747378752e-05
[59] train loss: 267.8406982421875, train metric: nan, lr: 9.999999747378752e-05
[60] train loss: 260.00518798828125, train metric: nan, lr: 9.999999747378752e-05
[61] train loss: 376.5662841796875, train metric: nan, lr: 9.999999747378752e-05
[62] train loss: 691.4417724609375, train metric: nan, lr: 9.999999747378752e-05
[63] train loss: 1191.25390625, train metric: nan, lr: 0.0009999775793403387
[64] train loss: 403.3852233886719, train metric: nan, lr: 0.0009991005063056946
[65] train loss: 940.69970703125, train metric: nan, lr: 0.0009969500824809074
[66] train loss: 649.402587890625, train metric: nan, lr: 0.0009935316629707813
[67] train loss: 483.865234375, train metric: nan, lr: 0.0009888538625091314
