[20] train loss: 0.5492189675569534, lr: 9.994393622037023e-05
[40] train loss: 0.4069289080798626, lr: 9.969501115847379e-05
[60] train loss: 0.5163939967751503, lr: 9.924798359861597e-05
[80] train loss: 0.44912954419851303, lr: 9.860464342636988e-05
[100] train loss: 0.5485767722129822, lr: 9.776754450285807e-05
[120] train loss: 0.9278024062514305, lr: 9.67400410445407e-05
[140] train loss: 1.0803794227540493, lr: 9.552620758768171e-05
[160] train loss: 0.862885370850563, lr: 9.413089719600976e-05
[180] train loss: 0.46555186063051224, lr: 9.255966870114207e-05
[200] train loss: 0.4122942164540291, lr: 9.081878670258448e-05
[220] train loss: 0.9625741243362427, lr: 8.891518518794328e-05
[240] train loss: 2.7483167722821236, lr: 8.68564602569677e-05
[260] train loss: 2.180054634809494, lr: 8.46508119138889e-05
[280] train loss: 1.935860350728035, lr: 8.230703679146245e-05
[300] train loss: 0.6285079717636108, lr: 7.983447721926495e-05
[320] train loss: 1.3629784546792507, lr: 7.724298484390602e-05
[340] train loss: 1.7565291821956635, lr: 7.454289880115539e-05
[360] train loss: 0.5160404965281487, lr: 7.174497295636684e-05
[380] train loss: 2.322694957256317, lr: 6.886036862852052e-05
[400] train loss: 0.7844907194375992, lr: 6.590057455468923e-05
[420] train loss: 1.2072424590587616, lr: 6.28774068900384e-05
[440] train loss: 0.6987251974642277, lr: 5.980289643048309e-05
[460] train loss: 0.834721315652132, lr: 5.668931407853961e-05
[480] train loss: 3.2343669533729553, lr: 5.354906534194015e-05
[500] train loss: 18.545557752251625, lr: 5.039466850575991e-05
[520] train loss: 1.3003271520137787, lr: 4.999999873689376e-05
[540] train loss: 0.6829340904951096, lr: 4.999999873689376e-05
[560] train loss: 0.42079736292362213, lr: 4.999999873689376e-05
[580] train loss: 0.8177559226751328, lr: 4.999999873689376e-05
[600] train loss: 0.7739617377519608, lr: 4.999999873689376e-05
[620] train loss: 0.6821819096803665, lr: 4.999999873689376e-05
[640] train loss: 1.5930356606841087, lr: 4.999999873689376e-05
[660] train loss: 1.08564130961895, lr: 4.999999873689376e-05
[680] train loss: 1.8050194904208183, lr: 4.999999873689376e-05
[700] train loss: 0.9342037066817284, lr: 4.999999873689376e-05
[720] train loss: 1.4067260511219501, lr: 4.999999873689376e-05
[740] train loss: 2.825872376561165, lr: 4.999999873689376e-05
[760] train loss: 1.936803974211216, lr: 4.999999873689376e-05
[780] train loss: 2.803852751851082, lr: 4.999999873689376e-05
[800] train loss: 1.7433903068304062, lr: 4.999999873689376e-05
[820] train loss: 0.6995042897760868, lr: 4.999999873689376e-05
[840] train loss: 2.017723187804222, lr: 4.999999873689376e-05
[860] train loss: 1.6404387280344963, lr: 4.999999873689376e-05
[880] train loss: 0.8889789506793022, lr: 4.999999873689376e-05
[900] train loss: 0.9170535132288933, lr: 4.999999873689376e-05
[920] train loss: 0.7259369790554047, lr: 4.999999873689376e-05
[940] train loss: 0.6423470489680767, lr: 4.999999873689376e-05
[960] train loss: 0.5417773462831974, lr: 4.999999873689376e-05
[980] train loss: 0.6080969050526619, lr: 4.999999873689376e-05
[1000] train loss: 0.5369325950741768, lr: 4.999999873689376e-05
[1020] train loss: 0.3184722885489464, lr: 9.994393622037023e-05
[1040] train loss: 15.562149167060852, lr: 9.969501115847379e-05
[1060] train loss: 4.2912521958351135, lr: 9.924798359861597e-05
[1080] train loss: 1.2880880534648895, lr: 9.860464342636988e-05
[1100] train loss: 1.225957214832306, lr: 9.776754450285807e-05
[1120] train loss: 2.476376712322235, lr: 9.67400410445407e-05
[1140] train loss: 4.796938389539719, lr: 9.552620758768171e-05
[1160] train loss: 1.3636909127235413, lr: 9.413089719600976e-05
[1180] train loss: 0.9931836277246475, lr: 9.255966870114207e-05
[1200] train loss: 0.6021975949406624, lr: 9.081878670258448e-05
[1220] train loss: 0.4766106903553009, lr: 8.891518518794328e-05
[1240] train loss: 0.623102456331253, lr: 8.68564602569677e-05
[1260] train loss: 0.5477279126644135, lr: 8.46508119138889e-05
[1280] train loss: 0.8911020159721375, lr: 8.230703679146245e-05
[1300] train loss: 0.7556485384702682, lr: 7.983447721926495e-05
[1320] train loss: 0.7755515202879906, lr: 7.724298484390602e-05
[1340] train loss: 0.5902884751558304, lr: 7.454289880115539e-05
[1360] train loss: 0.9398967921733856, lr: 7.174497295636684e-05
[1380] train loss: 0.9025273695588112, lr: 6.886036862852052e-05
[1400] train loss: 1.3922056034207344, lr: 6.590057455468923e-05
[1420] train loss: 0.858340322971344, lr: 6.28774068900384e-05
[1440] train loss: 1.317242681980133, lr: 5.980289643048309e-05
[1460] train loss: 0.9746209532022476, lr: 5.668931407853961e-05
[1480] train loss: 0.9375776648521423, lr: 5.354906534194015e-05
[1500] train loss: 0.8536715805530548, lr: 5.039466850575991e-05
[1520] train loss: 0.5213806331157684, lr: 4.999999873689376e-05
[1540] train loss: 1.2781786769628525, lr: 4.999999873689376e-05
[1560] train loss: 1.3373836427927017, lr: 4.999999873689376e-05
[1580] train loss: 0.6128414571285248, lr: 4.999999873689376e-05
[1600] train loss: 2.8244195580482483, lr: 4.999999873689376e-05
[1620] train loss: 3.2919534742832184, lr: 4.999999873689376e-05
[1640] train loss: 3.222699895501137, lr: 4.999999873689376e-05
[1660] train loss: 1.5392985045909882, lr: 4.999999873689376e-05
[1680] train loss: 0.7244930416345596, lr: 4.999999873689376e-05
[1700] train loss: 0.7874246686697006, lr: 4.999999873689376e-05
[1720] train loss: 1.9359170496463776, lr: 4.999999873689376e-05
[1740] train loss: 0.8246667310595512, lr: 4.999999873689376e-05
[1760] train loss: 0.3846803307533264, lr: 4.999999873689376e-05
[1780] train loss: 0.5284425243735313, lr: 4.999999873689376e-05
[1800] train loss: 0.6596468612551689, lr: 4.999999873689376e-05
[1820] train loss: 0.5609360933303833, lr: 4.999999873689376e-05
[1840] train loss: 0.513832300901413, lr: 4.999999873689376e-05
[1860] train loss: 0.6135331690311432, lr: 4.999999873689376e-05
[1880] train loss: 0.3888190910220146, lr: 4.999999873689376e-05
[1900] train loss: 0.7305049449205399, lr: 4.999999873689376e-05
[1920] train loss: 0.41156305372714996, lr: 4.999999873689376e-05
[1940] train loss: 0.43835315853357315, lr: 4.999999873689376e-05
[1960] train loss: 1.0258539393544197, lr: 4.999999873689376e-05
[1980] train loss: 0.6753608509898186, lr: 4.999999873689376e-05
[2000] train loss: 1.468699797987938, lr: 4.999999873689376e-05
[2020] train loss: 1.74247145652771, lr: 9.994393622037023e-05
[2040] train loss: 1.6642644703388214, lr: 9.969501115847379e-05
[2060] train loss: 1.0244682431221008, lr: 9.924798359861597e-05
[2080] train loss: 0.587368056178093, lr: 9.860464342636988e-05
[2100] train loss: 0.49747686460614204, lr: 9.776754450285807e-05
[2120] train loss: 0.35127586871385574, lr: 9.67400410445407e-05
[2140] train loss: 0.2617898918688297, lr: 9.552620758768171e-05
[2160] train loss: 0.4068460389971733, lr: 9.413089719600976e-05
[2180] train loss: 0.34633340686559677, lr: 9.255966870114207e-05
[2200] train loss: 0.4386848211288452, lr: 9.081878670258448e-05
[2220] train loss: 0.3328768275678158, lr: 8.891518518794328e-05
[2240] train loss: 0.3113600127398968, lr: 8.68564602569677e-05
[2260] train loss: 0.4169246517121792, lr: 8.46508119138889e-05
[2280] train loss: 0.4274236485362053, lr: 8.230703679146245e-05
[2300] train loss: 0.42831722646951675, lr: 7.983447721926495e-05
[2320] train loss: 0.6281722858548164, lr: 7.724298484390602e-05
[2340] train loss: 0.3822157606482506, lr: 7.454289880115539e-05
[2360] train loss: 0.3866102397441864, lr: 7.174497295636684e-05
[2380] train loss: 0.5315662398934364, lr: 6.886036862852052e-05
[2400] train loss: 0.4868117645382881, lr: 6.590057455468923e-05
[2420] train loss: 0.23973922803997993, lr: 6.28774068900384e-05
[2440] train loss: 0.25437454506754875, lr: 5.980289643048309e-05
[2460] train loss: 0.18593750521540642, lr: 5.668931407853961e-05
[2480] train loss: 0.6903180032968521, lr: 5.354906534194015e-05
[2500] train loss: 0.4027124121785164, lr: 5.039466850575991e-05
[2520] train loss: 0.3349034786224365, lr: 4.999999873689376e-05
[2540] train loss: 0.5067370757460594, lr: 4.999999873689376e-05
[2560] train loss: 0.28303050249814987, lr: 4.999999873689376e-05
[2580] train loss: 0.9993599653244019, lr: 4.999999873689376e-05
[2600] train loss: 0.5408374071121216, lr: 4.999999873689376e-05
[2620] train loss: 0.3307304382324219, lr: 4.999999873689376e-05
[2640] train loss: 0.22397339716553688, lr: 4.999999873689376e-05
[2660] train loss: 0.2797393575310707, lr: 4.999999873689376e-05
[2680] train loss: 0.284423615783453, lr: 4.999999873689376e-05
[2700] train loss: 0.2604192681610584, lr: 4.999999873689376e-05
[2720] train loss: 0.33437585085630417, lr: 4.999999873689376e-05
[2740] train loss: 0.24910913407802582, lr: 4.999999873689376e-05
[2760] train loss: 0.23401513323187828, lr: 4.999999873689376e-05
[2780] train loss: 0.21928123570978642, lr: 4.999999873689376e-05
[2800] train loss: 0.24901463091373444, lr: 4.999999873689376e-05
[2820] train loss: 0.30295234732329845, lr: 4.999999873689376e-05
[2840] train loss: 0.2627593167126179, lr: 4.999999873689376e-05
[2860] train loss: 0.25932687893509865, lr: 4.999999873689376e-05
[2880] train loss: 0.33885423839092255, lr: 4.999999873689376e-05
[2900] train loss: 0.2757200188934803, lr: 4.999999873689376e-05
[2920] train loss: 0.33513598144054413, lr: 4.999999873689376e-05
[2940] train loss: 0.25720522552728653, lr: 4.999999873689376e-05
[2960] train loss: 0.21290114149451256, lr: 4.999999873689376e-05
[2980] train loss: 0.2665785327553749, lr: 4.999999873689376e-05
[3000] train loss: 0.33527717739343643, lr: 4.999999873689376e-05
[3020] train loss: 0.3545023947954178, lr: 9.994393622037023e-05
[3040] train loss: 0.5380563959479332, lr: 9.969501115847379e-05
[3060] train loss: 0.35258176922798157, lr: 9.924798359861597e-05
[3080] train loss: 0.8842913210391998, lr: 9.860464342636988e-05
[3100] train loss: 0.5733359530568123, lr: 9.776754450285807e-05
[3120] train loss: 0.47710511833429337, lr: 9.67400410445407e-05
[3140] train loss: 0.421006940305233, lr: 9.552620758768171e-05
[3160] train loss: 0.4254390634596348, lr: 9.413089719600976e-05
[3180] train loss: 0.32012857496738434, lr: 9.255966870114207e-05
[3200] train loss: 0.44592292606830597, lr: 9.081878670258448e-05
[3220] train loss: 1.2229358609765768, lr: 8.891518518794328e-05
[3240] train loss: 0.30556151270866394, lr: 8.68564602569677e-05
[3260] train loss: 0.28889814764261246, lr: 8.46508119138889e-05
[3280] train loss: 0.2149701863527298, lr: 8.230703679146245e-05
[3300] train loss: 0.21766411513090134, lr: 7.983447721926495e-05
[3320] train loss: 0.3799666613340378, lr: 7.724298484390602e-05
[3340] train loss: 0.44270655512809753, lr: 7.454289880115539e-05
[3360] train loss: 0.6183629930019379, lr: 7.174497295636684e-05
[3380] train loss: 0.5524565055966377, lr: 6.886036862852052e-05
[3400] train loss: 0.4990011863410473, lr: 6.590057455468923e-05
[3420] train loss: 1.6574054136872292, lr: 6.28774068900384e-05
[3440] train loss: 2.164859727025032, lr: 5.980289643048309e-05
[3460] train loss: 2.7024688199162483, lr: 5.668931407853961e-05
[3480] train loss: 5.65951382368803, lr: 5.354906534194015e-05
[3500] train loss: 4.0398180186748505, lr: 5.039466850575991e-05
[3520] train loss: 6.288817699998617, lr: 4.999999873689376e-05
[3540] train loss: 1.248809739947319, lr: 4.999999873689376e-05
[3560] train loss: 0.7824173048138618, lr: 4.999999873689376e-05
[3580] train loss: 0.9262025505304337, lr: 4.999999873689376e-05
[3600] train loss: 0.7379920482635498, lr: 4.999999873689376e-05
[3620] train loss: 0.3920929320156574, lr: 4.999999873689376e-05
[3640] train loss: 0.5661902204155922, lr: 4.999999873689376e-05
[3660] train loss: 0.27058521658182144, lr: 4.999999873689376e-05
[3680] train loss: 0.36404938995838165, lr: 4.999999873689376e-05
[3700] train loss: 0.3518664166331291, lr: 4.999999873689376e-05
[3720] train loss: 0.32154737785458565, lr: 4.999999873689376e-05
[3740] train loss: 0.3307852577418089, lr: 4.999999873689376e-05
[3760] train loss: 0.24909879453480244, lr: 4.999999873689376e-05
[3780] train loss: 0.31376761943101883, lr: 4.999999873689376e-05
[3800] train loss: 0.2146516665816307, lr: 4.999999873689376e-05
[3820] train loss: 0.29196079075336456, lr: 4.999999873689376e-05
[3840] train loss: 0.223261971026659, lr: 4.999999873689376e-05
[3860] train loss: 0.38061485067009926, lr: 4.999999873689376e-05
[3880] train loss: 0.47130776941776276, lr: 4.999999873689376e-05
[3900] train loss: 0.5812899842858315, lr: 4.999999873689376e-05
[3920] train loss: 0.4732656106352806, lr: 4.999999873689376e-05
[3940] train loss: 0.2529277503490448, lr: 4.999999873689376e-05
[3960] train loss: 0.28350818529725075, lr: 4.999999873689376e-05
[3980] train loss: 0.3666912280023098, lr: 4.999999873689376e-05
[4000] train loss: 0.4560469575226307, lr: 4.999999873689376e-05
[4020] train loss: 0.26303649321198463, lr: 9.994393622037023e-05
[4040] train loss: 0.23105328530073166, lr: 9.969501115847379e-05
[4060] train loss: 0.36860770359635353, lr: 9.924798359861597e-05
[4080] train loss: 0.43590810149908066, lr: 9.860464342636988e-05
[4100] train loss: 26.772518306970596, lr: 9.776754450285807e-05
[4120] train loss: 12.66562482714653, lr: 9.67400410445407e-05
[4140] train loss: 1.2885132357478142, lr: 9.552620758768171e-05
[4160] train loss: 8.454034201800823, lr: 9.413089719600976e-05
[4180] train loss: 0.8151359781622887, lr: 9.255966870114207e-05
[4200] train loss: 0.5349422991275787, lr: 9.081878670258448e-05
[4220] train loss: 2.634474128484726, lr: 8.891518518794328e-05
[4240] train loss: 8.414400517940521, lr: 8.68564602569677e-05
[4260] train loss: 1.3633181005716324, lr: 8.46508119138889e-05
[4280] train loss: 2.3224416971206665, lr: 8.230703679146245e-05
[4300] train loss: 11.246332332491875, lr: 7.983447721926495e-05
[4320] train loss: 2.984483629465103, lr: 7.724298484390602e-05
[4340] train loss: 2.758529655635357, lr: 7.454289880115539e-05
[4360] train loss: 0.8385964184999466, lr: 7.174497295636684e-05
[4380] train loss: 0.9548460394144058, lr: 6.886036862852052e-05
[4400] train loss: 0.6189512684941292, lr: 6.590057455468923e-05
[4420] train loss: 0.4773220419883728, lr: 6.28774068900384e-05
[4440] train loss: 0.4705652743577957, lr: 5.980289643048309e-05
[4460] train loss: 0.4829195439815521, lr: 5.668931407853961e-05
[4480] train loss: 0.9601798504590988, lr: 5.354906534194015e-05
[4500] train loss: 0.5662539005279541, lr: 5.039466850575991e-05
[4520] train loss: 1.4933677539229393, lr: 4.999999873689376e-05
[4540] train loss: 3.697679575532675, lr: 4.999999873689376e-05
[4560] train loss: 3.0944777876138687, lr: 4.999999873689376e-05
[4580] train loss: 3.677801512181759, lr: 4.999999873689376e-05
[4600] train loss: 7.485954239964485, lr: 4.999999873689376e-05
[4620] train loss: 2.9027583301067352, lr: 4.999999873689376e-05
[4640] train loss: 1.6406414583325386, lr: 4.999999873689376e-05
[4660] train loss: 1.922452762722969, lr: 4.999999873689376e-05
[4680] train loss: 8.421616822481155, lr: 4.999999873689376e-05
[4700] train loss: 13.809102520346642, lr: 4.999999873689376e-05
[4720] train loss: 2.45016086101532, lr: 4.999999873689376e-05
[4740] train loss: 4.800941318273544, lr: 4.999999873689376e-05
[4760] train loss: 12.733436822891235, lr: 4.999999873689376e-05
[4780] train loss: 2.8916777968406677, lr: 4.999999873689376e-05
[4800] train loss: 3.7038770765066147, lr: 4.999999873689376e-05
[4820] train loss: 2.465811535716057, lr: 4.999999873689376e-05
[4840] train loss: 6.712804868817329, lr: 4.999999873689376e-05
[4860] train loss: 2.0927436351776123, lr: 4.999999873689376e-05
[4880] train loss: 1.3491819649934769, lr: 4.999999873689376e-05
[4900] train loss: 3.3160945028066635, lr: 4.999999873689376e-05
[4920] train loss: 1.3624969944357872, lr: 4.999999873689376e-05
[4940] train loss: 3.4721808806061745, lr: 4.999999873689376e-05
[4960] train loss: 1.8981437906622887, lr: 4.999999873689376e-05
[4980] train loss: 2.65938887745142, lr: 4.999999873689376e-05
[5000] train loss: 1.0471626073122025, lr: 4.999999873689376e-05
[5020] train loss: 0.6043684780597687, lr: 9.994393622037023e-05
[5040] train loss: 0.36996378749608994, lr: 9.969501115847379e-05
[5060] train loss: 0.37238647788763046, lr: 9.924798359861597e-05
[5080] train loss: 0.3167708031833172, lr: 9.860464342636988e-05
[5100] train loss: 0.3874281719326973, lr: 9.776754450285807e-05
[5120] train loss: 0.5513226985931396, lr: 9.67400410445407e-05
[5140] train loss: 0.40662630647420883, lr: 9.552620758768171e-05
[5160] train loss: 0.33087558299303055, lr: 9.413089719600976e-05
[5180] train loss: 0.30861032754182816, lr: 9.255966870114207e-05
[5200] train loss: 0.326498307287693, lr: 9.081878670258448e-05
[5220] train loss: 0.28732746094465256, lr: 8.891518518794328e-05
[5240] train loss: 0.30262809060513973, lr: 8.68564602569677e-05
[5260] train loss: 0.256137628108263, lr: 8.46508119138889e-05
[5280] train loss: 0.25064970552921295, lr: 8.230703679146245e-05
[5300] train loss: 0.22989612072706223, lr: 7.983447721926495e-05
[5320] train loss: 0.3522762507200241, lr: 7.724298484390602e-05
[5340] train loss: 0.3488461710512638, lr: 7.454289880115539e-05
[5360] train loss: 0.37276462838053703, lr: 7.174497295636684e-05
[5380] train loss: 0.248833280056715, lr: 6.886036862852052e-05
[5400] train loss: 0.39517465978860855, lr: 6.590057455468923e-05
[5420] train loss: 0.3011510372161865, lr: 6.28774068900384e-05
[5440] train loss: 0.3802461102604866, lr: 5.980289643048309e-05
[5460] train loss: 0.563641183078289, lr: 5.668931407853961e-05
[5480] train loss: 0.4592107906937599, lr: 5.354906534194015e-05
[5500] train loss: 0.299247432500124, lr: 5.039466850575991e-05
[5520] train loss: 0.3217143267393112, lr: 4.999999873689376e-05
[5540] train loss: 0.27402742952108383, lr: 4.999999873689376e-05
[5560] train loss: 0.2171798050403595, lr: 4.999999873689376e-05
[5580] train loss: 0.27582045644521713, lr: 4.999999873689376e-05
[5600] train loss: 0.29717225581407547, lr: 4.999999873689376e-05
[5620] train loss: 0.35534579679369926, lr: 4.999999873689376e-05
[5640] train loss: 6.314616098999977, lr: 4.999999873689376e-05
[5660] train loss: 2.232024446129799, lr: 4.999999873689376e-05
[5680] train loss: 6.318647250533104, lr: 4.999999873689376e-05
[5700] train loss: 0.9466088190674782, lr: 4.999999873689376e-05
[5720] train loss: 0.5893546417355537, lr: 4.999999873689376e-05
[5740] train loss: 0.4391802288591862, lr: 4.999999873689376e-05
[5760] train loss: 0.301317673176527, lr: 4.999999873689376e-05
[5780] train loss: 0.22366905212402344, lr: 4.999999873689376e-05
[5800] train loss: 0.2206009142100811, lr: 4.999999873689376e-05
[5820] train loss: 0.20165161043405533, lr: 4.999999873689376e-05
[5840] train loss: 0.21535046957433224, lr: 4.999999873689376e-05
[5860] train loss: 0.16887984424829483, lr: 4.999999873689376e-05
[5880] train loss: 0.17004750296473503, lr: 4.999999873689376e-05
[5900] train loss: 0.18113853968679905, lr: 4.999999873689376e-05
[5920] train loss: 0.1873687021434307, lr: 4.999999873689376e-05
[5940] train loss: 0.19145150110125542, lr: 4.999999873689376e-05
[5960] train loss: 0.17692678049206734, lr: 4.999999873689376e-05
[5980] train loss: 0.19308876432478428, lr: 4.999999873689376e-05
[6000] train loss: 0.1962058860808611, lr: 4.999999873689376e-05
[6020] train loss: 0.37355953454971313, lr: 9.994393622037023e-05
[6040] train loss: 0.3808142840862274, lr: 9.969501115847379e-05
[6060] train loss: 0.2751709334552288, lr: 9.924798359861597e-05
[6080] train loss: 0.3156910091638565, lr: 9.860464342636988e-05
[6100] train loss: 0.21515646018087864, lr: 9.776754450285807e-05
[6120] train loss: 0.26209553331136703, lr: 9.67400410445407e-05
[6140] train loss: 0.27800818532705307, lr: 9.552620758768171e-05
[6160] train loss: 1.0440533310174942, lr: 9.413089719600976e-05
[6180] train loss: 0.7944486141204834, lr: 9.255966870114207e-05
[6200] train loss: 0.3922940567135811, lr: 9.081878670258448e-05
[6220] train loss: 0.5321178585290909, lr: 8.891518518794328e-05
[6240] train loss: 1.9656143486499786, lr: 8.68564602569677e-05
[6260] train loss: 3.001693621277809, lr: 8.46508119138889e-05
[6280] train loss: 5.97993266582489, lr: 8.230703679146245e-05
[6300] train loss: 11.987641528248787, lr: 7.983447721926495e-05
[6320] train loss: 6.554946184158325, lr: 7.724298484390602e-05
[6340] train loss: 8.737188398838043, lr: 7.454289880115539e-05
[6360] train loss: 3.5776017755270004, lr: 7.174497295636684e-05
[6380] train loss: 1.7297651171684265, lr: 6.886036862852052e-05
[6400] train loss: 2.7786444425582886, lr: 6.590057455468923e-05
[6420] train loss: 2.3530153185129166, lr: 6.28774068900384e-05
[6440] train loss: 3.800621435046196, lr: 5.980289643048309e-05
[6460] train loss: 1.3151065409183502, lr: 5.668931407853961e-05
[6480] train loss: 1.0288300067186356, lr: 5.354906534194015e-05
[6500] train loss: 0.6177080571651459, lr: 5.039466850575991e-05
[6520] train loss: 0.7622197419404984, lr: 4.999999873689376e-05
[6540] train loss: 0.4007163345813751, lr: 4.999999873689376e-05
[6560] train loss: 0.4751074090600014, lr: 4.999999873689376e-05
[6580] train loss: 0.6628837287425995, lr: 4.999999873689376e-05
[6600] train loss: 1.4097800068557262, lr: 4.999999873689376e-05
[6620] train loss: 0.9354461431503296, lr: 4.999999873689376e-05
[6640] train loss: 0.7431720718741417, lr: 4.999999873689376e-05
[6660] train loss: 2.6526094153523445, lr: 4.999999873689376e-05
[6680] train loss: 1.1580516248941422, lr: 4.999999873689376e-05
[6700] train loss: 0.5112322196364403, lr: 4.999999873689376e-05
[6720] train loss: 0.3681814894080162, lr: 4.999999873689376e-05
[6740] train loss: 0.3659946694970131, lr: 4.999999873689376e-05
[6760] train loss: 0.40232790261507034, lr: 4.999999873689376e-05
[6780] train loss: 0.44152190536260605, lr: 4.999999873689376e-05
[6800] train loss: 1.410024881362915, lr: 4.999999873689376e-05
[6820] train loss: 3.267625942826271, lr: 4.999999873689376e-05
[6840] train loss: 4.374768510460854, lr: 4.999999873689376e-05
[6860] train loss: 4.6529733538627625, lr: 4.999999873689376e-05
[6880] train loss: 4.453149288892746, lr: 4.999999873689376e-05
[6900] train loss: 4.349405124783516, lr: 4.999999873689376e-05
[6920] train loss: 2.0242654532194138, lr: 4.999999873689376e-05
[6940] train loss: 2.470596268773079, lr: 4.999999873689376e-05
[6960] train loss: 2.908314771950245, lr: 4.999999873689376e-05
[6980] train loss: 1.0553909689188004, lr: 4.999999873689376e-05
[7000] train loss: 0.6824830546975136, lr: 4.999999873689376e-05
[7020] train loss: 0.3990703225135803, lr: 9.994393622037023e-05
[7040] train loss: 0.27699970081448555, lr: 9.969501115847379e-05
[7060] train loss: 0.8593226186931133, lr: 9.924798359861597e-05
[7080] train loss: 1.1913828700780869, lr: 9.860464342636988e-05
[7100] train loss: 4.12409582734108, lr: 9.776754450285807e-05
[7120] train loss: 1.1937723755836487, lr: 9.67400410445407e-05
[7140] train loss: 1.3050104528665543, lr: 9.552620758768171e-05
[7160] train loss: 0.7876900434494019, lr: 9.413089719600976e-05
[7180] train loss: 4.548667252063751, lr: 9.255966870114207e-05
[7200] train loss: 9.122907042503357, lr: 9.081878670258448e-05
[7220] train loss: 10.871195942163467, lr: 8.891518518794328e-05
[7240] train loss: 4.839368849992752, lr: 8.68564602569677e-05
[7260] train loss: 4.8440486788749695, lr: 8.46508119138889e-05
[7280] train loss: 4.129139810800552, lr: 8.230703679146245e-05
[7300] train loss: 2.4822951555252075, lr: 7.983447721926495e-05
[7320] train loss: 3.0782079100608826, lr: 7.724298484390602e-05
[7340] train loss: 14.38907241821289, lr: 7.454289880115539e-05
[7360] train loss: 2.9461172968149185, lr: 7.174497295636684e-05
[7380] train loss: 7.4371064603328705, lr: 6.886036862852052e-05
[7400] train loss: 5.935260474681854, lr: 6.590057455468923e-05
[7420] train loss: 3.6730815768241882, lr: 6.28774068900384e-05
[7440] train loss: 7.504331111907959, lr: 5.980289643048309e-05
[7460] train loss: 3.894548535346985, lr: 5.668931407853961e-05
[7480] train loss: 2.331757813692093, lr: 5.354906534194015e-05
[7500] train loss: 7.881805703043938, lr: 5.039466850575991e-05
[7520] train loss: 21.878046810626984, lr: 4.999999873689376e-05
[7540] train loss: 23.055271804332733, lr: 4.999999873689376e-05
[7560] train loss: 7.073020875453949, lr: 4.999999873689376e-05
[7580] train loss: 4.017941266298294, lr: 4.999999873689376e-05
[7600] train loss: 3.5583766996860504, lr: 4.999999873689376e-05
[7620] train loss: 2.939421445131302, lr: 4.999999873689376e-05
[7640] train loss: 4.353197567164898, lr: 4.999999873689376e-05
[7660] train loss: 7.163691952824593, lr: 4.999999873689376e-05
[7680] train loss: 5.286718040704727, lr: 4.999999873689376e-05
[7700] train loss: 5.173914849758148, lr: 4.999999873689376e-05
[7720] train loss: 6.167188286781311, lr: 4.999999873689376e-05
[7740] train loss: 3.435719221830368, lr: 4.999999873689376e-05
[7760] train loss: 2.2946910560131073, lr: 4.999999873689376e-05
[7780] train loss: 5.146916836500168, lr: 4.999999873689376e-05
[7800] train loss: 4.770622834563255, lr: 4.999999873689376e-05
[7820] train loss: 7.383356988430023, lr: 4.999999873689376e-05
[7840] train loss: 4.115077540278435, lr: 4.999999873689376e-05
[7860] train loss: 2.4388300478458405, lr: 4.999999873689376e-05
[7880] train loss: 3.243037760257721, lr: 4.999999873689376e-05
[7900] train loss: 9.561778217554092, lr: 4.999999873689376e-05
[7920] train loss: 4.258564114570618, lr: 4.999999873689376e-05
[7940] train loss: 5.116582244634628, lr: 4.999999873689376e-05
[7960] train loss: 4.12248420715332, lr: 4.999999873689376e-05
[7980] train loss: 10.350138545036316, lr: 4.999999873689376e-05
[8000] train loss: 5.182218670845032, lr: 4.999999873689376e-05
[8020] train loss: 2.618437260389328, lr: 9.994393622037023e-05
[8040] train loss: 3.846382290124893, lr: 9.969501115847379e-05
[8060] train loss: 3.536705993115902, lr: 9.924798359861597e-05
[8080] train loss: 1.9596226960420609, lr: 9.860464342636988e-05
[8100] train loss: 1.5785145238041878, lr: 9.776754450285807e-05
[8120] train loss: 3.0865675806999207, lr: 9.67400410445407e-05
[8140] train loss: 3.992071256041527, lr: 9.552620758768171e-05
[8160] train loss: 1.4565091282129288, lr: 9.413089719600976e-05
[8180] train loss: 1.9875947684049606, lr: 9.255966870114207e-05
[8200] train loss: 1.493351474404335, lr: 9.081878670258448e-05
[8220] train loss: 0.8461794555187225, lr: 8.891518518794328e-05
[8240] train loss: 0.5617341846227646, lr: 8.68564602569677e-05
[8260] train loss: 0.5983661413192749, lr: 8.46508119138889e-05
[8280] train loss: 0.503315195441246, lr: 8.230703679146245e-05
[8300] train loss: 0.561048150062561, lr: 7.983447721926495e-05
[8320] train loss: 0.8215358629822731, lr: 7.724298484390602e-05
[8340] train loss: 0.54704749584198, lr: 7.454289880115539e-05
[8360] train loss: 0.4721139073371887, lr: 7.174497295636684e-05
[8380] train loss: 0.7520867437124252, lr: 6.886036862852052e-05
[8400] train loss: 0.6571703553199768, lr: 6.590057455468923e-05
[8420] train loss: 1.6011640951037407, lr: 6.28774068900384e-05
[8440] train loss: 2.254181072115898, lr: 5.980289643048309e-05
[8460] train loss: 1.4490630328655243, lr: 5.668931407853961e-05
[8480] train loss: 1.1755176931619644, lr: 5.354906534194015e-05
[8500] train loss: 0.8337455093860626, lr: 5.039466850575991e-05
[8520] train loss: 1.1393106430768967, lr: 4.999999873689376e-05
[8540] train loss: 0.9105096161365509, lr: 4.999999873689376e-05
[8560] train loss: 1.7573541551828384, lr: 4.999999873689376e-05
[8580] train loss: 0.7739934846758842, lr: 4.999999873689376e-05
[8600] train loss: 0.6725383698940277, lr: 4.999999873689376e-05
[8620] train loss: 1.2313373312354088, lr: 4.999999873689376e-05
[8640] train loss: 8.556899227201939, lr: 4.999999873689376e-05
[8660] train loss: 5.090787336230278, lr: 4.999999873689376e-05
[8680] train loss: 2.350551262497902, lr: 4.999999873689376e-05
[8700] train loss: 1.491734690964222, lr: 4.999999873689376e-05
[8720] train loss: 4.208358362317085, lr: 4.999999873689376e-05
[8740] train loss: 4.204618811607361, lr: 4.999999873689376e-05
[8760] train loss: 2.709800362586975, lr: 4.999999873689376e-05
[8780] train loss: 3.2971314787864685, lr: 4.999999873689376e-05
[8800] train loss: 3.3842189088463783, lr: 4.999999873689376e-05
[8820] train loss: 1.7985409274697304, lr: 4.999999873689376e-05
[8840] train loss: 8.165014520287514, lr: 4.999999873689376e-05
[8860] train loss: 1.1891656443476677, lr: 4.999999873689376e-05
[8880] train loss: 0.511513739824295, lr: 4.999999873689376e-05
[8900] train loss: 0.5004303976893425, lr: 4.999999873689376e-05
[8920] train loss: 0.46286922693252563, lr: 4.999999873689376e-05
[8940] train loss: 0.5901586264371872, lr: 4.999999873689376e-05
[8960] train loss: 0.45382390171289444, lr: 4.999999873689376e-05
[8980] train loss: 0.6585242450237274, lr: 4.999999873689376e-05
[9000] train loss: 0.5995701849460602, lr: 4.999999873689376e-05
[9020] train loss: 0.4960203394293785, lr: 9.994393622037023e-05
[9040] train loss: 0.6019765064120293, lr: 9.969501115847379e-05
[9060] train loss: 0.3772398568689823, lr: 9.924798359861597e-05
[9080] train loss: 0.4054681211709976, lr: 9.860464342636988e-05
[9100] train loss: 0.5590026937425137, lr: 9.776754450285807e-05
[9120] train loss: 0.7131600379943848, lr: 9.67400410445407e-05
[9140] train loss: 0.6004348918795586, lr: 9.552620758768171e-05
[9160] train loss: 0.41130418330430984, lr: 9.413089719600976e-05
[9180] train loss: 0.3586933761835098, lr: 9.255966870114207e-05
[9200] train loss: 0.4217313602566719, lr: 9.081878670258448e-05
[9220] train loss: 3.0093092173337936, lr: 8.891518518794328e-05
[9240] train loss: 1.3097483813762665, lr: 8.68564602569677e-05
[9260] train loss: 1.29451035708189, lr: 8.46508119138889e-05
[9280] train loss: 1.118505172431469, lr: 8.230703679146245e-05
[9300] train loss: 1.3596300184726715, lr: 7.983447721926495e-05
[9320] train loss: 3.0064524710178375, lr: 7.724298484390602e-05
[9340] train loss: 1.520676627755165, lr: 7.454289880115539e-05
[9360] train loss: 1.601247027516365, lr: 7.174497295636684e-05
[9380] train loss: 1.182539850473404, lr: 6.886036862852052e-05
[9400] train loss: 0.8340298384428024, lr: 6.590057455468923e-05
[9420] train loss: 1.4249705746769905, lr: 6.28774068900384e-05
[9440] train loss: 1.7104299291968346, lr: 5.980289643048309e-05
[9460] train loss: 0.9073297195136547, lr: 5.668931407853961e-05
[9480] train loss: 2.7802697345614433, lr: 5.354906534194015e-05
[9500] train loss: 0.9659872651100159, lr: 5.039466850575991e-05
[9520] train loss: 1.8771780543029308, lr: 4.999999873689376e-05
[9540] train loss: 0.8267803937196732, lr: 4.999999873689376e-05
[9560] train loss: 1.049469269812107, lr: 4.999999873689376e-05
[9580] train loss: 0.9924576729536057, lr: 4.999999873689376e-05
[9600] train loss: 1.01795494556427, lr: 4.999999873689376e-05
[9620] train loss: 1.767675843089819, lr: 4.999999873689376e-05
[9640] train loss: 1.531266450881958, lr: 4.999999873689376e-05
[9660] train loss: 1.5708234310150146, lr: 4.999999873689376e-05
[9680] train loss: 0.8720352426171303, lr: 4.999999873689376e-05
[9700] train loss: 0.9630661606788635, lr: 4.999999873689376e-05
[9720] train loss: 0.75645362585783, lr: 4.999999873689376e-05
[9740] train loss: 0.6558431759476662, lr: 4.999999873689376e-05
[9760] train loss: 0.49684830754995346, lr: 4.999999873689376e-05
[9780] train loss: 0.4817880019545555, lr: 4.999999873689376e-05
[9800] train loss: 0.4108634367585182, lr: 4.999999873689376e-05
[9820] train loss: 0.32729125022888184, lr: 4.999999873689376e-05
[9840] train loss: 0.48539913445711136, lr: 4.999999873689376e-05
[9860] train loss: 0.3061743602156639, lr: 4.999999873689376e-05
[9880] train loss: 0.37280019745230675, lr: 4.999999873689376e-05
[9900] train loss: 0.2745250016450882, lr: 4.999999873689376e-05
[9920] train loss: 0.3364800252020359, lr: 4.999999873689376e-05
[9940] train loss: 0.7018049582839012, lr: 4.999999873689376e-05
[9960] train loss: 0.6850217394530773, lr: 4.999999873689376e-05
[9980] train loss: 0.4723629802465439, lr: 4.999999873689376e-05
[10000] train loss: 0.5662106201052666, lr: 4.999999873689376e-05
[10020] train loss: 0.34511393681168556, lr: 9.994393622037023e-05
[10040] train loss: 0.3427577540278435, lr: 9.969501115847379e-05
[10060] train loss: 0.8663040995597839, lr: 9.924798359861597e-05
[10080] train loss: 0.5327385067939758, lr: 9.860464342636988e-05
[10100] train loss: 0.450884111225605, lr: 9.776754450285807e-05
[10120] train loss: 0.5760927498340607, lr: 9.67400410445407e-05
[10140] train loss: 1.5696297660470009, lr: 9.552620758768171e-05
[10160] train loss: 1.3022551201283932, lr: 9.413089719600976e-05
[10180] train loss: 8.084275484085083, lr: 9.255966870114207e-05
[10200] train loss: 14.466921724379063, lr: 9.081878670258448e-05
[10220] train loss: 14.689233765006065, lr: 8.891518518794328e-05
[10240] train loss: 2.1309442967176437, lr: 8.68564602569677e-05
[20] train loss: 0.37685906887054443, lr: 9.994393622037023e-05
[40] train loss: 0.3628997951745987, lr: 9.969501115847379e-05
[60] train loss: 0.48728492856025696, lr: 9.924798359861597e-05
[80] train loss: 0.2759929336607456, lr: 9.860464342636988e-05
[100] train loss: 0.31449152156710625, lr: 9.776754450285807e-05
[120] train loss: 0.38439539074897766, lr: 9.67400410445407e-05
[140] train loss: 0.46185288578271866, lr: 9.552620758768171e-05
[160] train loss: 1.0443337485194206, lr: 9.413089719600976e-05
[180] train loss: 1.97248250618577, lr: 9.255966870114207e-05
[200] train loss: 0.7397119030356407, lr: 9.081878670258448e-05
[220] train loss: 0.5697098821401596, lr: 8.891518518794328e-05
[240] train loss: 1.524454478174448, lr: 8.68564602569677e-05
[260] train loss: 0.6704415269196033, lr: 8.46508119138889e-05
[280] train loss: 3.775511596351862, lr: 8.230703679146245e-05
[300] train loss: 1.6617162935435772, lr: 7.983447721926495e-05
[320] train loss: 0.5638164319097996, lr: 7.724298484390602e-05
[340] train loss: 1.1525391638278961, lr: 7.454289880115539e-05
[360] train loss: 1.064926903694868, lr: 7.174497295636684e-05
[380] train loss: 0.8379318937659264, lr: 6.886036862852052e-05
[400] train loss: 8.011278133839369, lr: 6.590057455468923e-05
[420] train loss: 1.0063088908791542, lr: 6.28774068900384e-05
[440] train loss: 2.452066883444786, lr: 5.980289643048309e-05
[460] train loss: 1.5577579885721207, lr: 5.668931407853961e-05
[480] train loss: 0.6143097877502441, lr: 5.354906534194015e-05
[500] train loss: 0.7775770500302315, lr: 5.039466850575991e-05
[520] train loss: 1.3076480031013489, lr: 4.999999873689376e-05
[540] train loss: 1.1742141097784042, lr: 4.999999873689376e-05
[560] train loss: 0.7853759527206421, lr: 4.999999873689376e-05
[580] train loss: 1.8634366989135742, lr: 4.999999873689376e-05
[600] train loss: 3.970291957259178, lr: 4.999999873689376e-05
[620] train loss: 3.443459674715996, lr: 4.999999873689376e-05
[640] train loss: 1.2286890521645546, lr: 4.999999873689376e-05
[660] train loss: 1.0097018480300903, lr: 4.999999873689376e-05
[680] train loss: 1.5229945480823517, lr: 4.999999873689376e-05
[700] train loss: 2.9324247166514397, lr: 4.999999873689376e-05
[720] train loss: 1.1921903640031815, lr: 4.999999873689376e-05
[740] train loss: 0.6522331014275551, lr: 4.999999873689376e-05
[760] train loss: 0.5968651250004768, lr: 4.999999873689376e-05
[780] train loss: 0.6041084676980972, lr: 4.999999873689376e-05
[800] train loss: 0.6664640381932259, lr: 4.999999873689376e-05
[820] train loss: 0.6105090379714966, lr: 4.999999873689376e-05
[840] train loss: 0.4586225152015686, lr: 4.999999873689376e-05
[860] train loss: 0.38645969331264496, lr: 4.999999873689376e-05
[880] train loss: 0.3598492443561554, lr: 4.999999873689376e-05
[900] train loss: 0.2875373773276806, lr: 4.999999873689376e-05
[920] train loss: 0.43955860286951065, lr: 4.999999873689376e-05
[940] train loss: 0.3526947721838951, lr: 4.999999873689376e-05
[960] train loss: 0.3223227821290493, lr: 4.999999873689376e-05
[980] train loss: 0.34320202469825745, lr: 4.999999873689376e-05
[1000] train loss: 0.9151213765144348, lr: 4.999999873689376e-05
[1020] train loss: 0.6178864166140556, lr: 9.994393622037023e-05
[1040] train loss: 5.465386927127838, lr: 9.969501115847379e-05
[1060] train loss: 1.6145041733980179, lr: 9.924798359861597e-05
[1080] train loss: 0.4746011905372143, lr: 9.860464342636988e-05
[1100] train loss: 0.8130542375147343, lr: 9.776754450285807e-05
[1120] train loss: 0.34300166368484497, lr: 9.67400410445407e-05
[1140] train loss: 0.34423984214663506, lr: 9.552620758768171e-05
[1160] train loss: 0.30715345591306686, lr: 9.413089719600976e-05
[1180] train loss: 0.2276049628853798, lr: 9.255966870114207e-05
[1200] train loss: 0.31484244763851166, lr: 9.081878670258448e-05
[1220] train loss: 0.25114529207348824, lr: 8.891518518794328e-05
[1240] train loss: 0.239774938672781, lr: 8.68564602569677e-05
[1260] train loss: 0.22415103390812874, lr: 8.46508119138889e-05
[1280] train loss: 0.28618257492780685, lr: 8.230703679146245e-05
[1300] train loss: 0.29943523183465004, lr: 7.983447721926495e-05
[1320] train loss: 0.25242286175489426, lr: 7.724298484390602e-05
[1340] train loss: 0.21401434391736984, lr: 7.454289880115539e-05
[1360] train loss: 0.27620599791407585, lr: 7.174497295636684e-05
[1380] train loss: 0.262676727026701, lr: 6.886036862852052e-05
[1400] train loss: 0.20891899429261684, lr: 6.590057455468923e-05
[1420] train loss: 0.24903101101517677, lr: 6.28774068900384e-05
[1440] train loss: 0.4795576184988022, lr: 5.980289643048309e-05
[1460] train loss: 0.4370298236608505, lr: 5.668931407853961e-05
[1480] train loss: 0.3445952869951725, lr: 5.354906534194015e-05
[1500] train loss: 0.3250834494829178, lr: 5.039466850575991e-05
[1520] train loss: 1.1513872034847736, lr: 4.999999873689376e-05
[1540] train loss: 2.1194835901260376, lr: 4.999999873689376e-05
[1560] train loss: 0.5888842195272446, lr: 4.999999873689376e-05
[1580] train loss: 0.2966570258140564, lr: 4.999999873689376e-05
[1600] train loss: 0.30427186191082, lr: 4.999999873689376e-05
[1620] train loss: 0.357221320271492, lr: 4.999999873689376e-05
[1640] train loss: 0.4085596762597561, lr: 4.999999873689376e-05
[1660] train loss: 0.40596045553684235, lr: 4.999999873689376e-05
[1680] train loss: 0.5376211181282997, lr: 4.999999873689376e-05
[1700] train loss: 0.32783374190330505, lr: 4.999999873689376e-05
[1720] train loss: 0.2661435827612877, lr: 4.999999873689376e-05
[1740] train loss: 0.21088111773133278, lr: 4.999999873689376e-05
[1760] train loss: 0.24760288000106812, lr: 4.999999873689376e-05
[1780] train loss: 0.4284566678106785, lr: 4.999999873689376e-05
[1800] train loss: 0.3455873280763626, lr: 4.999999873689376e-05
[1820] train loss: 0.3219735659658909, lr: 4.999999873689376e-05
[1840] train loss: 0.4093376398086548, lr: 4.999999873689376e-05
[1860] train loss: 0.22918814793229103, lr: 4.999999873689376e-05
[1880] train loss: 0.2639343626797199, lr: 4.999999873689376e-05
[1900] train loss: 0.2876659408211708, lr: 4.999999873689376e-05
[1920] train loss: 0.38526622019708157, lr: 4.999999873689376e-05
[1940] train loss: 0.3349459748715162, lr: 4.999999873689376e-05
[1960] train loss: 0.6565688028931618, lr: 4.999999873689376e-05
[1980] train loss: 0.566837802529335, lr: 4.999999873689376e-05
[2000] train loss: 0.4491160809993744, lr: 4.999999873689376e-05
[2020] train loss: 0.39285726845264435, lr: 9.994393622037023e-05
[2040] train loss: 0.7959897369146347, lr: 9.969501115847379e-05
[2060] train loss: 0.5627943426370621, lr: 9.924798359861597e-05
[2080] train loss: 0.2549061216413975, lr: 9.860464342636988e-05
[2100] train loss: 0.264318622648716, lr: 9.776754450285807e-05
[2120] train loss: 0.2929857224225998, lr: 9.67400410445407e-05
[2140] train loss: 0.2462928630411625, lr: 9.552620758768171e-05
[2160] train loss: 0.22753961011767387, lr: 9.413089719600976e-05
[2180] train loss: 0.2687549740076065, lr: 9.255966870114207e-05
[2200] train loss: 0.38348253443837166, lr: 9.081878670258448e-05
[2220] train loss: 0.39446742087602615, lr: 8.891518518794328e-05
[2240] train loss: 0.7347778528928757, lr: 8.68564602569677e-05
[2260] train loss: 0.6776653528213501, lr: 8.46508119138889e-05
[2280] train loss: 1.3635241948068142, lr: 8.230703679146245e-05
[2300] train loss: 2.4998909085989, lr: 7.983447721926495e-05
[2320] train loss: 1.451462984085083, lr: 7.724298484390602e-05
[2340] train loss: 1.6769697070121765, lr: 7.454289880115539e-05
[2360] train loss: 0.9858006983995438, lr: 7.174497295636684e-05
[2380] train loss: 0.9104526191949844, lr: 6.886036862852052e-05
[2400] train loss: 0.8534599989652634, lr: 6.590057455468923e-05
[2420] train loss: 3.4711288288235664, lr: 6.28774068900384e-05
[2440] train loss: 1.485349453985691, lr: 5.980289643048309e-05
[2460] train loss: 0.7881899178028107, lr: 5.668931407853961e-05
[2480] train loss: 2.377644866704941, lr: 5.354906534194015e-05
[2500] train loss: 2.288357824087143, lr: 5.039466850575991e-05
[2520] train loss: 6.491537868976593, lr: 4.999999873689376e-05
[2540] train loss: 3.096346437931061, lr: 4.999999873689376e-05
[2560] train loss: 2.060461476445198, lr: 4.999999873689376e-05
[2580] train loss: 0.4309099316596985, lr: 4.999999873689376e-05
[2600] train loss: 0.2802220582962036, lr: 4.999999873689376e-05
[2620] train loss: 0.3030921369791031, lr: 4.999999873689376e-05
[2640] train loss: 0.2961071729660034, lr: 4.999999873689376e-05
[2660] train loss: 0.2189767062664032, lr: 4.999999873689376e-05
[2680] train loss: 0.21560755372047424, lr: 4.999999873689376e-05
[2700] train loss: 0.19012800976634026, lr: 4.999999873689376e-05
[2720] train loss: 0.20763131976127625, lr: 4.999999873689376e-05
[2740] train loss: 0.2547115609049797, lr: 4.999999873689376e-05
[2760] train loss: 0.32253479212522507, lr: 4.999999873689376e-05
[2780] train loss: 0.3961142674088478, lr: 4.999999873689376e-05
[2800] train loss: 0.30536918342113495, lr: 4.999999873689376e-05
[2820] train loss: 0.2960433289408684, lr: 4.999999873689376e-05
[2840] train loss: 0.33949150145053864, lr: 4.999999873689376e-05
[2860] train loss: 0.5994995124638081, lr: 4.999999873689376e-05
[2880] train loss: 0.26683923229575157, lr: 4.999999873689376e-05
[2900] train loss: 0.2627530209720135, lr: 4.999999873689376e-05
[2920] train loss: 0.221736591309309, lr: 4.999999873689376e-05
[2940] train loss: 0.26193030923604965, lr: 4.999999873689376e-05
[2960] train loss: 0.23831414803862572, lr: 4.999999873689376e-05
[2980] train loss: 0.29986154101789, lr: 4.999999873689376e-05
[3000] train loss: 0.2970813661813736, lr: 4.999999873689376e-05
[3020] train loss: 0.3062676340341568, lr: 9.994393622037023e-05
[3040] train loss: 0.29664526134729385, lr: 9.969501115847379e-05
[3060] train loss: 0.2787677776068449, lr: 9.924798359861597e-05
[3080] train loss: 0.5487383157014847, lr: 9.860464342636988e-05
[3100] train loss: 0.380816213786602, lr: 9.776754450285807e-05
[3120] train loss: 0.3687378540635109, lr: 9.67400410445407e-05
[3140] train loss: 0.6438955962657928, lr: 9.552620758768171e-05
[3160] train loss: 0.48028863221406937, lr: 9.413089719600976e-05
[3180] train loss: 0.40520593523979187, lr: 9.255966870114207e-05
[3200] train loss: 0.5051455721259117, lr: 9.081878670258448e-05
[3220] train loss: 0.5833292901515961, lr: 8.891518518794328e-05
[3240] train loss: 1.989620566368103, lr: 8.68564602569677e-05
[3260] train loss: 1.3529023602604866, lr: 8.46508119138889e-05
[3280] train loss: 2.0665908753871918, lr: 8.230703679146245e-05
[3300] train loss: 1.5719226598739624, lr: 7.983447721926495e-05
[3320] train loss: 0.9967214465141296, lr: 7.724298484390602e-05
[3340] train loss: 3.114707663655281, lr: 7.454289880115539e-05
[3360] train loss: 7.288921043276787, lr: 7.174497295636684e-05
[3380] train loss: 0.9077707231044769, lr: 6.886036862852052e-05
[3400] train loss: 0.7093746736645699, lr: 6.590057455468923e-05
[3420] train loss: 0.4352111257612705, lr: 6.28774068900384e-05
[3440] train loss: 0.38730843365192413, lr: 5.980289643048309e-05
[3460] train loss: 0.2915828675031662, lr: 5.668931407853961e-05
[3480] train loss: 0.23184985667467117, lr: 5.354906534194015e-05
[3500] train loss: 0.28838759288191795, lr: 5.039466850575991e-05
[3520] train loss: 0.42756928503513336, lr: 4.999999873689376e-05
[3540] train loss: 4.593179680407047, lr: 4.999999873689376e-05
[3560] train loss: 0.746023915708065, lr: 4.999999873689376e-05
[3580] train loss: 0.4292774945497513, lr: 4.999999873689376e-05
[3600] train loss: 5.300004839897156, lr: 4.999999873689376e-05
[3620] train loss: 5.271490961313248, lr: 4.999999873689376e-05
[3640] train loss: 2.6399791836738586, lr: 4.999999873689376e-05
[3660] train loss: 3.5837802290916443, lr: 4.999999873689376e-05
[3680] train loss: 5.3463823944330215, lr: 4.999999873689376e-05
[3700] train loss: 5.895711898803711, lr: 4.999999873689376e-05
[3720] train loss: 10.403578504920006, lr: 4.999999873689376e-05
[3740] train loss: 2.2902157232165337, lr: 4.999999873689376e-05
[3760] train loss: 3.463382199406624, lr: 4.999999873689376e-05
[3780] train loss: 17.855276823043823, lr: 4.999999873689376e-05
[3800] train loss: 17.221881195902824, lr: 4.999999873689376e-05
[3820] train loss: 1.914170853793621, lr: 4.999999873689376e-05
[3840] train loss: 0.7854234874248505, lr: 4.999999873689376e-05
[3860] train loss: 0.9917220175266266, lr: 4.999999873689376e-05
[3880] train loss: 1.1598218977451324, lr: 4.999999873689376e-05
[3900] train loss: 1.5920064449310303, lr: 4.999999873689376e-05
[3920] train loss: 13.206477493047714, lr: 4.999999873689376e-05
[3940] train loss: 10.582782506942749, lr: 4.999999873689376e-05
[3960] train loss: 1.8348198533058167, lr: 4.999999873689376e-05
[3980] train loss: 1.8003827035427094, lr: 4.999999873689376e-05
[4000] train loss: 2.9300525784492493, lr: 4.999999873689376e-05
[4020] train loss: 3.8571491092443466, lr: 9.994393622037023e-05
[4040] train loss: 14.108674317598343, lr: 9.969501115847379e-05
[4060] train loss: 1.6463744640350342, lr: 9.924798359861597e-05
[4080] train loss: 0.83177250623703, lr: 9.860464342636988e-05
[4100] train loss: 2.1194454580545425, lr: 9.776754450285807e-05
[4120] train loss: 0.8476345464587212, lr: 9.67400410445407e-05
[4140] train loss: 0.7009502537548542, lr: 9.552620758768171e-05
[4160] train loss: 0.3970867022871971, lr: 9.413089719600976e-05
[4180] train loss: 0.5105856284499168, lr: 9.255966870114207e-05
[4200] train loss: 0.5997327715158463, lr: 9.081878670258448e-05
[4220] train loss: 0.765058621764183, lr: 8.891518518794328e-05
[4240] train loss: 0.4543580263853073, lr: 8.68564602569677e-05
[4260] train loss: 0.5299643501639366, lr: 8.46508119138889e-05
[4280] train loss: 0.3355185464024544, lr: 8.230703679146245e-05
[4300] train loss: 0.35355810448527336, lr: 7.983447721926495e-05
[4320] train loss: 0.38403084874153137, lr: 7.724298484390602e-05
[4340] train loss: 1.0264353454113007, lr: 7.454289880115539e-05
[4360] train loss: 9.780019648373127, lr: 7.174497295636684e-05
[4380] train loss: 6.913566753268242, lr: 6.886036862852052e-05
[4400] train loss: 1.514307864010334, lr: 6.590057455468923e-05
[4420] train loss: 0.7765378579497337, lr: 6.28774068900384e-05
[4440] train loss: 0.8392709791660309, lr: 5.980289643048309e-05
[4460] train loss: 0.4795342981815338, lr: 5.668931407853961e-05
[4480] train loss: 0.7066726386547089, lr: 5.354906534194015e-05
[4500] train loss: 1.0470886081457138, lr: 5.039466850575991e-05
[4520] train loss: 0.8117399141192436, lr: 4.999999873689376e-05
[4540] train loss: 0.5512212440371513, lr: 4.999999873689376e-05
[4560] train loss: 1.2009229362010956, lr: 4.999999873689376e-05
[4580] train loss: 0.7036144211888313, lr: 4.999999873689376e-05
[4600] train loss: 0.8116403222084045, lr: 4.999999873689376e-05
[4620] train loss: 2.3286615163087845, lr: 4.999999873689376e-05
[4640] train loss: 0.7889938056468964, lr: 4.999999873689376e-05
[4660] train loss: 1.0465477108955383, lr: 4.999999873689376e-05
[4680] train loss: 0.8660120069980621, lr: 4.999999873689376e-05
[4700] train loss: 0.5263344720005989, lr: 4.999999873689376e-05
[4720] train loss: 2.427691727876663, lr: 4.999999873689376e-05
[4740] train loss: 2.0445630252361298, lr: 4.999999873689376e-05
[4760] train loss: 1.5505054965615273, lr: 4.999999873689376e-05
[4780] train loss: 0.8018645495176315, lr: 4.999999873689376e-05
[4800] train loss: 0.7870908975601196, lr: 4.999999873689376e-05
[4820] train loss: 0.4666607864201069, lr: 4.999999873689376e-05
[4840] train loss: 0.45192795991897583, lr: 4.999999873689376e-05
[4860] train loss: 0.36777035519480705, lr: 4.999999873689376e-05
[4880] train loss: 0.33795513957738876, lr: 4.999999873689376e-05
[4900] train loss: 0.381835762411356, lr: 4.999999873689376e-05
[4920] train loss: 0.36524418741464615, lr: 4.999999873689376e-05
[4940] train loss: 0.29595039039850235, lr: 4.999999873689376e-05
[4960] train loss: 0.45115402713418007, lr: 4.999999873689376e-05
[4980] train loss: 0.4274371676146984, lr: 4.999999873689376e-05
[5000] train loss: 0.7229315415024757, lr: 4.999999873689376e-05
[5020] train loss: 1.4194212853908539, lr: 9.994393622037023e-05
[5040] train loss: 9.217084631323814, lr: 9.969501115847379e-05
[5060] train loss: 14.283495381474495, lr: 9.924798359861597e-05
[5080] train loss: 15.517624080181122, lr: 9.860464342636988e-05
[5100] train loss: 1.881657987833023, lr: 9.776754450285807e-05
[5120] train loss: 0.7570837289094925, lr: 9.67400410445407e-05
[5140] train loss: 1.5231430679559708, lr: 9.552620758768171e-05
[5160] train loss: 1.52721606194973, lr: 9.413089719600976e-05
[5180] train loss: 0.7664053738117218, lr: 9.255966870114207e-05
[5200] train loss: 0.44849684089422226, lr: 9.081878670258448e-05
[5220] train loss: 0.4093717336654663, lr: 8.891518518794328e-05
[5240] train loss: 0.44343357533216476, lr: 8.68564602569677e-05
[5260] train loss: 0.7874294444918633, lr: 8.46508119138889e-05
[5280] train loss: 2.0593540742993355, lr: 8.230703679146245e-05
[5300] train loss: 0.815739631652832, lr: 7.983447721926495e-05
[5320] train loss: 0.6542866714298725, lr: 7.724298484390602e-05
[5340] train loss: 1.9935968965291977, lr: 7.454289880115539e-05
[5360] train loss: 1.1004859507083893, lr: 7.174497295636684e-05
[5380] train loss: 0.7591370120644569, lr: 6.886036862852052e-05
[5400] train loss: 0.7248652167618275, lr: 6.590057455468923e-05
[5420] train loss: 0.7590740993618965, lr: 6.28774068900384e-05
[5440] train loss: 0.7384744882583618, lr: 5.980289643048309e-05
[5460] train loss: 0.4089714288711548, lr: 5.668931407853961e-05
[5480] train loss: 0.5272423923015594, lr: 5.354906534194015e-05
[5500] train loss: 1.1182710230350494, lr: 5.039466850575991e-05
[5520] train loss: 1.5075856894254684, lr: 4.999999873689376e-05
[5540] train loss: 1.6328345388174057, lr: 4.999999873689376e-05
[5560] train loss: 1.7873764783143997, lr: 4.999999873689376e-05
[5580] train loss: 1.6667234376072884, lr: 4.999999873689376e-05
[5600] train loss: 1.3393098339438438, lr: 4.999999873689376e-05
[5620] train loss: 1.4449155703186989, lr: 4.999999873689376e-05
[5640] train loss: 2.78944119066, lr: 4.999999873689376e-05
[5660] train loss: 1.7052783966064453, lr: 4.999999873689376e-05
[5680] train loss: 1.6275345832109451, lr: 4.999999873689376e-05
[5700] train loss: 5.523482844233513, lr: 4.999999873689376e-05
[5720] train loss: 3.082057014107704, lr: 4.999999873689376e-05
[5740] train loss: 2.1670834124088287, lr: 4.999999873689376e-05
[5760] train loss: 2.1140734180808067, lr: 4.999999873689376e-05
[5780] train loss: 2.3997947722673416, lr: 4.999999873689376e-05
[5800] train loss: 2.035040959715843, lr: 4.999999873689376e-05
[5820] train loss: 4.547718890011311, lr: 4.999999873689376e-05
[5840] train loss: 3.4877378791570663, lr: 4.999999873689376e-05
[5860] train loss: 2.1945776641368866, lr: 4.999999873689376e-05
[5880] train loss: 2.394345283508301, lr: 4.999999873689376e-05
[5900] train loss: 1.4187235981225967, lr: 4.999999873689376e-05
[5920] train loss: 1.2268803864717484, lr: 4.999999873689376e-05
[5940] train loss: 1.0527318120002747, lr: 4.999999873689376e-05
[5960] train loss: 3.196805492043495, lr: 4.999999873689376e-05
[5980] train loss: 7.2072466015815735, lr: 4.999999873689376e-05
[6000] train loss: 1.4994616955518723, lr: 4.999999873689376e-05
[6020] train loss: 11.512324884533882, lr: 9.994393622037023e-05
[6040] train loss: 11.1874640583992, lr: 9.969501115847379e-05
[6060] train loss: 7.8871816992759705, lr: 9.924798359861597e-05
[6080] train loss: 1.857034519314766, lr: 9.860464342636988e-05
[6100] train loss: 2.779527649283409, lr: 9.776754450285807e-05
[6120] train loss: 2.1864796578884125, lr: 9.67400410445407e-05
[6140] train loss: 1.4372135400772095, lr: 9.552620758768171e-05
[6160] train loss: 1.2197128683328629, lr: 9.413089719600976e-05
[6180] train loss: 1.0174878984689713, lr: 9.255966870114207e-05
[6200] train loss: 1.0639280751347542, lr: 9.081878670258448e-05
[6220] train loss: 1.4394067153334618, lr: 8.891518518794328e-05
[6240] train loss: 1.9431609436869621, lr: 8.68564602569677e-05
[6260] train loss: 2.142607182264328, lr: 8.46508119138889e-05
[6280] train loss: 2.18564110994339, lr: 8.230703679146245e-05
[6300] train loss: 1.2825897857546806, lr: 7.983447721926495e-05
[6320] train loss: 0.5197505503892899, lr: 7.724298484390602e-05
[6340] train loss: 0.5758480131626129, lr: 7.454289880115539e-05
[6360] train loss: 0.6849641054868698, lr: 7.174497295636684e-05
[6380] train loss: 0.6164501309394836, lr: 6.886036862852052e-05
[6400] train loss: 0.9954148083925247, lr: 6.590057455468923e-05
[6420] train loss: 0.572706937789917, lr: 6.28774068900384e-05
[6440] train loss: 0.602053813636303, lr: 5.980289643048309e-05
[6460] train loss: 0.8427695482969284, lr: 5.668931407853961e-05
[6480] train loss: 0.4704561084508896, lr: 5.354906534194015e-05
[6500] train loss: 0.5624530538916588, lr: 5.039466850575991e-05
[6520] train loss: 1.029639296233654, lr: 4.999999873689376e-05
[6540] train loss: 0.6552674770355225, lr: 4.999999873689376e-05
[6560] train loss: 0.7069211900234222, lr: 4.999999873689376e-05
[6580] train loss: 0.42036299407482147, lr: 4.999999873689376e-05
[6600] train loss: 0.36271852999925613, lr: 4.999999873689376e-05
[6620] train loss: 0.3486882448196411, lr: 4.999999873689376e-05
[6640] train loss: 0.32437796145677567, lr: 4.999999873689376e-05
[6660] train loss: 16.277300000190735, lr: 4.999999873689376e-05
[6680] train loss: 10.404864072799683, lr: 4.999999873689376e-05
[6700] train loss: 2.953817419707775, lr: 4.999999873689376e-05
[6720] train loss: 1.447347268462181, lr: 4.999999873689376e-05
[6740] train loss: 3.4333095028996468, lr: 4.999999873689376e-05
[6760] train loss: 5.936619862914085, lr: 4.999999873689376e-05
[6780] train loss: 2.788910746574402, lr: 4.999999873689376e-05
[6800] train loss: 5.64856643602252, lr: 4.999999873689376e-05
[6820] train loss: 1.230931669473648, lr: 4.999999873689376e-05
[6840] train loss: 2.518680229783058, lr: 4.999999873689376e-05
[6860] train loss: 0.8508338257670403, lr: 4.999999873689376e-05
[6880] train loss: 1.9569471590220928, lr: 4.999999873689376e-05
[6900] train loss: 2.436145104467869, lr: 4.999999873689376e-05
[6920] train loss: 1.2940668314695358, lr: 4.999999873689376e-05
[6940] train loss: 0.8734758049249649, lr: 4.999999873689376e-05
[6960] train loss: 3.4201951511204243, lr: 4.999999873689376e-05
[6980] train loss: 1.11349281296134, lr: 4.999999873689376e-05
[7000] train loss: 1.4367807358503342, lr: 4.999999873689376e-05
[7020] train loss: 0.7013417556881905, lr: 9.994393622037023e-05
[7040] train loss: 0.6083589494228363, lr: 9.969501115847379e-05
[7060] train loss: 0.4690031409263611, lr: 9.924798359861597e-05
[7080] train loss: 0.38852033764123917, lr: 9.860464342636988e-05
[7100] train loss: 0.36619342863559723, lr: 9.776754450285807e-05
[7120] train loss: 0.34934694319963455, lr: 9.67400410445407e-05
[7140] train loss: 0.33839432895183563, lr: 9.552620758768171e-05
[7160] train loss: 0.5609100982546806, lr: 9.413089719600976e-05
[7180] train loss: 4.377280950546265, lr: 9.255966870114207e-05
[7200] train loss: 2.2897664308547974, lr: 9.081878670258448e-05
[7220] train loss: 3.3996334224939346, lr: 8.891518518794328e-05
[7240] train loss: 1.2448724880814552, lr: 8.68564602569677e-05
[7260] train loss: 10.134465411305428, lr: 8.46508119138889e-05
[7280] train loss: 2.095100700855255, lr: 8.230703679146245e-05
[7300] train loss: 2.9753416180610657, lr: 7.983447721926495e-05
[7320] train loss: 4.497740536928177, lr: 7.724298484390602e-05
[7340] train loss: 2.4405240640044212, lr: 7.454289880115539e-05
[7360] train loss: 6.778829902410507, lr: 7.174497295636684e-05
[7380] train loss: 5.029829382896423, lr: 6.886036862852052e-05
[7400] train loss: 2.198853626847267, lr: 6.590057455468923e-05
[7420] train loss: 3.6918423771858215, lr: 6.28774068900384e-05
[7440] train loss: 2.204894706606865, lr: 5.980289643048309e-05
[7460] train loss: 2.649856835603714, lr: 5.668931407853961e-05
[7480] train loss: 2.7805358469486237, lr: 5.354906534194015e-05
[7500] train loss: 11.688644096255302, lr: 5.039466850575991e-05
[7520] train loss: 5.467852085828781, lr: 4.999999873689376e-05
[7540] train loss: 3.4050749391317368, lr: 4.999999873689376e-05
[7560] train loss: 3.615011118352413, lr: 4.999999873689376e-05
[7580] train loss: 3.83689034730196, lr: 4.999999873689376e-05
[7600] train loss: 4.490858472883701, lr: 4.999999873689376e-05
[7620] train loss: 2.799741744995117, lr: 4.999999873689376e-05
[7640] train loss: 3.22842375934124, lr: 4.999999873689376e-05
[7660] train loss: 3.056391879916191, lr: 4.999999873689376e-05
[7680] train loss: 2.558145448565483, lr: 4.999999873689376e-05
[7700] train loss: 0.9970791339874268, lr: 4.999999873689376e-05
[7720] train loss: 0.6025298610329628, lr: 4.999999873689376e-05
[7740] train loss: 0.4617021754384041, lr: 4.999999873689376e-05
[7760] train loss: 0.40754956752061844, lr: 4.999999873689376e-05
[7780] train loss: 0.3361622542142868, lr: 4.999999873689376e-05
[7800] train loss: 0.3758593276143074, lr: 4.999999873689376e-05
[7820] train loss: 0.3365682549774647, lr: 4.999999873689376e-05
[7840] train loss: 0.3556678704917431, lr: 4.999999873689376e-05
[7860] train loss: 0.33390699699521065, lr: 4.999999873689376e-05
[7880] train loss: 0.2951001040637493, lr: 4.999999873689376e-05
[7900] train loss: 0.30945856869220734, lr: 4.999999873689376e-05
[7920] train loss: 0.2783030495047569, lr: 4.999999873689376e-05
[7940] train loss: 0.39914239943027496, lr: 4.999999873689376e-05
[7960] train loss: 0.5151838585734367, lr: 4.999999873689376e-05
[7980] train loss: 0.26801837980747223, lr: 4.999999873689376e-05
[8000] train loss: 0.27322469651699066, lr: 4.999999873689376e-05
[8020] train loss: 0.2169019840657711, lr: 9.994393622037023e-05
[8040] train loss: 0.19884641095995903, lr: 9.969501115847379e-05
[8060] train loss: 0.19955290853977203, lr: 9.924798359861597e-05
[8080] train loss: 0.22162321209907532, lr: 9.860464342636988e-05
[8100] train loss: 0.1900910772383213, lr: 9.776754450285807e-05
[8120] train loss: 0.30476466566324234, lr: 9.67400410445407e-05
[8140] train loss: 0.36724475771188736, lr: 9.552620758768171e-05
[8160] train loss: 0.3413553424179554, lr: 9.413089719600976e-05
[8180] train loss: 0.26319509744644165, lr: 9.255966870114207e-05
[8200] train loss: 3.019482582807541, lr: 9.081878670258448e-05
[8220] train loss: 1.5497352182865143, lr: 8.891518518794328e-05
[8240] train loss: 1.888340026140213, lr: 8.68564602569677e-05
[8260] train loss: 1.603226751089096, lr: 8.46508119138889e-05
[8280] train loss: 1.078068993985653, lr: 8.230703679146245e-05
[8300] train loss: 1.7597846910357475, lr: 7.983447721926495e-05
[8320] train loss: 0.9848963469266891, lr: 7.724298484390602e-05
[8340] train loss: 1.447353072464466, lr: 7.454289880115539e-05
[8360] train loss: 1.222161926329136, lr: 7.174497295636684e-05
[8380] train loss: 0.9220774844288826, lr: 6.886036862852052e-05
[8400] train loss: 1.019851177930832, lr: 6.590057455468923e-05
[8420] train loss: 1.512980118393898, lr: 6.28774068900384e-05
[8440] train loss: 0.8273560106754303, lr: 5.980289643048309e-05
[8460] train loss: 0.9866532757878304, lr: 5.668931407853961e-05
[8480] train loss: 1.9287268184125423, lr: 5.354906534194015e-05
[8500] train loss: 1.5728800892829895, lr: 5.039466850575991e-05
[8520] train loss: 1.9360524639487267, lr: 4.999999873689376e-05
[8540] train loss: 0.9617067351937294, lr: 4.999999873689376e-05
[8560] train loss: 1.5013954043388367, lr: 4.999999873689376e-05
[8580] train loss: 5.672256626188755, lr: 4.999999873689376e-05
[8600] train loss: 5.958982229232788, lr: 4.999999873689376e-05
[8620] train loss: 3.926839917898178, lr: 4.999999873689376e-05
[8640] train loss: 4.7115828692913055, lr: 4.999999873689376e-05
[8660] train loss: 7.443104714155197, lr: 4.999999873689376e-05
[8680] train loss: 1.7766889929771423, lr: 4.999999873689376e-05
[8700] train loss: 0.9426827728748322, lr: 4.999999873689376e-05
[8720] train loss: 0.8132826611399651, lr: 4.999999873689376e-05
[8740] train loss: 0.8461005240678787, lr: 4.999999873689376e-05
[8760] train loss: 0.532882533967495, lr: 4.999999873689376e-05
[8780] train loss: 0.4367220625281334, lr: 4.999999873689376e-05
[8800] train loss: 0.5179185420274734, lr: 4.999999873689376e-05
[8820] train loss: 0.3607383444905281, lr: 4.999999873689376e-05
[8840] train loss: 0.5667464062571526, lr: 4.999999873689376e-05
[8860] train loss: 0.47548940777778625, lr: 4.999999873689376e-05
[8880] train loss: 0.2976551093161106, lr: 4.999999873689376e-05
[8900] train loss: 0.31503795087337494, lr: 4.999999873689376e-05
[8920] train loss: 0.2466769814491272, lr: 4.999999873689376e-05
[8940] train loss: 0.3393712565302849, lr: 4.999999873689376e-05
[8960] train loss: 0.29018258303403854, lr: 4.999999873689376e-05
[8980] train loss: 0.278019055724144, lr: 4.999999873689376e-05
[9000] train loss: 0.29117144644260406, lr: 4.999999873689376e-05
[9020] train loss: 0.2795344516634941, lr: 9.994393622037023e-05
[9040] train loss: 0.21491424553096294, lr: 9.969501115847379e-05
[9060] train loss: 0.24544969201087952, lr: 9.924798359861597e-05
[9080] train loss: 0.42137162759900093, lr: 9.860464342636988e-05
[9100] train loss: 0.5695165079087019, lr: 9.776754450285807e-05
[9120] train loss: 1.052764419466257, lr: 9.67400410445407e-05
[9140] train loss: 1.0235942006111145, lr: 9.552620758768171e-05
[9160] train loss: 0.5751422792673111, lr: 9.413089719600976e-05
[9180] train loss: 0.7132077179849148, lr: 9.255966870114207e-05
[9200] train loss: 0.3513566516339779, lr: 9.081878670258448e-05
[9220] train loss: 3.0878072530031204, lr: 8.891518518794328e-05
[9240] train loss: 1.459841676056385, lr: 8.68564602569677e-05
[9260] train loss: 1.5484626963734627, lr: 8.46508119138889e-05
[9280] train loss: 0.9132148027420044, lr: 8.230703679146245e-05
[9300] train loss: 0.6255715414881706, lr: 7.983447721926495e-05
[9320] train loss: 0.7153781950473785, lr: 7.724298484390602e-05
[9340] train loss: 6.404130131006241, lr: 7.454289880115539e-05
[9360] train loss: 2.0873550921678543, lr: 7.174497295636684e-05
[9380] train loss: 1.4058346301317215, lr: 6.886036862852052e-05
[9400] train loss: 1.137163519859314, lr: 6.590057455468923e-05
[9420] train loss: 1.4122962281107903, lr: 6.28774068900384e-05
[9440] train loss: 3.2872496843338013, lr: 5.980289643048309e-05
[9460] train loss: 13.498452834784985, lr: 5.668931407853961e-05
[9480] train loss: 3.4788550436496735, lr: 5.354906534194015e-05
[9500] train loss: 1.6762778386473656, lr: 5.039466850575991e-05
[9520] train loss: 1.8688743263483047, lr: 4.999999873689376e-05
[9540] train loss: 0.9326289892196655, lr: 4.999999873689376e-05
[9560] train loss: 1.30966567248106, lr: 4.999999873689376e-05
[9580] train loss: 1.7833727449178696, lr: 4.999999873689376e-05
[9600] train loss: 2.451927289366722, lr: 4.999999873689376e-05
[9620] train loss: 1.4073783457279205, lr: 4.999999873689376e-05
[9640] train loss: 0.7193111553788185, lr: 4.999999873689376e-05
[9660] train loss: 0.6605260409414768, lr: 4.999999873689376e-05
[9680] train loss: 1.2766362577676773, lr: 4.999999873689376e-05
[9700] train loss: 1.0218944549560547, lr: 4.999999873689376e-05
[9720] train loss: 0.8978398889303207, lr: 4.999999873689376e-05
[9740] train loss: 4.023864567279816, lr: 4.999999873689376e-05
[9760] train loss: 0.998737022280693, lr: 4.999999873689376e-05
[9780] train loss: 0.6697986796498299, lr: 4.999999873689376e-05
[9800] train loss: 0.5736615285277367, lr: 4.999999873689376e-05
[9820] train loss: 0.5348819270730019, lr: 4.999999873689376e-05
[9840] train loss: 0.7317961603403091, lr: 4.999999873689376e-05
[9860] train loss: 0.42822372168302536, lr: 4.999999873689376e-05
[9880] train loss: 0.6835531741380692, lr: 4.999999873689376e-05
[9900] train loss: 0.6884047389030457, lr: 4.999999873689376e-05
[9920] train loss: 0.8013181835412979, lr: 4.999999873689376e-05
[9940] train loss: 0.800273522734642, lr: 4.999999873689376e-05
[9960] train loss: 1.3078155741095543, lr: 4.999999873689376e-05
[9980] train loss: 0.5864959061145782, lr: 4.999999873689376e-05
[10000] train loss: 1.3011418282985687, lr: 4.999999873689376e-05
[10020] train loss: 0.8351920917630196, lr: 9.994393622037023e-05
[10040] train loss: 2.4995979219675064, lr: 9.969501115847379e-05
[10060] train loss: 6.044188544154167, lr: 9.924798359861597e-05
[10080] train loss: 1.7051294818520546, lr: 9.860464342636988e-05
[10100] train loss: 1.2804341316223145, lr: 9.776754450285807e-05
[10120] train loss: 1.3587762266397476, lr: 9.67400410445407e-05
[10140] train loss: 0.7523723840713501, lr: 9.552620758768171e-05
[10160] train loss: 0.5172588303685188, lr: 9.413089719600976e-05
[10180] train loss: 0.3979281149804592, lr: 9.255966870114207e-05
[10200] train loss: 0.3395684286952019, lr: 9.081878670258448e-05
[10220] train loss: 0.31660840287804604, lr: 8.891518518794328e-05
[10240] train loss: 0.37604498118162155, lr: 8.68564602569677e-05
[10260] train loss: 4.069455832242966, lr: 8.46508119138889e-05
[10280] train loss: 1.5225540846586227, lr: 8.230703679146245e-05
[10300] train loss: 0.550865039229393, lr: 7.983447721926495e-05
[10320] train loss: 2.0791690945625305, lr: 7.724298484390602e-05
[10340] train loss: 0.7025173828005791, lr: 7.454289880115539e-05
[10360] train loss: 1.923716962337494, lr: 7.174497295636684e-05
[10380] train loss: 1.8901981487870216, lr: 6.886036862852052e-05
[10400] train loss: 1.6333176046609879, lr: 6.590057455468923e-05
[10420] train loss: 1.8298570066690445, lr: 6.28774068900384e-05
[10440] train loss: 1.8875964507460594, lr: 5.980289643048309e-05
[10460] train loss: 1.7722833640873432, lr: 5.668931407853961e-05
[10480] train loss: 1.481110766530037, lr: 5.354906534194015e-05
[10500] train loss: 2.243053652346134, lr: 5.039466850575991e-05
[10520] train loss: 0.9495437368750572, lr: 4.999999873689376e-05
[10540] train loss: 1.0530097633600235, lr: 4.999999873689376e-05
[10560] train loss: 0.7714552655816078, lr: 4.999999873689376e-05
[10580] train loss: 0.7113063260912895, lr: 4.999999873689376e-05
[10600] train loss: 0.5872795134782791, lr: 4.999999873689376e-05
[10620] train loss: 0.5132116004824638, lr: 4.999999873689376e-05
[10640] train loss: 0.5324972122907639, lr: 4.999999873689376e-05
[10660] train loss: 0.3795353025197983, lr: 4.999999873689376e-05
[10680] train loss: 0.2808697894215584, lr: 4.999999873689376e-05
[10700] train loss: 0.2578808143734932, lr: 4.999999873689376e-05
[10720] train loss: 0.32783951237797737, lr: 4.999999873689376e-05
[10740] train loss: 0.31776566803455353, lr: 4.999999873689376e-05
[10760] train loss: 1.4114746153354645, lr: 4.999999873689376e-05
[10780] train loss: 1.0141512602567673, lr: 4.999999873689376e-05
[10800] train loss: 0.5902641788125038, lr: 4.999999873689376e-05
[10820] train loss: 0.5608491599559784, lr: 4.999999873689376e-05
[10840] train loss: 0.6605245396494865, lr: 4.999999873689376e-05
[10860] train loss: 0.4952056109905243, lr: 4.999999873689376e-05
[10880] train loss: 1.0242025256156921, lr: 4.999999873689376e-05
[10900] train loss: 1.3136149644851685, lr: 4.999999873689376e-05
[10920] train loss: 0.8965440317988396, lr: 4.999999873689376e-05
[10940] train loss: 0.97081358730793, lr: 4.999999873689376e-05
[10960] train loss: 0.809074379503727, lr: 4.999999873689376e-05
[10980] train loss: 1.9631368666887283, lr: 4.999999873689376e-05
[11000] train loss: 1.0647947937250137, lr: 4.999999873689376e-05
[11020] train loss: 0.7883893549442291, lr: 9.994393622037023e-05
[11040] train loss: 1.0548476576805115, lr: 9.969501115847379e-05
[11060] train loss: 2.19169432669878, lr: 9.924798359861597e-05
[11080] train loss: 1.256452552974224, lr: 9.860464342636988e-05
[11100] train loss: 1.2488476410508156, lr: 9.776754450285807e-05
[11120] train loss: 0.7214997932314873, lr: 9.67400410445407e-05
[11140] train loss: 0.5572804361581802, lr: 9.552620758768171e-05
[11160] train loss: 0.7233020514249802, lr: 9.413089719600976e-05
[11180] train loss: 0.9359922558069229, lr: 9.255966870114207e-05
[11200] train loss: 1.1885061971843243, lr: 9.081878670258448e-05
[11220] train loss: 0.6811685413122177, lr: 8.891518518794328e-05
[11240] train loss: 0.9951949007809162, lr: 8.68564602569677e-05
[11260] train loss: 0.9072538465261459, lr: 8.46508119138889e-05
[11280] train loss: 1.2127902209758759, lr: 8.230703679146245e-05
[11300] train loss: 1.029833346605301, lr: 7.983447721926495e-05
[11320] train loss: 0.5443796664476395, lr: 7.724298484390602e-05
[11340] train loss: 0.40485452860593796, lr: 7.454289880115539e-05
[11360] train loss: 0.7639045864343643, lr: 7.174497295636684e-05
[11380] train loss: 0.6453035473823547, lr: 6.886036862852052e-05
[11400] train loss: 0.49816036969423294, lr: 6.590057455468923e-05
[11420] train loss: 0.5063749998807907, lr: 6.28774068900384e-05
[11440] train loss: 0.6349309608340263, lr: 5.980289643048309e-05
[11460] train loss: 0.46324343234300613, lr: 5.668931407853961e-05
[11480] train loss: 0.6162557452917099, lr: 5.354906534194015e-05
[11500] train loss: 1.0087349191308022, lr: 5.039466850575991e-05
[11520] train loss: 0.7980727851390839, lr: 4.999999873689376e-05
[11540] train loss: 0.4389427974820137, lr: 4.999999873689376e-05
[11560] train loss: 0.40354107320308685, lr: 4.999999873689376e-05
[11580] train loss: 0.3952263779938221, lr: 4.999999873689376e-05
[11600] train loss: 0.6283179763704538, lr: 4.999999873689376e-05
[11620] train loss: 0.524584025144577, lr: 4.999999873689376e-05
[11640] train loss: 0.38948480039834976, lr: 4.999999873689376e-05
[11660] train loss: 0.9586396999657154, lr: 4.999999873689376e-05
[11680] train loss: 1.2775397598743439, lr: 4.999999873689376e-05
[11700] train loss: 0.8458214849233627, lr: 4.999999873689376e-05
[11720] train loss: 1.053252175450325, lr: 4.999999873689376e-05
[11740] train loss: 8.393092833459377, lr: 4.999999873689376e-05
[11760] train loss: 1.6436353921890259, lr: 4.999999873689376e-05
[11780] train loss: 4.775126248598099, lr: 4.999999873689376e-05
[11800] train loss: 1.7175132781267166, lr: 4.999999873689376e-05
[11820] train loss: 0.8238095194101334, lr: 4.999999873689376e-05
[11840] train loss: 1.8774415403604507, lr: 4.999999873689376e-05
[11860] train loss: 2.2336066216230392, lr: 4.999999873689376e-05
[11880] train loss: 1.514382928609848, lr: 4.999999873689376e-05
[11900] train loss: 0.9585385471582413, lr: 4.999999873689376e-05
[11920] train loss: 0.9598699361085892, lr: 4.999999873689376e-05
[11940] train loss: 1.2541628628969193, lr: 4.999999873689376e-05
[11960] train loss: 0.9200528338551521, lr: 4.999999873689376e-05
[11980] train loss: 0.5987142771482468, lr: 4.999999873689376e-05
[12000] train loss: 0.44541049003601074, lr: 4.999999873689376e-05
[12020] train loss: 0.2700705900788307, lr: 9.994393622037023e-05
[12040] train loss: 0.3843230903148651, lr: 9.969501115847379e-05
[12060] train loss: 0.24388215690851212, lr: 9.924798359861597e-05
[12080] train loss: 0.2607465460896492, lr: 9.860464342636988e-05
[12100] train loss: 0.30632607638835907, lr: 9.776754450285807e-05
[12120] train loss: 0.8394543007016182, lr: 9.67400410445407e-05
[12140] train loss: 6.039902850985527, lr: 9.552620758768171e-05
[12160] train loss: 1.7185389250516891, lr: 9.413089719600976e-05
[12180] train loss: 1.119606301188469, lr: 9.255966870114207e-05
[12200] train loss: 2.8623575419187546, lr: 9.081878670258448e-05
[12220] train loss: 3.6371384114027023, lr: 8.891518518794328e-05
[12240] train loss: 1.3216837495565414, lr: 8.68564602569677e-05
[12260] train loss: 1.0525812059640884, lr: 8.46508119138889e-05
[12280] train loss: 0.9223215356469154, lr: 8.230703679146245e-05
[12300] train loss: 2.1133681386709213, lr: 7.983447721926495e-05
[12320] train loss: 6.203779552131891, lr: 7.724298484390602e-05
[12340] train loss: 2.1901717260479927, lr: 7.454289880115539e-05
[12360] train loss: 1.4998988434672356, lr: 7.174497295636684e-05
[12380] train loss: 0.8981178402900696, lr: 6.886036862852052e-05
[12400] train loss: 0.5841831415891647, lr: 6.590057455468923e-05
[12420] train loss: 0.2932208552956581, lr: 6.28774068900384e-05
[12440] train loss: 0.25234536454081535, lr: 5.980289643048309e-05
[12460] train loss: 0.17056176625192165, lr: 5.668931407853961e-05
[12480] train loss: 0.17114145308732986, lr: 5.354906534194015e-05
[12500] train loss: 0.18780315667390823, lr: 5.039466850575991e-05
[12520] train loss: 0.19129251316189766, lr: 4.999999873689376e-05
[12540] train loss: 0.2735880836844444, lr: 4.999999873689376e-05
[12560] train loss: 0.18844081088900566, lr: 4.999999873689376e-05
[12580] train loss: 0.17231903597712517, lr: 4.999999873689376e-05
[12600] train loss: 0.20883609913289547, lr: 4.999999873689376e-05
[12620] train loss: 0.17514652758836746, lr: 4.999999873689376e-05
[12640] train loss: 0.31420423835515976, lr: 4.999999873689376e-05
[12660] train loss: 0.22583374753594398, lr: 4.999999873689376e-05
[12680] train loss: 0.21627568826079369, lr: 4.999999873689376e-05
[12700] train loss: 0.23879916593432426, lr: 4.999999873689376e-05
[12720] train loss: 0.2696671858429909, lr: 4.999999873689376e-05
[12740] train loss: 0.629556342959404, lr: 4.999999873689376e-05
[12760] train loss: 1.3014285415410995, lr: 4.999999873689376e-05
[12780] train loss: 1.2647025883197784, lr: 4.999999873689376e-05
[12800] train loss: 0.9489225074648857, lr: 4.999999873689376e-05
[12820] train loss: 2.078313946723938, lr: 4.999999873689376e-05
[12840] train loss: 3.883134610950947, lr: 4.999999873689376e-05
[12860] train loss: 5.498089782893658, lr: 4.999999873689376e-05
[12880] train loss: 2.255465157330036, lr: 4.999999873689376e-05
[12900] train loss: 3.7933253347873688, lr: 4.999999873689376e-05
[12920] train loss: 3.3669871240854263, lr: 4.999999873689376e-05
[12940] train loss: 4.481363862752914, lr: 4.999999873689376e-05
[12960] train loss: 7.139713756740093, lr: 4.999999873689376e-05
[12980] train loss: 7.84006242454052, lr: 4.999999873689376e-05
[13000] train loss: 2.719172842800617, lr: 4.999999873689376e-05
[13020] train loss: 2.748790554702282, lr: 9.994393622037023e-05
[13040] train loss: 1.7066489458084106, lr: 9.969501115847379e-05
[13060] train loss: 4.521387107670307, lr: 9.924798359861597e-05
[13080] train loss: 9.018728293478489, lr: 9.860464342636988e-05
[13100] train loss: 17.93693332374096, lr: 9.776754450285807e-05
[13120] train loss: 8.247207760810852, lr: 9.67400410445407e-05
[13140] train loss: 15.049121215939522, lr: 9.552620758768171e-05
[13160] train loss: 8.014503479003906, lr: 9.413089719600976e-05
[13180] train loss: 9.894345998764038, lr: 9.255966870114207e-05
[13200] train loss: 5.877424329519272, lr: 9.081878670258448e-05
[13220] train loss: 10.391129657626152, lr: 8.891518518794328e-05
[13240] train loss: 3.4354659616947174, lr: 8.68564602569677e-05
[13260] train loss: 4.838882923126221, lr: 8.46508119138889e-05
[13280] train loss: 6.477646589279175, lr: 8.230703679146245e-05
[13300] train loss: 5.1849746108055115, lr: 7.983447721926495e-05
[13320] train loss: 1.496494621038437, lr: 7.724298484390602e-05
[13340] train loss: 0.47430459409952164, lr: 7.454289880115539e-05
[13360] train loss: 0.45533450692892075, lr: 7.174497295636684e-05
[13380] train loss: 0.3749445304274559, lr: 6.886036862852052e-05
[13400] train loss: 0.4547121860086918, lr: 6.590057455468923e-05
[13420] train loss: 0.4135507494211197, lr: 6.28774068900384e-05
[13440] train loss: 0.3334915526211262, lr: 5.980289643048309e-05
[13460] train loss: 0.5082700438797474, lr: 5.668931407853961e-05
[13480] train loss: 0.3974585235118866, lr: 5.354906534194015e-05
[13500] train loss: 0.41295577585697174, lr: 5.039466850575991e-05
[13520] train loss: 0.7256852425634861, lr: 4.999999873689376e-05
[13540] train loss: 0.5192015953361988, lr: 4.999999873689376e-05
[13560] train loss: 0.45782653242349625, lr: 4.999999873689376e-05
[13580] train loss: 0.32444991171360016, lr: 4.999999873689376e-05
[13600] train loss: 6.664847895503044, lr: 4.999999873689376e-05
[13620] train loss: 2.094732955098152, lr: 4.999999873689376e-05
[13640] train loss: 2.748649738729, lr: 4.999999873689376e-05
[13660] train loss: 0.7147965729236603, lr: 4.999999873689376e-05
[13680] train loss: 0.4286167770624161, lr: 4.999999873689376e-05
[13700] train loss: 0.4346987307071686, lr: 4.999999873689376e-05
[13720] train loss: 0.43132635578513145, lr: 4.999999873689376e-05
[13740] train loss: 0.510011438280344, lr: 4.999999873689376e-05
[13760] train loss: 0.3951438255608082, lr: 4.999999873689376e-05
[13780] train loss: 0.49105097353458405, lr: 4.999999873689376e-05
[13800] train loss: 0.3717937134206295, lr: 4.999999873689376e-05
[13820] train loss: 0.39374664053320885, lr: 4.999999873689376e-05
[13840] train loss: 7.036134481430054, lr: 4.999999873689376e-05
[13860] train loss: 9.923437744379044, lr: 4.999999873689376e-05
[13880] train loss: 3.0640954226255417, lr: 4.999999873689376e-05
[13900] train loss: 2.1895038560032845, lr: 4.999999873689376e-05
[13920] train loss: 2.590990573167801, lr: 4.999999873689376e-05
[13940] train loss: 1.5552213713526726, lr: 4.999999873689376e-05
[13960] train loss: 1.891179732978344, lr: 4.999999873689376e-05
[13980] train loss: 0.9804013818502426, lr: 4.999999873689376e-05
[14000] train loss: 2.201333574950695, lr: 4.999999873689376e-05
[14020] train loss: 0.9196033030748367, lr: 9.994393622037023e-05
[14040] train loss: 2.0506419986486435, lr: 9.969501115847379e-05
[14060] train loss: 1.3389907330274582, lr: 9.924798359861597e-05
[14080] train loss: 1.1274127587676048, lr: 9.860464342636988e-05
[14100] train loss: 0.899353101849556, lr: 9.776754450285807e-05
[14120] train loss: 0.6860122159123421, lr: 9.67400410445407e-05
[20] train loss: 0.09779422357678413, lr: 0.0009994393913075328
[40] train loss: -0.12144928425550461, lr: 0.0009969500824809074
[60] train loss: -0.27142834663391113, lr: 0.000992479850538075
[80] train loss: -0.24676496535539627, lr: 0.000986046390607953
[100] train loss: -0.34667035192251205, lr: 0.0009776754304766655
[120] train loss: -0.09736664965748787, lr: 0.0009674003813415766
[140] train loss: -0.3387553542852402, lr: 0.0009552621049806476
[160] train loss: -0.2715846225619316, lr: 0.0009413089719600976
[180] train loss: -0.2890167571604252, lr: 0.0009255966870114207
[200] train loss: -0.2905846796929836, lr: 0.00090818788157776
[220] train loss: -0.311333741992712, lr: 0.0008891518809832633
[240] train loss: -0.36955972760915756, lr: 0.0008685645880177617
[260] train loss: -0.35294578969478607, lr: 0.0008465081336908042
[280] train loss: -0.2858785204589367, lr: 0.0008230703533627093
[300] train loss: -0.3032634072005749, lr: 0.0007983447285369039
[320] train loss: -0.3256269171833992, lr: 0.0007724298629909754
[340] train loss: -0.38742177933454514, lr: 0.0007454289589077234
[360] train loss: -0.37897057831287384, lr: 0.0007174497004598379
[20] train loss: 2.3460662811994553, metric: 36.3413462638855, lr: 0.0009994393913075328
[40] train loss: -0.10397123172879219, metric: 11.644040584564209, lr: 0.0009969500824809074
[60] train loss: -0.17292475700378418, metric: 7.394883155822754, lr: 0.000992479850538075
[80] train loss: -0.30364202708005905, metric: 6.645105838775635, lr: 0.000986046390607953
[100] train loss: -0.27190815284848213, metric: 6.7030497789382935, lr: 0.0009776754304766655
[120] train loss: -0.27988211438059807, metric: 6.190004587173462, lr: 0.0009674003813415766
[140] train loss: -0.23085037991404533, metric: 5.003183841705322, lr: 0.0009552621049806476
[160] train loss: -0.32353727519512177, metric: 6.732977628707886, lr: 0.0009413089719600976
[180] train loss: -0.08020077273249626, metric: 5.338447868824005, lr: 0.0009255966870114207
[200] train loss: -0.23293432965874672, metric: 6.054304599761963, lr: 0.00090818788157776
[220] train loss: -0.36721252650022507, metric: 5.850660860538483, lr: 0.0008891518809832633
[240] train loss: -0.3307250775396824, metric: 4.598925709724426, lr: 0.0008685645880177617
[260] train loss: -0.21388941630721092, metric: 7.758741855621338, lr: 0.0008465081336908042
[280] train loss: -0.2873574048280716, metric: 5.863815665245056, lr: 0.0008230703533627093
[300] train loss: -0.2582220435142517, metric: 5.127739906311035, lr: 0.0007983447285369039
[320] train loss: -0.12873179465532303, metric: 7.0494749546051025, lr: 0.0007724298629909754
[340] train loss: 0.14054156094789505, metric: 7.492677211761475, lr: 0.0007454289589077234
[360] train loss: 0.1346188299357891, metric: 9.56136965751648, lr: 0.0007174497004598379
[380] train loss: -0.06178361549973488, metric: 8.846023559570312, lr: 0.00068860367173329
[400] train loss: -0.19609656184911728, metric: 11.92373538017273, lr: 0.0006590057746507227
[420] train loss: -0.32965491339564323, metric: 7.2769423723220825, lr: 0.0006287740543484688
[440] train loss: -0.3188948296010494, metric: 5.687878131866455, lr: 0.000598029000684619
[460] train loss: -0.33878061920404434, metric: 5.312743425369263, lr: 0.0005668931407853961
[480] train loss: -0.3511185571551323, metric: 4.414995610713959, lr: 0.0005354906315915287
[500] train loss: -0.38184306770563126, metric: 5.051991581916809, lr: 0.0005039466777816415
[520] train loss: 1.84308647736907, metric: 21.043309688568115, lr: 0.0004723869787994772
[540] train loss: 0.7377786431461573, metric: 14.808075189590454, lr: 0.0004409373505041003
[560] train loss: -0.05469703674316406, metric: 11.509179592132568, lr: 0.0004097231721971184
[580] train loss: -0.10449700057506561, metric: 7.010149598121643, lr: 0.000378868862753734
[600] train loss: 0.3318011872470379, metric: 8.78177011013031, lr: 0.00034849741496145725
[620] train loss: 0.02407926507294178, metric: 9.382238626480103, lr: 0.0003187299007549882
[640] train loss: 0.0971430167555809, metric: 9.69956636428833, lr: 0.0002896849764510989
[660] train loss: -0.19899142906069756, metric: 6.503705620765686, lr: 0.0002614784170873463
[680] train loss: -0.06296145170927048, metric: 6.633209466934204, lr: 0.00023422270896844566
[700] train loss: 0.22442088276147842, metric: 9.740732908248901, lr: 0.00020802643848583102
[720] train loss: 5.698771573603153, metric: 14.923296451568604, lr: 0.00018299407383892685
[740] train loss: 0.5215114913880825, metric: 13.183852434158325, lr: 0.00015922538295853883
[760] train loss: -0.0735107772052288, metric: 7.305801868438721, lr: 0.00013681512791663408
[780] train loss: 0.39530323073267937, metric: 10.388341903686523, lr: 0.00011585262109292671
[800] train loss: -0.1537439189851284, metric: 11.763997316360474, lr: 9.999999747378752e-05
[820] train loss: 0.9437199607491493, metric: 13.521159648895264, lr: 9.999999747378752e-05
[840] train loss: 0.5147682428359985, metric: 14.813023924827576, lr: 9.999999747378752e-05
[860] train loss: 0.4077131748199463, metric: 14.169882774353027, lr: 9.999999747378752e-05
[880] train loss: 2.502368237823248, metric: 11.852234363555908, lr: 9.999999747378752e-05
[900] train loss: 0.628823533654213, metric: 9.674870491027832, lr: 9.999999747378752e-05
[920] train loss: 0.1672007404267788, metric: 8.311597347259521, lr: 9.999999747378752e-05
[940] train loss: 0.439712330698967, metric: 8.027224481105804, lr: 9.999999747378752e-05
[960] train loss: 0.1206246167421341, metric: 12.293926298618317, lr: 9.999999747378752e-05
[980] train loss: 0.06826857849955559, metric: 7.806696772575378, lr: 9.999999747378752e-05
[1000] train loss: -0.07695642486214638, metric: 7.351475358009338, lr: 9.999999747378752e-05
[1020] train loss: -0.17738303169608116, metric: 6.4992804527282715, lr: 0.0009994393913075328
[1040] train loss: 0.2851553075015545, metric: 8.844931364059448, lr: 0.0009969500824809074
[1060] train loss: -0.3230349123477936, metric: 4.850268721580505, lr: 0.000992479850538075
[1080] train loss: -0.36240629851818085, metric: 6.426233410835266, lr: 0.000986046390607953
[1100] train loss: -0.37102603167295456, metric: 5.012825965881348, lr: 0.0009776754304766655
[1120] train loss: -0.37931662797927856, metric: 3.718468427658081, lr: 0.0009674003813415766
[1140] train loss: -0.3594702333211899, metric: 5.864101767539978, lr: 0.0009552621049806476
[1160] train loss: -0.3282061889767647, metric: 5.9421626329422, lr: 0.0009413089719600976
[1180] train loss: -0.3441821113228798, metric: 4.761200189590454, lr: 0.0009255966870114207
[1200] train loss: -0.35153745859861374, metric: 4.817637622356415, lr: 0.00090818788157776
[1220] train loss: -0.398106649518013, metric: 4.222399890422821, lr: 0.0008891518809832633
[1240] train loss: -0.23472147062420845, metric: 5.466636776924133, lr: 0.0008685645880177617
[1260] train loss: -0.35332686454057693, metric: 4.095889389514923, lr: 0.0008465081336908042
[1280] train loss: -0.35858719795942307, metric: 4.27732253074646, lr: 0.0008230703533627093
[1300] train loss: -0.37148910760879517, metric: 4.418554425239563, lr: 0.0007983447285369039
[1320] train loss: -0.4119187518954277, metric: 3.1556098461151123, lr: 0.0007724298629909754
[1340] train loss: -0.4291854128241539, metric: 3.1929842233657837, lr: 0.0007454289589077234
[1360] train loss: -0.4303041025996208, metric: 3.4429425597190857, lr: 0.0007174497004598379
[1380] train loss: -0.4152415841817856, metric: 3.7281092405319214, lr: 0.00068860367173329
[1400] train loss: -0.40582622587680817, metric: 4.107456982135773, lr: 0.0006590057746507227
[1420] train loss: -0.41608311235904694, metric: 3.3589102625846863, lr: 0.0006287740543484688
[1440] train loss: -0.4095195010304451, metric: 3.4853837490081787, lr: 0.000598029000684619
[1460] train loss: -0.38584383577108383, metric: 5.862301528453827, lr: 0.0005668931407853961
[1480] train loss: -0.03716161847114563, metric: 5.221014559268951, lr: 0.0005354906315915287
[1500] train loss: -0.32090212404727936, metric: 5.4414971470832825, lr: 0.0005039466777816415
[1520] train loss: -0.36584626138210297, metric: 4.005787789821625, lr: 0.0004723869787994772
[1540] train loss: 0.1817178912460804, metric: 13.15145468711853, lr: 0.0004409373505041003
[1560] train loss: -0.32743988931179047, metric: 7.2471917271614075, lr: 0.0004097231721971184
[1580] train loss: -0.393426813185215, metric: 5.738895416259766, lr: 0.000378868862753734
[1600] train loss: -0.37290070950984955, metric: 5.706797242164612, lr: 0.00034849741496145725
[1620] train loss: -0.3896647319197655, metric: 4.972356915473938, lr: 0.0003187299007549882
[1640] train loss: -0.3918624669313431, metric: 4.897181928157806, lr: 0.0002896849764510989
[1660] train loss: -0.38039562851190567, metric: 6.648763298988342, lr: 0.0002614784170873463
[1680] train loss: -0.36631545424461365, metric: 4.86840295791626, lr: 0.00023422270896844566
[1700] train loss: -0.02531479299068451, metric: 10.956076502799988, lr: 0.00020802643848583102
[1720] train loss: -0.3221623972058296, metric: 5.642475843429565, lr: 0.00018299407383892685
[1740] train loss: -0.30247944220900536, metric: 6.042377829551697, lr: 0.00015922538295853883
[1760] train loss: -0.32513783499598503, metric: 6.894052028656006, lr: 0.00013681512791663408
[1780] train loss: -0.3034619688987732, metric: 5.470221519470215, lr: 0.00011585262109292671
[1800] train loss: -0.2759111039340496, metric: 6.4503196477890015, lr: 9.999999747378752e-05
[1820] train loss: -0.29588691145181656, metric: 5.799729824066162, lr: 9.999999747378752e-05
[1840] train loss: -0.31780973076820374, metric: 5.108398675918579, lr: 9.999999747378752e-05
[1860] train loss: -0.3550015538930893, metric: 5.732122421264648, lr: 9.999999747378752e-05
[1880] train loss: -0.37678368389606476, metric: 4.263398885726929, lr: 9.999999747378752e-05
[1900] train loss: -0.3545675240457058, metric: 5.268363833427429, lr: 9.999999747378752e-05
[1920] train loss: -0.25138260424137115, metric: 6.372099816799164, lr: 9.999999747378752e-05
[1940] train loss: -0.34685181826353073, metric: 6.046670198440552, lr: 9.999999747378752e-05
[1960] train loss: -0.3541625589132309, metric: 5.668265759944916, lr: 9.999999747378752e-05
[1980] train loss: -0.29078513383865356, metric: 5.19913375377655, lr: 9.999999747378752e-05
[2000] train loss: 0.4111615866422653, metric: 7.355701684951782, lr: 9.999999747378752e-05
[2020] train loss: 0.13831643760204315, metric: 6.8292237520217896, lr: 0.0009994393913075328
[2040] train loss: -0.22883712872862816, metric: 5.659916162490845, lr: 0.0009969500824809074
[2060] train loss: 0.5790282115340233, metric: 10.971313953399658, lr: 0.000992479850538075
[2080] train loss: 0.5101111494004726, metric: 8.901278853416443, lr: 0.000986046390607953
[2100] train loss: 1.1716794446110725, metric: 14.323024272918701, lr: 0.0009776754304766655
[2120] train loss: -0.020545803010463715, metric: 9.718785405158997, lr: 0.0009674003813415766
[2140] train loss: 0.3142361491918564, metric: 13.326253414154053, lr: 0.0009552621049806476
[2160] train loss: 1.0706523470580578, metric: 11.59432303905487, lr: 0.0009413089719600976
[2180] train loss: 1.0691242329776287, metric: 14.448539733886719, lr: 0.0009255966870114207
[2200] train loss: 0.7392229028046131, metric: 10.744877457618713, lr: 0.00090818788157776
[2220] train loss: -0.043427009135484695, metric: 9.328971028327942, lr: 0.0008891518809832633
[2240] train loss: -0.11680501699447632, metric: 6.953194677829742, lr: 0.0008685645880177617
[2260] train loss: -0.009249910712242126, metric: 8.144803285598755, lr: 0.0008465081336908042
[2280] train loss: 0.9442203156650066, metric: 14.100892543792725, lr: 0.0008230703533627093
[2300] train loss: 0.427566260099411, metric: 8.130489826202393, lr: 0.0007983447285369039
[2320] train loss: 0.25137755647301674, metric: 7.979159116744995, lr: 0.0007724298629909754
[2340] train loss: 2.079987484961748, metric: 10.060043096542358, lr: 0.0007454289589077234
[2360] train loss: 2.759890992194414, metric: 13.670880317687988, lr: 0.0007174497004598379
[2380] train loss: 1.6196224950253963, metric: 22.455894947052002, lr: 0.00068860367173329
[2400] train loss: 0.7935447506606579, metric: 11.189865589141846, lr: 0.0006590057746507227
[2420] train loss: 1.3399833589792252, metric: 10.85522198677063, lr: 0.0006287740543484688
[2440] train loss: 0.5845695324242115, metric: 9.828125476837158, lr: 0.000598029000684619
[2460] train loss: 0.21589430794119835, metric: 10.267390370368958, lr: 0.0005668931407853961
[2480] train loss: 1.9759347140789032, metric: 13.713242769241333, lr: 0.0005354906315915287
[2500] train loss: 5.982077978551388, metric: 18.31672191619873, lr: 0.0005039466777816415
[2520] train loss: 3.5111602805554867, metric: 14.3673757314682, lr: 0.0004723869787994772
[2540] train loss: 0.6787674985826015, metric: 10.433600425720215, lr: 0.0004409373505041003
[2560] train loss: 9.851075757294893, metric: 17.72153091430664, lr: 0.0004097231721971184
[2580] train loss: 3.1381488144397736, metric: 24.350560188293457, lr: 0.000378868862753734
[2600] train loss: 0.3031591847538948, metric: 17.98802089691162, lr: 0.00034849741496145725
[2620] train loss: -0.24558084085583687, metric: 12.026610851287842, lr: 0.0003187299007549882
[2640] train loss: -0.29687294363975525, metric: 8.400929927825928, lr: 0.0002896849764510989
[2660] train loss: -0.28869548812508583, metric: 7.063214421272278, lr: 0.0002614784170873463
[2680] train loss: -0.1960976980626583, metric: 7.147916197776794, lr: 0.00023422270896844566
[2700] train loss: -0.10260244086384773, metric: 11.120673418045044, lr: 0.00020802643848583102
[2720] train loss: -0.024519413709640503, metric: 11.007473945617676, lr: 0.00018299407383892685
[2740] train loss: -0.30557113140821457, metric: 9.298066139221191, lr: 0.00015922538295853883
[2760] train loss: -0.2696128822863102, metric: 7.9066321849823, lr: 0.00013681512791663408
[2780] train loss: -0.2389240600168705, metric: 7.850330352783203, lr: 0.00011585262109292671
[2800] train loss: -0.26594816893339157, metric: 7.945277452468872, lr: 9.999999747378752e-05
[2820] train loss: -0.2932491935789585, metric: 8.280685782432556, lr: 9.999999747378752e-05
[2840] train loss: -0.34320560842752457, metric: 7.8505178689956665, lr: 9.999999747378752e-05
[2860] train loss: -0.24020469561219215, metric: 11.711050510406494, lr: 9.999999747378752e-05
[2880] train loss: -0.21543186157941818, metric: 6.564868450164795, lr: 9.999999747378752e-05
[2900] train loss: 0.16570329666137695, metric: 11.409222602844238, lr: 9.999999747378752e-05
[2920] train loss: 0.11337035894393921, metric: 9.837053060531616, lr: 9.999999747378752e-05
[2940] train loss: -0.24958163499832153, metric: 9.652844071388245, lr: 9.999999747378752e-05
[2960] train loss: -0.19148439541459084, metric: 8.853622078895569, lr: 9.999999747378752e-05
[2980] train loss: -0.17549723386764526, metric: 9.693003416061401, lr: 9.999999747378752e-05
[3000] train loss: -0.15358267351984978, metric: 8.918832063674927, lr: 9.999999747378752e-05
[3020] train loss: 0.42773909494280815, metric: 10.462523698806763, lr: 0.0009994393913075328
[3040] train loss: -0.28714585304260254, metric: 5.909964561462402, lr: 0.0009969500824809074
[3060] train loss: -0.3121394142508507, metric: 5.044399976730347, lr: 0.000992479850538075
[3080] train loss: 0.548355296254158, metric: 15.020125389099121, lr: 0.000986046390607953
[3100] train loss: -0.19383595883846283, metric: 8.253145217895508, lr: 0.0009776754304766655
[3120] train loss: -0.21345772966742516, metric: 8.14319932460785, lr: 0.0009674003813415766
[3140] train loss: -0.09628085792064667, metric: 8.074753761291504, lr: 0.0009552621049806476
[3160] train loss: -0.13138193264603615, metric: 10.96230173110962, lr: 0.0009413089719600976
[3180] train loss: -0.18326428905129433, metric: 10.697580099105835, lr: 0.0009255966870114207
[3200] train loss: -0.07279431074857712, metric: 7.281421422958374, lr: 0.00090818788157776
[3220] train loss: -0.18639837577939034, metric: 5.670623064041138, lr: 0.0008891518809832633
[3240] train loss: -0.2049722671508789, metric: 7.458007574081421, lr: 0.0008685645880177617
[3260] train loss: -0.31606877595186234, metric: 5.382958471775055, lr: 0.0008465081336908042
[3280] train loss: -0.28529589995741844, metric: 5.037040293216705, lr: 0.0008230703533627093
[3300] train loss: -0.12901126593351364, metric: 9.827446460723877, lr: 0.0007983447285369039
[3320] train loss: 0.46194417774677277, metric: 17.69891881942749, lr: 0.0007724298629909754
[3340] train loss: 0.08956339210271835, metric: 14.298454999923706, lr: 0.0007454289589077234
[3360] train loss: -0.1607199665158987, metric: 8.276788234710693, lr: 0.0007174497004598379
[3380] train loss: -0.16262936033308506, metric: 7.534317970275879, lr: 0.00068860367173329
[3400] train loss: 0.17536873742938042, metric: 12.28612232208252, lr: 0.0006590057746507227
[3420] train loss: -0.11910213157534599, metric: 8.82336175441742, lr: 0.0006287740543484688
[3440] train loss: 0.8720670491456985, metric: 12.646366477012634, lr: 0.000598029000684619
[3460] train loss: 1.1200667060911655, metric: 8.775126099586487, lr: 0.0005668931407853961
[3480] train loss: 1.1041693687438965, metric: 21.546316623687744, lr: 0.0005354906315915287
[3500] train loss: 0.4340840056538582, metric: 14.14295220375061, lr: 0.0005039466777816415
[3520] train loss: 0.28462884575128555, metric: 7.356873035430908, lr: 0.0004723869787994772
[3540] train loss: -0.13637500256299973, metric: 8.10521125793457, lr: 0.0004409373505041003
[3560] train loss: -0.19467436894774437, metric: 5.119361519813538, lr: 0.0004097231721971184
[3580] train loss: 0.14022882655262947, metric: 7.474676609039307, lr: 0.000378868862753734
[3600] train loss: 14.373369812965393, metric: 56.12955093383789, lr: 0.00034849741496145725
[3620] train loss: 3.884994298219681, metric: 37.610637187957764, lr: 0.0003187299007549882
[3640] train loss: 1.0481825955212116, metric: 17.708247184753418, lr: 0.0002896849764510989
[3660] train loss: 22.431131947785616, metric: 23.169762134552002, lr: 0.0002614784170873463
[3680] train loss: 3.201793607324362, metric: 29.413336992263794, lr: 0.00023422270896844566
[3700] train loss: 8.031286403536797, metric: 31.721997261047363, lr: 0.00020802643848583102
[3720] train loss: 5.090486623346806, metric: 17.96147584915161, lr: 0.00018299407383892685
[3740] train loss: 2.372127939015627, metric: 17.66682004928589, lr: 0.00015922538295853883
[3760] train loss: 3.655811246484518, metric: 19.237396240234375, lr: 0.00013681512791663408
[3780] train loss: 4.361479565501213, metric: 18.636098384857178, lr: 0.00011585262109292671
[3800] train loss: 11.28391931951046, metric: 20.333812475204468, lr: 9.999999747378752e-05
[3820] train loss: 23.410876274108887, metric: 27.400461673736572, lr: 9.999999747378752e-05
[3840] train loss: 14.355063080787659, metric: 22.584623098373413, lr: 9.999999747378752e-05
[3860] train loss: 5.12645497918129, metric: 23.459383487701416, lr: 9.999999747378752e-05
[3880] train loss: 1.8687406927347183, metric: 16.40508794784546, lr: 9.999999747378752e-05
[3900] train loss: 6.5349781177937984, metric: 17.406768798828125, lr: 9.999999747378752e-05
[3920] train loss: 7.829225465655327, metric: 18.438382863998413, lr: 9.999999747378752e-05
[3940] train loss: 6.066370293498039, metric: 21.104512214660645, lr: 9.999999747378752e-05
[3960] train loss: 3.5157665610313416, metric: 16.649141311645508, lr: 9.999999747378752e-05
[3980] train loss: 1.469108484685421, metric: 16.567585945129395, lr: 9.999999747378752e-05
[4000] train loss: 9.080656006932259, metric: 22.625133514404297, lr: 9.999999747378752e-05
[4020] train loss: 0.7948000431060791, metric: 18.189993381500244, lr: 0.0009994393913075328
[4040] train loss: 0.5709970630705357, metric: 13.828452825546265, lr: 0.0009969500824809074
[4060] train loss: 4.027273241430521, metric: 17.571357011795044, lr: 0.000992479850538075
[4080] train loss: 7.435290299355984, metric: 16.4016170501709, lr: 0.000986046390607953
[4100] train loss: 5.453012570738792, metric: 23.632817268371582, lr: 0.0009776754304766655
[4120] train loss: 0.43201882019639015, metric: 15.665594339370728, lr: 0.0009674003813415766
[4140] train loss: 4.114193230867386, metric: 17.312716364860535, lr: 0.0009552621049806476
[4160] train loss: 0.29086875170469284, metric: 10.570119857788086, lr: 0.0009413089719600976
[4180] train loss: 0.011823844164609909, metric: 11.991065740585327, lr: 0.0009255966870114207
[4200] train loss: -0.18634091317653656, metric: 8.493034482002258, lr: 0.00090818788157776
[4220] train loss: -0.2255326621234417, metric: 8.691697835922241, lr: 0.0008891518809832633
[4240] train loss: -0.26135484501719475, metric: 7.790397524833679, lr: 0.0008685645880177617
[4260] train loss: -0.11554494127631187, metric: 10.411096096038818, lr: 0.0008465081336908042
[4280] train loss: -0.19465885311365128, metric: 8.035019159317017, lr: 0.0008230703533627093
[4300] train loss: -0.058610595762729645, metric: 8.876609563827515, lr: 0.0007983447285369039
[4320] train loss: -0.26567109301686287, metric: 7.180199861526489, lr: 0.0007724298629909754
[4340] train loss: -0.2583737187087536, metric: 9.43215811252594, lr: 0.0007454289589077234
[4360] train loss: 0.038998618721961975, metric: 13.797403335571289, lr: 0.0007174497004598379
[4380] train loss: 0.3217170685529709, metric: 13.534786939620972, lr: 0.00068860367173329
[4400] train loss: 0.11874855309724808, metric: 17.82313585281372, lr: 0.0006590057746507227
[4420] train loss: 0.2587205581367016, metric: 9.584233045578003, lr: 0.0006287740543484688
[4440] train loss: -0.01913924515247345, metric: 8.502310633659363, lr: 0.000598029000684619
[4460] train loss: 0.06975684687495232, metric: 12.778719186782837, lr: 0.0005668931407853961
[4480] train loss: 0.12210969254374504, metric: 12.924808144569397, lr: 0.0005354906315915287
[4500] train loss: -0.007645443081855774, metric: 9.465031147003174, lr: 0.0005039466777816415
[4520] train loss: 0.3590952567756176, metric: 13.6233549118042, lr: 0.0004723869787994772
[4540] train loss: 0.14923903346061707, metric: 13.320382356643677, lr: 0.0004409373505041003
[4560] train loss: -0.22105426713824272, metric: 9.817596673965454, lr: 0.0004097231721971184
[4580] train loss: -0.11975299194455147, metric: 10.755908131599426, lr: 0.000378868862753734
[4600] train loss: 0.006468087434768677, metric: 16.260093927383423, lr: 0.00034849741496145725
[4620] train loss: 0.8208526745438576, metric: 14.772366046905518, lr: 0.0003187299007549882
[4640] train loss: 0.22549352794885635, metric: 12.147441148757935, lr: 0.0002896849764510989
[4660] train loss: 0.19794709980487823, metric: 16.296308755874634, lr: 0.0002614784170873463
[4680] train loss: 0.12880072742700577, metric: 17.321326732635498, lr: 0.00023422270896844566
[4700] train loss: 0.06300078704953194, metric: 12.463164329528809, lr: 0.00020802643848583102
[4720] train loss: -0.19343522191047668, metric: 9.02825391292572, lr: 0.00018299407383892685
[4740] train loss: -0.06446199864149094, metric: 13.027743816375732, lr: 0.00015922538295853883
[4760] train loss: -0.17428302764892578, metric: 12.005245923995972, lr: 0.00013681512791663408
[4780] train loss: -0.06287211179733276, metric: 11.536398887634277, lr: 0.00011585262109292671
[4800] train loss: -0.09737563878297806, metric: 9.836473822593689, lr: 9.999999747378752e-05
[4820] train loss: -0.2239852473139763, metric: 9.846393942832947, lr: 9.999999747378752e-05
[4840] train loss: 0.94329384714365, metric: 18.635796308517456, lr: 9.999999747378752e-05
[4860] train loss: 4.365834750235081, metric: 30.341550827026367, lr: 9.999999747378752e-05
[4880] train loss: 10.955553524196148, metric: 23.95883846282959, lr: 9.999999747378752e-05
[4900] train loss: 6.882586449384689, metric: 22.074276447296143, lr: 9.999999747378752e-05
[4920] train loss: 4.185321792960167, metric: 25.78823184967041, lr: 9.999999747378752e-05
[4940] train loss: 1.6166468001902103, metric: 25.028255939483643, lr: 9.999999747378752e-05
[4960] train loss: 0.22931169345974922, metric: 17.30863642692566, lr: 9.999999747378752e-05
[4980] train loss: 0.27410194277763367, metric: 15.214537143707275, lr: 9.999999747378752e-05
[5000] train loss: 0.039296139031648636, metric: 12.187424421310425, lr: 9.999999747378752e-05
[5020] train loss: -0.009883861988782883, metric: 10.603507041931152, lr: 0.0009994393913075328
[5040] train loss: -0.14224160090088844, metric: 7.468914985656738, lr: 0.0009969500824809074
[5060] train loss: 0.3055109828710556, metric: 10.450172662734985, lr: 0.000992479850538075
[5080] train loss: 0.35753507539629936, metric: 10.591435432434082, lr: 0.000986046390607953
[5100] train loss: 5.202121198177338, metric: 16.084880352020264, lr: 0.0009776754304766655
[5120] train loss: 1.3285785466432571, metric: 30.24827766418457, lr: 0.0009674003813415766
[5140] train loss: 3.5713774412870407, metric: 27.543746948242188, lr: 0.0009552621049806476
[5160] train loss: 1.1283114850521088, metric: 16.410618782043457, lr: 0.0009413089719600976
[5180] train loss: 1.0361973755061626, metric: 15.49780535697937, lr: 0.0009255966870114207
[5200] train loss: 1.307489987462759, metric: 17.153141975402832, lr: 0.00090818788157776
[5220] train loss: 0.2664097733795643, metric: 10.663886785507202, lr: 0.0008891518809832633
[5240] train loss: 0.9949468597769737, metric: 12.526577949523926, lr: 0.0008685645880177617
[5260] train loss: 0.4551750272512436, metric: 11.91277003288269, lr: 0.0008465081336908042
[5280] train loss: 0.3401994928717613, metric: 10.056698560714722, lr: 0.0008230703533627093
[5300] train loss: 1.8321430571377277, metric: 10.612689971923828, lr: 0.0007983447285369039
[5320] train loss: 0.37248241528868675, metric: 10.39685595035553, lr: 0.0007724298629909754
[5340] train loss: 0.8272325396537781, metric: 14.552462577819824, lr: 0.0007454289589077234
[5360] train loss: 0.542038980871439, metric: 12.468929767608643, lr: 0.0007174497004598379
[5380] train loss: 1.29991015791893, metric: 9.223965406417847, lr: 0.00068860367173329
[5400] train loss: 2.276365216821432, metric: 11.733211994171143, lr: 0.0006590057746507227
[5420] train loss: 4.542394995689392, metric: 18.666529655456543, lr: 0.0006287740543484688
[5440] train loss: 9.328720919787884, metric: 16.680718302726746, lr: 0.000598029000684619
[5460] train loss: 0.5832933597266674, metric: 21.080897092819214, lr: 0.0005668931407853961
[5480] train loss: 0.11301406472921371, metric: 13.307565212249756, lr: 0.0005354906315915287
[5500] train loss: -0.16365190967917442, metric: 9.300348281860352, lr: 0.0005039466777816415
[5520] train loss: -0.052524663507938385, metric: 9.36255133152008, lr: 0.0004723869787994772
[5540] train loss: 0.15857140719890594, metric: 10.154128670692444, lr: 0.0004409373505041003
[5560] train loss: -0.10034861788153648, metric: 8.248580694198608, lr: 0.0004097231721971184
[5580] train loss: -0.05408064275979996, metric: 10.474792242050171, lr: 0.000378868862753734
[5600] train loss: -0.2090778350830078, metric: 9.58408808708191, lr: 0.00034849741496145725
[5620] train loss: 0.5893407464027405, metric: 14.333000898361206, lr: 0.0003187299007549882
[5640] train loss: 12.986551821231842, metric: 27.446123600006104, lr: 0.0002896849764510989
[5660] train loss: 7.824510037899017, metric: 30.000009059906006, lr: 0.0002614784170873463
[5680] train loss: 1.5729337595403194, metric: 23.659306526184082, lr: 0.00023422270896844566
[5700] train loss: 3.111119505017996, metric: 19.40002727508545, lr: 0.00020802643848583102
[5720] train loss: 1.630418799817562, metric: 17.399279832839966, lr: 0.00018299407383892685
[5740] train loss: 3.011359505355358, metric: 19.480373859405518, lr: 0.00015922538295853883
[5760] train loss: 4.497255481779575, metric: 22.64401364326477, lr: 0.00013681512791663408
[5780] train loss: 8.469211556017399, metric: 24.010586738586426, lr: 0.00011585262109292671
[5800] train loss: 6.223986528813839, metric: 20.534878730773926, lr: 9.999999747378752e-05
[5820] train loss: 6.775553330779076, metric: 17.92705225944519, lr: 9.999999747378752e-05
[5840] train loss: 2.764832705259323, metric: 27.331178188323975, lr: 9.999999747378752e-05
[5860] train loss: 2.1054844558238983, metric: 27.058510065078735, lr: 9.999999747378752e-05
[5880] train loss: 2.354094970971346, metric: 28.686827659606934, lr: 9.999999747378752e-05
[5900] train loss: 8.063708454370499, metric: 21.472727298736572, lr: 9.999999747378752e-05
[5920] train loss: 12.79703825712204, metric: 24.037564754486084, lr: 9.999999747378752e-05
[5940] train loss: 3.3408313244581223, metric: 20.855127811431885, lr: 9.999999747378752e-05
[5960] train loss: 1.2327941618859768, metric: 23.273775577545166, lr: 9.999999747378752e-05
[5980] train loss: 2.10701834410429, metric: 20.077275037765503, lr: 9.999999747378752e-05
[6000] train loss: 3.9157592467963696, metric: 23.222813606262207, lr: 9.999999747378752e-05
[6020] train loss: 2.090409532189369, metric: 22.167038440704346, lr: 0.0009994393913075328
[6040] train loss: 0.5159906335175037, metric: 21.93470573425293, lr: 0.0009969500824809074
[6060] train loss: 0.5498515665531158, metric: 14.224891185760498, lr: 0.000992479850538075
[6080] train loss: 0.5776629038155079, metric: 16.11222517490387, lr: 0.000986046390607953
[6100] train loss: 1.0341994352638721, metric: 16.028849601745605, lr: 0.0009776754304766655
[6120] train loss: 16.348693326115608, metric: 26.784616947174072, lr: 0.0009674003813415766
[6140] train loss: 5.181650705635548, metric: 17.83125066757202, lr: 0.0009552621049806476
[6160] train loss: 1.2000514641404152, metric: 22.652302265167236, lr: 0.0009413089719600976
[6180] train loss: 0.0489189438521862, metric: 16.603546857833862, lr: 0.0009255966870114207
[6200] train loss: -0.1718667484819889, metric: 12.628573894500732, lr: 0.00090818788157776
[6220] train loss: -0.2322450578212738, metric: 9.356415748596191, lr: 0.0008891518809832633
[6240] train loss: -0.2099655568599701, metric: 10.989849090576172, lr: 0.0008685645880177617
[6260] train loss: -0.249278474599123, metric: 10.409933686256409, lr: 0.0008465081336908042
[6280] train loss: -0.22373991087079048, metric: 7.253418803215027, lr: 0.0008230703533627093
[6300] train loss: -0.2537112794816494, metric: 7.690611839294434, lr: 0.0007983447285369039
[6320] train loss: -0.17053290084004402, metric: 9.051782131195068, lr: 0.0007724298629909754
[6340] train loss: -0.25708137825131416, metric: 8.524304389953613, lr: 0.0007454289589077234
[6360] train loss: -0.3065880164504051, metric: 7.064557790756226, lr: 0.0007174497004598379
[6380] train loss: -0.28565963357686996, metric: 7.034203767776489, lr: 0.00068860367173329
[6400] train loss: -0.28991732746362686, metric: 7.0795228481292725, lr: 0.0006590057746507227
[6420] train loss: -0.32837749272584915, metric: 7.117045760154724, lr: 0.0006287740543484688
[6440] train loss: -0.32720044255256653, metric: 6.863882660865784, lr: 0.000598029000684619
[6460] train loss: -0.33092111349105835, metric: 6.851890563964844, lr: 0.0005668931407853961
[6480] train loss: -0.3100894205272198, metric: 6.591308236122131, lr: 0.0005354906315915287
[6500] train loss: -0.33730512857437134, metric: 6.141909956932068, lr: 0.0005039466777816415
[6520] train loss: -0.30298444628715515, metric: 7.129290580749512, lr: 0.0004723869787994772
[6540] train loss: -0.05398527905344963, metric: 8.183172583580017, lr: 0.0004409373505041003
[6560] train loss: 0.08701484650373459, metric: 8.385625839233398, lr: 0.0004097231721971184
[6580] train loss: 0.013655349612236023, metric: 12.122653365135193, lr: 0.000378868862753734
[6600] train loss: -0.17039090022444725, metric: 9.316104769706726, lr: 0.00034849741496145725
[6620] train loss: -0.05092673376202583, metric: 13.148894786834717, lr: 0.0003187299007549882
[6640] train loss: -0.02596961334347725, metric: 12.621094703674316, lr: 0.0002896849764510989
[6660] train loss: 5.9203681498765945, metric: 22.15221643447876, lr: 0.0002614784170873463
[6680] train loss: 2.007423248142004, metric: 17.034191131591797, lr: 0.00023422270896844566
[6700] train loss: 1.7565168514847755, metric: 18.59997797012329, lr: 0.00020802643848583102
[6720] train loss: 0.9946765750646591, metric: 17.627755880355835, lr: 0.00018299407383892685
[6740] train loss: 3.523167211562395, metric: 17.799389839172363, lr: 0.00015922538295853883
[6760] train loss: 5.314795106649399, metric: 19.596360683441162, lr: 0.00013681512791663408
[6780] train loss: 4.169616013765335, metric: 14.82237434387207, lr: 0.00011585262109292671
[6800] train loss: 0.8783562406897545, metric: 14.377180337905884, lr: 9.999999747378752e-05
[6820] train loss: 2.4496579840779305, metric: 14.871616840362549, lr: 9.999999747378752e-05
[6840] train loss: 7.055499643087387, metric: 17.216623783111572, lr: 9.999999747378752e-05
[6860] train loss: 6.467737648636103, metric: 17.27173924446106, lr: 9.999999747378752e-05
[6880] train loss: 4.258197512477636, metric: 21.533392667770386, lr: 9.999999747378752e-05
[6900] train loss: 1.5041333064436913, metric: 12.745451211929321, lr: 9.999999747378752e-05
[6920] train loss: 0.712665718048811, metric: 11.796512126922607, lr: 9.999999747378752e-05
[6940] train loss: 0.2552575394511223, metric: 11.04633641242981, lr: 9.999999747378752e-05
[6960] train loss: -0.074571643024683, metric: 12.820650696754456, lr: 9.999999747378752e-05
[6980] train loss: 1.2773502059280872, metric: 12.999533414840698, lr: 9.999999747378752e-05
[7000] train loss: 0.7734940834343433, metric: 17.93315362930298, lr: 9.999999747378752e-05
[7020] train loss: 10.820577383041382, metric: 31.07668972015381, lr: 0.0009994393913075328
[7040] train loss: 0.3054654002189636, metric: 14.008394718170166, lr: 0.0009969500824809074
[7060] train loss: 0.6351798586547375, metric: 11.939473271369934, lr: 0.000992479850538075
[7080] train loss: 0.39088116958737373, metric: 12.75382125377655, lr: 0.000986046390607953
[7100] train loss: 1.151577416807413, metric: 11.880860090255737, lr: 0.0009776754304766655
[7120] train loss: 0.21856577694416046, metric: 13.305663585662842, lr: 0.0009674003813415766
[7140] train loss: 0.3635556437075138, metric: 12.120342493057251, lr: 0.0009552621049806476
[7160] train loss: 0.8869165107607841, metric: 14.857924222946167, lr: 0.0009413089719600976
[7180] train loss: 8.242321595549583, metric: 34.2354154586792, lr: 0.0009255966870114207
[7200] train loss: 1.2220304161310196, metric: 18.595420837402344, lr: 0.00090818788157776
[7220] train loss: 0.43792473897337914, metric: 13.819396495819092, lr: 0.0008891518809832633
[7240] train loss: 2.9549967646598816, metric: 17.204177856445312, lr: 0.0008685645880177617
[7260] train loss: 0.36744024977087975, metric: 11.91441035270691, lr: 0.0008465081336908042
[7280] train loss: 0.9560298956930637, metric: 15.0196533203125, lr: 0.0008230703533627093
[7300] train loss: 1.1052063554525375, metric: 12.771790504455566, lr: 0.0007983447285369039
[7320] train loss: 1.424981001764536, metric: 13.606031656265259, lr: 0.0007724298629909754
[7340] train loss: 1.26260457187891, metric: 15.379190444946289, lr: 0.0007454289589077234
[7360] train loss: 2.2769700698554516, metric: 15.022571563720703, lr: 0.0007174497004598379
[7380] train loss: 2.371441848576069, metric: 17.88999032974243, lr: 0.00068860367173329
[7400] train loss: 4.065844371914864, metric: 22.519158363342285, lr: 0.0006590057746507227
[7420] train loss: 3.619177959859371, metric: 18.799346446990967, lr: 0.0006287740543484688
[7440] train loss: 0.9567365646362305, metric: 15.082443952560425, lr: 0.000598029000684619
[7460] train loss: 1.5351821929216385, metric: 14.388477683067322, lr: 0.0005668931407853961
[7480] train loss: 1.8723664730787277, metric: 19.8732647895813, lr: 0.0005354906315915287
[7500] train loss: 1.8494759649038315, metric: 16.624287128448486, lr: 0.0005039466777816415
[7520] train loss: 1.8610255979001522, metric: 17.54923152923584, lr: 0.0004723869787994772
[7540] train loss: 1.411465846002102, metric: 18.84681987762451, lr: 0.0004409373505041003
[7560] train loss: 2.969598241150379, metric: 13.844362735748291, lr: 0.0004097231721971184
[7580] train loss: 4.644087910652161, metric: 21.70897912979126, lr: 0.000378868862753734
[7600] train loss: 5.736138224601746, metric: 23.2466139793396, lr: 0.00034849741496145725
[7620] train loss: 5.599928796291351, metric: 24.510459899902344, lr: 0.0003187299007549882
[7640] train loss: 3.336682051420212, metric: 28.284688472747803, lr: 0.0002896849764510989
[7660] train loss: 3.051687702536583, metric: 29.34946060180664, lr: 0.0002614784170873463
[7680] train loss: 1.5799067169427872, metric: 33.92693257331848, lr: 0.00023422270896844566
[7700] train loss: 1.679984025657177, metric: 26.552939891815186, lr: 0.00020802643848583102
[7720] train loss: 0.11416993662714958, metric: 15.60980772972107, lr: 0.00018299407383892685
[7740] train loss: 0.0016392841935157776, metric: 12.326566219329834, lr: 0.00015922538295853883
[7760] train loss: 0.06026555225253105, metric: 12.77579951286316, lr: 0.00013681512791663408
[7780] train loss: 0.9954669699072838, metric: 13.42116379737854, lr: 0.00011585262109292671
[7800] train loss: 0.5557587519288063, metric: 16.62088966369629, lr: 9.999999747378752e-05
[7820] train loss: 0.15344883129000664, metric: 15.663482904434204, lr: 9.999999747378752e-05
[7840] train loss: 0.04965833202004433, metric: 13.771739959716797, lr: 9.999999747378752e-05
[7860] train loss: 0.14142735302448273, metric: 14.601053714752197, lr: 9.999999747378752e-05
[7880] train loss: -0.003384251147508621, metric: 12.774192810058594, lr: 9.999999747378752e-05
[7900] train loss: -0.08695642650127411, metric: 12.818507432937622, lr: 9.999999747378752e-05
[7920] train loss: -0.13222411274909973, metric: 10.773247480392456, lr: 9.999999747378752e-05
[7940] train loss: 0.16040242090821266, metric: 13.193209409713745, lr: 9.999999747378752e-05
[7960] train loss: 0.3669181950390339, metric: 14.288275718688965, lr: 9.999999747378752e-05
[7980] train loss: 0.5401643067598343, metric: 14.319396734237671, lr: 9.999999747378752e-05
[8000] train loss: -0.004656476899981499, metric: 13.480883359909058, lr: 9.999999747378752e-05
[8020] train loss: -0.1673002988100052, metric: 11.539295434951782, lr: 0.0009994393913075328
[8040] train loss: -0.1695466712117195, metric: 12.430640697479248, lr: 0.0009969500824809074
[8060] train loss: -0.06141047552227974, metric: 13.328598499298096, lr: 0.000992479850538075
[8080] train loss: 0.12628281116485596, metric: 14.886858463287354, lr: 0.000986046390607953
[8100] train loss: 3.214742671698332, metric: 15.984445571899414, lr: 0.0009776754304766655
[8120] train loss: 0.2240361012518406, metric: 15.698073148727417, lr: 0.0009674003813415766
[8140] train loss: -0.16124940291047096, metric: 13.512619495391846, lr: 0.0009552621049806476
[8160] train loss: 1.3201391957700253, metric: 14.075758695602417, lr: 0.0009413089719600976
[8180] train loss: 0.24504483491182327, metric: 14.75974988937378, lr: 0.0009255966870114207
[8200] train loss: 5.50684218108654, metric: 15.915379524230957, lr: 0.00090818788157776
[8220] train loss: 1.6508977115154266, metric: 25.269690990447998, lr: 0.0008891518809832633
[8240] train loss: 0.6373129338026047, metric: 14.252067565917969, lr: 0.0008685645880177617
[8260] train loss: 5.84065904468298, metric: 20.795390605926514, lr: 0.0008465081336908042
[8280] train loss: 1.0026016645133495, metric: 20.122258186340332, lr: 0.0008230703533627093
[8300] train loss: 4.283219873905182, metric: 45.40689754486084, lr: 0.0007983447285369039
[8320] train loss: 17.37241616845131, metric: 33.06038856506348, lr: 0.0007724298629909754
[8340] train loss: 2.292475536465645, metric: 33.34347057342529, lr: 0.0007454289589077234
[8360] train loss: 0.9083515852689743, metric: 23.977608680725098, lr: 0.0007174497004598379
[8380] train loss: 6.1453277468681335, metric: 21.726832151412964, lr: 0.00068860367173329
[8400] train loss: 6.294077921658754, metric: 22.2972412109375, lr: 0.0006590057746507227
[8420] train loss: 3.0226316079497337, metric: 19.981515884399414, lr: 0.0006287740543484688
[8440] train loss: 0.8463740348815918, metric: 14.841201543807983, lr: 0.000598029000684619
[8460] train loss: 1.4193307645618916, metric: 15.991140842437744, lr: 0.0005668931407853961
[8480] train loss: 1.9042761400341988, metric: 18.20848822593689, lr: 0.0005354906315915287
[8500] train loss: 0.9229766800999641, metric: 18.066208839416504, lr: 0.0005039466777816415
[8520] train loss: 0.43520742282271385, metric: 15.397480010986328, lr: 0.0004723869787994772
[8540] train loss: 5.782650217413902, metric: 18.522164344787598, lr: 0.0004409373505041003
[8560] train loss: 5.675291981548071, metric: 17.152745723724365, lr: 0.0004097231721971184
[8580] train loss: 1.0415965132415295, metric: 21.398649215698242, lr: 0.000378868862753734
[8600] train loss: 0.8144222907721996, metric: 19.32029390335083, lr: 0.00034849741496145725
[8620] train loss: 1.2634783796966076, metric: 15.86869478225708, lr: 0.0003187299007549882
[8640] train loss: 2.433837588876486, metric: 16.238173007965088, lr: 0.0002896849764510989
[8660] train loss: 1.5031230710446835, metric: 14.421729564666748, lr: 0.0002614784170873463
[8680] train loss: 1.4748589992523193, metric: 19.459596395492554, lr: 0.00023422270896844566
[8700] train loss: 0.46734269708395004, metric: 13.863648176193237, lr: 0.00020802643848583102
[8720] train loss: 2.138401698321104, metric: 23.56401014328003, lr: 0.00018299407383892685
[8740] train loss: 0.5184774957597256, metric: 19.60795760154724, lr: 0.00015922538295853883
[8760] train loss: 0.2315928414463997, metric: 17.537047386169434, lr: 0.00013681512791663408
[8780] train loss: 0.24471154808998108, metric: 15.928087711334229, lr: 0.00011585262109292671
[8800] train loss: 0.0939246341586113, metric: 17.48958730697632, lr: 9.999999747378752e-05
[8820] train loss: 0.17460329830646515, metric: 19.06711220741272, lr: 9.999999747378752e-05
[8840] train loss: 0.34899938479065895, metric: 17.92704701423645, lr: 9.999999747378752e-05
[8860] train loss: 0.34740231558680534, metric: 19.356138229370117, lr: 9.999999747378752e-05
[8880] train loss: 0.36616405099630356, metric: 17.677496433258057, lr: 9.999999747378752e-05
[8900] train loss: 0.20023620873689651, metric: 17.210156679153442, lr: 9.999999747378752e-05
[8920] train loss: 0.1626477874815464, metric: 13.830089092254639, lr: 9.999999747378752e-05
[8940] train loss: 0.03391548991203308, metric: 14.72901177406311, lr: 9.999999747378752e-05
[8960] train loss: -0.05604622885584831, metric: 16.02147102355957, lr: 9.999999747378752e-05
[8980] train loss: -0.12469355389475822, metric: 14.650044918060303, lr: 9.999999747378752e-05
[9000] train loss: 0.017783012241125107, metric: 15.411744117736816, lr: 9.999999747378752e-05
[9020] train loss: -0.08311821520328522, metric: 13.499682664871216, lr: 0.0009994393913075328
[9040] train loss: -0.20543578639626503, metric: 10.088244438171387, lr: 0.0009969500824809074
[9060] train loss: -0.24987918883562088, metric: 9.363411664962769, lr: 0.000992479850538075
[9080] train loss: -0.2563861347734928, metric: 8.899070978164673, lr: 0.000986046390607953
[9100] train loss: -0.21490763500332832, metric: 7.544058680534363, lr: 0.0009776754304766655
[9120] train loss: -0.2912541590631008, metric: 7.041708469390869, lr: 0.0009674003813415766
[9140] train loss: -0.21829310432076454, metric: 8.06026291847229, lr: 0.0009552621049806476
[9160] train loss: -0.2772582396864891, metric: 7.269839286804199, lr: 0.0009413089719600976
[9180] train loss: -0.272428497672081, metric: 7.520859599113464, lr: 0.0009255966870114207
[9200] train loss: -0.1647539883852005, metric: 7.899151921272278, lr: 0.00090818788157776
[9220] train loss: 3.1988036520779133, metric: 19.5299654006958, lr: 0.0008891518809832633
[9240] train loss: 0.38764552026987076, metric: 17.182298183441162, lr: 0.0008685645880177617
[9260] train loss: -0.08147374913096428, metric: 11.082297801971436, lr: 0.0008465081336908042
[9280] train loss: 0.335882056504488, metric: 10.718048095703125, lr: 0.0008230703533627093
[9300] train loss: 0.4901159480214119, metric: 11.975828886032104, lr: 0.0007983447285369039
[9320] train loss: 3.3429152704775333, metric: 17.008118391036987, lr: 0.0007724298629909754
[9340] train loss: 0.9458490833640099, metric: 17.60054087638855, lr: 0.0007454289589077234
[9360] train loss: 2.0282069854438305, metric: 21.07655358314514, lr: 0.0007174497004598379
[9380] train loss: 0.6412109173834324, metric: 12.376279473304749, lr: 0.00068860367173329
[9400] train loss: 0.5794845223426819, metric: 15.107658863067627, lr: 0.0006590057746507227
[9420] train loss: 0.9760341867804527, metric: 16.209538221359253, lr: 0.0006287740543484688
[9440] train loss: 3.8593142963945866, metric: 22.681827545166016, lr: 0.000598029000684619
[9460] train loss: 0.8438622131943703, metric: 13.09857165813446, lr: 0.0005668931407853961
[9480] train loss: 0.47318338230252266, metric: 14.596277952194214, lr: 0.0005354906315915287
[9500] train loss: 0.1710285171866417, metric: 13.076180934906006, lr: 0.0005039466777816415
[9520] train loss: 0.2257927805185318, metric: 11.896970987319946, lr: 0.0004723869787994772
[9540] train loss: -0.11966986954212189, metric: 10.793804407119751, lr: 0.0004409373505041003
[9560] train loss: 0.026106953620910645, metric: 12.545303583145142, lr: 0.0004097231721971184
[9580] train loss: -0.18163659423589706, metric: 12.129972219467163, lr: 0.000378868862753734
[9600] train loss: -0.07819373533129692, metric: 9.812000274658203, lr: 0.00034849741496145725
[9620] train loss: -0.16929741948843002, metric: 10.959479808807373, lr: 0.0003187299007549882
[9640] train loss: -0.036444541066884995, metric: 10.720333337783813, lr: 0.0002896849764510989
[9660] train loss: 0.3670554906129837, metric: 11.356687545776367, lr: 0.0002614784170873463
[9680] train loss: 0.3469364568591118, metric: 10.693575978279114, lr: 0.00023422270896844566
[9700] train loss: 0.15232984721660614, metric: 12.53450870513916, lr: 0.00020802643848583102
[9720] train loss: 0.7698345594108105, metric: 11.032157897949219, lr: 0.00018299407383892685
[9740] train loss: 3.1619986593723297, metric: 18.524051666259766, lr: 0.00015922538295853883
[9760] train loss: 1.5518816709518433, metric: 21.724449634552002, lr: 0.00013681512791663408
[9780] train loss: 0.5151432491838932, metric: 15.815998792648315, lr: 0.00011585262109292671
[9800] train loss: 0.3510875776410103, metric: 16.931119441986084, lr: 9.999999747378752e-05
[9820] train loss: 0.10774131491780281, metric: 14.42392361164093, lr: 9.999999747378752e-05
[9840] train loss: -0.029637690633535385, metric: 13.382544040679932, lr: 9.999999747378752e-05
[9860] train loss: 0.027073446661233902, metric: 15.41100788116455, lr: 9.999999747378752e-05
[9880] train loss: -0.0566277839243412, metric: 16.484016180038452, lr: 9.999999747378752e-05
[9900] train loss: -0.13463278859853745, metric: 14.269530653953552, lr: 9.999999747378752e-05
[9920] train loss: -0.08838153257966042, metric: 15.444289684295654, lr: 9.999999747378752e-05
[9940] train loss: -0.03855687752366066, metric: 14.104382991790771, lr: 9.999999747378752e-05
[9960] train loss: 0.07345237955451012, metric: 13.449400424957275, lr: 9.999999747378752e-05
[9980] train loss: -0.060828231275081635, metric: 13.594923257827759, lr: 9.999999747378752e-05
[10000] train loss: 0.24237562343478203, metric: 16.690012454986572, lr: 9.999999747378752e-05
[10020] train loss: 0.10369043424725533, metric: 12.503121733665466, lr: 0.0009994393913075328
[10040] train loss: 0.07240273058414459, metric: 12.518056154251099, lr: 0.0009969500824809074
[10060] train loss: 0.6469536200165749, metric: 14.247166395187378, lr: 0.000992479850538075
[10080] train loss: 2.3251624517142773, metric: 15.447355270385742, lr: 0.000986046390607953
[10100] train loss: 2.071062408387661, metric: 12.871433019638062, lr: 0.0009776754304766655
[10120] train loss: 0.36952633038163185, metric: 10.400954008102417, lr: 0.0009674003813415766
[10140] train loss: 0.44356243312358856, metric: 10.684074521064758, lr: 0.0009552621049806476
[10160] train loss: 0.2402496039867401, metric: 14.979422330856323, lr: 0.0009413089719600976
[10180] train loss: -0.2318085841834545, metric: 6.950574636459351, lr: 0.0009255966870114207
[10200] train loss: -0.10826659575104713, metric: 7.739908695220947, lr: 0.00090818788157776
[10220] train loss: -0.09693453460931778, metric: 7.023548603057861, lr: 0.0008891518809832633
[10240] train loss: -0.2506469152867794, metric: 6.853657484054565, lr: 0.0008685645880177617
[10260] train loss: 0.07852143421769142, metric: 13.749964475631714, lr: 0.0008465081336908042
[10280] train loss: -0.12739193253219128, metric: 9.620246410369873, lr: 0.0008230703533627093
[10300] train loss: -0.23422710597515106, metric: 9.23851990699768, lr: 0.0007983447285369039
[10320] train loss: -0.23496106266975403, metric: 9.391967058181763, lr: 0.0007724298629909754
[10340] train loss: -0.20286523550748825, metric: 9.012386083602905, lr: 0.0007454289589077234
[10360] train loss: 1.2239969745278358, metric: 12.056265354156494, lr: 0.0007174497004598379
[10380] train loss: -0.08475879579782486, metric: 9.16135025024414, lr: 0.00068860367173329
[10400] train loss: 0.04908761382102966, metric: 9.832198858261108, lr: 0.0006590057746507227
[10420] train loss: 0.3655680865049362, metric: 9.484073996543884, lr: 0.0006287740543484688
[10440] train loss: 0.67878657579422, metric: 10.704187512397766, lr: 0.000598029000684619
[10460] train loss: 1.1104653142392635, metric: 9.329142093658447, lr: 0.0005668931407853961
[10480] train loss: 0.3999041020870209, metric: 9.051094055175781, lr: 0.0005354906315915287
[10500] train loss: 0.4236341007053852, metric: 15.312639832496643, lr: 0.0005039466777816415
[10520] train loss: 1.2675643898546696, metric: 9.732651591300964, lr: 0.0004723869787994772
[10540] train loss: -0.008284341543912888, metric: 9.372684717178345, lr: 0.0004409373505041003
[10560] train loss: -0.20273522287607193, metric: 7.0436012744903564, lr: 0.0004097231721971184
[10580] train loss: -0.23812349513173103, metric: 9.665032625198364, lr: 0.000378868862753734
[10600] train loss: -0.1753128245472908, metric: 7.70784592628479, lr: 0.00034849741496145725
[10620] train loss: -0.2409597635269165, metric: 8.54617702960968, lr: 0.0003187299007549882
[10640] train loss: -0.2894011661410332, metric: 8.440438032150269, lr: 0.0002896849764510989
[10660] train loss: -0.2806692570447922, metric: 7.851666331291199, lr: 0.0002614784170873463
[10680] train loss: -0.2851998805999756, metric: 9.13742446899414, lr: 0.00023422270896844566
[10700] train loss: -0.30066879093647003, metric: 7.41640830039978, lr: 0.00020802643848583102
[10720] train loss: -0.2662033177912235, metric: 6.38725209236145, lr: 0.00018299407383892685
[10740] train loss: -0.222275298088789, metric: 5.9838865995407104, lr: 0.00015922538295853883
[10760] train loss: 2.9035596065223217, metric: 19.956754684448242, lr: 0.00013681512791663408
[10780] train loss: 1.0583350397646427, metric: 13.67672848701477, lr: 0.00011585262109292671
[10800] train loss: 0.4263424947857857, metric: 12.90115475654602, lr: 9.999999747378752e-05
[10820] train loss: 0.6367733851075172, metric: 13.851102113723755, lr: 9.999999747378752e-05
[10840] train loss: 3.0851432271301746, metric: 16.21978998184204, lr: 9.999999747378752e-05
[10860] train loss: 0.8904706165194511, metric: 12.561075210571289, lr: 9.999999747378752e-05
[10880] train loss: 0.5515516810119152, metric: 10.934950113296509, lr: 9.999999747378752e-05
[10900] train loss: 2.7229055240750313, metric: 12.39264702796936, lr: 9.999999747378752e-05
[10920] train loss: 0.5759987868368626, metric: 13.072523593902588, lr: 9.999999747378752e-05
[10940] train loss: 0.04259753227233887, metric: 10.244201421737671, lr: 9.999999747378752e-05
[10960] train loss: 0.09339732490479946, metric: 10.864142656326294, lr: 9.999999747378752e-05
[10980] train loss: -0.006819751113653183, metric: 13.139785885810852, lr: 9.999999747378752e-05
[11000] train loss: 0.6244785152375698, metric: 11.304481863975525, lr: 9.999999747378752e-05
[11020] train loss: 0.8056129515171051, metric: 11.173820734024048, lr: 0.0009994393913075328
[11040] train loss: 0.6475012116134167, metric: 11.432017803192139, lr: 0.0009969500824809074
[11060] train loss: -0.09716704115271568, metric: 9.007214069366455, lr: 0.000992479850538075
[11080] train loss: -0.207035843282938, metric: 7.702466607093811, lr: 0.000986046390607953
[11100] train loss: -0.2053479328751564, metric: 8.336653232574463, lr: 0.0009776754304766655
[11120] train loss: -0.1942153312265873, metric: 7.3628740310668945, lr: 0.0009674003813415766
[11140] train loss: -0.19336886331439018, metric: 7.626951694488525, lr: 0.0009552621049806476
[11160] train loss: -0.20903142541646957, metric: 8.470758318901062, lr: 0.0009413089719600976
[11180] train loss: -0.03191047161817551, metric: 10.0184907913208, lr: 0.0009255966870114207
[11200] train loss: -0.12384204566478729, metric: 8.503234624862671, lr: 0.00090818788157776
[11220] train loss: -0.19552892073988914, metric: 8.397351145744324, lr: 0.0008891518809832633
[11240] train loss: -0.18107765167951584, metric: 6.088617563247681, lr: 0.0008685645880177617
[11260] train loss: -0.17049748823046684, metric: 6.994413375854492, lr: 0.0008465081336908042
[11280] train loss: 2.976681962609291, metric: 22.076788902282715, lr: 0.0008230703533627093
[11300] train loss: 0.9893159195780754, metric: 14.580807447433472, lr: 0.0007983447285369039
[11320] train loss: 0.4105856865644455, metric: 13.993118524551392, lr: 0.0007724298629909754
[11340] train loss: 0.35063840448856354, metric: 16.133257150650024, lr: 0.0007454289589077234
[11360] train loss: 0.22362251207232475, metric: 14.037214994430542, lr: 0.0007174497004598379
[11380] train loss: 0.11518069356679916, metric: 18.2367742061615, lr: 0.00068860367173329
[11400] train loss: -0.22248009219765663, metric: 13.1638023853302, lr: 0.0006590057746507227
[11420] train loss: -0.27575691789388657, metric: 11.724095344543457, lr: 0.0006287740543484688
[11440] train loss: -0.3101170286536217, metric: 10.884699821472168, lr: 0.000598029000684619
[11460] train loss: -0.3255421593785286, metric: 8.965577483177185, lr: 0.0005668931407853961
[11480] train loss: -0.3520395830273628, metric: 7.32725465297699, lr: 0.0005354906315915287
[11500] train loss: -0.3339952155947685, metric: 8.098324298858643, lr: 0.0005039466777816415
[11520] train loss: -0.3228348344564438, metric: 7.7844226360321045, lr: 0.0004723869787994772
[11540] train loss: -0.3189959339797497, metric: 7.09142792224884, lr: 0.0004409373505041003
[11560] train loss: -0.31159671023488045, metric: 7.405077934265137, lr: 0.0004097231721971184
[11580] train loss: -0.29675932601094246, metric: 8.434807181358337, lr: 0.000378868862753734
[11600] train loss: -0.11924264580011368, metric: 9.316080212593079, lr: 0.00034849741496145725
[11620] train loss: -0.13472919538617134, metric: 9.108494758605957, lr: 0.0003187299007549882
[11640] train loss: -0.16975482180714607, metric: 7.792796969413757, lr: 0.0002896849764510989
[11660] train loss: -0.19179536402225494, metric: 7.954429388046265, lr: 0.0002614784170873463
[11680] train loss: -0.19689341261982918, metric: 7.8761104345321655, lr: 0.00023422270896844566
[11700] train loss: -0.2268059104681015, metric: 7.370473742485046, lr: 0.00020802643848583102
[11720] train loss: -0.14418937638401985, metric: 8.725616216659546, lr: 0.00018299407383892685
[11740] train loss: -0.02299877256155014, metric: 11.144941091537476, lr: 0.00015922538295853883
[11760] train loss: -0.18424370884895325, metric: 10.361696362495422, lr: 0.00013681512791663408
[11780] train loss: 1.1901431567966938, metric: 18.702763080596924, lr: 0.00011585262109292671
[11800] train loss: 0.6424620039761066, metric: 12.420429706573486, lr: 9.999999747378752e-05
[11820] train loss: 3.2648342922329903, metric: 15.479718208312988, lr: 9.999999747378752e-05
[11840] train loss: 2.2471974566578865, metric: 22.23179054260254, lr: 9.999999747378752e-05
[11860] train loss: 1.7105389833450317, metric: 17.262914657592773, lr: 9.999999747378752e-05
[11880] train loss: 1.127303421497345, metric: 16.168939113616943, lr: 9.999999747378752e-05
[11900] train loss: 0.4521889388561249, metric: 16.71139097213745, lr: 9.999999747378752e-05
[11920] train loss: 0.23715075850486755, metric: 12.122681140899658, lr: 9.999999747378752e-05
[11940] train loss: 1.2678316682577133, metric: 14.012117862701416, lr: 9.999999747378752e-05
[11960] train loss: 4.247143663465977, metric: 16.065763235092163, lr: 9.999999747378752e-05
[11980] train loss: 3.2160759046673775, metric: 24.096387147903442, lr: 9.999999747378752e-05
[12000] train loss: 1.1251847594976425, metric: 14.467094421386719, lr: 9.999999747378752e-05
[12020] train loss: 0.22407924011349678, metric: 18.244633197784424, lr: 0.0009994393913075328
[12040] train loss: 0.07689431309700012, metric: 9.64325737953186, lr: 0.0009969500824809074
[12060] train loss: 0.7527368403971195, metric: 13.657785892486572, lr: 0.000992479850538075
[12080] train loss: 1.1099931970238686, metric: 18.03092861175537, lr: 0.000986046390607953
[12100] train loss: 2.1383051574230194, metric: 16.395341157913208, lr: 0.0009776754304766655
[12120] train loss: 0.5978671759366989, metric: 12.120393633842468, lr: 0.0009674003813415766
[12140] train loss: 5.302780605852604, metric: 16.358235836029053, lr: 0.0009552621049806476
[12160] train loss: 3.33080618083477, metric: 16.30980634689331, lr: 0.0009413089719600976
[12180] train loss: 0.5561291836202145, metric: 18.51699995994568, lr: 0.0009255966870114207
[12200] train loss: -0.059317655861377716, metric: 14.707027673721313, lr: 0.00090818788157776
[12220] train loss: -0.05040544643998146, metric: 10.644274950027466, lr: 0.0008891518809832633
[12240] train loss: -0.03365502133965492, metric: 10.302521705627441, lr: 0.0008685645880177617
[12260] train loss: -0.20278555527329445, metric: 10.440477132797241, lr: 0.0008465081336908042
[12280] train loss: 0.2146441824734211, metric: 8.809326410293579, lr: 0.0008230703533627093
[12300] train loss: 0.444222342222929, metric: 11.42646598815918, lr: 0.0007983447285369039
[12320] train loss: -0.21417467668652534, metric: 9.633286714553833, lr: 0.0007724298629909754
[12340] train loss: -0.24286125972867012, metric: 9.147405505180359, lr: 0.0007454289589077234
[12360] train loss: -0.3065328262746334, metric: 8.181392431259155, lr: 0.0007174497004598379
[12380] train loss: -0.26856688410043716, metric: 7.908856511116028, lr: 0.00068860367173329
[12400] train loss: -0.3429703339934349, metric: 8.106231451034546, lr: 0.0006590057746507227
[12420] train loss: -0.3535361588001251, metric: 8.089324831962585, lr: 0.0006287740543484688
[12440] train loss: -0.24640686810016632, metric: 7.626125812530518, lr: 0.000598029000684619
[12460] train loss: -0.3216806650161743, metric: 6.874054431915283, lr: 0.0005668931407853961
[12480] train loss: -0.3210577331483364, metric: 7.593201398849487, lr: 0.0005354906315915287
[12500] train loss: -0.1902112029492855, metric: 8.225705862045288, lr: 0.0005039466777816415
[12520] train loss: -0.27435503900051117, metric: 8.81609058380127, lr: 0.0004723869787994772
[12540] train loss: -0.12941158935427666, metric: 9.422262191772461, lr: 0.0004409373505041003
[12560] train loss: 0.8636263720691204, metric: 14.297008037567139, lr: 0.0004097231721971184
[12580] train loss: 0.0016084685921669006, metric: 11.34110689163208, lr: 0.000378868862753734
[12600] train loss: -0.07384566962718964, metric: 10.697088479995728, lr: 0.00034849741496145725
[12620] train loss: 0.10802469030022621, metric: 10.620380878448486, lr: 0.0003187299007549882
[12640] train loss: 0.49214310944080353, metric: 9.801709294319153, lr: 0.0002896849764510989
[12660] train loss: 0.18308963626623154, metric: 11.376427412033081, lr: 0.0002614784170873463
[12680] train loss: 0.06587788835167885, metric: 7.867010951042175, lr: 0.00023422270896844566
[12700] train loss: 0.0008275583386421204, metric: 8.362694144248962, lr: 0.00020802643848583102
[12720] train loss: -0.07045724615454674, metric: 7.329010605812073, lr: 0.00018299407383892685
[12740] train loss: -0.12184927985072136, metric: 8.013137459754944, lr: 0.00015922538295853883
[12760] train loss: -0.23974739387631416, metric: 8.422409415245056, lr: 0.00013681512791663408
[12780] train loss: -0.2264992743730545, metric: 7.629392147064209, lr: 0.00011585262109292671
[12800] train loss: -0.15656829252839088, metric: 8.647993564605713, lr: 9.999999747378752e-05
[12820] train loss: 9.237844686955214, metric: 19.69080877304077, lr: 9.999999747378752e-05
[12840] train loss: 3.09286180883646, metric: 16.145312786102295, lr: 9.999999747378752e-05
[12860] train loss: 5.527692794799805, metric: 13.684583187103271, lr: 9.999999747378752e-05
[12880] train loss: 4.324378665536642, metric: 19.25710940361023, lr: 9.999999747378752e-05
[12900] train loss: 3.5434763245284557, metric: 24.611114501953125, lr: 9.999999747378752e-05
[12920] train loss: 10.661603830754757, metric: 29.250129461288452, lr: 9.999999747378752e-05
[12940] train loss: 7.0196153074502945, metric: 25.26975965499878, lr: 9.999999747378752e-05
[12960] train loss: 2.79086172580719, metric: 22.56614923477173, lr: 9.999999747378752e-05
[12980] train loss: 1.687538307160139, metric: 15.268982648849487, lr: 9.999999747378752e-05
[13000] train loss: 0.855485163629055, metric: 13.236966371536255, lr: 9.999999747378752e-05
[13020] train loss: 1.8369823098182678, metric: 14.775536060333252, lr: 0.0009994393913075328
[13040] train loss: 3.744101192802191, metric: 15.24815320968628, lr: 0.0009969500824809074
[13060] train loss: 1.048660084605217, metric: 16.146416425704956, lr: 0.000992479850538075
[13080] train loss: 5.574833497405052, metric: 18.48011541366577, lr: 0.000986046390607953
[13100] train loss: 4.738908618688583, metric: 28.81209373474121, lr: 0.0009776754304766655
[13120] train loss: 8.189266994595528, metric: 20.76957893371582, lr: 0.0009674003813415766
[13140] train loss: 2.4005843177437782, metric: 17.14931082725525, lr: 0.0009552621049806476
[13160] train loss: 2.814180228859186, metric: 17.16243076324463, lr: 0.0009413089719600976
[13180] train loss: 0.8083569146692753, metric: 17.248716354370117, lr: 0.0009255966870114207
[13200] train loss: 0.4894481487572193, metric: 10.515407681465149, lr: 0.00090818788157776
[13220] train loss: 2.3160903453826904, metric: 14.079413414001465, lr: 0.0008891518809832633
[13240] train loss: 2.2825666069984436, metric: 16.460200786590576, lr: 0.0008685645880177617
[13260] train loss: 19.72156010195613, metric: 24.748399019241333, lr: 0.0008465081336908042
[13280] train loss: 4.600637137889862, metric: 29.03524160385132, lr: 0.0008230703533627093
[13300] train loss: 6.994534309953451, metric: 21.55528163909912, lr: 0.0007983447285369039
[13320] train loss: 1.2134914696216583, metric: 24.431668758392334, lr: 0.0007724298629909754
[13340] train loss: -0.033841539174318314, metric: 15.74643588066101, lr: 0.0007454289589077234
[13360] train loss: -0.14065396413207054, metric: 11.18894076347351, lr: 0.0007174497004598379
[13380] train loss: 0.13395623490214348, metric: 12.177690744400024, lr: 0.00068860367173329
[13400] train loss: 0.3050573766231537, metric: 10.493138551712036, lr: 0.0006590057746507227
[13420] train loss: -0.21534660458564758, metric: 9.963103532791138, lr: 0.0006287740543484688
[13440] train loss: -0.23516269400715828, metric: 8.830557942390442, lr: 0.000598029000684619
[13460] train loss: 2.5892866365611553, metric: 9.852110385894775, lr: 0.0005668931407853961
[13480] train loss: 2.1763572357594967, metric: 17.415589570999146, lr: 0.0005354906315915287
[13500] train loss: 2.6373192593455315, metric: 15.583870887756348, lr: 0.0005039466777816415
[13520] train loss: 0.25080906599760056, metric: 13.182071685791016, lr: 0.0004723869787994772
[13540] train loss: -0.03114103525876999, metric: 8.874229431152344, lr: 0.0004409373505041003
[13560] train loss: -0.1373855583369732, metric: 9.963027834892273, lr: 0.0004097231721971184
[13580] train loss: 0.04188790172338486, metric: 10.408243179321289, lr: 0.000378868862753734
[13600] train loss: 0.14434358105063438, metric: 12.13413119316101, lr: 0.00034849741496145725
[13620] train loss: -0.04576323553919792, metric: 11.081209897994995, lr: 0.0003187299007549882
[13640] train loss: -0.026423968374729156, metric: 9.678990483283997, lr: 0.0002896849764510989
[13660] train loss: 0.12137147411704063, metric: 9.778558850288391, lr: 0.0002614784170873463
[13680] train loss: 0.062060318887233734, metric: 9.547845840454102, lr: 0.00023422270896844566
[13700] train loss: 0.15319272130727768, metric: 11.404711246490479, lr: 0.00020802643848583102
[13720] train loss: -0.035499390214681625, metric: 10.925589799880981, lr: 0.00018299407383892685
[13740] train loss: 0.2129538506269455, metric: 10.777907609939575, lr: 0.00015922538295853883
[13760] train loss: 0.35633014142513275, metric: 10.621359825134277, lr: 0.00013681512791663408
[13780] train loss: 0.15326346084475517, metric: 10.565823554992676, lr: 0.00011585262109292671
[13800] train loss: 1.3531902339309454, metric: 10.44964861869812, lr: 9.999999747378752e-05
[13820] train loss: 1.1194816306233406, metric: 12.103314518928528, lr: 9.999999747378752e-05
[13840] train loss: 15.744159936904907, metric: 29.80327868461609, lr: 9.999999747378752e-05
[13860] train loss: 12.289102017879486, metric: 30.016366004943848, lr: 9.999999747378752e-05
[13880] train loss: 2.694982398301363, metric: 25.875370025634766, lr: 9.999999747378752e-05
[13900] train loss: 2.7555404491722584, metric: 21.805226802825928, lr: 9.999999747378752e-05
[13920] train loss: 2.1831096969544888, metric: 27.041422605514526, lr: 9.999999747378752e-05
[13940] train loss: 1.0648457556962967, metric: 22.441239595413208, lr: 9.999999747378752e-05
[13960] train loss: 1.4588640481233597, metric: 18.36270785331726, lr: 9.999999747378752e-05
[13980] train loss: 3.2376931719481945, metric: 18.95925760269165, lr: 9.999999747378752e-05
[14000] train loss: 12.132406808435917, metric: 22.71563196182251, lr: 9.999999747378752e-05
[14020] train loss: 5.22756864130497, metric: 27.634589195251465, lr: 0.0009994393913075328
[14040] train loss: 0.9666378349065781, metric: 24.583272457122803, lr: 0.0009969500824809074
[14060] train loss: 0.7450284510850906, metric: 15.336416721343994, lr: 0.000992479850538075
[14080] train loss: 0.30687496066093445, metric: 11.167240381240845, lr: 0.000986046390607953
[14100] train loss: 0.6853466294705868, metric: 11.533941984176636, lr: 0.0009776754304766655
[14120] train loss: 1.502307839691639, metric: 13.07196044921875, lr: 0.0009674003813415766
[14140] train loss: 0.1812513954937458, metric: 13.168455839157104, lr: 0.0009552621049806476
[14160] train loss: 0.8478155210614204, metric: 12.413765907287598, lr: 0.0009413089719600976
[14180] train loss: 0.5346928276121616, metric: 15.872338771820068, lr: 0.0009255966870114207
[14200] train loss: 0.42799628525972366, metric: 11.170344352722168, lr: 0.00090818788157776
[14220] train loss: 0.005985334515571594, metric: 11.811936855316162, lr: 0.0008891518809832633
[14240] train loss: -0.02408602461218834, metric: 10.865506410598755, lr: 0.0008685645880177617
[14260] train loss: -0.15365713089704514, metric: 9.878966569900513, lr: 0.0008465081336908042
[14280] train loss: -0.011234141886234283, metric: 8.471563816070557, lr: 0.0008230703533627093
[14300] train loss: -0.08452438935637474, metric: 13.034624576568604, lr: 0.0007983447285369039
[14320] train loss: 0.32745369523763657, metric: 10.228480219841003, lr: 0.0007724298629909754
[14340] train loss: 2.537841349840164, metric: 17.972230434417725, lr: 0.0007454289589077234
[14360] train loss: 0.461362037807703, metric: 13.974157333374023, lr: 0.0007174497004598379
[14380] train loss: 0.043793950229883194, metric: 13.407958030700684, lr: 0.00068860367173329
[14400] train loss: -0.0299556665122509, metric: 12.665147304534912, lr: 0.0006590057746507227
[14420] train loss: 0.5154432132840157, metric: 14.606816291809082, lr: 0.0006287740543484688
[14440] train loss: 0.8402273617684841, metric: 15.457587003707886, lr: 0.000598029000684619
[14460] train loss: 0.5395786538720131, metric: 15.861312627792358, lr: 0.0005668931407853961
[14480] train loss: 0.1755644641816616, metric: 12.575652718544006, lr: 0.0005354906315915287
[14500] train loss: -0.12420506030321121, metric: 12.079544305801392, lr: 0.0005039466777816415
[14520] train loss: -0.021470636129379272, metric: 12.102602005004883, lr: 0.0004723869787994772
[14540] train loss: -0.16478881984949112, metric: 10.235348224639893, lr: 0.0004409373505041003
[14560] train loss: -0.1690360028296709, metric: 13.259262084960938, lr: 0.0004097231721971184
[14580] train loss: 1.19871511682868, metric: 11.500880718231201, lr: 0.000378868862753734
[14600] train loss: 1.5896676667034626, metric: 18.09522533416748, lr: 0.00034849741496145725
[14620] train loss: 0.27470535039901733, metric: 16.792796850204468, lr: 0.0003187299007549882
[14640] train loss: 0.8094600178301334, metric: 13.329382538795471, lr: 0.0002896849764510989
[14660] train loss: 0.842966016381979, metric: 11.807853102684021, lr: 0.0002614784170873463
[14680] train loss: 0.42733706533908844, metric: 13.555562973022461, lr: 0.00023422270896844566
[14700] train loss: 0.224233016371727, metric: 14.135474920272827, lr: 0.00020802643848583102
[14720] train loss: 0.3358176536858082, metric: 14.224079728126526, lr: 0.00018299407383892685
[14740] train loss: 0.1624816432595253, metric: 13.665081024169922, lr: 0.00015922538295853883
[14760] train loss: 1.7059846483170986, metric: 13.234488487243652, lr: 0.00013681512791663408
[14780] train loss: 2.386570770293474, metric: 14.240316390991211, lr: 0.00011585262109292671
[14800] train loss: 2.32488651946187, metric: 16.284175395965576, lr: 9.999999747378752e-05
[14820] train loss: 6.178642299026251, metric: 19.35515022277832, lr: 9.999999747378752e-05
[14840] train loss: 5.878679811954498, metric: 18.78760075569153, lr: 9.999999747378752e-05
[14860] train loss: 8.786024928092957, metric: 30.13307523727417, lr: 9.999999747378752e-05
[14880] train loss: 0.8176506459712982, metric: 17.55607795715332, lr: 9.999999747378752e-05
[14900] train loss: 0.60686419531703, metric: 18.894304513931274, lr: 9.999999747378752e-05
[14920] train loss: 0.3087148815393448, metric: 10.917831182479858, lr: 9.999999747378752e-05
[14940] train loss: 0.06592993810772896, metric: 11.368699431419373, lr: 9.999999747378752e-05
[14960] train loss: 0.06836467236280441, metric: 12.959699869155884, lr: 9.999999747378752e-05
[14980] train loss: 0.3648999109864235, metric: 13.530953168869019, lr: 9.999999747378752e-05
[15000] train loss: 0.4329562336206436, metric: 11.642361879348755, lr: 9.999999747378752e-05
[15020] train loss: 0.04822361841797829, metric: 9.261489868164062, lr: 0.0009994393913075328
[15040] train loss: 0.1747906431555748, metric: 11.081424713134766, lr: 0.0009969500824809074
[15060] train loss: 0.033374182879924774, metric: 13.379420518875122, lr: 0.000992479850538075
[15080] train loss: 0.010508451610803604, metric: 13.828951597213745, lr: 0.000986046390607953
[15100] train loss: 0.7736151106655598, metric: 13.250017404556274, lr: 0.0009776754304766655
[15120] train loss: 0.7791893631219864, metric: 11.903255224227905, lr: 0.0009674003813415766
[15140] train loss: 1.206557098776102, metric: 15.192063570022583, lr: 0.0009552621049806476
[15160] train loss: 1.5451105535030365, metric: 13.043591022491455, lr: 0.0009413089719600976
[15180] train loss: 0.8296844623982906, metric: 20.113240480422974, lr: 0.0009255966870114207
[15200] train loss: 5.538254544138908, metric: 19.578783988952637, lr: 0.00090818788157776
[15220] train loss: 2.9818126894533634, metric: 21.92496395111084, lr: 0.0008891518809832633
[15240] train loss: 3.2485847026109695, metric: 19.255178928375244, lr: 0.0008685645880177617
[15260] train loss: 0.9808607213199139, metric: 19.09114933013916, lr: 0.0008465081336908042
[15280] train loss: 1.1870538108050823, metric: 16.74162244796753, lr: 0.0008230703533627093
[15300] train loss: 1.8072390481829643, metric: 13.380855560302734, lr: 0.0007983447285369039
[15320] train loss: 5.3925709798932076, metric: 16.57476043701172, lr: 0.0007724298629909754
[15340] train loss: 3.617694891989231, metric: 16.66918969154358, lr: 0.0007454289589077234
[15360] train loss: 0.4590511657297611, metric: 11.572921752929688, lr: 0.0007174497004598379
[15380] train loss: 0.6570169851183891, metric: 16.17932677268982, lr: 0.00068860367173329
[15400] train loss: 0.12073677405714989, metric: 11.915079593658447, lr: 0.0006590057746507227
[15420] train loss: -0.15252447500824928, metric: 10.012764692306519, lr: 0.0006287740543484688
[15440] train loss: -0.045377787202596664, metric: 9.358386993408203, lr: 0.000598029000684619
[15460] train loss: -0.017648998647928238, metric: 12.492058753967285, lr: 0.0005668931407853961
[15480] train loss: -0.11624894291162491, metric: 11.021777868270874, lr: 0.0005354906315915287
[15500] train loss: -0.06920068711042404, metric: 10.49303126335144, lr: 0.0005039466777816415
[15520] train loss: 0.11906877532601357, metric: 11.259487628936768, lr: 0.0004723869787994772
[15540] train loss: -0.07795486599206924, metric: 12.371553182601929, lr: 0.0004409373505041003
[15560] train loss: -0.20733317360281944, metric: 9.88215684890747, lr: 0.0004097231721971184
[15580] train loss: -0.15642089024186134, metric: 7.792437434196472, lr: 0.000378868862753734
[15600] train loss: -0.2290927618741989, metric: 7.8295780420303345, lr: 0.00034849741496145725
[15620] train loss: -0.2603973336517811, metric: 7.931177377700806, lr: 0.0003187299007549882
[15640] train loss: -0.22954228520393372, metric: 7.709815502166748, lr: 0.0002896849764510989
[15660] train loss: -0.1976369172334671, metric: 8.397435784339905, lr: 0.0002614784170873463
[15680] train loss: -0.06927222013473511, metric: 7.689024925231934, lr: 0.00023422270896844566
[15700] train loss: 0.02189137041568756, metric: 7.7483954429626465, lr: 0.00020802643848583102
[15720] train loss: 0.012390971183776855, metric: 11.800901770591736, lr: 0.00018299407383892685
[15740] train loss: -0.17213640362024307, metric: 8.628687739372253, lr: 0.00015922538295853883
[15760] train loss: -0.07621699199080467, metric: 11.74661374092102, lr: 0.00013681512791663408
[15780] train loss: -0.16563985869288445, metric: 13.266912460327148, lr: 0.00011585262109292671
[15800] train loss: -0.11516032740473747, metric: 12.987553238868713, lr: 9.999999747378752e-05
[15820] train loss: -0.06259609013795853, metric: 11.06198251247406, lr: 9.999999747378752e-05
[15840] train loss: 0.014031067490577698, metric: 11.26826536655426, lr: 9.999999747378752e-05
[15860] train loss: -0.02358626201748848, metric: 11.875224828720093, lr: 9.999999747378752e-05
[15880] train loss: 2.0857506319880486, metric: 16.10487651824951, lr: 9.999999747378752e-05
[15900] train loss: 3.217832911759615, metric: 11.759406924247742, lr: 9.999999747378752e-05
[15920] train loss: 1.1109699830412865, metric: 15.385117530822754, lr: 9.999999747378752e-05
[15940] train loss: 0.24066748097538948, metric: 16.901150226593018, lr: 9.999999747378752e-05
[15960] train loss: -0.011945515871047974, metric: 15.397247314453125, lr: 9.999999747378752e-05
[15980] train loss: -0.03732366859912872, metric: 12.541083335876465, lr: 9.999999747378752e-05
[16000] train loss: -0.1263643577694893, metric: 12.544768810272217, lr: 9.999999747378752e-05
[16020] train loss: 0.3906663805246353, metric: 10.026054382324219, lr: 0.0009994393913075328
[16040] train loss: -0.1988346166908741, metric: 9.576824188232422, lr: 0.0009969500824809074
[16060] train loss: -0.22012406587600708, metric: 9.792543888092041, lr: 0.000992479850538075
[16080] train loss: -0.19630222022533417, metric: 10.280445575714111, lr: 0.000986046390607953
[16100] train loss: -0.10292735695838928, metric: 10.171229004859924, lr: 0.0009776754304766655
[16120] train loss: -0.15707535296678543, metric: 9.62047255039215, lr: 0.0009674003813415766
[16140] train loss: -0.24772394075989723, metric: 11.604729413986206, lr: 0.0009552621049806476
[16160] train loss: -0.18460889905691147, metric: 7.349875211715698, lr: 0.0009413089719600976
[16180] train loss: -0.2237313650548458, metric: 7.897034287452698, lr: 0.0009255966870114207
[16200] train loss: -0.2385583072900772, metric: 8.453580617904663, lr: 0.00090818788157776
[16220] train loss: -0.22259221225976944, metric: 8.970556735992432, lr: 0.0008891518809832633
[16240] train loss: -0.2841404154896736, metric: 8.222159385681152, lr: 0.0008685645880177617
[16260] train loss: -0.24344955012202263, metric: 7.713913202285767, lr: 0.0008465081336908042
[16280] train loss: -0.2812809348106384, metric: 8.436384439468384, lr: 0.0008230703533627093
[16300] train loss: -0.18288464471697807, metric: 7.52287495136261, lr: 0.0007983447285369039
[16320] train loss: -0.16042649000883102, metric: 8.242162823677063, lr: 0.0007724298629909754
[16340] train loss: -0.17762495204806328, metric: 9.86638879776001, lr: 0.0007454289589077234
[16360] train loss: -0.3022937588393688, metric: 8.302511215209961, lr: 0.0007174497004598379
[16380] train loss: -0.17290376871824265, metric: 10.456419229507446, lr: 0.00068860367173329
[16400] train loss: 1.7038651555776596, metric: 18.37776756286621, lr: 0.0006590057746507227
[16420] train loss: 3.8175882659852505, metric: 15.749539852142334, lr: 0.0006287740543484688
[16440] train loss: 1.337562471628189, metric: 18.213319301605225, lr: 0.000598029000684619
[16460] train loss: 0.18801694735884666, metric: 11.729942679405212, lr: 0.0005668931407853961
[16480] train loss: 0.07985781133174896, metric: 12.121465921401978, lr: 0.0005354906315915287
[16500] train loss: 0.2131425328552723, metric: 13.229953050613403, lr: 0.0005039466777816415
[16520] train loss: 0.008385080844163895, metric: 11.082907438278198, lr: 0.0004723869787994772
[16540] train loss: -0.14329128339886665, metric: 9.294942140579224, lr: 0.0004409373505041003
[16560] train loss: -0.17847011983394623, metric: 8.879806876182556, lr: 0.0004097231721971184
[16580] train loss: -0.17207637801766396, metric: 8.12239158153534, lr: 0.000378868862753734
[16600] train loss: -0.08543610572814941, metric: 10.094908714294434, lr: 0.00034849741496145725
[16620] train loss: 0.2140745036303997, metric: 9.58765995502472, lr: 0.0003187299007549882
[16640] train loss: 1.4276981689035892, metric: 14.647838115692139, lr: 0.0002896849764510989
[16660] train loss: 0.7555610574781895, metric: 19.822727918624878, lr: 0.0002614784170873463
[16680] train loss: 0.2652420736849308, metric: 21.971953868865967, lr: 0.00023422270896844566
[16700] train loss: 0.8135505728423595, metric: 20.274171352386475, lr: 0.00020802643848583102
[16720] train loss: 0.37415146082639694, metric: 19.971237421035767, lr: 0.00018299407383892685
[16740] train loss: 0.21821201965212822, metric: 16.516255378723145, lr: 0.00015922538295853883
[16760] train loss: 0.38934917002916336, metric: 11.801450967788696, lr: 0.00013681512791663408
[16780] train loss: 0.21244631707668304, metric: 12.630046844482422, lr: 0.00011585262109292671
[16800] train loss: 0.19179468229413033, metric: 12.089161157608032, lr: 9.999999747378752e-05
[16820] train loss: 0.13487279415130615, metric: 10.238867044448853, lr: 9.999999747378752e-05
[16840] train loss: -0.016738932579755783, metric: 8.658455848693848, lr: 9.999999747378752e-05
[16860] train loss: 0.5063874088227749, metric: 13.178407669067383, lr: 9.999999747378752e-05
[16880] train loss: 0.8515030704438686, metric: 11.92412281036377, lr: 9.999999747378752e-05
[16900] train loss: 15.05829931795597, metric: 30.38307523727417, lr: 9.999999747378752e-05
[16920] train loss: 4.082651749253273, metric: 20.425154209136963, lr: 9.999999747378752e-05
[16940] train loss: 1.9474286884069443, metric: 12.782701253890991, lr: 9.999999747378752e-05
[16960] train loss: 1.254644252359867, metric: 14.604295253753662, lr: 9.999999747378752e-05
[16980] train loss: 1.298997562378645, metric: 18.173632860183716, lr: 9.999999747378752e-05
[17000] train loss: 0.9251544065773487, metric: 15.78102993965149, lr: 9.999999747378752e-05
[17020] train loss: 0.13954288884997368, metric: 13.572401523590088, lr: 0.0009994393913075328
[17040] train loss: -0.15982002392411232, metric: 10.431221008300781, lr: 0.0009969500824809074
[17060] train loss: 0.028896119445562363, metric: 10.595532655715942, lr: 0.000992479850538075
[17080] train loss: -0.14614425972104073, metric: 11.710498571395874, lr: 0.000986046390607953
[17100] train loss: -0.20468254387378693, metric: 8.352234721183777, lr: 0.0009776754304766655
[17120] train loss: 0.007054463028907776, metric: 10.355753421783447, lr: 0.0009674003813415766
[17140] train loss: -0.04220416769385338, metric: 13.462916851043701, lr: 0.0009552621049806476
[17160] train loss: 0.2066475786268711, metric: 15.277552604675293, lr: 0.0009413089719600976
[17180] train loss: 0.15752296149730682, metric: 10.481003999710083, lr: 0.0009255966870114207
[17200] train loss: 0.06810171902179718, metric: 11.159322261810303, lr: 0.00090818788157776
[17220] train loss: 0.030448686331510544, metric: 11.51220178604126, lr: 0.0008891518809832633
[17240] train loss: -0.015037674456834793, metric: 10.787495255470276, lr: 0.0008685645880177617
[17260] train loss: -0.22987817227840424, metric: 10.589625000953674, lr: 0.0008465081336908042
[17280] train loss: 0.0955212451517582, metric: 7.628612518310547, lr: 0.0008230703533627093
[17300] train loss: 0.004442203789949417, metric: 12.535903930664062, lr: 0.0007983447285369039
[17320] train loss: -0.16391195729374886, metric: 11.126846075057983, lr: 0.0007724298629909754
[17340] train loss: 0.11576858907938004, metric: 11.25913953781128, lr: 0.0007454289589077234
[17360] train loss: -0.10515527427196503, metric: 10.290141940116882, lr: 0.0007174497004598379
[17380] train loss: 0.512913428246975, metric: 10.264816284179688, lr: 0.00068860367173329
[17400] train loss: 1.8422524966299534, metric: 12.53138780593872, lr: 0.0006590057746507227
[17420] train loss: 0.200506541877985, metric: 13.094744205474854, lr: 0.0006287740543484688
[17440] train loss: -0.20392346382141113, metric: 9.805100321769714, lr: 0.000598029000684619
[17460] train loss: -0.24887856096029282, metric: 10.299361944198608, lr: 0.0005668931407853961
[17480] train loss: 0.004320614039897919, metric: 10.828675031661987, lr: 0.0005354906315915287
[17500] train loss: 1.3040105663239956, metric: 11.31849217414856, lr: 0.0005039466777816415
[17520] train loss: 0.6379963830113411, metric: 11.033539056777954, lr: 0.0004723869787994772
[17540] train loss: 0.623077217489481, metric: 13.671722769737244, lr: 0.0004409373505041003
[17560] train loss: -0.017649661749601364, metric: 10.02521562576294, lr: 0.0004097231721971184
[17580] train loss: 0.4025570712983608, metric: 13.12392807006836, lr: 0.000378868862753734
[17600] train loss: -0.21525025367736816, metric: 8.891130447387695, lr: 0.00034849741496145725
[17620] train loss: -0.29549406468868256, metric: 9.543214082717896, lr: 0.0003187299007549882
[17640] train loss: -0.20772578194737434, metric: 9.826180934906006, lr: 0.0002896849764510989
[17660] train loss: -0.24401050806045532, metric: 10.674859523773193, lr: 0.0002614784170873463
[17680] train loss: -0.2361486665904522, metric: 8.829285860061646, lr: 0.00023422270896844566
[17700] train loss: -0.13636013492941856, metric: 9.072744727134705, lr: 0.00020802643848583102
[17720] train loss: -0.13231303915381432, metric: 9.629166960716248, lr: 0.00018299407383892685
[17740] train loss: -0.2254965528845787, metric: 9.984370231628418, lr: 0.00015922538295853883
[17760] train loss: -0.21495773270726204, metric: 8.237526893615723, lr: 0.00013681512791663408
[17780] train loss: 0.07449932396411896, metric: 11.853365898132324, lr: 0.00011585262109292671
[17800] train loss: 1.0250117480754852, metric: 13.62927782535553, lr: 9.999999747378752e-05
[17820] train loss: 0.3022296875715256, metric: 9.710784792900085, lr: 9.999999747378752e-05
[17840] train loss: 1.6248275935649872, metric: 12.155068159103394, lr: 9.999999747378752e-05
[17860] train loss: 1.2485273256897926, metric: 15.424018144607544, lr: 9.999999747378752e-05
[17880] train loss: 0.40556539595127106, metric: 13.661837100982666, lr: 9.999999747378752e-05
[17900] train loss: 0.012168165296316147, metric: 10.569095134735107, lr: 9.999999747378752e-05
[17920] train loss: 0.04487794265151024, metric: 10.390079975128174, lr: 9.999999747378752e-05
[17940] train loss: 0.8672454729676247, metric: 17.09496307373047, lr: 9.999999747378752e-05
[17960] train loss: 0.05874606594443321, metric: 14.59225594997406, lr: 9.999999747378752e-05
[17980] train loss: 0.03129158169031143, metric: 13.563210010528564, lr: 9.999999747378752e-05
[18000] train loss: 0.18754366785287857, metric: 14.575943231582642, lr: 9.999999747378752e-05
[18020] train loss: -0.20905231311917305, metric: 9.655529499053955, lr: 0.0009994393913075328
[18040] train loss: -0.27718405798077583, metric: 10.328254222869873, lr: 0.0009969500824809074
[18060] train loss: -0.2904878370463848, metric: 8.793236136436462, lr: 0.000992479850538075
[18080] train loss: -0.3053218312561512, metric: 6.415573835372925, lr: 0.000986046390607953
[18100] train loss: -0.32033754140138626, metric: 6.118406891822815, lr: 0.0009776754304766655
[18120] train loss: -0.30972474068403244, metric: 5.922773957252502, lr: 0.0009674003813415766
[18140] train loss: -0.3243527337908745, metric: 5.503499627113342, lr: 0.0009552621049806476
[18160] train loss: -0.19092722237110138, metric: 6.614212274551392, lr: 0.0009413089719600976
[18180] train loss: 0.14089661836624146, metric: 9.144238471984863, lr: 0.0009255966870114207
[18200] train loss: -0.100667305290699, metric: 8.160335898399353, lr: 0.00090818788157776
[18220] train loss: 0.19508704915642738, metric: 7.920008659362793, lr: 0.0008891518809832633
[18240] train loss: 0.25233084335923195, metric: 7.372980356216431, lr: 0.0008685645880177617
[18260] train loss: 0.7774849683046341, metric: 9.463848352432251, lr: 0.0008465081336908042
[18280] train loss: 0.30438902974128723, metric: 7.498870015144348, lr: 0.0008230703533627093
[18300] train loss: 0.5872074253857136, metric: 10.55208146572113, lr: 0.0007983447285369039
[18320] train loss: 0.19497528672218323, metric: 12.695785999298096, lr: 0.0007724298629909754
[18340] train loss: 0.1479819156229496, metric: 13.105279207229614, lr: 0.0007454289589077234
[18360] train loss: 0.08755757659673691, metric: 11.606994152069092, lr: 0.0007174497004598379
[18380] train loss: -0.0031760521233081818, metric: 8.121559381484985, lr: 0.00068860367173329
[18400] train loss: -0.16208038851618767, metric: 7.871726870536804, lr: 0.0006590057746507227
[18420] train loss: 0.08401649072766304, metric: 9.840931177139282, lr: 0.0006287740543484688
[18440] train loss: 0.9236130081117153, metric: 19.275736570358276, lr: 0.000598029000684619
[18460] train loss: 0.06070294603705406, metric: 12.181028366088867, lr: 0.0005668931407853961
[18480] train loss: 0.23570333793759346, metric: 11.762149572372437, lr: 0.0005354906315915287
[18500] train loss: -0.14533278346061707, metric: 9.916027069091797, lr: 0.0005039466777816415
[18520] train loss: 0.3105524852871895, metric: 13.283246278762817, lr: 0.0004723869787994772
[18540] train loss: 0.6128254495561123, metric: 11.071027994155884, lr: 0.0004409373505041003
[18560] train loss: 4.20966312661767, metric: 15.783206462860107, lr: 0.0004097231721971184
[18580] train loss: 0.20057475939393044, metric: 13.912630319595337, lr: 0.000378868862753734
[18600] train loss: 0.11415417864918709, metric: 11.52394711971283, lr: 0.00034849741496145725
[18620] train loss: 0.43713659793138504, metric: 12.97058093547821, lr: 0.0003187299007549882
[18640] train loss: 0.27236457914114, metric: 11.84801971912384, lr: 0.0002896849764510989
[18660] train loss: 0.1698676124215126, metric: 8.937846183776855, lr: 0.0002614784170873463
[18680] train loss: 1.561367467045784, metric: 9.460428714752197, lr: 0.00023422270896844566
[18700] train loss: 3.1229558549821377, metric: 14.098207235336304, lr: 0.00020802643848583102
[18720] train loss: 1.7799455560743809, metric: 19.16751790046692, lr: 0.00018299407383892685
[18740] train loss: 0.701507218182087, metric: 17.69703769683838, lr: 0.00015922538295853883
[18760] train loss: 0.2176591157913208, metric: 10.5446457862854, lr: 0.00013681512791663408
[18780] train loss: 0.3856539651751518, metric: 14.900449991226196, lr: 0.00011585262109292671
[18800] train loss: 0.4060802273452282, metric: 16.516817331314087, lr: 9.999999747378752e-05
[18820] train loss: 0.21391689777374268, metric: 12.246336698532104, lr: 9.999999747378752e-05
[18840] train loss: 0.18041004985570908, metric: 10.059557557106018, lr: 9.999999747378752e-05
[18860] train loss: 0.9666263721883297, metric: 12.14989447593689, lr: 9.999999747378752e-05
[18880] train loss: 0.2801581025123596, metric: 11.1416996717453, lr: 9.999999747378752e-05
[18900] train loss: 0.12974128127098083, metric: 12.662316679954529, lr: 9.999999747378752e-05
[18920] train loss: 0.8176043145358562, metric: 9.949975371360779, lr: 9.999999747378752e-05
[18940] train loss: 3.3517587818205357, metric: 19.404507637023926, lr: 9.999999747378752e-05
[18960] train loss: 0.31234073266386986, metric: 11.595928192138672, lr: 9.999999747378752e-05
[18980] train loss: -0.15716223418712616, metric: 9.644461393356323, lr: 9.999999747378752e-05
[19000] train loss: -0.17578701674938202, metric: 9.78361439704895, lr: 9.999999747378752e-05
[19020] train loss: -0.1606338806450367, metric: 8.086687564849854, lr: 0.0009994393913075328
[19040] train loss: -0.3224293291568756, metric: 7.037061452865601, lr: 0.0009969500824809074
[19060] train loss: -0.2385241612792015, metric: 7.25632631778717, lr: 0.000992479850538075
[19080] train loss: -0.16305583715438843, metric: 8.12935757637024, lr: 0.000986046390607953
[19100] train loss: -0.2721671350300312, metric: 8.301784992218018, lr: 0.0009776754304766655
[19120] train loss: -0.34271297603845596, metric: 8.706076502799988, lr: 0.0009674003813415766
[19140] train loss: -0.3627701848745346, metric: 8.302489995956421, lr: 0.0009552621049806476
[19160] train loss: -0.37186481058597565, metric: 6.427710652351379, lr: 0.0009413089719600976
[19180] train loss: -0.3549351841211319, metric: 6.581923007965088, lr: 0.0009255966870114207
[19200] train loss: -0.32850077003240585, metric: 5.420159101486206, lr: 0.00090818788157776
[19220] train loss: -0.3261922597885132, metric: 5.200532793998718, lr: 0.0008891518809832633
[19240] train loss: -0.33194533735513687, metric: 5.5604939460754395, lr: 0.0008685645880177617
[19260] train loss: -0.3174104765057564, metric: 6.556769371032715, lr: 0.0008465081336908042
[19280] train loss: -0.269491046667099, metric: 7.21185302734375, lr: 0.0008230703533627093
[19300] train loss: -0.2987513802945614, metric: 8.162418723106384, lr: 0.0007983447285369039
[19320] train loss: -0.3849895969033241, metric: 5.405540347099304, lr: 0.0007724298629909754
[19340] train loss: -0.34123142808675766, metric: 4.157049119472504, lr: 0.0007454289589077234
[19360] train loss: -0.3686106577515602, metric: 5.366193890571594, lr: 0.0007174497004598379
[19380] train loss: -0.3782438859343529, metric: 4.065216302871704, lr: 0.00068860367173329
[19400] train loss: -0.3437519557774067, metric: 5.3047856092453, lr: 0.0006590057746507227
[19420] train loss: -0.26797686517238617, metric: 5.167775630950928, lr: 0.0006287740543484688
[19440] train loss: -0.3557480126619339, metric: 4.7044379115104675, lr: 0.000598029000684619
[19460] train loss: 3.0674680173397064, metric: 20.586315631866455, lr: 0.0005668931407853961
[19480] train loss: 0.26836803182959557, metric: 12.45305848121643, lr: 0.0005354906315915287
[19500] train loss: 0.12009790539741516, metric: 11.979755640029907, lr: 0.0005039466777816415
[19520] train loss: 0.44115932658314705, metric: 15.839498043060303, lr: 0.0004723869787994772
[19540] train loss: 0.27835671976208687, metric: 13.421063661575317, lr: 0.0004409373505041003
[19560] train loss: 0.20433418080210686, metric: 12.694578647613525, lr: 0.0004097231721971184
[19580] train loss: 0.21655698865652084, metric: 11.19074821472168, lr: 0.000378868862753734
[19600] train loss: 0.007894273847341537, metric: 9.609247922897339, lr: 0.00034849741496145725
[19620] train loss: -0.15744119137525558, metric: 10.13843297958374, lr: 0.0003187299007549882
[19640] train loss: -0.11912976577877998, metric: 11.918752670288086, lr: 0.0002896849764510989
[19660] train loss: -0.1452012099325657, metric: 9.687613487243652, lr: 0.0002614784170873463
[19680] train loss: -0.1366422064602375, metric: 9.769969940185547, lr: 0.00023422270896844566
[19700] train loss: -0.16384121030569077, metric: 9.126120686531067, lr: 0.00020802643848583102
[19720] train loss: 0.12783517688512802, metric: 11.05130934715271, lr: 0.00018299407383892685
[19740] train loss: -0.0879063680768013, metric: 9.225576400756836, lr: 0.00015922538295853883
[19760] train loss: -0.07864146679639816, metric: 10.91320264339447, lr: 0.00013681512791663408
[19780] train loss: 0.09505258500576019, metric: 12.26038122177124, lr: 0.00011585262109292671
[19800] train loss: -0.0723913200199604, metric: 11.91401743888855, lr: 9.999999747378752e-05
[19820] train loss: -0.03563620522618294, metric: 14.536306381225586, lr: 9.999999747378752e-05
[19840] train loss: -0.1431366316974163, metric: 10.655435681343079, lr: 9.999999747378752e-05
[19860] train loss: -0.010084917768836021, metric: 11.640120029449463, lr: 9.999999747378752e-05
[19880] train loss: -0.11243332549929619, metric: 13.208854675292969, lr: 9.999999747378752e-05
[19900] train loss: -0.20771270990371704, metric: 11.764068841934204, lr: 9.999999747378752e-05
[19920] train loss: -0.2703961879014969, metric: 8.153907418251038, lr: 9.999999747378752e-05
[19940] train loss: -0.20925266668200493, metric: 9.157569885253906, lr: 9.999999747378752e-05
[19960] train loss: -0.23412533104419708, metric: 12.705628871917725, lr: 9.999999747378752e-05
[19980] train loss: 1.5991185903549194, metric: 16.742985725402832, lr: 9.999999747378752e-05
[20000] train loss: 1.4182262420654297, metric: 14.713919639587402, lr: 9.999999747378752e-05
[20020] train loss: 0.19062182307243347, metric: 9.327208757400513, lr: 0.0009994393913075328
[20040] train loss: 0.06900811567902565, metric: 12.753452777862549, lr: 0.0009969500824809074
[20060] train loss: 0.07241469994187355, metric: 9.78497326374054, lr: 0.000992479850538075
[20080] train loss: 0.12612176686525345, metric: 10.385322093963623, lr: 0.000986046390607953
[20100] train loss: 0.20834066346287727, metric: 8.818834066390991, lr: 0.0009776754304766655
[20120] train loss: -0.004975065588951111, metric: 9.282513499259949, lr: 0.0009674003813415766
[20140] train loss: -0.06793628633022308, metric: 9.917734861373901, lr: 0.0009552621049806476
[20160] train loss: -0.1729845106601715, metric: 6.5509278774261475, lr: 0.0009413089719600976
[20180] train loss: -0.19080370664596558, metric: 6.200585842132568, lr: 0.0009255966870114207
[20200] train loss: -0.10504584014415741, metric: 6.813129425048828, lr: 0.00090818788157776
[20220] train loss: 0.19867517799139023, metric: 12.437602639198303, lr: 0.0008891518809832633
[20240] train loss: -0.15714780241250992, metric: 11.51946496963501, lr: 0.0008685645880177617
[20260] train loss: -0.20491039752960205, metric: 6.761032938957214, lr: 0.0008465081336908042
[20280] train loss: -0.2664783336222172, metric: 8.014119386672974, lr: 0.0008230703533627093
[20300] train loss: -0.16714366897940636, metric: 7.076831579208374, lr: 0.0007983447285369039
[20320] train loss: -0.18733469396829605, metric: 6.946656584739685, lr: 0.0007724298629909754
[20340] train loss: -0.11207959055900574, metric: 8.917544960975647, lr: 0.0007454289589077234
[20360] train loss: -0.16229010000824928, metric: 9.873157858848572, lr: 0.0007174497004598379
[20380] train loss: -0.17727994918823242, metric: 7.001910924911499, lr: 0.00068860367173329
[20400] train loss: 0.021734051406383514, metric: 8.287301421165466, lr: 0.0006590057746507227
[20420] train loss: -0.19378985092043877, metric: 7.858311891555786, lr: 0.0006287740543484688
[20440] train loss: 0.8174332976341248, metric: 11.19996201992035, lr: 0.000598029000684619
[20460] train loss: 0.7292093671858311, metric: 9.494012475013733, lr: 0.0005668931407853961
[20480] train loss: -0.09902859106659889, metric: 7.686583876609802, lr: 0.0005354906315915287
[20500] train loss: 0.4097730182111263, metric: 17.53572702407837, lr: 0.0005039466777816415
[20520] train loss: 0.7089029811322689, metric: 14.517445802688599, lr: 0.0004723869787994772
[20540] train loss: 0.27172114700078964, metric: 13.973445177078247, lr: 0.0004409373505041003
[20560] train loss: 0.9124855138361454, metric: 16.026419401168823, lr: 0.0004097231721971184
[20580] train loss: 2.189062003046274, metric: 18.472060441970825, lr: 0.000378868862753734
[20600] train loss: 0.9304041899740696, metric: 13.160430669784546, lr: 0.00034849741496145725
[20620] train loss: 1.8227843716740608, metric: 15.96151852607727, lr: 0.0003187299007549882
[20640] train loss: 0.737576074898243, metric: 13.31070327758789, lr: 0.0002896849764510989
[20660] train loss: 0.18423602357506752, metric: 9.956170916557312, lr: 0.0002614784170873463
[20680] train loss: 0.7912575341761112, metric: 13.789391279220581, lr: 0.00023422270896844566
[20700] train loss: 2.593497361987829, metric: 15.647277116775513, lr: 0.00020802643848583102
[20720] train loss: 2.4169097542762756, metric: 15.464545965194702, lr: 0.00018299407383892685
[20740] train loss: 2.548339657485485, metric: 15.826629638671875, lr: 0.00015922538295853883
[20760] train loss: 4.100173991173506, metric: 22.173033237457275, lr: 0.00013681512791663408
[20780] train loss: 2.9447945058345795, metric: 32.673694133758545, lr: 0.00011585262109292671
[20800] train loss: 2.6183246970176697, metric: 24.753538370132446, lr: 9.999999747378752e-05
[20820] train loss: 1.460004448890686, metric: 13.501814842224121, lr: 9.999999747378752e-05
[20840] train loss: 1.2546853721141815, metric: 19.62684154510498, lr: 9.999999747378752e-05
[20860] train loss: 1.2076551243662834, metric: 14.84254002571106, lr: 9.999999747378752e-05
[20880] train loss: 1.8298787325620651, metric: 13.303544282913208, lr: 9.999999747378752e-05
[20900] train loss: 0.7492090463638306, metric: 13.326101779937744, lr: 9.999999747378752e-05
[20920] train loss: 0.3961068280041218, metric: 13.095821380615234, lr: 9.999999747378752e-05
[20940] train loss: 0.6406792253255844, metric: 13.836082935333252, lr: 9.999999747378752e-05
[20960] train loss: 3.506536543369293, metric: 14.797245025634766, lr: 9.999999747378752e-05
[20980] train loss: 1.035953152924776, metric: 12.912353992462158, lr: 9.999999747378752e-05
[21000] train loss: 10.128861464560032, metric: 21.90826964378357, lr: 9.999999747378752e-05
[21020] train loss: 1.1394534073770046, metric: 23.241917610168457, lr: 0.0009994393913075328
[21040] train loss: 0.39095087349414825, metric: 12.039591312408447, lr: 0.0009969500824809074
[21060] train loss: -0.024870142340660095, metric: 9.944868087768555, lr: 0.000992479850538075
[21080] train loss: 0.05734493210911751, metric: 8.180440902709961, lr: 0.000986046390607953
[21100] train loss: 0.027621831744909286, metric: 9.56445050239563, lr: 0.0009776754304766655
[21120] train loss: -0.20234007015824318, metric: 8.395387768745422, lr: 0.0009674003813415766
[21140] train loss: 0.4865124598145485, metric: 9.107128143310547, lr: 0.0009552621049806476
[21160] train loss: 0.12933547049760818, metric: 9.242544651031494, lr: 0.0009413089719600976
[21180] train loss: 0.34685802459716797, metric: 16.2708101272583, lr: 0.0009255966870114207
[21200] train loss: 0.03641989454627037, metric: 15.410521745681763, lr: 0.00090818788157776
[21220] train loss: 1.3071716949343681, metric: 15.342711210250854, lr: 0.0008891518809832633
[21240] train loss: 0.39197270572185516, metric: 11.069056510925293, lr: 0.0008685645880177617
[21260] train loss: 4.190946348011494, metric: 18.784354209899902, lr: 0.0008465081336908042
[21280] train loss: 2.2029802054166794, metric: 18.677623987197876, lr: 0.0008230703533627093
[21300] train loss: 0.527874406427145, metric: 13.310428142547607, lr: 0.0007983447285369039
[21320] train loss: 0.6399548538029194, metric: 10.682076454162598, lr: 0.0007724298629909754
[21340] train loss: 0.4672727696597576, metric: 10.55312442779541, lr: 0.0007454289589077234
[21360] train loss: 1.379414651542902, metric: 10.491541147232056, lr: 0.0007174497004598379
[21380] train loss: 0.6051158159971237, metric: 10.878645420074463, lr: 0.00068860367173329
[21400] train loss: 0.8762441426515579, metric: 10.810378789901733, lr: 0.0006590057746507227
[21420] train loss: 0.1664692498743534, metric: 10.164511799812317, lr: 0.0006287740543484688
[21440] train loss: -0.12844356521964073, metric: 8.702932357788086, lr: 0.000598029000684619
[21460] train loss: 0.6782138869166374, metric: 11.9032222032547, lr: 0.0005668931407853961
[21480] train loss: 0.4441083110868931, metric: 11.634698867797852, lr: 0.0005354906315915287
[21500] train loss: 0.8708947338163853, metric: 13.793944239616394, lr: 0.0005039466777816415
[21520] train loss: 1.9593706093728542, metric: 12.612337589263916, lr: 0.0004723869787994772
[21540] train loss: 1.2868822775781155, metric: 21.192114114761353, lr: 0.0004409373505041003
[21560] train loss: 5.547714315354824, metric: 19.642795085906982, lr: 0.0004097231721971184
[21580] train loss: 1.585177544504404, metric: 17.70945143699646, lr: 0.000378868862753734
[21600] train loss: 11.248493704944849, metric: 17.641252994537354, lr: 0.00034849741496145725
[21620] train loss: 0.4652777872979641, metric: 16.77502679824829, lr: 0.0003187299007549882
[21640] train loss: 0.4817337766289711, metric: 12.896349430084229, lr: 0.0002896849764510989
[21660] train loss: 0.940090972930193, metric: 13.199398756027222, lr: 0.0002614784170873463
[21680] train loss: 3.357639990746975, metric: 14.474565267562866, lr: 0.00023422270896844566
[21700] train loss: 4.139919385313988, metric: 17.00521683692932, lr: 0.00020802643848583102
[21720] train loss: 1.1494998037815094, metric: 17.621517658233643, lr: 0.00018299407383892685
[21740] train loss: 1.6127206534147263, metric: 19.999815464019775, lr: 0.00015922538295853883
[21760] train loss: 8.820768617093563, metric: 22.54224419593811, lr: 0.00013681512791663408
[21780] train loss: 10.541284117847681, metric: 22.17724084854126, lr: 0.00011585262109292671
[21800] train loss: 0.9744431748986244, metric: 13.061226844787598, lr: 9.999999747378752e-05
[21820] train loss: 1.3450690619647503, metric: 13.44969630241394, lr: 9.999999747378752e-05
[21840] train loss: 0.8968163803219795, metric: 12.605599164962769, lr: 9.999999747378752e-05
[21860] train loss: 1.7795021533966064, metric: 17.057473182678223, lr: 9.999999747378752e-05
[21880] train loss: 11.040128387510777, metric: 17.97561764717102, lr: 9.999999747378752e-05
[21900] train loss: 6.244734093546867, metric: 17.770654678344727, lr: 9.999999747378752e-05
[21920] train loss: 1.380640272051096, metric: 18.30027198791504, lr: 9.999999747378752e-05
[21940] train loss: 0.6464074663817883, metric: 16.16884756088257, lr: 9.999999747378752e-05
[21960] train loss: 0.9992908090353012, metric: 15.735240936279297, lr: 9.999999747378752e-05
[21980] train loss: 0.5355873629450798, metric: 13.096141576766968, lr: 9.999999747378752e-05
[22000] train loss: 0.19382817670702934, metric: 13.267577886581421, lr: 9.999999747378752e-05
[22020] train loss: 7.331670105457306, metric: 23.802587270736694, lr: 0.0009994393913075328
[22040] train loss: 0.13079143315553665, metric: 11.896616697311401, lr: 0.0009969500824809074
[22060] train loss: 0.05840800702571869, metric: 12.247178077697754, lr: 0.000992479850538075
[22080] train loss: 0.6929553411900997, metric: 11.541768789291382, lr: 0.000986046390607953
[22100] train loss: 0.482032835483551, metric: 13.095188736915588, lr: 0.0009776754304766655
[22120] train loss: 1.0745215602219105, metric: 14.88891887664795, lr: 0.0009674003813415766
[22140] train loss: 1.7087807320058346, metric: 13.414578914642334, lr: 0.0009552621049806476
[22160] train loss: 1.0274318680167198, metric: 11.709555387496948, lr: 0.0009413089719600976
[22180] train loss: 0.3102691322565079, metric: 14.316740036010742, lr: 0.0009255966870114207
[22200] train loss: 0.22935503721237183, metric: 12.196349382400513, lr: 0.00090818788157776
[22220] train loss: 0.6622065976262093, metric: 12.347601890563965, lr: 0.0008891518809832633
[22240] train loss: 0.8342165239155293, metric: 12.6903817653656, lr: 0.0008685645880177617
[22260] train loss: 1.9408732987940311, metric: 11.501898527145386, lr: 0.0008465081336908042
[22280] train loss: 0.4437067247927189, metric: 10.08651578426361, lr: 0.0008230703533627093
[22300] train loss: 0.4965975917875767, metric: 11.101346731185913, lr: 0.0007983447285369039
[22320] train loss: 4.582129295915365, metric: 12.942762732505798, lr: 0.0007724298629909754
[22340] train loss: 0.6350841969251633, metric: 12.920750617980957, lr: 0.0007454289589077234
[22360] train loss: 0.4680982977151871, metric: 11.644315361976624, lr: 0.0007174497004598379
[22380] train loss: 1.1080119125545025, metric: 14.492296695709229, lr: 0.00068860367173329
[22400] train loss: 0.8340813964605331, metric: 11.457481265068054, lr: 0.0006590057746507227
[22420] train loss: 0.4178781770169735, metric: 14.639638185501099, lr: 0.0006287740543484688
[22440] train loss: 2.3086564615368843, metric: 14.362294435501099, lr: 0.000598029000684619
[22460] train loss: 0.23213965818285942, metric: 11.78696894645691, lr: 0.0005668931407853961
[22480] train loss: 2.086367029696703, metric: 14.179323434829712, lr: 0.0005354906315915287
[22500] train loss: 2.731771718710661, metric: 16.39150094985962, lr: 0.0005039466777816415
[22520] train loss: 2.0526319593191147, metric: 16.27479386329651, lr: 0.0004723869787994772
[22540] train loss: 0.269357044249773, metric: 12.320541858673096, lr: 0.0004409373505041003
[22560] train loss: -0.07669869810342789, metric: 8.561047077178955, lr: 0.0004097231721971184
[22580] train loss: -0.21972879394888878, metric: 9.440407991409302, lr: 0.000378868862753734
[22600] train loss: -0.18253641203045845, metric: 9.907168865203857, lr: 0.00034849741496145725
[22620] train loss: -0.216277327388525, metric: 9.19045877456665, lr: 0.0003187299007549882
[22640] train loss: -0.23054974898695946, metric: 8.16987681388855, lr: 0.0002896849764510989
[22660] train loss: -0.1927366815507412, metric: 9.485795259475708, lr: 0.0002614784170873463
[22680] train loss: -0.24515201151371002, metric: 8.633786082267761, lr: 0.00023422270896844566
[22700] train loss: -0.27468356117606163, metric: 8.05963933467865, lr: 0.00020802643848583102
[22720] train loss: -0.24610532447695732, metric: 8.017021894454956, lr: 0.00018299407383892685
[22740] train loss: -0.24264220148324966, metric: 8.643540143966675, lr: 0.00015922538295853883
[22760] train loss: -0.27119552716612816, metric: 8.043752670288086, lr: 0.00013681512791663408
[22780] train loss: -0.29733189940452576, metric: 8.035914182662964, lr: 0.00011585262109292671
[22800] train loss: -0.2830606773495674, metric: 8.417080163955688, lr: 9.999999747378752e-05
[22820] train loss: -0.15538093447685242, metric: 9.276228070259094, lr: 9.999999747378752e-05
[22840] train loss: -0.06092981994152069, metric: 9.052480936050415, lr: 9.999999747378752e-05
[22860] train loss: -0.02101048082113266, metric: 9.849644660949707, lr: 9.999999747378752e-05
[22880] train loss: -0.2107730470597744, metric: 9.487616300582886, lr: 9.999999747378752e-05
[22900] train loss: -0.1721571907401085, metric: 10.103407621383667, lr: 9.999999747378752e-05
[22920] train loss: 0.04712696745991707, metric: 11.465188264846802, lr: 9.999999747378752e-05
[22940] train loss: -0.051006898283958435, metric: 10.535802364349365, lr: 9.999999747378752e-05
[22960] train loss: -0.15567859634757042, metric: 8.270223617553711, lr: 9.999999747378752e-05
[22980] train loss: 0.13918231427669525, metric: 10.154280424118042, lr: 9.999999747378752e-05
[23000] train loss: -0.20056138560175896, metric: 7.603505849838257, lr: 9.999999747378752e-05
[23020] train loss: -0.2865443341434002, metric: 7.176953315734863, lr: 0.0009994393913075328
[23040] train loss: -0.33221159875392914, metric: 6.285115003585815, lr: 0.0009969500824809074
[23060] train loss: 1.1536711901426315, metric: 27.858229637145996, lr: 0.000992479850538075
[23080] train loss: 1.4191066212952137, metric: 16.34323811531067, lr: 0.000986046390607953
[23100] train loss: 1.0234350115060806, metric: 12.550097465515137, lr: 0.0009776754304766655
[23120] train loss: 1.2975444830954075, metric: 11.13004994392395, lr: 0.0009674003813415766
[23140] train loss: 5.217527903616428, metric: 16.440622806549072, lr: 0.0009552621049806476
[23160] train loss: 0.7863689102232456, metric: 19.48893427848816, lr: 0.0009413089719600976
[23180] train loss: 0.19395915418863297, metric: 12.280715227127075, lr: 0.0009255966870114207
[23200] train loss: 0.3501511700451374, metric: 15.13994836807251, lr: 0.00090818788157776
[23220] train loss: 0.47770408540964127, metric: 11.442864656448364, lr: 0.0008891518809832633
[23240] train loss: 0.4248344898223877, metric: 12.971060752868652, lr: 0.0008685645880177617
[23260] train loss: 0.3135327361524105, metric: 10.570310831069946, lr: 0.0008465081336908042
[23280] train loss: 1.7870464324951172, metric: 21.55515956878662, lr: 0.0008230703533627093
[23300] train loss: 10.317056391388178, metric: 34.38920736312866, lr: 0.0007983447285369039
[23320] train loss: 0.8008825518190861, metric: 22.041686058044434, lr: 0.0007724298629909754
[23340] train loss: 0.7322241067886353, metric: 18.428220748901367, lr: 0.0007454289589077234
[23360] train loss: 0.2673281840980053, metric: 13.239351511001587, lr: 0.0007174497004598379
[23380] train loss: 0.8481898196041584, metric: 18.736953020095825, lr: 0.00068860367173329
[23400] train loss: 2.8418424129486084, metric: 17.91193437576294, lr: 0.0006590057746507227
[23420] train loss: 1.4758162572979927, metric: 17.29604458808899, lr: 0.0006287740543484688
[23440] train loss: 2.2739329040050507, metric: 25.51659917831421, lr: 0.000598029000684619
[23460] train loss: 0.46300944313406944, metric: 17.919926643371582, lr: 0.0005668931407853961
[23480] train loss: 0.46366508305072784, metric: 13.928404808044434, lr: 0.0005354906315915287
[23500] train loss: 1.5525203123688698, metric: 13.985237836837769, lr: 0.0005039466777816415
[23520] train loss: 1.224111668765545, metric: 14.41007375717163, lr: 0.0004723869787994772
[23540] train loss: 1.2340085469186306, metric: 14.939939975738525, lr: 0.0004409373505041003
[23560] train loss: 3.4045587331056595, metric: 19.397834300994873, lr: 0.0004097231721971184
[23580] train loss: 0.25596214085817337, metric: 13.631866455078125, lr: 0.000378868862753734
[23600] train loss: 0.30356454849243164, metric: 13.139111757278442, lr: 0.00034849741496145725
[23620] train loss: 1.1755386367440224, metric: 17.413153171539307, lr: 0.0003187299007549882
[23640] train loss: 4.516208842396736, metric: 19.158060550689697, lr: 0.0002896849764510989
[23660] train loss: 1.8162034898996353, metric: 15.775459051132202, lr: 0.0002614784170873463
[23680] train loss: 2.264604926109314, metric: 18.884469985961914, lr: 0.00023422270896844566
[23700] train loss: 6.937688082456589, metric: 20.837830543518066, lr: 0.00020802643848583102
[23720] train loss: 6.796679139137268, metric: 19.492799758911133, lr: 0.00018299407383892685
[23740] train loss: 4.517562210559845, metric: 19.451029062271118, lr: 0.00015922538295853883
[23760] train loss: 1.8400998264551163, metric: 22.099764347076416, lr: 0.00013681512791663408
[23780] train loss: 1.9945589900016785, metric: 17.968849420547485, lr: 0.00011585262109292671
[23800] train loss: 1.8974470496177673, metric: 15.626852989196777, lr: 9.999999747378752e-05
[23820] train loss: 1.6117559522390366, metric: 20.16928744316101, lr: 9.999999747378752e-05
[23840] train loss: 0.873296782374382, metric: 17.619385242462158, lr: 9.999999747378752e-05
[23860] train loss: 0.9038231857120991, metric: 17.290896892547607, lr: 9.999999747378752e-05
[23880] train loss: 0.44565847516059875, metric: 14.723218441009521, lr: 9.999999747378752e-05
[23900] train loss: 0.4158896692097187, metric: 12.69740343093872, lr: 9.999999747378752e-05
[23920] train loss: 1.946416512131691, metric: 13.005344152450562, lr: 9.999999747378752e-05
[23940] train loss: 1.3169150836765766, metric: 15.446840763092041, lr: 9.999999747378752e-05
[23960] train loss: 0.6625252068042755, metric: 13.740309000015259, lr: 9.999999747378752e-05
[23980] train loss: 0.947652954608202, metric: 13.815452098846436, lr: 9.999999747378752e-05
[24000] train loss: 0.672822292894125, metric: 14.826362013816833, lr: 9.999999747378752e-05
[24020] train loss: 0.04701077565550804, metric: 15.476998329162598, lr: 0.0009994393913075328
[24040] train loss: 0.4237530417740345, metric: 14.514992952346802, lr: 0.0009969500824809074
[24060] train loss: 0.508916012942791, metric: 11.406828761100769, lr: 0.000992479850538075
[24080] train loss: 0.7769005745649338, metric: 19.207446098327637, lr: 0.000986046390607953
[24100] train loss: 0.405821580439806, metric: 10.880157709121704, lr: 0.0009776754304766655
[24120] train loss: 2.577883690595627, metric: 17.64499545097351, lr: 0.0009674003813415766
[24140] train loss: 0.9919324144721031, metric: 14.466497659683228, lr: 0.0009552621049806476
[24160] train loss: 0.09218468889594078, metric: 11.164246559143066, lr: 0.0009413089719600976
[24180] train loss: 1.675114966928959, metric: 12.826289176940918, lr: 0.0009255966870114207
[24200] train loss: 0.6661878079175949, metric: 13.588013172149658, lr: 0.00090818788157776
[24220] train loss: 0.2830217815935612, metric: 14.088188648223877, lr: 0.0008891518809832633
[24240] train loss: 0.7524563558399677, metric: 21.540966749191284, lr: 0.0008685645880177617
[24260] train loss: 0.43713799491524696, metric: 19.90522837638855, lr: 0.0008465081336908042
[24280] train loss: -0.07274321839213371, metric: 10.477295398712158, lr: 0.0008230703533627093
[24300] train loss: -0.1262567713856697, metric: 11.827772855758667, lr: 0.0007983447285369039
[24320] train loss: 0.251093290746212, metric: 13.450963258743286, lr: 0.0007724298629909754
[24340] train loss: 0.48503731191158295, metric: 17.302847623825073, lr: 0.0007454289589077234
[24360] train loss: 1.6545787248760462, metric: 11.506018996238708, lr: 0.0007174497004598379
[24380] train loss: 0.357801117002964, metric: 8.821646928787231, lr: 0.00068860367173329
[24400] train loss: 2.1542591899633408, metric: 17.861743927001953, lr: 0.0006590057746507227
[24420] train loss: 0.6086496599018574, metric: 11.498199224472046, lr: 0.0006287740543484688
[24440] train loss: 0.670631892979145, metric: 11.676038980484009, lr: 0.000598029000684619
[24460] train loss: 0.42240745574235916, metric: 17.766236543655396, lr: 0.0005668931407853961
[24480] train loss: -0.08303125575184822, metric: 11.13261866569519, lr: 0.0005354906315915287
[24500] train loss: -0.07851902581751347, metric: 9.167053699493408, lr: 0.0005039466777816415
[24520] train loss: -0.05850119702517986, metric: 9.702250719070435, lr: 0.0004723869787994772
[24540] train loss: 0.24106185883283615, metric: 8.647438526153564, lr: 0.0004409373505041003
[24560] train loss: 0.3004765212535858, metric: 12.578407764434814, lr: 0.0004097231721971184
[24580] train loss: 1.3987167328596115, metric: 20.19585156440735, lr: 0.000378868862753734
[24600] train loss: 0.05984251946210861, metric: 15.877066135406494, lr: 0.00034849741496145725
[24620] train loss: 0.11729206517338753, metric: 10.21842074394226, lr: 0.0003187299007549882
[24640] train loss: -0.07320626452565193, metric: 9.919958114624023, lr: 0.0002896849764510989
[24660] train loss: -0.13684115186333656, metric: 9.959132671356201, lr: 0.0002614784170873463
[24680] train loss: -0.16966178640723228, metric: 9.154581546783447, lr: 0.00023422270896844566
[24700] train loss: -0.195193063467741, metric: 8.629674196243286, lr: 0.00020802643848583102
[24720] train loss: -0.14454110339283943, metric: 10.068289279937744, lr: 0.00018299407383892685
[24740] train loss: -0.1309564933180809, metric: 10.286827802658081, lr: 0.00015922538295853883
[24760] train loss: -0.22003689035773277, metric: 11.01534628868103, lr: 0.00013681512791663408
[24780] train loss: -0.26788952946662903, metric: 9.663073778152466, lr: 0.00011585262109292671
[24800] train loss: -0.25528134778141975, metric: 10.506819725036621, lr: 9.999999747378752e-05
[24820] train loss: -0.23805127665400505, metric: 10.252568006515503, lr: 9.999999747378752e-05
[24840] train loss: -0.25342390686273575, metric: 9.913583874702454, lr: 9.999999747378752e-05
[24860] train loss: -0.2619115673005581, metric: 9.013230323791504, lr: 9.999999747378752e-05
[24880] train loss: -0.20422976091504097, metric: 9.156855463981628, lr: 9.999999747378752e-05
[24900] train loss: -0.12085483968257904, metric: 8.589147806167603, lr: 9.999999747378752e-05
[24920] train loss: -0.1791190169751644, metric: 8.621540307998657, lr: 9.999999747378752e-05
[24940] train loss: -0.15933021530508995, metric: 10.013324737548828, lr: 9.999999747378752e-05
[24960] train loss: 0.041953977197408676, metric: 9.841393828392029, lr: 9.999999747378752e-05
[24980] train loss: 0.15690646320581436, metric: 10.893756747245789, lr: 9.999999747378752e-05
[25000] train loss: 0.07641886174678802, metric: 9.762698292732239, lr: 9.999999747378752e-05
[25020] train loss: -0.14019325003027916, metric: 8.68762457370758, lr: 0.0009994393913075328
[25040] train loss: 0.13428406789898872, metric: 8.389161348342896, lr: 0.0009969500824809074
[25060] train loss: 0.3163137324154377, metric: 10.42696726322174, lr: 0.000992479850538075
[25080] train loss: 1.5251638442277908, metric: 12.71708071231842, lr: 0.000986046390607953
[25100] train loss: 0.815915659070015, metric: 19.654345512390137, lr: 0.0009776754304766655
[25120] train loss: 0.035156626254320145, metric: 10.889880895614624, lr: 0.0009674003813415766
[25140] train loss: 0.012259863317012787, metric: 8.810776472091675, lr: 0.0009552621049806476
[25160] train loss: 0.07073554396629333, metric: 8.544974684715271, lr: 0.0009413089719600976
[25180] train loss: 0.37204141169786453, metric: 10.281071424484253, lr: 0.0009255966870114207
[25200] train loss: 0.22942066565155983, metric: 10.95918083190918, lr: 0.00090818788157776
[25220] train loss: 0.3028404600918293, metric: 12.26038932800293, lr: 0.0008891518809832633
[25240] train loss: 0.5723211988806725, metric: 12.363923072814941, lr: 0.0008685645880177617
[25260] train loss: 0.08528580144047737, metric: 12.404439449310303, lr: 0.0008465081336908042
[25280] train loss: 0.11544319242238998, metric: 10.197727680206299, lr: 0.0008230703533627093
[25300] train loss: 0.9953849576413631, metric: 14.302657842636108, lr: 0.0007983447285369039
[25320] train loss: 3.1888508945703506, metric: 15.53111720085144, lr: 0.0007724298629909754
[25340] train loss: 0.5264557786285877, metric: 19.513137340545654, lr: 0.0007454289589077234
[25360] train loss: 0.6886769011616707, metric: 16.072629928588867, lr: 0.0007174497004598379
[25380] train loss: -0.155648123472929, metric: 11.895814657211304, lr: 0.00068860367173329
[25400] train loss: -0.09698193147778511, metric: 8.748239517211914, lr: 0.0006590057746507227
[25420] train loss: -0.11236253753304482, metric: 7.704009056091309, lr: 0.0006287740543484688
[25440] train loss: -0.2169283926486969, metric: 7.831650972366333, lr: 0.000598029000684619
[25460] train loss: -0.07265369221568108, metric: 10.735528469085693, lr: 0.0005668931407853961
[25480] train loss: -0.1446925289928913, metric: 6.434274315834045, lr: 0.0005354906315915287
[25500] train loss: 0.23834392800927162, metric: 7.689197897911072, lr: 0.0005039466777816415
[25520] train loss: 1.442785818129778, metric: 11.146904230117798, lr: 0.0004723869787994772
[25540] train loss: 0.16119415313005447, metric: 12.019571781158447, lr: 0.0004409373505041003
[25560] train loss: 0.157130666077137, metric: 10.86873972415924, lr: 0.0004097231721971184
[25580] train loss: -0.12194611877202988, metric: 8.823309659957886, lr: 0.000378868862753734
[25600] train loss: 0.04535038024187088, metric: 9.08349609375, lr: 0.00034849741496145725
[25620] train loss: -0.04961048811674118, metric: 13.901962280273438, lr: 0.0003187299007549882
[25640] train loss: -0.19800740480422974, metric: 9.522095441818237, lr: 0.0002896849764510989
[25660] train loss: -0.1789054498076439, metric: 9.19145679473877, lr: 0.0002614784170873463
[25680] train loss: -0.19270608946681023, metric: 9.86445426940918, lr: 0.00023422270896844566
[25700] train loss: -0.250243678689003, metric: 9.059742212295532, lr: 0.00020802643848583102
[25720] train loss: -0.2977277934551239, metric: 9.715277075767517, lr: 0.00018299407383892685
[25740] train loss: -0.33752137422561646, metric: 6.87800669670105, lr: 0.00015922538295853883
[25760] train loss: -0.33492205291986465, metric: 9.0385183095932, lr: 0.00013681512791663408
[25780] train loss: -0.2823368161916733, metric: 12.43997871875763, lr: 0.00011585262109292671
[25800] train loss: -0.2153037190437317, metric: 7.340569019317627, lr: 9.999999747378752e-05
[25820] train loss: -0.16100749373435974, metric: 8.132102966308594, lr: 9.999999747378752e-05
[25840] train loss: -0.08640110865235329, metric: 10.687869548797607, lr: 9.999999747378752e-05
[25860] train loss: -0.1532408446073532, metric: 11.42817997932434, lr: 9.999999747378752e-05
[25880] train loss: -0.240939661860466, metric: 10.593715906143188, lr: 9.999999747378752e-05
[25900] train loss: -0.3031610697507858, metric: 8.733636736869812, lr: 9.999999747378752e-05
[25920] train loss: -0.2420222908258438, metric: 7.678701877593994, lr: 9.999999747378752e-05
[25940] train loss: -0.2849836237728596, metric: 7.506784677505493, lr: 9.999999747378752e-05
[25960] train loss: -0.25201067328453064, metric: 7.757630109786987, lr: 9.999999747378752e-05
[25980] train loss: -0.16695476695895195, metric: 10.245585083961487, lr: 9.999999747378752e-05
[26000] train loss: -0.058160364627838135, metric: 8.432230472564697, lr: 9.999999747378752e-05
[26020] train loss: 0.44937125593423843, metric: 9.795621395111084, lr: 0.0009994393913075328
[26040] train loss: 0.01442018523812294, metric: 8.342591404914856, lr: 0.0009969500824809074
[26060] train loss: -0.19792980700731277, metric: 7.654947996139526, lr: 0.000992479850538075
[26080] train loss: -0.1969269961118698, metric: 9.142729759216309, lr: 0.000986046390607953
[26100] train loss: -0.12452493235468864, metric: 7.8890460729599, lr: 0.0009776754304766655
[26120] train loss: 1.3271558284759521, metric: 16.33160972595215, lr: 0.0009674003813415766
[26140] train loss: 2.4276592284440994, metric: 17.550517559051514, lr: 0.0009552621049806476
[26160] train loss: 1.0912401005625725, metric: 17.963526248931885, lr: 0.0009413089719600976
[26180] train loss: 0.2907707691192627, metric: 12.97994875907898, lr: 0.0009255966870114207
[26200] train loss: 3.227080576121807, metric: 13.759862899780273, lr: 0.00090818788157776
[26220] train loss: 3.448047436773777, metric: 18.21806573867798, lr: 0.0008891518809832633
[26240] train loss: 0.575436107814312, metric: 19.33470916748047, lr: 0.0008685645880177617
[26260] train loss: 0.5194081626832485, metric: 12.76267671585083, lr: 0.0008465081336908042
[26280] train loss: 0.21479885280132294, metric: 14.091365098953247, lr: 0.0008230703533627093
[26300] train loss: 0.7742782570421696, metric: 13.858827352523804, lr: 0.0007983447285369039
[26320] train loss: 0.2142932526767254, metric: 10.93959379196167, lr: 0.0007724298629909754
[26340] train loss: 0.10983109101653099, metric: 9.3879234790802, lr: 0.0007454289589077234
[26360] train loss: 0.4859265759587288, metric: 10.12692642211914, lr: 0.0007174497004598379
[26380] train loss: 1.1489269584417343, metric: 13.913950800895691, lr: 0.00068860367173329
[26400] train loss: 0.8683239705860615, metric: 14.57219934463501, lr: 0.0006590057746507227
[26420] train loss: 0.3348950706422329, metric: 21.46809673309326, lr: 0.0006287740543484688
[26440] train loss: 0.025283943861722946, metric: 15.845656394958496, lr: 0.000598029000684619
[26460] train loss: 0.23196593672037125, metric: 12.595717430114746, lr: 0.0005668931407853961
[26480] train loss: 0.6967690028250217, metric: 12.45307731628418, lr: 0.0005354906315915287
[26500] train loss: 0.019349370151758194, metric: 11.602571249008179, lr: 0.0005039466777816415
[26520] train loss: 0.13033649697899818, metric: 18.091840267181396, lr: 0.0004723869787994772
[26540] train loss: 0.08119698241353035, metric: 14.206145524978638, lr: 0.0004409373505041003
[26560] train loss: 0.6353136673569679, metric: 10.501904129981995, lr: 0.0004097231721971184
[26580] train loss: 0.3528953157365322, metric: 11.638463973999023, lr: 0.000378868862753734
[26600] train loss: 0.14984845370054245, metric: 11.082682132720947, lr: 0.00034849741496145725
[26620] train loss: 0.0538366362452507, metric: 10.631700158119202, lr: 0.0003187299007549882
[26640] train loss: 0.8131721913814545, metric: 16.8735032081604, lr: 0.0002896849764510989
[26660] train loss: 1.0940927565097809, metric: 12.806008577346802, lr: 0.0002614784170873463
[26680] train loss: 0.4686560072004795, metric: 13.633660554885864, lr: 0.00023422270896844566
[26700] train loss: 0.8538981042802334, metric: 13.439176321029663, lr: 0.00020802643848583102
[26720] train loss: 1.5261525176465511, metric: 11.743216514587402, lr: 0.00018299407383892685
[26740] train loss: 0.6884862370789051, metric: 12.260293245315552, lr: 0.00015922538295853883
[26760] train loss: -0.0016819648444652557, metric: 10.11850881576538, lr: 0.00013681512791663408
[26780] train loss: 0.5456732250750065, metric: 11.219653129577637, lr: 0.00011585262109292671
[26800] train loss: 11.535266932100058, metric: 19.87153196334839, lr: 9.999999747378752e-05
[26820] train loss: 2.9513074196875095, metric: 13.395277261734009, lr: 9.999999747378752e-05
[26840] train loss: 0.74104168638587, metric: 10.804086446762085, lr: 9.999999747378752e-05
[26860] train loss: 0.04672930762171745, metric: 11.435476541519165, lr: 9.999999747378752e-05
[26880] train loss: 1.4324674755334854, metric: 12.68269157409668, lr: 9.999999747378752e-05
[26900] train loss: 7.7130517438054085, metric: 21.716632604599, lr: 9.999999747378752e-05
[26920] train loss: 1.797793671488762, metric: 14.122387647628784, lr: 9.999999747378752e-05
[26940] train loss: 6.13891313970089, metric: 16.420980215072632, lr: 9.999999747378752e-05
[26960] train loss: 0.34487660974264145, metric: 12.641288995742798, lr: 9.999999747378752e-05
[26980] train loss: 1.5769309997558594, metric: 11.640979766845703, lr: 9.999999747378752e-05
[27000] train loss: 1.1701536625623703, metric: 12.425289511680603, lr: 9.999999747378752e-05
[27020] train loss: 0.7589092627167702, metric: 12.449295997619629, lr: 0.0009994393913075328
[27040] train loss: 0.48462484776973724, metric: 9.504397869110107, lr: 0.0009969500824809074
[27060] train loss: 1.0993053130805492, metric: 11.360525846481323, lr: 0.000992479850538075
[27080] train loss: 0.12779060751199722, metric: 9.454843044281006, lr: 0.000986046390607953
[27100] train loss: 0.15906788408756256, metric: 8.807852506637573, lr: 0.0009776754304766655
[27120] train loss: 0.5343809202313423, metric: 9.101123809814453, lr: 0.0009674003813415766
[27140] train loss: 3.6529096961021423, metric: 17.69995355606079, lr: 0.0009552621049806476
[27160] train loss: 0.13282618671655655, metric: 13.635741472244263, lr: 0.0009413089719600976
[27180] train loss: 0.07723637670278549, metric: 10.48806607723236, lr: 0.0009255966870114207
[27200] train loss: -0.122294582426548, metric: 9.333434462547302, lr: 0.00090818788157776
[27220] train loss: 0.9723637886345387, metric: 10.706985712051392, lr: 0.0008891518809832633
[27240] train loss: 0.6516067907214165, metric: 13.45121967792511, lr: 0.0008685645880177617
[27260] train loss: 0.42387788370251656, metric: 12.970125913619995, lr: 0.0008465081336908042
[27280] train loss: 0.6758078634738922, metric: 13.671582460403442, lr: 0.0008230703533627093
[27300] train loss: 0.7767548263072968, metric: 11.991864442825317, lr: 0.0007983447285369039
[27320] train loss: 0.39926842972636223, metric: 13.465555429458618, lr: 0.0007724298629909754
[27340] train loss: 0.09337479248642921, metric: 12.637638092041016, lr: 0.0007454289589077234
[27360] train loss: 0.08868153765797615, metric: 10.820700526237488, lr: 0.0007174497004598379
[27380] train loss: -0.006628882139921188, metric: 15.339023351669312, lr: 0.00068860367173329
[27400] train loss: -0.17620804905891418, metric: 10.630623817443848, lr: 0.0006590057746507227
[27420] train loss: -0.3050457425415516, metric: 7.301300525665283, lr: 0.0006287740543484688
[27440] train loss: -0.26756440103054047, metric: 8.499626874923706, lr: 0.000598029000684619
[27460] train loss: -0.279448963701725, metric: 7.758249759674072, lr: 0.0005668931407853961
[27480] train loss: -0.26406627893447876, metric: 7.873845338821411, lr: 0.0005354906315915287
[27500] train loss: -0.2379848137497902, metric: 7.582837104797363, lr: 0.0005039466777816415
[27520] train loss: -0.2964763641357422, metric: 7.800442218780518, lr: 0.0004723869787994772
[27540] train loss: -0.3083029016852379, metric: 7.811026573181152, lr: 0.0004409373505041003
[27560] train loss: -0.2874646671116352, metric: 7.277610659599304, lr: 0.0004097231721971184
[27580] train loss: -0.3205820098519325, metric: 6.969267129898071, lr: 0.000378868862753734
[27600] train loss: 0.08090553432703018, metric: 12.59339690208435, lr: 0.00034849741496145725
[27620] train loss: 0.06438110023736954, metric: 12.864025354385376, lr: 0.0003187299007549882
[27640] train loss: -0.10622844099998474, metric: 9.414691090583801, lr: 0.0002896849764510989
[27660] train loss: 1.4112837798893452, metric: 18.864436149597168, lr: 0.0002614784170873463
[27680] train loss: 1.048958234488964, metric: 16.763145685195923, lr: 0.00023422270896844566
[27700] train loss: 1.0053277611732483, metric: 11.790302753448486, lr: 0.00020802643848583102
[27720] train loss: 0.1738375872373581, metric: 14.27693247795105, lr: 0.00018299407383892685
[27740] train loss: 0.7592087350785732, metric: 12.767515182495117, lr: 0.00015922538295853883
[27760] train loss: 0.39643778651952744, metric: 12.654817342758179, lr: 0.00013681512791663408
[27780] train loss: 1.559896256774664, metric: 13.003602981567383, lr: 0.00011585262109292671
[27800] train loss: 0.5471707358956337, metric: 11.6380136013031, lr: 9.999999747378752e-05
[27820] train loss: 0.7482090778648853, metric: 11.933665752410889, lr: 9.999999747378752e-05
[27840] train loss: 1.5195016376674175, metric: 16.305724620819092, lr: 9.999999747378752e-05
[27860] train loss: 0.5637234263122082, metric: 15.489943742752075, lr: 9.999999747378752e-05
[27880] train loss: 0.9398198463022709, metric: 13.427909851074219, lr: 9.999999747378752e-05
[27900] train loss: 0.793984767049551, metric: 13.571625709533691, lr: 9.999999747378752e-05
[27920] train loss: 0.8088355585932732, metric: 13.318609952926636, lr: 9.999999747378752e-05
[27940] train loss: 3.622436936944723, metric: 15.289555549621582, lr: 9.999999747378752e-05
[27960] train loss: 1.6096863895654678, metric: 13.925319910049438, lr: 9.999999747378752e-05
[27980] train loss: 4.091648694127798, metric: 16.629483699798584, lr: 9.999999747378752e-05
[28000] train loss: 2.04159677028656, metric: 15.526844263076782, lr: 9.999999747378752e-05
[28020] train loss: 0.7611005045473576, metric: 11.943050861358643, lr: 0.0009994393913075328
[28040] train loss: 0.6496345475316048, metric: 12.50716757774353, lr: 0.0009969500824809074
[28060] train loss: 0.41956984251737595, metric: 13.81582760810852, lr: 0.000992479850538075
[28080] train loss: 0.41282329708337784, metric: 16.244288444519043, lr: 0.000986046390607953
[28100] train loss: 1.2930561751127243, metric: 14.235878229141235, lr: 0.0009776754304766655
[28120] train loss: 4.404273569583893, metric: 15.047708988189697, lr: 0.0009674003813415766
[28140] train loss: 1.078988216817379, metric: 16.06631326675415, lr: 0.0009552621049806476
[28160] train loss: 0.8170518204569817, metric: 16.72505259513855, lr: 0.0009413089719600976
[28180] train loss: 0.24609769880771637, metric: 11.772312879562378, lr: 0.0009255966870114207
[28200] train loss: -0.08160589262843132, metric: 10.788105487823486, lr: 0.00090818788157776
[28220] train loss: 0.2482079230248928, metric: 11.730314016342163, lr: 0.0008891518809832633
[28240] train loss: 0.12886592000722885, metric: 11.91605281829834, lr: 0.0008685645880177617
[28260] train loss: 0.07968657463788986, metric: 8.963655352592468, lr: 0.0008465081336908042
[28280] train loss: 1.140284888446331, metric: 12.881625175476074, lr: 0.0008230703533627093
[28300] train loss: 0.7848035395145416, metric: 14.919395208358765, lr: 0.0007983447285369039
[28320] train loss: 1.1136638522148132, metric: 10.880452156066895, lr: 0.0007724298629909754
[28340] train loss: 1.063718643039465, metric: 13.043825149536133, lr: 0.0007454289589077234
[28360] train loss: 3.0765503235161304, metric: 13.390426397323608, lr: 0.0007174497004598379
[28380] train loss: 0.6726930290460587, metric: 12.19419264793396, lr: 0.00068860367173329
[28400] train loss: 0.0519350990653038, metric: 11.693182945251465, lr: 0.0006590057746507227
[28420] train loss: 0.5771309733390808, metric: 12.955702781677246, lr: 0.0006287740543484688
[28440] train loss: 0.33782392740249634, metric: 13.865771412849426, lr: 0.000598029000684619
[28460] train loss: 0.17127860710024834, metric: 11.962215781211853, lr: 0.0005668931407853961
[28480] train loss: 1.1467902548611164, metric: 12.441577911376953, lr: 0.0005354906315915287
[28500] train loss: 0.32045697048306465, metric: 11.936063766479492, lr: 0.0005039466777816415
[28520] train loss: 1.4110025838017464, metric: 11.596372842788696, lr: 0.0004723869787994772
[28540] train loss: 0.6792880147695541, metric: 11.466938018798828, lr: 0.0004409373505041003
[28560] train loss: 0.3359203673899174, metric: 10.462001085281372, lr: 0.0004097231721971184
[28580] train loss: 0.9260373115539551, metric: 13.723760604858398, lr: 0.000378868862753734
[28600] train loss: 1.0040108934044838, metric: 13.470476150512695, lr: 0.00034849741496145725
[28620] train loss: 1.3448470197618008, metric: 12.891509771347046, lr: 0.0003187299007549882
[28640] train loss: 1.5359886288642883, metric: 14.954781770706177, lr: 0.0002896849764510989
[28660] train loss: 0.4655638113617897, metric: 14.704008340835571, lr: 0.0002614784170873463
[28680] train loss: 2.337857022881508, metric: 13.917986631393433, lr: 0.00023422270896844566
[28700] train loss: 0.4023607559502125, metric: 11.541491389274597, lr: 0.00020802643848583102
[28720] train loss: 0.18511273711919785, metric: 10.45151674747467, lr: 0.00018299407383892685
[28740] train loss: 0.17107746377587318, metric: 8.317560315132141, lr: 0.00015922538295853883
[28760] train loss: 0.28168245777487755, metric: 7.332550287246704, lr: 0.00013681512791663408
[28780] train loss: 1.1817599572241306, metric: 11.000611543655396, lr: 0.00011585262109292671
[28800] train loss: 0.750182431191206, metric: 11.877450346946716, lr: 9.999999747378752e-05
[28820] train loss: 1.910571288317442, metric: 16.15305185317993, lr: 9.999999747378752e-05
[28840] train loss: 3.893275871872902, metric: 15.207155466079712, lr: 9.999999747378752e-05
[28860] train loss: 3.870568670332432, metric: 19.60421323776245, lr: 9.999999747378752e-05
[28880] train loss: 2.487525898963213, metric: 18.65857243537903, lr: 9.999999747378752e-05
[28900] train loss: 0.9082464538514614, metric: 17.51087784767151, lr: 9.999999747378752e-05
[28920] train loss: 1.822644431143999, metric: 15.72799015045166, lr: 9.999999747378752e-05
[28940] train loss: 3.0029378160834312, metric: 17.527896404266357, lr: 9.999999747378752e-05
[28960] train loss: 6.61481598764658, metric: 21.70160222053528, lr: 9.999999747378752e-05
[28980] train loss: 2.8732505924999714, metric: 18.172264099121094, lr: 9.999999747378752e-05
[29000] train loss: 1.2718972861766815, metric: 15.864924669265747, lr: 9.999999747378752e-05
[29020] train loss: 0.6840910352766514, metric: 11.659993648529053, lr: 0.0009994393913075328
[29040] train loss: 0.36955758929252625, metric: 11.657285451889038, lr: 0.0009969500824809074
[29060] train loss: 0.39228447154164314, metric: 11.779089450836182, lr: 0.000992479850538075
[29080] train loss: 1.375739336013794, metric: 11.755720615386963, lr: 0.000986046390607953
[29100] train loss: 0.6762398891150951, metric: 18.594148755073547, lr: 0.0009776754304766655
[29120] train loss: 2.0529585480690002, metric: 10.337735056877136, lr: 0.0009674003813415766
[29140] train loss: 0.24748717993497849, metric: 10.38974416255951, lr: 0.0009552621049806476
[29160] train loss: 0.1942211166024208, metric: 9.361270070075989, lr: 0.0009413089719600976
[29180] train loss: -4.3120235204696655e-05, metric: 8.624884486198425, lr: 0.0009255966870114207
[29200] train loss: 0.43511974811553955, metric: 14.721888542175293, lr: 0.00090818788157776
[29220] train loss: -0.0018251873552799225, metric: 12.855321645736694, lr: 0.0008891518809832633
[29240] train loss: 0.40869035199284554, metric: 11.633085370063782, lr: 0.0008685645880177617
[29260] train loss: 0.5721713192760944, metric: 11.35968279838562, lr: 0.0008465081336908042
[29280] train loss: 0.04854605346918106, metric: 12.5826416015625, lr: 0.0008230703533627093
[29300] train loss: 0.33804477751255035, metric: 10.047376155853271, lr: 0.0007983447285369039
[29320] train loss: 0.7027796171605587, metric: 11.500388741493225, lr: 0.0007724298629909754
[29340] train loss: 1.34694342315197, metric: 17.378983974456787, lr: 0.0007454289589077234
[29360] train loss: 2.556580100208521, metric: 16.675726890563965, lr: 0.0007174497004598379
[29380] train loss: 3.472051728516817, metric: 19.07868194580078, lr: 0.00068860367173329
[29400] train loss: 0.09949655085802078, metric: 11.906781196594238, lr: 0.0006590057746507227
[29420] train loss: 1.406326536089182, metric: 12.136526823043823, lr: 0.0006287740543484688
[29440] train loss: 2.5879244543612003, metric: 16.199559211730957, lr: 0.000598029000684619
[29460] train loss: 0.8647139929234982, metric: 16.874852657318115, lr: 0.0005668931407853961
[29480] train loss: 1.2153116650879383, metric: 9.277271270751953, lr: 0.0005354906315915287
[29500] train loss: 0.5210989937186241, metric: 10.702555060386658, lr: 0.0005039466777816415
[29520] train loss: 0.600463192909956, metric: 17.749019861221313, lr: 0.0004723869787994772
[29540] train loss: 0.20531145110726357, metric: 14.306455373764038, lr: 0.0004409373505041003
[29560] train loss: 0.7320658043026924, metric: 15.830347776412964, lr: 0.0004097231721971184
[29580] train loss: 1.0608801431953907, metric: 16.99837589263916, lr: 0.000378868862753734
[29600] train loss: 4.433895673602819, metric: 18.7941472530365, lr: 0.00034849741496145725
[29620] train loss: 0.48892326280474663, metric: 11.726146936416626, lr: 0.0003187299007549882
[29640] train loss: 0.6173814982175827, metric: 10.499444961547852, lr: 0.0002896849764510989
[29660] train loss: 0.5330402590334415, metric: 11.765725135803223, lr: 0.0002614784170873463
[29680] train loss: 0.23707079887390137, metric: 14.168329954147339, lr: 0.00023422270896844566
[29700] train loss: 2.7027917355298996, metric: 18.74733591079712, lr: 0.00020802643848583102
[29720] train loss: 0.4617236852645874, metric: 16.064528465270996, lr: 0.00018299407383892685
[29740] train loss: -0.00023557990789413452, metric: 12.550387382507324, lr: 0.00015922538295853883
[29760] train loss: 0.05348975211381912, metric: 13.956772089004517, lr: 0.00013681512791663408
[29780] train loss: -0.0027050524950027466, metric: 12.662071228027344, lr: 0.00011585262109292671
[29800] train loss: 0.05264710262417793, metric: 12.442663431167603, lr: 9.999999747378752e-05
[29820] train loss: 0.05150246247649193, metric: 13.847527980804443, lr: 9.999999747378752e-05
[29840] train loss: 0.1637325882911682, metric: 14.60352087020874, lr: 9.999999747378752e-05
[29860] train loss: 0.20929814875125885, metric: 14.077223777770996, lr: 9.999999747378752e-05
[29880] train loss: 0.17380106821656227, metric: 14.841704368591309, lr: 9.999999747378752e-05
[29900] train loss: 0.11610428988933563, metric: 14.769534587860107, lr: 9.999999747378752e-05
[29920] train loss: 0.10654355958104134, metric: 12.94454574584961, lr: 9.999999747378752e-05
[29940] train loss: 1.0745465382933617, metric: 13.416782855987549, lr: 9.999999747378752e-05
[29960] train loss: 1.449753500521183, metric: 15.455309391021729, lr: 9.999999747378752e-05
[29980] train loss: 0.12828492373228073, metric: 12.603209972381592, lr: 9.999999747378752e-05
[30000] train loss: 0.1685112565755844, metric: 10.638890981674194, lr: 9.999999747378752e-05
[30020] train loss: 0.141783457249403, metric: 11.543221235275269, lr: 0.0009994393913075328
[30040] train loss: 0.0635664276778698, metric: 12.07834243774414, lr: 0.0009969500824809074
[30060] train loss: -0.05809152126312256, metric: 9.227276086807251, lr: 0.000992479850538075
[30080] train loss: -0.18600860983133316, metric: 8.922541499137878, lr: 0.000986046390607953
[30100] train loss: -0.20552944764494896, metric: 9.313762307167053, lr: 0.0009776754304766655
[30120] train loss: -0.21686659008264542, metric: 8.550450325012207, lr: 0.0009674003813415766
[30140] train loss: -0.25831054151058197, metric: 9.041011333465576, lr: 0.0009552621049806476
[30160] train loss: -0.26680994033813477, metric: 9.171559929847717, lr: 0.0009413089719600976
[30180] train loss: -0.18740415200591087, metric: 8.459496259689331, lr: 0.0009255966870114207
[30200] train loss: -0.16837245225906372, metric: 7.004141688346863, lr: 0.00090818788157776
[30220] train loss: 0.7335960902273655, metric: 15.61864948272705, lr: 0.0008891518809832633
[30240] train loss: 1.7828579619526863, metric: 15.28204083442688, lr: 0.0008685645880177617
[30260] train loss: 0.33746764436364174, metric: 11.839837789535522, lr: 0.0008465081336908042
[30280] train loss: 0.5849671140313148, metric: 10.971084833145142, lr: 0.0008230703533627093
[30300] train loss: 0.38424936309456825, metric: 10.498635411262512, lr: 0.0007983447285369039
[30320] train loss: 1.327355295419693, metric: 12.543382406234741, lr: 0.0007724298629909754
[30340] train loss: 1.055859737098217, metric: 12.368179559707642, lr: 0.0007454289589077234
[30360] train loss: 0.4735499396920204, metric: 11.931885719299316, lr: 0.0007174497004598379
[30380] train loss: 0.2526700161397457, metric: 13.23230528831482, lr: 0.00068860367173329
[30400] train loss: 0.8443132378160954, metric: 10.674049854278564, lr: 0.0006590057746507227
[30420] train loss: 0.5105057768523693, metric: 13.16812539100647, lr: 0.0006287740543484688
[30440] train loss: 0.37650252506136894, metric: 12.104920148849487, lr: 0.000598029000684619
[30460] train loss: 0.3203737288713455, metric: 12.538463115692139, lr: 0.0005668931407853961
[30480] train loss: 0.46118615195155144, metric: 14.95398998260498, lr: 0.0005354906315915287
[30500] train loss: 0.7517932616174221, metric: 12.804855108261108, lr: 0.0005039466777816415
[30520] train loss: 0.7908111214637756, metric: 15.095460414886475, lr: 0.0004723869787994772
[30540] train loss: 1.132656380534172, metric: 12.886574506759644, lr: 0.0004409373505041003
[30560] train loss: 0.6983935907483101, metric: 11.74060869216919, lr: 0.0004097231721971184
[30580] train loss: 0.953403327614069, metric: 9.917083024978638, lr: 0.000378868862753734
[30600] train loss: 1.0788533799350262, metric: 10.266377449035645, lr: 0.00034849741496145725
[30620] train loss: 0.6354571841657162, metric: 11.270835399627686, lr: 0.0003187299007549882
[30640] train loss: 0.5022332482039928, metric: 10.04515552520752, lr: 0.0002896849764510989
[30660] train loss: 3.594230841845274, metric: 16.858771085739136, lr: 0.0002614784170873463
[30680] train loss: 0.6316251270473003, metric: 11.576186418533325, lr: 0.00023422270896844566
[30700] train loss: 0.4512796700000763, metric: 11.082721710205078, lr: 0.00020802643848583102
[30720] train loss: 0.5518670380115509, metric: 13.792574882507324, lr: 0.00018299407383892685
[30740] train loss: 0.006300017237663269, metric: 15.540581703186035, lr: 0.00015922538295853883
[30760] train loss: -0.16304386407136917, metric: 14.737673997879028, lr: 0.00013681512791663408
[30780] train loss: -0.190844614058733, metric: 13.444840431213379, lr: 0.00011585262109292671
[30800] train loss: -0.08184103295207024, metric: 13.993161678314209, lr: 9.999999747378752e-05
[30820] train loss: -0.12282078340649605, metric: 13.10132384300232, lr: 9.999999747378752e-05
[30840] train loss: -0.07407660409808159, metric: 12.716051578521729, lr: 9.999999747378752e-05
[30860] train loss: -0.18960532173514366, metric: 12.380285024642944, lr: 9.999999747378752e-05
[30880] train loss: -0.0227007158100605, metric: 14.050772428512573, lr: 9.999999747378752e-05
[30900] train loss: -0.175357636064291, metric: 12.77728533744812, lr: 9.999999747378752e-05
[30920] train loss: -0.19003356248140335, metric: 12.177990436553955, lr: 9.999999747378752e-05
[30940] train loss: -0.22492508217692375, metric: 11.833444595336914, lr: 9.999999747378752e-05
[30960] train loss: 0.035106442868709564, metric: 12.006471395492554, lr: 9.999999747378752e-05
[30980] train loss: 0.028185442090034485, metric: 12.446381092071533, lr: 9.999999747378752e-05
[31000] train loss: 0.4094195142388344, metric: 11.573062658309937, lr: 9.999999747378752e-05
[31020] train loss: -0.09105005487799644, metric: 11.100416421890259, lr: 0.0009994393913075328
[31040] train loss: -0.26087910309433937, metric: 11.513965606689453, lr: 0.0009969500824809074
[31060] train loss: -0.29024939239025116, metric: 11.108973026275635, lr: 0.000992479850538075
[31080] train loss: -0.32574833929538727, metric: 11.07274580001831, lr: 0.000986046390607953
[31100] train loss: -0.30436335876584053, metric: 9.605312585830688, lr: 0.0009776754304766655
[31120] train loss: -0.31661388650536537, metric: 10.323868989944458, lr: 0.0009674003813415766
[31140] train loss: -0.31395144015550613, metric: 10.1503826379776, lr: 0.0009552621049806476
[31160] train loss: -0.1637619584798813, metric: 11.428369045257568, lr: 0.0009413089719600976
[31180] train loss: -0.31314339488744736, metric: 9.787962913513184, lr: 0.0009255966870114207
[31200] train loss: -0.3237948939204216, metric: 9.189465165138245, lr: 0.00090818788157776
[31220] train loss: -0.32585688680410385, metric: 8.92380666732788, lr: 0.0008891518809832633
[31240] train loss: 0.36640680953860283, metric: 13.942472219467163, lr: 0.0008685645880177617
[31260] train loss: -0.23305543139576912, metric: 10.254050016403198, lr: 0.0008465081336908042
[31280] train loss: -0.30539946258068085, metric: 8.490296602249146, lr: 0.0008230703533627093
[31300] train loss: -0.31268884986639023, metric: 10.142139911651611, lr: 0.0007983447285369039
[31320] train loss: -0.31095973402261734, metric: 8.218525886535645, lr: 0.0007724298629909754
[31340] train loss: -0.08721385523676872, metric: 8.148075819015503, lr: 0.0007454289589077234
[31360] train loss: -0.15213099494576454, metric: 7.135263204574585, lr: 0.0007174497004598379
[31380] train loss: -0.13892610743641853, metric: 7.602181553840637, lr: 0.00068860367173329
[31400] train loss: -0.13304370269179344, metric: 7.918787956237793, lr: 0.0006590057746507227
[31420] train loss: -0.29117172583937645, metric: 7.466860890388489, lr: 0.0006287740543484688
[31440] train loss: -0.004955582320690155, metric: 6.607056379318237, lr: 0.000598029000684619
[31460] train loss: 0.13446108996868134, metric: 9.306147813796997, lr: 0.0005668931407853961
[31480] train loss: -0.03612145036458969, metric: 11.868080139160156, lr: 0.0005354906315915287
[31500] train loss: -0.03696053475141525, metric: 9.394562244415283, lr: 0.0005039466777816415
[31520] train loss: 0.20754000172019005, metric: 15.671683549880981, lr: 0.0004723869787994772
[31540] train loss: -0.04940970614552498, metric: 11.89011287689209, lr: 0.0004409373505041003
[31560] train loss: -0.20389488711953163, metric: 10.289626836776733, lr: 0.0004097231721971184
[31580] train loss: -0.21179389581084251, metric: 11.313464403152466, lr: 0.000378868862753734
[31600] train loss: -0.23581266403198242, metric: 7.79211699962616, lr: 0.00034849741496145725
[31620] train loss: -0.026686929166316986, metric: 8.971275329589844, lr: 0.0003187299007549882
[31640] train loss: -0.055468909442424774, metric: 9.867644309997559, lr: 0.0002896849764510989
[31660] train loss: -0.17240343987941742, metric: 9.844112753868103, lr: 0.0002614784170873463
[31680] train loss: -0.030756548047065735, metric: 8.98301100730896, lr: 0.00023422270896844566
[31700] train loss: -0.04912824183702469, metric: 10.808205485343933, lr: 0.00020802643848583102
[31720] train loss: -0.08773466944694519, metric: 12.0215904712677, lr: 0.00018299407383892685
[31740] train loss: 3.4163256995379925, metric: 14.485844612121582, lr: 0.00015922538295853883
[31760] train loss: 0.007182091474533081, metric: 14.15605878829956, lr: 0.00013681512791663408
[31780] train loss: -0.21516099199652672, metric: 11.1921067237854, lr: 0.00011585262109292671
[31800] train loss: -0.19396543875336647, metric: 11.194418668746948, lr: 9.999999747378752e-05
[31820] train loss: -0.2438601292669773, metric: 8.763193845748901, lr: 9.999999747378752e-05
[31840] train loss: -0.2905780151486397, metric: 7.845364451408386, lr: 9.999999747378752e-05
[31860] train loss: -0.25094613432884216, metric: 9.935495138168335, lr: 9.999999747378752e-05
[31880] train loss: -0.262655109167099, metric: 9.5265634059906, lr: 9.999999747378752e-05
[31900] train loss: -0.22356031090021133, metric: 9.182229042053223, lr: 9.999999747378752e-05
[31920] train loss: -0.14923686161637306, metric: 9.926784038543701, lr: 9.999999747378752e-05
[31940] train loss: -0.15487141534686089, metric: 13.521942377090454, lr: 9.999999747378752e-05
[31960] train loss: -0.18171922862529755, metric: 10.58747398853302, lr: 9.999999747378752e-05
[31980] train loss: 0.003657568246126175, metric: 10.310379981994629, lr: 9.999999747378752e-05
[32000] train loss: -0.15677576139569283, metric: 10.826858758926392, lr: 9.999999747378752e-05
[32020] train loss: 0.1747116930782795, metric: 10.793376207351685, lr: 0.0009994393913075328
[32040] train loss: 0.772851325571537, metric: 13.187091827392578, lr: 0.0009969500824809074
[32060] train loss: 2.474974501878023, metric: 18.239948749542236, lr: 0.000992479850538075
[32080] train loss: 6.227130617946386, metric: 17.66009783744812, lr: 0.000986046390607953
[32100] train loss: 1.1996312700212002, metric: 15.60652208328247, lr: 0.0009776754304766655
[32120] train loss: 0.4161284267902374, metric: 18.780434608459473, lr: 0.0009674003813415766
[32140] train loss: -0.00018006190657615662, metric: 11.427906513214111, lr: 0.0009552621049806476
[32160] train loss: 0.08712083101272583, metric: 10.447152137756348, lr: 0.0009413089719600976
[32180] train loss: 0.17028585821390152, metric: 9.749817371368408, lr: 0.0009255966870114207
[32200] train loss: 0.12339507043361664, metric: 9.763629078865051, lr: 0.00090818788157776
[32220] train loss: 0.030057523399591446, metric: 9.900765657424927, lr: 0.0008891518809832633
[32240] train loss: -0.1884814091026783, metric: 9.071514129638672, lr: 0.0008685645880177617
[32260] train loss: 1.5758304707705975, metric: 16.0544114112854, lr: 0.0008465081336908042
[32280] train loss: 0.5671465434134007, metric: 15.745982646942139, lr: 0.0008230703533627093
[32300] train loss: -0.02909380942583084, metric: 12.400146007537842, lr: 0.0007983447285369039
[32320] train loss: 0.28916357457637787, metric: 13.483031034469604, lr: 0.0007724298629909754
[32340] train loss: 0.6540482416749, metric: 12.6604642868042, lr: 0.0007454289589077234
[32360] train loss: 6.896116741001606, metric: 20.789148807525635, lr: 0.0007174497004598379
[32380] train loss: 1.0567764639854431, metric: 12.96068811416626, lr: 0.00068860367173329
[32400] train loss: 0.5323966890573502, metric: 10.494935154914856, lr: 0.0006590057746507227
[32420] train loss: -0.04050392284989357, metric: 14.76760983467102, lr: 0.0006287740543484688
[32440] train loss: 0.16909516975283623, metric: 10.038592338562012, lr: 0.000598029000684619
[32460] train loss: -0.17905083298683167, metric: 11.00929594039917, lr: 0.0005668931407853961
[32480] train loss: -0.07143038138747215, metric: 12.208263397216797, lr: 0.0005354906315915287
[32500] train loss: -0.20129240304231644, metric: 12.70665955543518, lr: 0.0005039466777816415
[32520] train loss: -0.19285163283348083, metric: 10.295819878578186, lr: 0.0004723869787994772
[32540] train loss: 3.309164371341467, metric: 22.11590325832367, lr: 0.0004409373505041003
[32560] train loss: 1.3077610060572624, metric: 21.446414709091187, lr: 0.0004097231721971184
[32580] train loss: 1.952968742698431, metric: 10.598767280578613, lr: 0.000378868862753734
[32600] train loss: 0.028409328311681747, metric: 12.745603442192078, lr: 0.00034849741496145725
[32620] train loss: 0.07860453426837921, metric: 9.006530284881592, lr: 0.0003187299007549882
[32640] train loss: 0.29506732150912285, metric: 10.288925170898438, lr: 0.0002896849764510989
[32660] train loss: 0.19164986535906792, metric: 8.440794229507446, lr: 0.0002614784170873463
[32680] train loss: 0.6456923671066761, metric: 11.732394576072693, lr: 0.00023422270896844566
[32700] train loss: 0.5541403964161873, metric: 10.260679960250854, lr: 0.00020802643848583102
[32720] train loss: -0.06343728676438332, metric: 11.301997303962708, lr: 0.00018299407383892685
[32740] train loss: -0.1393812894821167, metric: 12.827850461006165, lr: 0.00015922538295853883
[32760] train loss: -0.12031478807330132, metric: 12.731451272964478, lr: 0.00013681512791663408
[32780] train loss: 2.704529419541359, metric: 19.915646076202393, lr: 0.00011585262109292671
[32800] train loss: 1.6128268390893936, metric: 18.545676708221436, lr: 9.999999747378752e-05
[32820] train loss: 2.891562681645155, metric: 20.14504647254944, lr: 9.999999747378752e-05
[32840] train loss: 3.811176508665085, metric: 16.98796582221985, lr: 9.999999747378752e-05
[32860] train loss: 1.6014758422970772, metric: 16.131585597991943, lr: 9.999999747378752e-05
[32880] train loss: 2.6664124950766563, metric: 16.17046570777893, lr: 9.999999747378752e-05
[32900] train loss: 2.5648584328591824, metric: 17.662190437316895, lr: 9.999999747378752e-05
[32920] train loss: 2.1230850145220757, metric: 16.03311038017273, lr: 9.999999747378752e-05
[32940] train loss: 11.67452023923397, metric: 21.726891040802002, lr: 9.999999747378752e-05
[32960] train loss: 3.350775845348835, metric: 18.246889352798462, lr: 9.999999747378752e-05
[32980] train loss: 0.3396383263170719, metric: 16.123061656951904, lr: 9.999999747378752e-05
[33000] train loss: 0.10872792080044746, metric: 12.287954568862915, lr: 9.999999747378752e-05
[33020] train loss: -0.1929003745317459, metric: 10.1486097574234, lr: 0.0009994393913075328
[33040] train loss: -0.25833938643336296, metric: 9.383676767349243, lr: 0.0009969500824809074
[33060] train loss: -0.232052493840456, metric: 8.197326302528381, lr: 0.000992479850538075
[33080] train loss: -0.2456256002187729, metric: 7.883997201919556, lr: 0.000986046390607953
[33100] train loss: -0.2644513286650181, metric: 9.905853748321533, lr: 0.0009776754304766655
[33120] train loss: -0.23125933855772018, metric: 8.502226114273071, lr: 0.0009674003813415766
[33140] train loss: -0.2097298465669155, metric: 10.030375242233276, lr: 0.0009552621049806476
[33160] train loss: -0.0195147767663002, metric: 9.840425252914429, lr: 0.0009413089719600976
[33180] train loss: 0.11854556202888489, metric: 10.284937858581543, lr: 0.0009255966870114207
[33200] train loss: 0.17826661095023155, metric: 11.755372285842896, lr: 0.00090818788157776
[33220] train loss: -0.02253759652376175, metric: 10.00900673866272, lr: 0.0008891518809832633
[33240] train loss: 0.46509967371821404, metric: 12.197224855422974, lr: 0.0008685645880177617
[33260] train loss: 0.2151038981974125, metric: 10.235683917999268, lr: 0.0008465081336908042
[33280] train loss: 0.09092937037348747, metric: 10.526085615158081, lr: 0.0008230703533627093
[33300] train loss: -0.12924911826848984, metric: 13.170738697052002, lr: 0.0007983447285369039
[33320] train loss: 0.27765193209052086, metric: 11.817445397377014, lr: 0.0007724298629909754
[33340] train loss: 0.20033615827560425, metric: 11.388888835906982, lr: 0.0007454289589077234
[33360] train loss: 1.4826953373849392, metric: 14.774957180023193, lr: 0.0007174497004598379
[33380] train loss: 0.5833863466978073, metric: 13.389004468917847, lr: 0.00068860367173329
[33400] train loss: 1.3503412157297134, metric: 12.867828607559204, lr: 0.0006590057746507227
[33420] train loss: 0.9335859827697277, metric: 12.801955819129944, lr: 0.0006287740543484688
[33440] train loss: 1.8740487322211266, metric: 14.527179718017578, lr: 0.000598029000684619
[33460] train loss: 2.914072372019291, metric: 21.517199993133545, lr: 0.0005668931407853961
[33480] train loss: 2.3494222909212112, metric: 16.993671894073486, lr: 0.0005354906315915287
[33500] train loss: 1.5120546519756317, metric: 16.496178150177002, lr: 0.0005039466777816415
[33520] train loss: 0.7392236813902855, metric: 16.460172653198242, lr: 0.0004723869787994772
[33540] train loss: 1.3889583051204681, metric: 13.414566278457642, lr: 0.0004409373505041003
[33560] train loss: 0.4308077432215214, metric: 13.505252599716187, lr: 0.0004097231721971184
[33580] train loss: 0.4224467761814594, metric: 16.154820919036865, lr: 0.000378868862753734
[33600] train loss: -0.05195967108011246, metric: 12.453454732894897, lr: 0.00034849741496145725
[33620] train loss: -0.20990095660090446, metric: 10.918839931488037, lr: 0.0003187299007549882
[33640] train loss: -0.2855262756347656, metric: 11.301450848579407, lr: 0.0002896849764510989
[33660] train loss: -0.23060975223779678, metric: 9.488479614257812, lr: 0.0002614784170873463
[33680] train loss: -0.2731836289167404, metric: 9.007003664970398, lr: 0.00023422270896844566
[33700] train loss: -0.24939799681305885, metric: 8.797069072723389, lr: 0.00020802643848583102
[33720] train loss: -0.11881256476044655, metric: 11.591474294662476, lr: 0.00018299407383892685
[33740] train loss: -0.2688909024000168, metric: 10.396684646606445, lr: 0.00015922538295853883
[33760] train loss: -0.18177440017461777, metric: 11.223249197006226, lr: 0.00013681512791663408
[33780] train loss: -0.18775133043527603, metric: 11.398544311523438, lr: 0.00011585262109292671
[33800] train loss: 7.697420351207256, metric: 36.822317123413086, lr: 9.999999747378752e-05
[33820] train loss: 3.717300847172737, metric: 22.256460189819336, lr: 9.999999747378752e-05
[33840] train loss: 2.3108437284827232, metric: 20.607592582702637, lr: 9.999999747378752e-05
[33860] train loss: 7.719147652387619, metric: 23.498926162719727, lr: 9.999999747378752e-05
[33880] train loss: 3.228083550930023, metric: 20.780245304107666, lr: 9.999999747378752e-05
[33900] train loss: 2.2829150557518005, metric: 17.503082036972046, lr: 9.999999747378752e-05
[33920] train loss: 1.4848996512591839, metric: 15.069079160690308, lr: 9.999999747378752e-05
[33940] train loss: 3.077283814549446, metric: 18.226192951202393, lr: 9.999999747378752e-05
[33960] train loss: 0.7928104028105736, metric: 18.27695369720459, lr: 9.999999747378752e-05
[33980] train loss: 0.29631271585822105, metric: 14.568244218826294, lr: 9.999999747378752e-05
[34000] train loss: 0.17377281561493874, metric: 11.837042808532715, lr: 9.999999747378752e-05
[34020] train loss: -0.07180354744195938, metric: 8.369847297668457, lr: 0.0009994393913075328
[34040] train loss: -0.05508163571357727, metric: 9.365910053253174, lr: 0.0009969500824809074
[34060] train loss: -0.1526985950767994, metric: 9.782236814498901, lr: 0.000992479850538075
[34080] train loss: -0.08344671130180359, metric: 9.181190490722656, lr: 0.000986046390607953
[34100] train loss: -0.1721027810126543, metric: 8.681965112686157, lr: 0.0009776754304766655
[34120] train loss: -0.06497559696435928, metric: 8.591453075408936, lr: 0.0009674003813415766
[34140] train loss: 0.44636230543255806, metric: 9.436111688613892, lr: 0.0009552621049806476
[34160] train loss: 0.7944384180009365, metric: 8.2642502784729, lr: 0.0009413089719600976
[34180] train loss: 0.02600201964378357, metric: 8.21684455871582, lr: 0.0009255966870114207
[34200] train loss: -0.011346589773893356, metric: 9.365350008010864, lr: 0.00090818788157776
[34220] train loss: 1.6979571133852005, metric: 12.45408046245575, lr: 0.0008891518809832633
[34240] train loss: 0.5616304390132427, metric: 10.045922756195068, lr: 0.0008685645880177617
[34260] train loss: 3.3473509438335896, metric: 13.121440410614014, lr: 0.0008465081336908042
[34280] train loss: 0.8147539086639881, metric: 13.531487464904785, lr: 0.0008230703533627093
[34300] train loss: 0.9885206036269665, metric: 10.731415629386902, lr: 0.0007983447285369039
[34320] train loss: 0.24401616677641869, metric: 15.74342393875122, lr: 0.0007724298629909754
[34340] train loss: -0.08533584699034691, metric: 10.918383598327637, lr: 0.0007454289589077234
[34360] train loss: 1.4260086864233017, metric: 13.90012788772583, lr: 0.0007174497004598379
[34380] train loss: 0.9593049995601177, metric: 17.797868967056274, lr: 0.00068860367173329
[34400] train loss: 0.8538344390690327, metric: 17.215139627456665, lr: 0.0006590057746507227
[34420] train loss: 0.7209135666489601, metric: 20.12512969970703, lr: 0.0006287740543484688
[34440] train loss: 0.37814054638147354, metric: 16.6769437789917, lr: 0.000598029000684619
[34460] train loss: 0.281359501183033, metric: 16.619616985321045, lr: 0.0005668931407853961
[34480] train loss: 0.1835029385983944, metric: 13.978789806365967, lr: 0.0005354906315915287
[34500] train loss: 0.08514988422393799, metric: 13.378886699676514, lr: 0.0005039466777816415
[34520] train loss: 0.24784426763653755, metric: 13.257348775863647, lr: 0.0004723869787994772
[34540] train loss: 0.11282255873084068, metric: 12.927361011505127, lr: 0.0004409373505041003
[34560] train loss: 1.0254104807972908, metric: 13.61807918548584, lr: 0.0004097231721971184
[34580] train loss: 0.6459661163389683, metric: 13.515713691711426, lr: 0.000378868862753734
[34600] train loss: 0.7754758223891258, metric: 14.943183898925781, lr: 0.00034849741496145725
[34620] train loss: 1.8620980717241764, metric: 14.031258583068848, lr: 0.0003187299007549882
[34640] train loss: 1.702275663614273, metric: 15.857712745666504, lr: 0.0002896849764510989
[34660] train loss: 0.5594333708286285, metric: 12.924950122833252, lr: 0.0002614784170873463
[34680] train loss: 1.8954830840229988, metric: 16.658534049987793, lr: 0.00023422270896844566
[34700] train loss: 0.5564278811216354, metric: 18.55319571495056, lr: 0.00020802643848583102
[34720] train loss: 0.9719110429286957, metric: 17.209726810455322, lr: 0.00018299407383892685
[34740] train loss: 0.4175749272108078, metric: 14.452242970466614, lr: 0.00015922538295853883
[34760] train loss: 1.072042241692543, metric: 17.47498345375061, lr: 0.00013681512791663408
[34780] train loss: 0.5610675103962421, metric: 12.078588843345642, lr: 0.00011585262109292671
[34800] train loss: 0.20493470504879951, metric: 11.161368131637573, lr: 9.999999747378752e-05
[34820] train loss: 5.725866943597794, metric: 24.758678913116455, lr: 9.999999747378752e-05
[34840] train loss: 1.9146139696240425, metric: 17.745215892791748, lr: 9.999999747378752e-05
[34860] train loss: 5.984295140951872, metric: 17.27555823326111, lr: 9.999999747378752e-05
[34880] train loss: 3.77665626257658, metric: 16.839356660842896, lr: 9.999999747378752e-05
[34900] train loss: 2.2385834753513336, metric: 14.349900007247925, lr: 9.999999747378752e-05
[34920] train loss: 0.30048972740769386, metric: 14.170835256576538, lr: 9.999999747378752e-05
[34940] train loss: 0.9374846033751965, metric: 14.91858720779419, lr: 9.999999747378752e-05
[34960] train loss: 1.7921822480857372, metric: 14.859128713607788, lr: 9.999999747378752e-05
[34980] train loss: 1.2735976800322533, metric: 15.246176958084106, lr: 9.999999747378752e-05
[35000] train loss: 0.20424096286296844, metric: 15.067278385162354, lr: 9.999999747378752e-05
[35020] train loss: 0.3959134891629219, metric: 13.450884103775024, lr: 0.0009994393913075328
[35040] train loss: 1.1667109578847885, metric: 13.741150856018066, lr: 0.0009969500824809074
[35060] train loss: 1.1074452735483646, metric: 12.785517692565918, lr: 0.000992479850538075
[35080] train loss: 6.454131823033094, metric: 12.431167125701904, lr: 0.000986046390607953
[35100] train loss: 0.11289636418223381, metric: 9.756192684173584, lr: 0.0009776754304766655
[35120] train loss: 0.9123595356941223, metric: 12.840734720230103, lr: 0.0009674003813415766
[35140] train loss: 3.918423254042864, metric: 16.340044736862183, lr: 0.0009552621049806476
[35160] train loss: 1.0169208720326424, metric: 13.570877313613892, lr: 0.0009413089719600976
[35180] train loss: 0.3557281047105789, metric: 12.339950799942017, lr: 0.0009255966870114207
[35200] train loss: 0.8072558045387268, metric: 14.29878830909729, lr: 0.00090818788157776
[35220] train loss: 2.5589487552642822, metric: 17.444694995880127, lr: 0.0008891518809832633
[35240] train loss: 1.6730386391282082, metric: 15.310084581375122, lr: 0.0008685645880177617
[35260] train loss: 4.520172689110041, metric: 16.860100984573364, lr: 0.0008465081336908042
[35280] train loss: 0.6077312547713518, metric: 12.905512809753418, lr: 0.0008230703533627093
[35300] train loss: 1.2343296706676483, metric: 11.414273262023926, lr: 0.0007983447285369039
[35320] train loss: 2.5659825187176466, metric: 14.851777791976929, lr: 0.0007724298629909754
[35340] train loss: 1.8858733288943768, metric: 17.368507623672485, lr: 0.0007454289589077234
[35360] train loss: 0.2408987358212471, metric: 15.610373973846436, lr: 0.0007174497004598379
[35380] train loss: -0.1459333412349224, metric: 10.385375499725342, lr: 0.00068860367173329
[35400] train loss: -0.09291023761034012, metric: 8.907517433166504, lr: 0.0006590057746507227
[35420] train loss: -0.1395086720585823, metric: 8.669311761856079, lr: 0.0006287740543484688
[35440] train loss: 0.0502295196056366, metric: 11.10352635383606, lr: 0.000598029000684619
[35460] train loss: 0.5953057929873466, metric: 14.113403797149658, lr: 0.0005668931407853961
[35480] train loss: 0.005507525056600571, metric: 10.67438018321991, lr: 0.0005354906315915287
[35500] train loss: 0.23462114855647087, metric: 10.615190029144287, lr: 0.0005039466777816415
[35520] train loss: 0.198053739964962, metric: 8.191615104675293, lr: 0.0004723869787994772
[35540] train loss: -0.11046953499317169, metric: 11.415418148040771, lr: 0.0004409373505041003
[35560] train loss: 0.43432484194636345, metric: 13.840387225151062, lr: 0.0004097231721971184
[35580] train loss: 0.29814740642905235, metric: 12.3043212890625, lr: 0.000378868862753734
[35600] train loss: -0.1117316298186779, metric: 11.5587477684021, lr: 0.00034849741496145725
[35620] train loss: 1.2154552973806858, metric: 14.265675783157349, lr: 0.0003187299007549882
[35640] train loss: 0.6156556457281113, metric: 13.119232416152954, lr: 0.0002896849764510989
[35660] train loss: 0.2820551469922066, metric: 13.856717109680176, lr: 0.0002614784170873463
[35680] train loss: 1.502012986689806, metric: 17.916876077651978, lr: 0.00023422270896844566
[35700] train loss: 0.26716333255171776, metric: 14.86241602897644, lr: 0.00020802643848583102
[35720] train loss: 0.5015306733548641, metric: 12.974161148071289, lr: 0.00018299407383892685
[35740] train loss: 1.0184858553111553, metric: 12.306888818740845, lr: 0.00015922538295853883
[35760] train loss: 0.5893609076738358, metric: 11.926341772079468, lr: 0.00013681512791663408
[35780] train loss: 0.46485085785388947, metric: 13.410969614982605, lr: 0.00011585262109292671
[35800] train loss: 0.397115983068943, metric: 13.48028564453125, lr: 9.999999747378752e-05
[35820] train loss: 0.20150058716535568, metric: 12.158729076385498, lr: 9.999999747378752e-05
[35840] train loss: 0.28376881778240204, metric: 11.884480357170105, lr: 9.999999747378752e-05
[35860] train loss: 3.1190060824155807, metric: 21.80357527732849, lr: 9.999999747378752e-05
[35880] train loss: 1.102111130952835, metric: 14.691838502883911, lr: 9.999999747378752e-05
[35900] train loss: 0.8068552725017071, metric: 16.286570072174072, lr: 9.999999747378752e-05
[35920] train loss: 1.450692892074585, metric: 19.61350655555725, lr: 9.999999747378752e-05
[35940] train loss: 1.6155533008277416, metric: 18.7106831073761, lr: 9.999999747378752e-05
[35960] train loss: 1.1029701605439186, metric: 17.40319561958313, lr: 9.999999747378752e-05
[35980] train loss: 1.0227871425449848, metric: 13.905320882797241, lr: 9.999999747378752e-05
[36000] train loss: 1.3756829537451267, metric: 13.213032007217407, lr: 9.999999747378752e-05
[36020] train loss: 1.3861264437437057, metric: 10.894899129867554, lr: 0.0009994393913075328
[36040] train loss: 2.969328559935093, metric: 13.751198530197144, lr: 0.0009969500824809074
[36060] train loss: 0.2320106364786625, metric: 12.284571647644043, lr: 0.000992479850538075
[36080] train loss: 0.18482941389083862, metric: 11.69307279586792, lr: 0.000986046390607953
[36100] train loss: 0.642849363386631, metric: 10.396207094192505, lr: 0.0009776754304766655
[36120] train loss: 0.7960079312324524, metric: 12.692762851715088, lr: 0.0009674003813415766
[36140] train loss: 0.2867400199174881, metric: 13.48743724822998, lr: 0.0009552621049806476
[36160] train loss: 0.7228783667087555, metric: 9.987157821655273, lr: 0.0009413089719600976
[36180] train loss: 0.8027382232248783, metric: 10.166595220565796, lr: 0.0009255966870114207
[36200] train loss: 5.255517054349184, metric: 15.45089602470398, lr: 0.00090818788157776
[36220] train loss: 0.7211076803505421, metric: 12.075777769088745, lr: 0.0008891518809832633
[36240] train loss: 1.7782084457576275, metric: 9.953020095825195, lr: 0.0008685645880177617
[36260] train loss: 2.178697507828474, metric: 10.963186383247375, lr: 0.0008465081336908042
[36280] train loss: 1.3487280793488026, metric: 11.073090195655823, lr: 0.0008230703533627093
[36300] train loss: 0.27605029940605164, metric: 10.856567859649658, lr: 0.0007983447285369039
[36320] train loss: 1.0218089446425438, metric: 9.783874988555908, lr: 0.0007724298629909754
[36340] train loss: 1.7386768721044064, metric: 17.058847904205322, lr: 0.0007454289589077234
[36360] train loss: 0.3122592605650425, metric: 16.751940488815308, lr: 0.0007174497004598379
[36380] train loss: 0.07124670594930649, metric: 14.878221035003662, lr: 0.00068860367173329
[36400] train loss: 0.10295924916863441, metric: 12.463216781616211, lr: 0.0006590057746507227
[36420] train loss: -0.2603820972144604, metric: 11.796512365341187, lr: 0.0006287740543484688
[36440] train loss: -0.21483492851257324, metric: 11.95823621749878, lr: 0.000598029000684619
[36460] train loss: -0.26623378694057465, metric: 12.649670124053955, lr: 0.0005668931407853961
[36480] train loss: -0.24828610196709633, metric: 12.716196537017822, lr: 0.0005354906315915287
[36500] train loss: -0.11747600510716438, metric: 14.384953022003174, lr: 0.0005039466777816415
[36520] train loss: -0.2256469838321209, metric: 13.412878513336182, lr: 0.0004723869787994772
[36540] train loss: -0.17103897407650948, metric: 11.928684711456299, lr: 0.0004409373505041003
[36560] train loss: -0.1450369507074356, metric: 11.735903024673462, lr: 0.0004097231721971184
[36580] train loss: -0.12153099477291107, metric: 12.81760549545288, lr: 0.000378868862753734
[36600] train loss: -0.07064832001924515, metric: 12.812237977981567, lr: 0.00034849741496145725
[36620] train loss: -0.1939775012433529, metric: 12.510610818862915, lr: 0.0003187299007549882
[36640] train loss: 0.10053025558590889, metric: 12.112028121948242, lr: 0.0002896849764510989
[36660] train loss: -0.048715755343437195, metric: 12.602404594421387, lr: 0.0002614784170873463
[36680] train loss: -0.19599801674485207, metric: 10.477116107940674, lr: 0.00023422270896844566
[36700] train loss: -0.24563157185912132, metric: 11.01599931716919, lr: 0.00020802643848583102
[36720] train loss: -0.19828093610703945, metric: 10.838783025741577, lr: 0.00018299407383892685
[36740] train loss: -0.17006190866231918, metric: 10.952324390411377, lr: 0.00015922538295853883
[36760] train loss: 0.8277705162763596, metric: 13.12227463722229, lr: 0.00013681512791663408
[36780] train loss: 0.06267359852790833, metric: 10.307258486747742, lr: 0.00011585262109292671
[36800] train loss: -0.1464780606329441, metric: 10.108896970748901, lr: 9.999999747378752e-05
[36820] train loss: -0.008242860436439514, metric: 11.021363973617554, lr: 9.999999747378752e-05
[36840] train loss: -0.019739285111427307, metric: 10.02818477153778, lr: 9.999999747378752e-05
[36860] train loss: 4.459643306210637, metric: 14.804951906204224, lr: 9.999999747378752e-05
[36880] train loss: 0.17285539582371712, metric: 11.640592575073242, lr: 9.999999747378752e-05
[36900] train loss: 11.203871455043554, metric: 21.71384048461914, lr: 9.999999747378752e-05
[36920] train loss: 1.0439522676169872, metric: 13.794574737548828, lr: 9.999999747378752e-05
[36940] train loss: 0.6244431808590889, metric: 12.535671710968018, lr: 9.999999747378752e-05
[36960] train loss: 0.8025269135832787, metric: 13.33017110824585, lr: 9.999999747378752e-05
[36980] train loss: 0.8545094504952431, metric: 18.413817405700684, lr: 9.999999747378752e-05
[37000] train loss: 1.3781109191477299, metric: 19.22542142868042, lr: 9.999999747378752e-05
[37020] train loss: 1.6260823458433151, metric: 20.099990844726562, lr: 0.0009994393913075328
[37040] train loss: 0.10674668848514557, metric: 15.111740827560425, lr: 0.0009969500824809074
[37060] train loss: 1.0841029547154903, metric: 13.587878704071045, lr: 0.000992479850538075
[37080] train loss: 1.6780790127813816, metric: 14.099723815917969, lr: 0.000986046390607953
[37100] train loss: 1.3214064165949821, metric: 12.087510585784912, lr: 0.0009776754304766655
[37120] train loss: 0.40199585258960724, metric: 10.636419177055359, lr: 0.0009674003813415766
[37140] train loss: 0.14945130795240402, metric: 9.870769143104553, lr: 0.0009552621049806476
[37160] train loss: -0.10168901458382607, metric: 8.326606631278992, lr: 0.0009413089719600976
[37180] train loss: 0.028595957905054092, metric: 9.366142272949219, lr: 0.0009255966870114207
[37200] train loss: -0.08256888762116432, metric: 7.520009160041809, lr: 0.00090818788157776
[37220] train loss: -0.08860695734620094, metric: 9.841993570327759, lr: 0.0008891518809832633
[37240] train loss: -0.21937448531389236, metric: 7.610379695892334, lr: 0.0008685645880177617
[37260] train loss: -0.15338006988167763, metric: 6.9019615650177, lr: 0.0008465081336908042
[37280] train loss: -0.2783445306122303, metric: 7.1989065408706665, lr: 0.0008230703533627093
[37300] train loss: -0.2577303685247898, metric: 7.8096684217453, lr: 0.0007983447285369039
[37320] train loss: 0.08760298043489456, metric: 10.037641167640686, lr: 0.0007724298629909754
[37340] train loss: -0.22233223170042038, metric: 9.5103178024292, lr: 0.0007454289589077234
[37360] train loss: -0.04507610201835632, metric: 7.3096925020217896, lr: 0.0007174497004598379
[37380] train loss: 9.686738345772028, metric: 20.429819583892822, lr: 0.00068860367173329
[37400] train loss: 0.14129837974905968, metric: 12.256053924560547, lr: 0.0006590057746507227
[37420] train loss: 0.21580318734049797, metric: 12.292327880859375, lr: 0.0006287740543484688
[37440] train loss: 0.2882763333618641, metric: 12.945324182510376, lr: 0.000598029000684619
[37460] train loss: -0.013554297387599945, metric: 13.020744800567627, lr: 0.0005668931407853961
[37480] train loss: -0.1497606374323368, metric: 10.450176000595093, lr: 0.0005354906315915287
[37500] train loss: -0.19948144629597664, metric: 10.539883255958557, lr: 0.0005039466777816415
[37520] train loss: -0.08934714645147324, metric: 8.617544889450073, lr: 0.0004723869787994772
[37540] train loss: -0.22789854556322098, metric: 7.681097984313965, lr: 0.0004409373505041003
[37560] train loss: -0.25663188472390175, metric: 9.515087842941284, lr: 0.0004097231721971184
[37580] train loss: -0.21578938513994217, metric: 8.85158395767212, lr: 0.000378868862753734
[37600] train loss: -0.23794802278280258, metric: 8.197579860687256, lr: 0.00034849741496145725
[37620] train loss: -0.16427212208509445, metric: 7.448716640472412, lr: 0.0003187299007549882
[37640] train loss: -0.2403278835117817, metric: 7.748395204544067, lr: 0.0002896849764510989
[37660] train loss: -0.15953224524855614, metric: 11.149352431297302, lr: 0.0002614784170873463
[37680] train loss: -0.12630880624055862, metric: 11.351893424987793, lr: 0.00023422270896844566
[37700] train loss: -0.1619640551507473, metric: 9.259700775146484, lr: 0.00020802643848583102
[37720] train loss: -0.0825747475028038, metric: 9.501662492752075, lr: 0.00018299407383892685
[37740] train loss: -0.1775328703224659, metric: 7.953546762466431, lr: 0.00015922538295853883
[37760] train loss: 0.3563288189470768, metric: 12.868254899978638, lr: 0.00013681512791663408
[37780] train loss: 0.5494631007313728, metric: 10.008017659187317, lr: 0.00011585262109292671
[37800] train loss: 1.4070517346262932, metric: 11.22459077835083, lr: 9.999999747378752e-05
[37820] train loss: 1.0437005832791328, metric: 16.4320011138916, lr: 9.999999747378752e-05
[37840] train loss: 0.6075110733509064, metric: 15.74863052368164, lr: 9.999999747378752e-05
[37860] train loss: 0.8344877362251282, metric: 16.168922781944275, lr: 9.999999747378752e-05
[37880] train loss: 0.5085403919219971, metric: 15.178690195083618, lr: 9.999999747378752e-05
[37900] train loss: 1.6288536973297596, metric: 16.718236684799194, lr: 9.999999747378752e-05
[37920] train loss: 0.12396837770938873, metric: 13.209205865859985, lr: 9.999999747378752e-05
[37940] train loss: 0.08571755886077881, metric: 10.763295412063599, lr: 9.999999747378752e-05
[37960] train loss: 0.10732605308294296, metric: 12.041455030441284, lr: 9.999999747378752e-05
[37980] train loss: 0.3630201518535614, metric: 12.950592041015625, lr: 9.999999747378752e-05
[38000] train loss: 0.239708062261343, metric: 12.25212836265564, lr: 9.999999747378752e-05
[38020] train loss: 0.0006315931677818298, metric: 10.04589033126831, lr: 0.0009994393913075328
[38040] train loss: 0.3465222530066967, metric: 11.01550817489624, lr: 0.0009969500824809074
[38060] train loss: -0.02601933479309082, metric: 8.516405582427979, lr: 0.000992479850538075
[38080] train loss: -0.04538198933005333, metric: 8.552389740943909, lr: 0.000986046390607953
[38100] train loss: 0.20335371792316437, metric: 8.907975435256958, lr: 0.0009776754304766655
[38120] train loss: -0.039913665503263474, metric: 10.308197498321533, lr: 0.0009674003813415766
[38140] train loss: -0.07568565011024475, metric: 9.57276976108551, lr: 0.0009552621049806476
[38160] train loss: -0.2212214060127735, metric: 8.00797176361084, lr: 0.0009413089719600976
[38180] train loss: -0.2544381022453308, metric: 8.143343925476074, lr: 0.0009255966870114207
[38200] train loss: 0.008004184812307358, metric: 8.212731122970581, lr: 0.00090818788157776
[38220] train loss: 0.35609104111790657, metric: 8.246518611907959, lr: 0.0008891518809832633
[38240] train loss: 0.21502607315778732, metric: 9.560526251792908, lr: 0.0008685645880177617
[38260] train loss: 0.06042782962322235, metric: 9.113592863082886, lr: 0.0008465081336908042
[38280] train loss: -0.09067701920866966, metric: 8.255178213119507, lr: 0.0008230703533627093
[38300] train loss: 5.610535405576229, metric: 13.780094265937805, lr: 0.0007983447285369039
[38320] train loss: 0.6981292366981506, metric: 11.4828040599823, lr: 0.0007724298629909754
[38340] train loss: 0.452656127512455, metric: 10.275120258331299, lr: 0.0007454289589077234
[38360] train loss: 0.22854609787464142, metric: 10.075531959533691, lr: 0.0007174497004598379
[38380] train loss: 0.5362384393811226, metric: 10.803699970245361, lr: 0.00068860367173329
[38400] train loss: 0.015376314520835876, metric: 9.437562942504883, lr: 0.0006590057746507227
[38420] train loss: -0.250181682407856, metric: 8.467787742614746, lr: 0.0006287740543484688
[38440] train loss: -0.30616559088230133, metric: 8.341701030731201, lr: 0.000598029000684619
[38460] train loss: -0.255014818161726, metric: 7.603221654891968, lr: 0.0005668931407853961
[38480] train loss: -0.2691488526761532, metric: 7.774731397628784, lr: 0.0005354906315915287
[38500] train loss: -0.1160750687122345, metric: 8.47676396369934, lr: 0.0005039466777816415
[38520] train loss: -0.2129136398434639, metric: 8.805914759635925, lr: 0.0004723869787994772
[38540] train loss: 0.01631246879696846, metric: 11.264127492904663, lr: 0.0004409373505041003
[38560] train loss: -0.12847312912344933, metric: 10.630824089050293, lr: 0.0004097231721971184
[38580] train loss: 0.6186829768121243, metric: 11.292189478874207, lr: 0.000378868862753734
[38600] train loss: -0.0005340613424777985, metric: 9.49574589729309, lr: 0.00034849741496145725
[38620] train loss: 1.9681076109409332, metric: 14.71876859664917, lr: 0.0003187299007549882
[38640] train loss: 8.659097373485565, metric: 20.29187774658203, lr: 0.0002896849764510989
[38660] train loss: 1.1700107529759407, metric: 15.51575756072998, lr: 0.0002614784170873463
[38680] train loss: 0.517068162560463, metric: 11.571372032165527, lr: 0.00023422270896844566
[38700] train loss: 0.37024546787142754, metric: 12.202621936798096, lr: 0.00020802643848583102
[38720] train loss: -0.046174224466085434, metric: 10.517264127731323, lr: 0.00018299407383892685
[38740] train loss: 0.2493147999048233, metric: 14.741697072982788, lr: 0.00015922538295853883
[38760] train loss: -0.14198891073465347, metric: 13.96688985824585, lr: 0.00013681512791663408
[38780] train loss: 0.3904869742691517, metric: 16.136049270629883, lr: 0.00011585262109292671
[38800] train loss: -0.13515231758356094, metric: 12.265459299087524, lr: 9.999999747378752e-05
[38820] train loss: -0.2234315536916256, metric: 10.651558876037598, lr: 9.999999747378752e-05
[38840] train loss: -0.027008604258298874, metric: 11.535634279251099, lr: 9.999999747378752e-05
[38860] train loss: -0.057082515209913254, metric: 12.331835985183716, lr: 9.999999747378752e-05
[38880] train loss: -0.0417923741042614, metric: 8.987308025360107, lr: 9.999999747378752e-05
[38900] train loss: 0.01192193478345871, metric: 8.847096681594849, lr: 9.999999747378752e-05
[38920] train loss: 3.50332310795784, metric: 14.470172882080078, lr: 9.999999747378752e-05
[38940] train loss: 1.789146151393652, metric: 17.445223331451416, lr: 9.999999747378752e-05
[38960] train loss: 2.1113000102341175, metric: 16.02541708946228, lr: 9.999999747378752e-05
[38980] train loss: 0.5161430574953556, metric: 17.32491636276245, lr: 9.999999747378752e-05
[39000] train loss: 0.9169988352805376, metric: 11.868359804153442, lr: 9.999999747378752e-05
[39020] train loss: 0.24151000380516052, metric: 10.615256905555725, lr: 0.0009994393913075328
[39040] train loss: 0.2120257392525673, metric: 10.645934820175171, lr: 0.0009969500824809074
[39060] train loss: 0.2341141626238823, metric: 9.991212129592896, lr: 0.000992479850538075
[39080] train loss: 0.2734748385846615, metric: 16.67719793319702, lr: 0.000986046390607953
[39100] train loss: -0.05053442716598511, metric: 12.489347696304321, lr: 0.0009776754304766655
[39120] train loss: 0.2142743542790413, metric: 10.321005463600159, lr: 0.0009674003813415766
[39140] train loss: 0.6140112578868866, metric: 14.183091878890991, lr: 0.0009552621049806476
[39160] train loss: 1.5843730755150318, metric: 18.37991499900818, lr: 0.0009413089719600976
[39180] train loss: 0.6434112712740898, metric: 14.076080560684204, lr: 0.0009255966870114207
[39200] train loss: 2.9659070670604706, metric: 17.170395851135254, lr: 0.00090818788157776
[39220] train loss: 0.38658449053764343, metric: 18.54572081565857, lr: 0.0008891518809832633
[39240] train loss: 0.9779235310852528, metric: 15.732641696929932, lr: 0.0008685645880177617
[39260] train loss: 0.10801144689321518, metric: 11.435667514801025, lr: 0.0008465081336908042
[39280] train loss: 0.28938110917806625, metric: 12.502994060516357, lr: 0.0008230703533627093
[39300] train loss: 0.2678978852927685, metric: 12.636345148086548, lr: 0.0007983447285369039
[39320] train loss: 0.7915870547294617, metric: 10.782156705856323, lr: 0.0007724298629909754
[39340] train loss: 3.952405333518982, metric: 13.901139736175537, lr: 0.0007454289589077234
[39360] train loss: 1.975824497640133, metric: 14.459696173667908, lr: 0.0007174497004598379
[39380] train loss: 0.25673967227339745, metric: 10.713386178016663, lr: 0.00068860367173329
[39400] train loss: 0.0012319497764110565, metric: 9.396164178848267, lr: 0.0006590057746507227
[39420] train loss: -0.11103691160678864, metric: 11.42008900642395, lr: 0.0006287740543484688
[39440] train loss: 0.15704936161637306, metric: 13.901826858520508, lr: 0.000598029000684619
[39460] train loss: -0.18985412642359734, metric: 11.640991687774658, lr: 0.0005668931407853961
[39480] train loss: -0.1745869405567646, metric: 13.326843500137329, lr: 0.0005354906315915287
[39500] train loss: -0.26655976846814156, metric: 12.137091159820557, lr: 0.0005039466777816415
[39520] train loss: -0.20801225677132607, metric: 10.50045371055603, lr: 0.0004723869787994772
[39540] train loss: -0.24604740738868713, metric: 9.868679404258728, lr: 0.0004409373505041003
[39560] train loss: -0.23001344501972198, metric: 11.897145748138428, lr: 0.0004097231721971184
[39580] train loss: -0.17541830241680145, metric: 10.211306691169739, lr: 0.000378868862753734
[39600] train loss: -0.22545062378048897, metric: 8.869803071022034, lr: 0.00034849741496145725
[39620] train loss: -0.217090655118227, metric: 9.97943925857544, lr: 0.0003187299007549882
[39640] train loss: -0.236967783421278, metric: 8.377718806266785, lr: 0.0002896849764510989
[39660] train loss: -0.2817431576550007, metric: 9.095802783966064, lr: 0.0002614784170873463
[39680] train loss: -0.25232166796922684, metric: 10.037202835083008, lr: 0.00023422270896844566
[39700] train loss: -0.1779560223221779, metric: 10.043333292007446, lr: 0.00020802643848583102
[39720] train loss: -0.08406748250126839, metric: 9.734342575073242, lr: 0.00018299407383892685
[39740] train loss: -0.10019949823617935, metric: 8.56757140159607, lr: 0.00015922538295853883
[39760] train loss: 0.00814196839928627, metric: 7.398226737976074, lr: 0.00013681512791663408
[39780] train loss: -0.13808593899011612, metric: 9.420042753219604, lr: 0.00011585262109292671
[39800] train loss: -0.109998419880867, metric: 8.67400336265564, lr: 9.999999747378752e-05
[39820] train loss: -0.1292872093617916, metric: 7.338895678520203, lr: 9.999999747378752e-05
[39840] train loss: 0.13359321281313896, metric: 8.879315495491028, lr: 9.999999747378752e-05
[39860] train loss: -0.07207263633608818, metric: 10.729215383529663, lr: 9.999999747378752e-05
[39880] train loss: -0.10223597288131714, metric: 9.948874950408936, lr: 9.999999747378752e-05
[39900] train loss: -0.12890536710619926, metric: 10.165070295333862, lr: 9.999999747378752e-05
[39920] train loss: -0.06528443843126297, metric: 9.559678196907043, lr: 9.999999747378752e-05
[39940] train loss: 1.8560359440743923, metric: 22.14108371734619, lr: 9.999999747378752e-05
[39960] train loss: 1.780245952308178, metric: 20.279042720794678, lr: 9.999999747378752e-05
[39980] train loss: 5.804174367338419, metric: 18.15608549118042, lr: 9.999999747378752e-05
[40000] train loss: 3.3693025708198547, metric: 17.796488285064697, lr: 9.999999747378752e-05
[40020] train loss: 5.43182123452425, metric: 12.534930944442749, lr: 0.0009994393913075328
[40040] train loss: -0.008615389466285706, metric: 10.628392934799194, lr: 0.0009969500824809074
[40060] train loss: -0.13752514123916626, metric: 10.041254758834839, lr: 0.000992479850538075
[40080] train loss: 0.12225629389286041, metric: 10.019366264343262, lr: 0.000986046390607953
[40100] train loss: -0.06810549274086952, metric: 13.113670825958252, lr: 0.0009776754304766655
[40120] train loss: -0.1327672004699707, metric: 13.582181453704834, lr: 0.0009674003813415766
[40140] train loss: 0.003208201378583908, metric: 15.696972370147705, lr: 0.0009552621049806476
[40160] train loss: -0.15912479907274246, metric: 12.583289623260498, lr: 0.0009413089719600976
[40180] train loss: -0.07987944781780243, metric: 10.293652653694153, lr: 0.0009255966870114207
[40200] train loss: -0.13235250860452652, metric: 12.810254573822021, lr: 0.00090818788157776
[40220] train loss: 0.6181043162941933, metric: 12.168647289276123, lr: 0.0008891518809832633
[40240] train loss: 0.8089174889028072, metric: 11.79797101020813, lr: 0.0008685645880177617
[40260] train loss: 0.5562350153923035, metric: 12.77712893486023, lr: 0.0008465081336908042
[40280] train loss: 1.3572844229638577, metric: 12.573225975036621, lr: 0.0008230703533627093
[40300] train loss: -0.11313695088028908, metric: 10.127308368682861, lr: 0.0007983447285369039
[40320] train loss: -0.149893868714571, metric: 11.772091627120972, lr: 0.0007724298629909754
[40340] train loss: -0.2672404907643795, metric: 8.608841180801392, lr: 0.0007454289589077234
[40360] train loss: -0.2833770364522934, metric: 9.570643663406372, lr: 0.0007174497004598379
[40380] train loss: -0.18424256145954132, metric: 8.425683617591858, lr: 0.00068860367173329
[40400] train loss: 0.20367446541786194, metric: 9.700340270996094, lr: 0.0006590057746507227
[40420] train loss: 0.2565511241555214, metric: 12.230372071266174, lr: 0.0006287740543484688
[40440] train loss: -0.24197837337851524, metric: 9.928334951400757, lr: 0.000598029000684619
[40460] train loss: 0.4184391684830189, metric: 16.340847969055176, lr: 0.0005668931407853961
[40480] train loss: 0.14155058190226555, metric: 11.890107035636902, lr: 0.0005354906315915287
[40500] train loss: -0.08901223540306091, metric: 10.691709041595459, lr: 0.0005039466777816415
[40520] train loss: 0.17566104978322983, metric: 9.838047862052917, lr: 0.0004723869787994772
[40540] train loss: 0.2075997032225132, metric: 8.189451694488525, lr: 0.0004409373505041003
[40560] train loss: 0.21077965199947357, metric: 8.288001298904419, lr: 0.0004097231721971184
[40580] train loss: 2.1573444455862045, metric: 10.138705253601074, lr: 0.000378868862753734
[40600] train loss: -0.15249703079462051, metric: 8.717519521713257, lr: 0.00034849741496145725
[40620] train loss: -0.16252391040325165, metric: 8.479589939117432, lr: 0.0003187299007549882
[40640] train loss: -0.035270750522613525, metric: 8.038949012756348, lr: 0.0002896849764510989
[40660] train loss: -0.2025236301124096, metric: 7.570767402648926, lr: 0.0002614784170873463
[40680] train loss: 0.13932005316019058, metric: 8.978284358978271, lr: 0.00023422270896844566
[40700] train loss: 0.1790246143937111, metric: 8.9809068441391, lr: 0.00020802643848583102
[40720] train loss: -0.05658155679702759, metric: 11.041462421417236, lr: 0.00018299407383892685
[40740] train loss: -0.08618410304188728, metric: 9.167785048484802, lr: 0.00015922538295853883
[40760] train loss: -0.17140407860279083, metric: 9.248570084571838, lr: 0.00013681512791663408
[40780] train loss: 0.2075589969754219, metric: 8.543713569641113, lr: 0.00011585262109292671
[40800] train loss: -0.13046268373727798, metric: 8.915528893470764, lr: 9.999999747378752e-05
[40820] train loss: -0.14104589074850082, metric: 7.808382630348206, lr: 9.999999747378752e-05
[40840] train loss: -0.20297864452004433, metric: 7.573448181152344, lr: 9.999999747378752e-05
[40860] train loss: -0.22588074579834938, metric: 8.087509155273438, lr: 9.999999747378752e-05
[40880] train loss: -0.1418405883014202, metric: 8.572408676147461, lr: 9.999999747378752e-05
[40900] train loss: -0.25433511286973953, metric: 6.404891490936279, lr: 9.999999747378752e-05
[40920] train loss: -0.10205182805657387, metric: 8.366873025894165, lr: 9.999999747378752e-05
[40940] train loss: -0.22936318442225456, metric: 8.484749674797058, lr: 9.999999747378752e-05
[40960] train loss: -0.12406191974878311, metric: 8.103860855102539, lr: 9.999999747378752e-05
[40980] train loss: 0.6056049168109894, metric: 18.419278144836426, lr: 9.999999747378752e-05
[41000] train loss: 0.06470456719398499, metric: 12.986404418945312, lr: 9.999999747378752e-05
[41020] train loss: -0.1801835335791111, metric: 11.311551809310913, lr: 0.0009994393913075328
[41040] train loss: -0.19637245684862137, metric: 9.711959600448608, lr: 0.0009969500824809074
[41060] train loss: -0.05810096859931946, metric: 9.150481581687927, lr: 0.000992479850538075
[41080] train loss: -0.03227002173662186, metric: 9.125316143035889, lr: 0.000986046390607953
[41100] train loss: -0.08978822454810143, metric: 8.262330055236816, lr: 0.0009776754304766655
[41120] train loss: -0.1738332137465477, metric: 6.8680198192596436, lr: 0.0009674003813415766
[41140] train loss: -0.031222734600305557, metric: 8.395498037338257, lr: 0.0009552621049806476
[41160] train loss: -0.13546083867549896, metric: 7.388376355171204, lr: 0.0009413089719600976
[41180] train loss: -0.1837543100118637, metric: 7.328894376754761, lr: 0.0009255966870114207
[41200] train loss: -0.11350509896874428, metric: 7.623495817184448, lr: 0.00090818788157776
[41220] train loss: 0.3758397288620472, metric: 8.70985460281372, lr: 0.0008891518809832633
[41240] train loss: 0.11260203272104263, metric: 9.792359828948975, lr: 0.0008685645880177617
[41260] train loss: 0.11915498599410057, metric: 10.140256762504578, lr: 0.0008465081336908042
[41280] train loss: -0.06946761906147003, metric: 8.511652112007141, lr: 0.0008230703533627093
[41300] train loss: -0.13348214328289032, metric: 8.749294400215149, lr: 0.0007983447285369039
[41320] train loss: -0.10741011798381805, metric: 9.61752188205719, lr: 0.0007724298629909754
[41340] train loss: -0.06501663848757744, metric: 9.493221998214722, lr: 0.0007454289589077234
[41360] train loss: 0.0324975848197937, metric: 7.333645701408386, lr: 0.0007174497004598379
[41380] train loss: 0.9356513731181622, metric: 12.697356581687927, lr: 0.00068860367173329
[41400] train loss: 0.8070644326508045, metric: 13.187562465667725, lr: 0.0006590057746507227
[41420] train loss: 0.560676097869873, metric: 7.767080187797546, lr: 0.0006287740543484688
[41440] train loss: 0.29837625846266747, metric: 8.823382377624512, lr: 0.000598029000684619
[41460] train loss: 0.7071220353245735, metric: 12.415549278259277, lr: 0.0005668931407853961
[41480] train loss: 0.957916796207428, metric: 14.123677253723145, lr: 0.0005354906315915287
[41500] train loss: 0.037556763738393784, metric: 10.323567628860474, lr: 0.0005039466777816415
[41520] train loss: -0.20502760633826256, metric: 9.759286403656006, lr: 0.0004723869787994772
[41540] train loss: 0.11236131563782692, metric: 9.449310302734375, lr: 0.0004409373505041003
[41560] train loss: 0.07666490972042084, metric: 8.324276208877563, lr: 0.0004097231721971184
[41580] train loss: 0.3058977276086807, metric: 9.318915486335754, lr: 0.000378868862753734
[41600] train loss: 0.17787211388349533, metric: 11.32632303237915, lr: 0.00034849741496145725
[41620] train loss: 1.0543078929185867, metric: 11.286965131759644, lr: 0.0003187299007549882
[41640] train loss: 1.3281609900295734, metric: 12.908031940460205, lr: 0.0002896849764510989
[41660] train loss: 0.8562916330993176, metric: 12.603119134902954, lr: 0.0002614784170873463
[41680] train loss: 3.4408147782087326, metric: 16.59092903137207, lr: 0.00023422270896844566
[41700] train loss: 1.2435389049351215, metric: 15.155863046646118, lr: 0.00020802643848583102
[41720] train loss: 1.8149501793086529, metric: 16.24270987510681, lr: 0.00018299407383892685
[41740] train loss: 2.8916112184524536, metric: 20.301401615142822, lr: 0.00015922538295853883
[41760] train loss: 1.386326115578413, metric: 14.831683158874512, lr: 0.00013681512791663408
[41780] train loss: 0.2848112918436527, metric: 16.022109746932983, lr: 0.00011585262109292671
[41800] train loss: 1.302722204476595, metric: 18.062808990478516, lr: 9.999999747378752e-05
[41820] train loss: 0.6736490428447723, metric: 14.318835735321045, lr: 9.999999747378752e-05
[41840] train loss: 0.16581597924232483, metric: 11.635367393493652, lr: 9.999999747378752e-05
[41860] train loss: 0.0042090341448783875, metric: 9.473328590393066, lr: 9.999999747378752e-05
[41880] train loss: -0.14504079148173332, metric: 9.61152982711792, lr: 9.999999747378752e-05
[41900] train loss: 0.04075952246785164, metric: 8.913546323776245, lr: 9.999999747378752e-05
[41920] train loss: 1.5947727002203465, metric: 11.334244966506958, lr: 9.999999747378752e-05
[41940] train loss: 0.3702019415795803, metric: 11.012095212936401, lr: 9.999999747378752e-05
[41960] train loss: 0.1602027229964733, metric: 11.769067764282227, lr: 9.999999747378752e-05
[41980] train loss: 0.6785041764378548, metric: 8.939478158950806, lr: 9.999999747378752e-05
[42000] train loss: 1.4484291523694992, metric: 12.012626647949219, lr: 9.999999747378752e-05
[42020] train loss: 0.2349567599594593, metric: 11.03019654750824, lr: 0.0009994393913075328
[42040] train loss: 0.08907148987054825, metric: 8.357868671417236, lr: 0.0009969500824809074
[42060] train loss: -0.14191890880465508, metric: 6.564934968948364, lr: 0.000992479850538075
[42080] train loss: -0.15959283709526062, metric: 8.137348651885986, lr: 0.000986046390607953
[42100] train loss: -0.14848753809928894, metric: 7.477893948554993, lr: 0.0009776754304766655
[42120] train loss: -0.23507529124617577, metric: 6.496958374977112, lr: 0.0009674003813415766
[42140] train loss: -0.26181141287088394, metric: 6.880417346954346, lr: 0.0009552621049806476
[42160] train loss: -0.11169480159878731, metric: 7.367571711540222, lr: 0.0009413089719600976
[42180] train loss: -0.20768171176314354, metric: 8.4990975856781, lr: 0.0009255966870114207
[42200] train loss: -0.12357751652598381, metric: 8.061998844146729, lr: 0.00090818788157776
[42220] train loss: -0.20887859910726547, metric: 8.275216937065125, lr: 0.0008891518809832633
[42240] train loss: -0.17740601301193237, metric: 8.194236397743225, lr: 0.0008685645880177617
[42260] train loss: 0.0024671554565429688, metric: 11.493229150772095, lr: 0.0008465081336908042
[42280] train loss: 0.06594957783818245, metric: 9.905438423156738, lr: 0.0008230703533627093
[42300] train loss: -0.19081012159585953, metric: 9.638627052307129, lr: 0.0007983447285369039
[42320] train loss: -0.23956623673439026, metric: 7.321784734725952, lr: 0.0007724298629909754
[42340] train loss: -0.0004776418209075928, metric: 6.266098499298096, lr: 0.0007454289589077234
[42360] train loss: -0.25841014087200165, metric: 6.541765570640564, lr: 0.0007174497004598379
[42380] train loss: -0.24890802800655365, metric: 6.805919170379639, lr: 0.00068860367173329
[42400] train loss: -0.2191130481660366, metric: 6.857074499130249, lr: 0.0006590057746507227
[42420] train loss: -0.2501920387148857, metric: 7.033524751663208, lr: 0.0006287740543484688
[42440] train loss: -0.2672058716416359, metric: 7.925143837928772, lr: 0.000598029000684619
[42460] train loss: -0.13649862259626389, metric: 6.39986789226532, lr: 0.0005668931407853961
[42480] train loss: -0.19164326041936874, metric: 6.835052967071533, lr: 0.0005354906315915287
[42500] train loss: 0.7432678565382957, metric: 13.530233383178711, lr: 0.0005039466777816415
[42520] train loss: 0.025221727788448334, metric: 10.45460295677185, lr: 0.0004723869787994772
[42540] train loss: -0.06907417252659798, metric: 8.829606056213379, lr: 0.0004409373505041003
[42560] train loss: -0.09790755435824394, metric: 7.456167697906494, lr: 0.0004097231721971184
[42580] train loss: 3.767496634274721, metric: 10.338392734527588, lr: 0.000378868862753734
[42600] train loss: 0.9579517059028149, metric: 12.157623052597046, lr: 0.00034849741496145725
[42620] train loss: 0.24647505208849907, metric: 10.330154418945312, lr: 0.0003187299007549882
[42640] train loss: 0.8808579966425896, metric: 18.561167001724243, lr: 0.0002896849764510989
[42660] train loss: 2.489486515522003, metric: 13.636510372161865, lr: 0.0002614784170873463
[42680] train loss: 0.5084610618650913, metric: 15.996883392333984, lr: 0.00023422270896844566
[42700] train loss: -0.08126525580883026, metric: 14.493136882781982, lr: 0.00020802643848583102
[42720] train loss: -0.2188047170639038, metric: 12.977388381958008, lr: 0.00018299407383892685
[42740] train loss: -0.11111943796277046, metric: 13.498899459838867, lr: 0.00015922538295853883
[42760] train loss: 0.03488081321120262, metric: 9.318984746932983, lr: 0.00013681512791663408
[42780] train loss: 0.04713694751262665, metric: 11.263239622116089, lr: 0.00011585262109292671
[42800] train loss: 0.26969557255506516, metric: 13.45837652683258, lr: 9.999999747378752e-05
[42820] train loss: 0.6088878400623798, metric: 11.01046884059906, lr: 9.999999747378752e-05
[42840] train loss: -0.013486746698617935, metric: 11.24034035205841, lr: 9.999999747378752e-05
[42860] train loss: -0.13834507018327713, metric: 8.756418585777283, lr: 9.999999747378752e-05
[42880] train loss: -0.26580142602324486, metric: 7.396220445632935, lr: 9.999999747378752e-05
[42900] train loss: -0.1992027722299099, metric: 8.448198914527893, lr: 9.999999747378752e-05
[42920] train loss: 0.6592623703181744, metric: 11.047494173049927, lr: 9.999999747378752e-05
[42940] train loss: 0.2661621496081352, metric: 12.468271255493164, lr: 9.999999747378752e-05
[42960] train loss: -0.020881302654743195, metric: 10.110997676849365, lr: 9.999999747378752e-05
[42980] train loss: 0.06099645048379898, metric: 10.363627195358276, lr: 9.999999747378752e-05
[43000] train loss: 0.09919516742229462, metric: 11.00847315788269, lr: 9.999999747378752e-05
[43020] train loss: 1.4722031205892563, metric: 14.108731269836426, lr: 0.0009994393913075328
[43040] train loss: 0.3838989604264498, metric: 13.883813858032227, lr: 0.0009969500824809074
[43060] train loss: 2.067843060940504, metric: 12.457436323165894, lr: 0.000992479850538075
[43080] train loss: 0.05301908776164055, metric: 10.754454970359802, lr: 0.000986046390607953
[43100] train loss: 0.19762424752116203, metric: 10.411194324493408, lr: 0.0009776754304766655
[43120] train loss: 0.19233914464712143, metric: 11.514665365219116, lr: 0.0009674003813415766
[43140] train loss: 0.2165437638759613, metric: 14.296915769577026, lr: 0.0009552621049806476
[43160] train loss: 0.1512090526521206, metric: 14.018442511558533, lr: 0.0009413089719600976
[43180] train loss: 0.06702303886413574, metric: 11.342470169067383, lr: 0.0009255966870114207
[43200] train loss: 0.12093699723482132, metric: 12.46157431602478, lr: 0.00090818788157776
[43220] train loss: 0.46958935260772705, metric: 11.86921513080597, lr: 0.0008891518809832633
[43240] train loss: 0.6344292461872101, metric: 13.82888925075531, lr: 0.0008685645880177617
[43260] train loss: 1.1047112420201302, metric: 13.091450810432434, lr: 0.0008465081336908042
[43280] train loss: 3.305228505283594, metric: 14.937376618385315, lr: 0.0008230703533627093
[43300] train loss: 3.0744158551096916, metric: 13.789591550827026, lr: 0.0007983447285369039
[43320] train loss: 0.3916453644633293, metric: 13.909165740013123, lr: 0.0007724298629909754
[43340] train loss: 1.739051029086113, metric: 14.165849447250366, lr: 0.0007454289589077234
[43360] train loss: 1.5354233458638191, metric: 14.189827799797058, lr: 0.0007174497004598379
[43380] train loss: 0.7272275686264038, metric: 15.244951248168945, lr: 0.00068860367173329
[43400] train loss: 0.398030124604702, metric: 12.484327793121338, lr: 0.0006590057746507227
[43420] train loss: 1.8280310779809952, metric: 14.398476600646973, lr: 0.0006287740543484688
[43440] train loss: 1.5435019731521606, metric: 16.338862895965576, lr: 0.000598029000684619
[43460] train loss: 2.7059699296951294, metric: 19.906131744384766, lr: 0.0005668931407853961
[43480] train loss: 1.0326751060783863, metric: 15.893712759017944, lr: 0.0005354906315915287
[43500] train loss: 1.7912782989442348, metric: 15.486880540847778, lr: 0.0005039466777816415
[43520] train loss: 3.2555414885282516, metric: 28.364206075668335, lr: 0.0004723869787994772
[43540] train loss: 0.025728747248649597, metric: 13.99105167388916, lr: 0.0004409373505041003
[43560] train loss: -0.14625003933906555, metric: 12.25470495223999, lr: 0.0004097231721971184
[43580] train loss: 0.3504028581082821, metric: 13.748618125915527, lr: 0.000378868862753734
[43600] train loss: 1.2933735698461533, metric: 18.010229349136353, lr: 0.00034849741496145725
[43620] train loss: 0.38198625668883324, metric: 14.716085433959961, lr: 0.0003187299007549882
[43640] train loss: 0.619347557425499, metric: 12.314530611038208, lr: 0.0002896849764510989
[43660] train loss: 1.0249108523130417, metric: 13.973633289337158, lr: 0.0002614784170873463
[43680] train loss: 1.145802065730095, metric: 16.637315034866333, lr: 0.00023422270896844566
[43700] train loss: 2.861189503222704, metric: 17.317601442337036, lr: 0.00020802643848583102
[43720] train loss: 1.1272704377770424, metric: 21.518689155578613, lr: 0.00018299407383892685
[43740] train loss: 3.913745764642954, metric: 22.798349857330322, lr: 0.00015922538295853883
[43760] train loss: 7.123956806957722, metric: 19.268216848373413, lr: 0.00013681512791663408
[43780] train loss: 2.334668282419443, metric: 15.79489278793335, lr: 0.00011585262109292671
[43800] train loss: 0.08037181571125984, metric: 13.52538275718689, lr: 9.999999747378752e-05
[43820] train loss: 0.3618799075484276, metric: 12.839117050170898, lr: 9.999999747378752e-05
[43840] train loss: -0.05606984347105026, metric: 14.783660173416138, lr: 9.999999747378752e-05
[43860] train loss: -0.07856478914618492, metric: 11.459590196609497, lr: 9.999999747378752e-05
[43880] train loss: -0.21033668145537376, metric: 10.314574480056763, lr: 9.999999747378752e-05
[43900] train loss: -0.07671589776873589, metric: 13.178001642227173, lr: 9.999999747378752e-05
[43920] train loss: -0.07715334370732307, metric: 11.773329734802246, lr: 9.999999747378752e-05
[43940] train loss: -0.0755079947412014, metric: 11.859882354736328, lr: 9.999999747378752e-05
[43960] train loss: 0.4522481933236122, metric: 10.442909955978394, lr: 9.999999747378752e-05
[43980] train loss: -0.2615085355937481, metric: 8.699858665466309, lr: 9.999999747378752e-05
[44000] train loss: -0.2383759394288063, metric: 9.151861786842346, lr: 9.999999747378752e-05
[44020] train loss: -0.2738066166639328, metric: 8.750234246253967, lr: 0.0009994393913075328
[44040] train loss: 1.0424035117030144, metric: 13.562219142913818, lr: 0.0009969500824809074
[44060] train loss: -0.06737861409783363, metric: 10.61479902267456, lr: 0.000992479850538075
[44080] train loss: -0.16770188137888908, metric: 11.805717945098877, lr: 0.000986046390607953
[44100] train loss: -0.026365362107753754, metric: 9.46919596195221, lr: 0.0009776754304766655
[44120] train loss: -0.12008955329656601, metric: 9.052132368087769, lr: 0.0009674003813415766
[44140] train loss: 0.37236811593174934, metric: 11.683835506439209, lr: 0.0009552621049806476
[44160] train loss: 5.3418545220047235, metric: 15.613286256790161, lr: 0.0009413089719600976
[44180] train loss: 0.8035437427461147, metric: 18.86858034133911, lr: 0.0009255966870114207
[44200] train loss: 0.36251482367515564, metric: 14.77054476737976, lr: 0.00090818788157776
[44220] train loss: 0.15756569430232048, metric: 20.745142936706543, lr: 0.0008891518809832633
[44240] train loss: 0.17092490941286087, metric: 10.077587842941284, lr: 0.0008685645880177617
[44260] train loss: 0.008568767458200455, metric: 9.665338516235352, lr: 0.0008465081336908042
[44280] train loss: 0.1540057212114334, metric: 12.200075626373291, lr: 0.0008230703533627093
[44300] train loss: 0.763788066804409, metric: 18.75367283821106, lr: 0.0007983447285369039
[44320] train loss: 0.4330197423696518, metric: 14.733920097351074, lr: 0.0007724298629909754
[44340] train loss: -0.0779600627720356, metric: 10.320805549621582, lr: 0.0007454289589077234
[44360] train loss: 0.00016465038061141968, metric: 13.867247104644775, lr: 0.0007174497004598379
[44380] train loss: 0.1241830512881279, metric: 18.554792404174805, lr: 0.00068860367173329
[44400] train loss: 0.34647949039936066, metric: 10.958613157272339, lr: 0.0006590057746507227
[44420] train loss: 1.8890139311552048, metric: 13.509621381759644, lr: 0.0006287740543484688
[44440] train loss: 1.2982841283082962, metric: 16.267781972885132, lr: 0.000598029000684619
[44460] train loss: 1.0198346786201, metric: 17.24816608428955, lr: 0.0005668931407853961
[44480] train loss: 3.1786083467304707, metric: 16.922790050506592, lr: 0.0005354906315915287
[44500] train loss: 2.733395352959633, metric: 17.025734663009644, lr: 0.0005039466777816415
[44520] train loss: 0.4849938936531544, metric: 11.885120868682861, lr: 0.0004723869787994772
[44540] train loss: 0.9211918525397778, metric: 14.959716081619263, lr: 0.0004409373505041003
[44560] train loss: 0.3485706262290478, metric: 18.13438367843628, lr: 0.0004097231721971184
[44580] train loss: 0.3197565786540508, metric: 11.404797911643982, lr: 0.000378868862753734
[44600] train loss: 0.1430227980017662, metric: 10.597964406013489, lr: 0.00034849741496145725
[44620] train loss: 0.0860714539885521, metric: 11.722346067428589, lr: 0.0003187299007549882
[44640] train loss: 0.1689963899552822, metric: 13.758778810501099, lr: 0.0002896849764510989
[44660] train loss: -0.029129374772310257, metric: 11.878983974456787, lr: 0.0002614784170873463
[44680] train loss: 0.30405838415026665, metric: 12.740983009338379, lr: 0.00023422270896844566
[44700] train loss: -0.12795641645789146, metric: 12.10241150856018, lr: 0.00020802643848583102
[44720] train loss: -0.055157411843538284, metric: 10.502941846847534, lr: 0.00018299407383892685
[44740] train loss: 0.2104622758924961, metric: 13.36351490020752, lr: 0.00015922538295853883
[44760] train loss: -0.054916419088840485, metric: 14.837695837020874, lr: 0.00013681512791663408
[44780] train loss: -0.10081185773015022, metric: 10.880465745925903, lr: 0.00011585262109292671
[44800] train loss: -0.09313923120498657, metric: 10.265875816345215, lr: 9.999999747378752e-05
[44820] train loss: -0.16903617233037949, metric: 10.036526679992676, lr: 9.999999747378752e-05
[44840] train loss: 0.5080577433109283, metric: 12.109171390533447, lr: 9.999999747378752e-05
[44860] train loss: 1.2813370525836945, metric: 13.034199237823486, lr: 9.999999747378752e-05
[44880] train loss: 6.879264492541552, metric: 17.517413854599, lr: 9.999999747378752e-05
[44900] train loss: 3.902559570968151, metric: 18.3971529006958, lr: 9.999999747378752e-05
[44920] train loss: 2.8953982032835484, metric: 17.339600563049316, lr: 9.999999747378752e-05
[44940] train loss: 5.664649184793234, metric: 18.244395971298218, lr: 9.999999747378752e-05
[44960] train loss: 1.7605040855705738, metric: 17.07001221179962, lr: 9.999999747378752e-05
[44980] train loss: 3.1712345965206623, metric: 15.834588289260864, lr: 9.999999747378752e-05
[45000] train loss: 0.9651701673865318, metric: 16.95640993118286, lr: 9.999999747378752e-05
[45020] train loss: 0.48790306597948074, metric: 13.607369422912598, lr: 0.0009994393913075328
[45040] train loss: 2.1050948202610016, metric: 14.242677211761475, lr: 0.0009969500824809074
[45060] train loss: 1.4480741880834103, metric: 17.254371166229248, lr: 0.000992479850538075
[45080] train loss: 0.5915684439241886, metric: 16.91403102874756, lr: 0.000986046390607953
[45100] train loss: 0.05327412858605385, metric: 13.115638732910156, lr: 0.0009776754304766655
[45120] train loss: 0.3511095680296421, metric: 12.625683069229126, lr: 0.0009674003813415766
[45140] train loss: 0.10029760375618935, metric: 12.866970539093018, lr: 0.0009552621049806476
[45160] train loss: 0.2754707299172878, metric: 12.933610677719116, lr: 0.0009413089719600976
[45180] train loss: -0.05833589285612106, metric: 12.8286372423172, lr: 0.0009255966870114207
[45200] train loss: 0.27474695071578026, metric: 13.71611213684082, lr: 0.00090818788157776
[45220] train loss: 0.037845224142074585, metric: 9.835275650024414, lr: 0.0008891518809832633
[45240] train loss: 0.031028643250465393, metric: 10.749698877334595, lr: 0.0008685645880177617
[45260] train loss: -0.0621156319975853, metric: 8.660595655441284, lr: 0.0008465081336908042
[45280] train loss: 0.2573065012693405, metric: 12.19455349445343, lr: 0.0008230703533627093
[45300] train loss: 1.3043873570859432, metric: 14.456687688827515, lr: 0.0007983447285369039
[45320] train loss: 2.995656356215477, metric: 12.222132563591003, lr: 0.0007724298629909754
[45340] train loss: 0.5940704718232155, metric: 17.072957515716553, lr: 0.0007454289589077234
[45360] train loss: 1.2163544110953808, metric: 13.286283493041992, lr: 0.0007174497004598379
[45380] train loss: 0.4496742859482765, metric: 14.983748435974121, lr: 0.00068860367173329
[45400] train loss: 1.480550393462181, metric: 15.91215467453003, lr: 0.0006590057746507227
[45420] train loss: 1.3902410119771957, metric: 23.963675022125244, lr: 0.0006287740543484688
[45440] train loss: 1.1595850884914398, metric: 23.353806018829346, lr: 0.000598029000684619
[45460] train loss: 1.0339744091033936, metric: 24.846432209014893, lr: 0.0005668931407853961
[45480] train loss: 0.6817679293453693, metric: 12.391233444213867, lr: 0.0005354906315915287
[45500] train loss: 0.37762027233839035, metric: 11.538670063018799, lr: 0.0005039466777816415
[45520] train loss: 0.45139043405652046, metric: 12.487802743911743, lr: 0.0004723869787994772
[45540] train loss: 1.5547329634428024, metric: 17.068898916244507, lr: 0.0004409373505041003
[45560] train loss: 1.5199702382087708, metric: 14.037614345550537, lr: 0.0004097231721971184
[45580] train loss: 0.23977621644735336, metric: 19.686955451965332, lr: 0.000378868862753734
[45600] train loss: -0.08984537422657013, metric: 11.986902952194214, lr: 0.00034849741496145725
[45620] train loss: 0.5224513076245785, metric: 20.20656728744507, lr: 0.0003187299007549882
[45640] train loss: -0.15186718106269836, metric: 11.986719608306885, lr: 0.0002896849764510989
[45660] train loss: -0.12726553156971931, metric: 10.39344835281372, lr: 0.0002614784170873463
[45680] train loss: -0.18804797157645226, metric: 10.341559410095215, lr: 0.00023422270896844566
[45700] train loss: -0.10304940119385719, metric: 11.698870420455933, lr: 0.00020802643848583102
[45720] train loss: -0.010006505995988846, metric: 11.139793872833252, lr: 0.00018299407383892685
[45740] train loss: -0.03381015732884407, metric: 10.377467155456543, lr: 0.00015922538295853883
[45760] train loss: -0.017160087823867798, metric: 9.95650315284729, lr: 0.00013681512791663408
[45780] train loss: 0.13923164084553719, metric: 11.909250736236572, lr: 0.00011585262109292671
[45800] train loss: -0.13428563624620438, metric: 11.534252166748047, lr: 9.999999747378752e-05
[45820] train loss: -0.015867862850427628, metric: 10.65593957901001, lr: 9.999999747378752e-05
[45840] train loss: 3.6550187170505524, metric: 11.70571231842041, lr: 9.999999747378752e-05
[45860] train loss: 9.69473810493946, metric: 17.33314609527588, lr: 9.999999747378752e-05
[45880] train loss: 3.265055648982525, metric: 15.887367486953735, lr: 9.999999747378752e-05
[45900] train loss: 0.3779301866889, metric: 11.896445035934448, lr: 9.999999747378752e-05
[45920] train loss: 0.04099040850996971, metric: 11.56982946395874, lr: 9.999999747378752e-05
[45940] train loss: -0.09961317852139473, metric: 11.05299425125122, lr: 9.999999747378752e-05
[45960] train loss: -0.1644134595990181, metric: 10.339419841766357, lr: 9.999999747378752e-05
[45980] train loss: -0.14788416773080826, metric: 10.95076584815979, lr: 9.999999747378752e-05
[46000] train loss: -0.198941882699728, metric: 10.844385623931885, lr: 9.999999747378752e-05
[20] train loss: 0.9019297733902931, metric: 19.20182490348816, lr: 0.0009994393913075328
[40] train loss: 0.08194318786263466, metric: 13.792027473449707, lr: 0.0009969500824809074
[60] train loss: 0.4095180556178093, metric: 11.922002792358398, lr: 0.000992479850538075
[80] train loss: -0.06282177940011024, metric: 12.154624223709106, lr: 0.000986046390607953
[100] train loss: -0.014886952936649323, metric: 13.378278255462646, lr: 0.0009776754304766655
[120] train loss: -0.2393755242228508, metric: 9.953893899917603, lr: 0.0009674003813415766
[140] train loss: -0.17565525323152542, metric: 8.960810661315918, lr: 0.0009552621049806476
[160] train loss: 0.12739553302526474, metric: 8.55586314201355, lr: 0.0009413089719600976
[180] train loss: -0.026133693754673004, metric: 8.779702425003052, lr: 0.0009255966870114207
[200] train loss: -0.27817805111408234, metric: 8.934442639350891, lr: 0.00090818788157776
[220] train loss: -0.33052513748407364, metric: 9.653805255889893, lr: 0.0008891518809832633
[240] train loss: -0.23491717129945755, metric: 7.655038595199585, lr: 0.0008685645880177617
[260] train loss: -0.31299421191215515, metric: 7.943978905677795, lr: 0.0008465081336908042
[280] train loss: -0.3001987636089325, metric: 7.766957998275757, lr: 0.0008230703533627093
[300] train loss: -0.21457390114665031, metric: 7.423564910888672, lr: 0.0007983447285369039
[320] train loss: -0.23429453745484352, metric: 7.318381667137146, lr: 0.0007724298629909754
[340] train loss: -0.283180121332407, metric: 8.267001986503601, lr: 0.0007454289589077234
[360] train loss: 0.29589657858014107, metric: 10.138482332229614, lr: 0.0007174497004598379
[380] train loss: -0.18804239481687546, metric: 9.05455732345581, lr: 0.00068860367173329
[400] train loss: -0.251714326441288, metric: 7.270882487297058, lr: 0.0006590057746507227
[420] train loss: 0.8226293325424194, metric: 8.69343090057373, lr: 0.0006287740543484688
[440] train loss: 0.521620973944664, metric: 11.104897737503052, lr: 0.000598029000684619
[460] train loss: 0.46025075390934944, metric: 8.866708397865295, lr: 0.0005668931407853961
[480] train loss: 0.3611358068883419, metric: 10.65715479850769, lr: 0.0005354906315915287
[500] train loss: 0.10814977809786797, metric: 13.180602788925171, lr: 0.0005039466777816415
[520] train loss: 0.7988076284527779, metric: 15.661316275596619, lr: 0.0004723869787994772
[540] train loss: -0.1460014283657074, metric: 9.376668691635132, lr: 0.0004409373505041003
[560] train loss: -0.1016920730471611, metric: 9.152409076690674, lr: 0.0004097231721971184
[580] train loss: -0.20788830146193504, metric: 7.70923376083374, lr: 0.000378868862753734
[600] train loss: 0.028269998729228973, metric: 8.800240278244019, lr: 0.00034849741496145725
[620] train loss: -0.2646583281457424, metric: 8.037996768951416, lr: 0.0003187299007549882
[640] train loss: -0.282592810690403, metric: 7.562014102935791, lr: 0.0002896849764510989
[660] train loss: -0.11835096031427383, metric: 9.938461542129517, lr: 0.0002614784170873463
[680] train loss: 0.4281297139823437, metric: 11.549908995628357, lr: 0.00023422270896844566
[700] train loss: 4.060014147311449, metric: 18.8190279006958, lr: 0.00020802643848583102
[720] train loss: 6.985143557190895, metric: 18.240391492843628, lr: 0.00018299407383892685
[740] train loss: 1.047039933502674, metric: 14.208513498306274, lr: 0.00015922538295853883
[760] train loss: 0.5152199491858482, metric: 12.337531805038452, lr: 0.00013681512791663408
[780] train loss: 0.05904734507203102, metric: 9.674233794212341, lr: 0.00011585262109292671
[800] train loss: 2.5983376279473305, metric: 10.224152565002441, lr: 9.999999747378752e-05
[820] train loss: 0.3006429485976696, metric: 14.312761545181274, lr: 9.999999747378752e-05
[840] train loss: 0.15828335657715797, metric: 13.670143604278564, lr: 9.999999747378752e-05
[860] train loss: 0.08011481538414955, metric: 11.996778011322021, lr: 9.999999747378752e-05
[880] train loss: 0.09015917405486107, metric: 12.424391269683838, lr: 9.999999747378752e-05
[900] train loss: 0.008294593542814255, metric: 10.097007751464844, lr: 9.999999747378752e-05
[920] train loss: 0.017632540315389633, metric: 9.895085096359253, lr: 9.999999747378752e-05
[940] train loss: -0.06197337433695793, metric: 9.048223733901978, lr: 9.999999747378752e-05
[960] train loss: -0.04282446578145027, metric: 9.254057168960571, lr: 9.999999747378752e-05
[980] train loss: 0.019914641976356506, metric: 9.953825950622559, lr: 9.999999747378752e-05
[1000] train loss: 0.5024049952626228, metric: 10.709608793258667, lr: 9.999999747378752e-05
[1020] train loss: -0.007418004795908928, metric: 9.587706208229065, lr: 0.0009994393913075328
[1040] train loss: 0.282125748693943, metric: 17.341060161590576, lr: 0.0009969500824809074
[1060] train loss: -0.28565430268645287, metric: 9.881853103637695, lr: 0.000992479850538075
[1080] train loss: -0.27172887325286865, metric: 9.567681550979614, lr: 0.000986046390607953
[1100] train loss: -0.25234802439808846, metric: 8.17592453956604, lr: 0.0009776754304766655
[1120] train loss: -0.3376006856560707, metric: 7.539109110832214, lr: 0.0009674003813415766
[1140] train loss: -0.3469145894050598, metric: 7.015646934509277, lr: 0.0009552621049806476
[1160] train loss: -0.30589257180690765, metric: 8.914551496505737, lr: 0.0009413089719600976
[1180] train loss: -0.3273814022541046, metric: 6.410967230796814, lr: 0.0009255966870114207
[1200] train loss: -0.3808419331908226, metric: 6.8667837381362915, lr: 0.00090818788157776
[1220] train loss: -0.33974598348140717, metric: 6.624687671661377, lr: 0.0008891518809832633
[1240] train loss: -0.30927055329084396, metric: 8.621784210205078, lr: 0.0008685645880177617
[1260] train loss: -0.3400590270757675, metric: 6.81599760055542, lr: 0.0008465081336908042
[1280] train loss: -0.2936343848705292, metric: 7.518906593322754, lr: 0.0008230703533627093
[1300] train loss: -0.3595237731933594, metric: 6.8802571296691895, lr: 0.0007983447285369039
[1320] train loss: -0.32666201889514923, metric: 6.022272706031799, lr: 0.0007724298629909754
[1340] train loss: -0.18189479410648346, metric: 6.700498700141907, lr: 0.0007454289589077234
[1360] train loss: -0.17222602665424347, metric: 6.581907868385315, lr: 0.0007174497004598379
[1380] train loss: -0.24727094545960426, metric: 6.5905210971832275, lr: 0.00068860367173329
[1400] train loss: -0.2679191268980503, metric: 6.55096435546875, lr: 0.0006590057746507227
[1420] train loss: -0.33093351125717163, metric: 5.968512773513794, lr: 0.0006287740543484688
[1440] train loss: -0.35689475387334824, metric: 5.728905558586121, lr: 0.000598029000684619
[1460] train loss: -0.36840277165174484, metric: 5.704135179519653, lr: 0.0005668931407853961
[1480] train loss: -0.27739591151475906, metric: 7.347178220748901, lr: 0.0005354906315915287
[1500] train loss: -0.28013796359300613, metric: 7.762647390365601, lr: 0.0005039466777816415
[1520] train loss: -0.26079585403203964, metric: 8.229569435119629, lr: 0.0004723869787994772
[1540] train loss: 0.31565064936876297, metric: 18.265910148620605, lr: 0.0004409373505041003
[1560] train loss: -0.1857171542942524, metric: 8.714092016220093, lr: 0.0004097231721971184
[1580] train loss: -0.15438349545001984, metric: 9.078568935394287, lr: 0.000378868862753734
[1600] train loss: -0.20002976804971695, metric: 9.068623781204224, lr: 0.00034849741496145725
[1620] train loss: -0.18026777356863022, metric: 9.7059965133667, lr: 0.0003187299007549882
[1640] train loss: -0.1812567450106144, metric: 8.128986358642578, lr: 0.0002896849764510989
[1660] train loss: -0.1317290998995304, metric: 7.06807279586792, lr: 0.0002614784170873463
[1680] train loss: -0.27264777943491936, metric: 9.201971530914307, lr: 0.00023422270896844566
[1700] train loss: -0.30226151272654533, metric: 10.06367540359497, lr: 0.00020802643848583102
[1720] train loss: -0.3039790131151676, metric: 10.053577899932861, lr: 0.00018299407383892685
[1740] train loss: -0.30642230063676834, metric: 8.045596599578857, lr: 0.00015922538295853883
[1760] train loss: -0.26733841374516487, metric: 7.431602358818054, lr: 0.00013681512791663408
[1780] train loss: -0.2565122917294502, metric: 7.917394161224365, lr: 0.00011585262109292671
[1800] train loss: 0.008848734200000763, metric: 9.380981683731079, lr: 9.999999747378752e-05
[1820] train loss: -0.15722275152802467, metric: 9.38995623588562, lr: 9.999999747378752e-05
[1840] train loss: 0.07067917287349701, metric: 7.671164870262146, lr: 9.999999747378752e-05
[1860] train loss: 0.6142289862036705, metric: 10.611797571182251, lr: 9.999999747378752e-05
[1880] train loss: 1.2762890383601189, metric: 12.185970425605774, lr: 9.999999747378752e-05
[1900] train loss: 0.23569348081946373, metric: 12.561307430267334, lr: 9.999999747378752e-05
[1920] train loss: 0.6630766242742538, metric: 11.528315544128418, lr: 9.999999747378752e-05
[1940] train loss: 1.416745975613594, metric: 12.944360256195068, lr: 9.999999747378752e-05
[1960] train loss: 0.20591053366661072, metric: 9.052624821662903, lr: 9.999999747378752e-05
[1980] train loss: -0.06100400164723396, metric: 9.897811532020569, lr: 9.999999747378752e-05
[2000] train loss: -0.004432499408721924, metric: 9.965981721878052, lr: 9.999999747378752e-05
[2020] train loss: -0.2649027220904827, metric: 9.11583662033081, lr: 0.0009994393913075328
[2040] train loss: -0.06061549484729767, metric: 7.407099485397339, lr: 0.0009969500824809074
[2060] train loss: 0.261611495167017, metric: 15.397930383682251, lr: 0.000992479850538075
[2080] train loss: 0.17078600078821182, metric: 10.870003938674927, lr: 0.000986046390607953
[2100] train loss: 0.32289329543709755, metric: 11.478825807571411, lr: 0.0009776754304766655
[2120] train loss: 0.9721893966197968, metric: 15.147451639175415, lr: 0.0009674003813415766
[2140] train loss: 0.20616278052330017, metric: 17.11816108226776, lr: 0.0009552621049806476
[2160] train loss: 1.9374740943312645, metric: 12.36416506767273, lr: 0.0009413089719600976
[2180] train loss: 0.39852292463183403, metric: 13.822908401489258, lr: 0.0009255966870114207
[2200] train loss: 0.9052916541695595, metric: 13.917232513427734, lr: 0.00090818788157776
[2220] train loss: 0.0008932314813137054, metric: 11.891821384429932, lr: 0.0008891518809832633
[2240] train loss: 2.8136034682393074, metric: 14.273172378540039, lr: 0.0008685645880177617
[2260] train loss: 0.6507039330899715, metric: 16.701171398162842, lr: 0.0008465081336908042
[2280] train loss: 2.2315199971199036, metric: 15.433012247085571, lr: 0.0008230703533627093
[2300] train loss: 2.2981152161955833, metric: 15.760639667510986, lr: 0.0007983447285369039
[2320] train loss: 0.9657689779996872, metric: 17.959604501724243, lr: 0.0007724298629909754
[2340] train loss: 0.01167013868689537, metric: 12.820785522460938, lr: 0.0007454289589077234
[2360] train loss: 0.27339309826493263, metric: 11.990576267242432, lr: 0.0007174497004598379
[2380] train loss: 0.2637920118868351, metric: 10.628142595291138, lr: 0.00068860367173329
[2400] train loss: 0.7617134861648083, metric: 11.352726221084595, lr: 0.0006590057746507227
[2420] train loss: 0.0937831811606884, metric: 8.790138483047485, lr: 0.0006287740543484688
[2440] train loss: 0.06296933442354202, metric: 8.770138025283813, lr: 0.000598029000684619
[2460] train loss: 2.457786276936531, metric: 11.99985957145691, lr: 0.0005668931407853961
[2480] train loss: 6.153262887150049, metric: 15.781973600387573, lr: 0.0005354906315915287
[2500] train loss: -0.078164491802454, metric: 13.530752658843994, lr: 0.0005039466777816415
[2520] train loss: 0.7655310817062855, metric: 12.522483825683594, lr: 0.0004723869787994772
[2540] train loss: 2.1303767189383507, metric: 11.239165782928467, lr: 0.0004409373505041003
[2560] train loss: -0.17736535891890526, metric: 8.086350440979004, lr: 0.0004097231721971184
[2580] train loss: -0.25403784587979317, metric: 11.904945373535156, lr: 0.000378868862753734
[2600] train loss: -0.2808219864964485, metric: 10.026060581207275, lr: 0.00034849741496145725
[2620] train loss: -0.19590382277965546, metric: 9.68292760848999, lr: 0.0003187299007549882
[2640] train loss: -0.2975103110074997, metric: 11.210048079490662, lr: 0.0002896849764510989
[2660] train loss: -0.2539815977215767, metric: 10.659874439239502, lr: 0.0002614784170873463
[2680] train loss: -0.3182239942252636, metric: 8.467934727668762, lr: 0.00023422270896844566
[2700] train loss: -0.05157452076673508, metric: 9.594329357147217, lr: 0.00020802643848583102
[2720] train loss: 0.299671046435833, metric: 11.269946813583374, lr: 0.00018299407383892685
[2740] train loss: -0.018575839698314667, metric: 9.219372749328613, lr: 0.00015922538295853883
[2760] train loss: -0.11146046593785286, metric: 11.04980218410492, lr: 0.00013681512791663408
[2780] train loss: -0.054782792925834656, metric: 10.958300232887268, lr: 0.00011585262109292671
[2800] train loss: 0.5449888557195663, metric: 11.81072747707367, lr: 9.999999747378752e-05
[2820] train loss: 1.4315630905330181, metric: 18.41332769393921, lr: 9.999999747378752e-05
[2840] train loss: 2.6120913848280907, metric: 14.884003162384033, lr: 9.999999747378752e-05
[2860] train loss: 1.3666836321353912, metric: 22.688892364501953, lr: 9.999999747378752e-05
[2880] train loss: 8.83497902750969, metric: 21.321420192718506, lr: 9.999999747378752e-05
[2900] train loss: 1.3163813203573227, metric: 12.891216278076172, lr: 9.999999747378752e-05
[2920] train loss: 0.11769116297364235, metric: 13.943816184997559, lr: 9.999999747378752e-05
[2940] train loss: -0.16425985470414162, metric: 12.897861242294312, lr: 9.999999747378752e-05
[2960] train loss: -0.14634279906749725, metric: 11.40372347831726, lr: 9.999999747378752e-05
[2980] train loss: -0.1660396046936512, metric: 11.240263104438782, lr: 9.999999747378752e-05
[3000] train loss: -0.1355959177017212, metric: 12.966128826141357, lr: 9.999999747378752e-05
[3020] train loss: -0.243366539478302, metric: 10.918221473693848, lr: 0.0009994393913075328
[3040] train loss: -0.1910022310912609, metric: 9.108996629714966, lr: 0.0009969500824809074
[3060] train loss: 0.3669205494225025, metric: 12.167734146118164, lr: 0.000992479850538075
[3080] train loss: 2.312046978622675, metric: 15.689303874969482, lr: 0.000986046390607953
[3100] train loss: 0.33050834760069847, metric: 16.032697916030884, lr: 0.0009776754304766655
[3120] train loss: 0.013921011239290237, metric: 11.329104661941528, lr: 0.0009674003813415766
[3140] train loss: -0.17186934873461723, metric: 12.171265125274658, lr: 0.0009552621049806476
[3160] train loss: -0.17694643512368202, metric: 10.843154907226562, lr: 0.0009413089719600976
[3180] train loss: 0.5899532586336136, metric: 11.048617839813232, lr: 0.0009255966870114207
[3200] train loss: 6.155481088906527, metric: 13.915194749832153, lr: 0.00090818788157776
[3220] train loss: 0.566976223140955, metric: 14.365551710128784, lr: 0.0008891518809832633
[3240] train loss: 0.0007202476263046265, metric: 9.53471064567566, lr: 0.0008685645880177617
[3260] train loss: 0.024587363004684448, metric: 8.95418667793274, lr: 0.0008465081336908042
[3280] train loss: -0.04793454334139824, metric: 7.70945131778717, lr: 0.0008230703533627093
[3300] train loss: 0.0164886973798275, metric: 8.435012936592102, lr: 0.0007983447285369039
[3320] train loss: -0.20214742049574852, metric: 10.277187466621399, lr: 0.0007724298629909754
[3340] train loss: -0.09330954775214195, metric: 8.412234425544739, lr: 0.0007454289589077234
[3360] train loss: -0.29771681129932404, metric: 8.99732780456543, lr: 0.0007174497004598379
[3380] train loss: -0.25342199206352234, metric: 7.819413185119629, lr: 0.00068860367173329
[3400] train loss: -0.26559290289878845, metric: 8.734970688819885, lr: 0.0006590057746507227
[3420] train loss: 1.3257168531417847, metric: 9.292738556861877, lr: 0.0006287740543484688
[3440] train loss: 1.5197110287845135, metric: 9.290063381195068, lr: 0.000598029000684619
[3460] train loss: 1.4772399105131626, metric: 9.811051845550537, lr: 0.0005668931407853961
[3480] train loss: 0.03476604074239731, metric: 8.756280422210693, lr: 0.0005354906315915287
[3500] train loss: -0.30296561121940613, metric: 9.534579038619995, lr: 0.0005039466777816415
[3520] train loss: -0.25335585325956345, metric: 8.675057888031006, lr: 0.0004723869787994772
[3540] train loss: -0.08015794306993484, metric: 8.58931052684784, lr: 0.0004409373505041003
[3560] train loss: 0.4358922950923443, metric: 15.674621105194092, lr: 0.0004097231721971184
[3580] train loss: 0.20564736798405647, metric: 15.628264665603638, lr: 0.000378868862753734
[3600] train loss: 2.696992129087448, metric: 25.290520668029785, lr: 0.00034849741496145725
[3620] train loss: 5.181710187345743, metric: 23.164803504943848, lr: 0.0003187299007549882
[3640] train loss: 4.762282341718674, metric: 25.485061168670654, lr: 0.0002896849764510989
[3660] train loss: 6.09570412710309, metric: 20.63469696044922, lr: 0.0002614784170873463
[3680] train loss: 6.899850971996784, metric: 23.321452856063843, lr: 0.00023422270896844566
[3700] train loss: 2.718480609357357, metric: 17.377363204956055, lr: 0.00020802643848583102
[3720] train loss: 4.113237142562866, metric: 17.010364532470703, lr: 0.00018299407383892685
[3740] train loss: 2.6594218313694, metric: 14.533034324645996, lr: 0.00015922538295853883
[3760] train loss: 4.329320996999741, metric: 18.334079027175903, lr: 0.00013681512791663408
[3780] train loss: 2.8855205811560154, metric: 21.18540358543396, lr: 0.00011585262109292671
[3800] train loss: 0.6148821376264095, metric: 18.661269903182983, lr: 9.999999747378752e-05
[3820] train loss: 2.320003893226385, metric: 18.75487470626831, lr: 9.999999747378752e-05
[3840] train loss: 0.6268573254346848, metric: 13.657411813735962, lr: 9.999999747378752e-05
[3860] train loss: 0.222270417958498, metric: 11.72849440574646, lr: 9.999999747378752e-05
[3880] train loss: 5.470919251441956, metric: 18.857091426849365, lr: 9.999999747378752e-05
[3900] train loss: 6.265234410762787, metric: 20.125436782836914, lr: 9.999999747378752e-05
[3920] train loss: 0.990670956671238, metric: 17.921196937561035, lr: 9.999999747378752e-05
[3940] train loss: 1.3457314223051071, metric: 16.970815658569336, lr: 9.999999747378752e-05
[3960] train loss: 1.9815888851881027, metric: 20.413121223449707, lr: 9.999999747378752e-05
[3980] train loss: 1.5708053074777126, metric: 17.102463245391846, lr: 9.999999747378752e-05
[4000] train loss: 3.4437932185828686, metric: 17.334084510803223, lr: 9.999999747378752e-05
[4020] train loss: 3.7620896100997925, metric: 20.962288856506348, lr: 0.0009994393913075328
[4040] train loss: 3.060853522270918, metric: 16.920210123062134, lr: 0.0009969500824809074
[4060] train loss: 1.51247663423419, metric: 14.822638034820557, lr: 0.000992479850538075
[4080] train loss: 3.1256354451179504, metric: 19.37463665008545, lr: 0.000986046390607953
[4100] train loss: 3.8603556901216507, metric: 21.73815631866455, lr: 0.0009776754304766655
[4120] train loss: 0.26085323840379715, metric: 15.324551820755005, lr: 0.0009674003813415766
[4140] train loss: 0.4780985973775387, metric: 13.239818811416626, lr: 0.0009552621049806476
[4160] train loss: 0.3295823261141777, metric: 14.404964447021484, lr: 0.0009413089719600976
[4180] train loss: 0.7303358484059572, metric: 12.676119327545166, lr: 0.0009255966870114207
[4200] train loss: 3.6063644401729107, metric: 15.113041162490845, lr: 0.00090818788157776
[4220] train loss: 1.6456403620541096, metric: 26.452453136444092, lr: 0.0008891518809832633
[4240] train loss: 0.5295364446938038, metric: 11.546988010406494, lr: 0.0008685645880177617
[4260] train loss: -0.11032803729176521, metric: 11.74728274345398, lr: 0.0008465081336908042
[4280] train loss: -0.08105439692735672, metric: 8.900368928909302, lr: 0.0008230703533627093
[4300] train loss: -0.20954827219247818, metric: 8.51780915260315, lr: 0.0007983447285369039
[4320] train loss: -0.18669313937425613, metric: 9.687360525131226, lr: 0.0007724298629909754
[4340] train loss: -0.0029538534581661224, metric: 8.743894338607788, lr: 0.0007454289589077234
[4360] train loss: 0.08882492035627365, metric: 10.037681818008423, lr: 0.0007174497004598379
[4380] train loss: 0.038227628916502, metric: 8.259805917739868, lr: 0.00068860367173329
[4400] train loss: -0.07859919592738152, metric: 7.898839712142944, lr: 0.0006590057746507227
[4420] train loss: -0.08301812410354614, metric: 7.600987792015076, lr: 0.0006287740543484688
[4440] train loss: 0.007927149534225464, metric: 7.742369890213013, lr: 0.000598029000684619
[4460] train loss: -0.017314091324806213, metric: 9.283445239067078, lr: 0.0005668931407853961
[4480] train loss: 0.6867045350372791, metric: 10.914698600769043, lr: 0.0005354906315915287
[4500] train loss: 0.3258117809891701, metric: 9.844476580619812, lr: 0.0005039466777816415
[4520] train loss: 0.1956283524632454, metric: 13.26790165901184, lr: 0.0004723869787994772
[4540] train loss: -0.06275933608412743, metric: 14.219748497009277, lr: 0.0004409373505041003
[4560] train loss: -0.013503432273864746, metric: 12.64529824256897, lr: 0.0004097231721971184
[4580] train loss: -0.11017248034477234, metric: 14.246119737625122, lr: 0.000378868862753734
[4600] train loss: 0.41704409569501877, metric: 16.355612993240356, lr: 0.00034849741496145725
[4620] train loss: 0.7588365934789181, metric: 17.9603910446167, lr: 0.0003187299007549882
[4640] train loss: 0.15492341294884682, metric: 12.813790798187256, lr: 0.0002896849764510989
[4660] train loss: 0.2494608238339424, metric: 12.197643399238586, lr: 0.0002614784170873463
[4680] train loss: 0.24385076016187668, metric: 17.115002870559692, lr: 0.00023422270896844566
[4700] train loss: 0.4443497508764267, metric: 15.569809913635254, lr: 0.00020802643848583102
[4720] train loss: -0.10230178385972977, metric: 11.467644214630127, lr: 0.00018299407383892685
[4740] train loss: -0.0822293721139431, metric: 11.619395732879639, lr: 0.00015922538295853883
[4760] train loss: -0.21415221691131592, metric: 8.758489966392517, lr: 0.00013681512791663408
[20] train loss: -0.12016677111387253, metric: 10.73081374168396, lr: 0.0009994393913075328
[40] train loss: -0.2574331946671009, metric: 7.907861828804016, lr: 0.0009969500824809074
[60] train loss: -0.33628199249505997, metric: 7.988246202468872, lr: 0.000992479850538075
[80] train loss: 0.002025023102760315, metric: 9.828841209411621, lr: 0.000986046390607953
[100] train loss: -0.3204442709684372, metric: 9.151350259780884, lr: 0.0009776754304766655
[120] train loss: -0.2753168195486069, metric: 9.104899168014526, lr: 0.0009674003813415766
[140] train loss: -0.31273698806762695, metric: 7.03422474861145, lr: 0.0009552621049806476
[160] train loss: -0.29289091005921364, metric: 9.72085952758789, lr: 0.0009413089719600976
[180] train loss: -0.15986273437738419, metric: 8.115418076515198, lr: 0.0009255966870114207
[200] train loss: -0.27277158200740814, metric: 7.325374484062195, lr: 0.00090818788157776
[220] train loss: -0.140839621424675, metric: 8.24704122543335, lr: 0.0008891518809832633
[240] train loss: 0.6707871779799461, metric: 7.55271303653717, lr: 0.0008685645880177617
[260] train loss: -0.12445004284381866, metric: 8.334752202033997, lr: 0.0008465081336908042
[280] train loss: -0.2135971412062645, metric: 7.594014644622803, lr: 0.0008230703533627093
[300] train loss: -0.18989058956503868, metric: 8.208826899528503, lr: 0.0007983447285369039
[320] train loss: -0.12642236799001694, metric: 12.315469145774841, lr: 0.0007724298629909754
[340] train loss: 0.4320745952427387, metric: 9.843412280082703, lr: 0.0007454289589077234
[360] train loss: 0.7123065814375877, metric: 8.006364822387695, lr: 0.0007174497004598379
[380] train loss: -0.05010206997394562, metric: 9.916223168373108, lr: 0.00068860367173329
[400] train loss: 0.0008215531706809998, metric: 9.311164379119873, lr: 0.0006590057746507227
[420] train loss: 0.017032518982887268, metric: 9.16327714920044, lr: 0.0006287740543484688
[440] train loss: 0.13032767921686172, metric: 9.330398559570312, lr: 0.000598029000684619
[460] train loss: 0.33018733933568, metric: 10.316705226898193, lr: 0.0005668931407853961
[480] train loss: 1.270811878144741, metric: 10.440150260925293, lr: 0.0005354906315915287
[500] train loss: 1.3114093765616417, metric: 8.979568719863892, lr: 0.0005039466777816415
[520] train loss: 1.4116560071706772, metric: 16.220218896865845, lr: 0.0004723869787994772
[540] train loss: -0.18899830803275108, metric: 8.899632811546326, lr: 0.0004409373505041003
[560] train loss: -0.1014990583062172, metric: 11.716227769851685, lr: 0.0004097231721971184
[580] train loss: -0.06113173067569733, metric: 7.613569021224976, lr: 0.000378868862753734
[600] train loss: -0.03970596194267273, metric: 12.493690490722656, lr: 0.00034849741496145725
[620] train loss: -0.08680971339344978, metric: 11.13142704963684, lr: 0.0003187299007549882
[640] train loss: 0.6732743009924889, metric: 8.55291736125946, lr: 0.0002896849764510989
[660] train loss: 0.027786962687969208, metric: 10.209955215454102, lr: 0.0002614784170873463
[680] train loss: -0.1208607591688633, metric: 7.8440961837768555, lr: 0.00023422270896844566
[700] train loss: -0.16156096011400223, metric: 7.328259468078613, lr: 0.00020802643848583102
[720] train loss: -0.07514771446585655, metric: 8.691763401031494, lr: 0.00018299407383892685
[740] train loss: -0.011743161827325821, metric: 10.825575113296509, lr: 0.00015922538295853883
[760] train loss: 0.1289723552763462, metric: 11.249501943588257, lr: 0.00013681512791663408
[780] train loss: -0.1667460948228836, metric: 8.892853021621704, lr: 0.00011585262109292671
[800] train loss: 0.18104622140526772, metric: 9.21445894241333, lr: 9.999999747378752e-05
[820] train loss: 0.11895168572664261, metric: 9.60517144203186, lr: 9.999999747378752e-05
[840] train loss: -0.11454121768474579, metric: 8.99836540222168, lr: 9.999999747378752e-05
[860] train loss: -0.2230330854654312, metric: 8.13269829750061, lr: 9.999999747378752e-05
[880] train loss: -0.21060793846845627, metric: 8.265486359596252, lr: 9.999999747378752e-05
[900] train loss: 0.415336936712265, metric: 11.309086084365845, lr: 9.999999747378752e-05
[920] train loss: 4.662689879536629, metric: 15.155417680740356, lr: 9.999999747378752e-05
[940] train loss: 4.222945600748062, metric: 16.10417878627777, lr: 9.999999747378752e-05
[960] train loss: 0.0909828282892704, metric: 9.709017395973206, lr: 9.999999747378752e-05
[980] train loss: -0.13292737305164337, metric: 10.036503314971924, lr: 9.999999747378752e-05
[1000] train loss: -0.24181577190756798, metric: 7.1768494844436646, lr: 9.999999747378752e-05
[1020] train loss: -0.20330410450696945, metric: 6.477941632270813, lr: 0.0009994393913075328
[1040] train loss: 0.753946740180254, metric: 15.91916275024414, lr: 0.0009969500824809074
[1060] train loss: 0.10558154806494713, metric: 11.805394172668457, lr: 0.000992479850538075
[1080] train loss: 0.4118848517537117, metric: 10.814273118972778, lr: 0.000986046390607953
[1100] train loss: 0.056793153285980225, metric: 11.02594542503357, lr: 0.0009776754304766655
[1120] train loss: -0.03410787507891655, metric: 10.605765342712402, lr: 0.0009674003813415766
[1140] train loss: -0.005712632089853287, metric: 10.768704175949097, lr: 0.0009552621049806476
[1160] train loss: -0.022496618330478668, metric: 9.334394693374634, lr: 0.0009413089719600976
[1180] train loss: -0.15849701687693596, metric: 9.49515986442566, lr: 0.0009255966870114207
[1200] train loss: 0.3587379492819309, metric: 9.484779477119446, lr: 0.00090818788157776
[1220] train loss: -0.11237899959087372, metric: 10.12574291229248, lr: 0.0008891518809832633
[1240] train loss: 0.213933065533638, metric: 10.301878929138184, lr: 0.0008685645880177617
[1260] train loss: 0.58786441385746, metric: 10.968011856079102, lr: 0.0008465081336908042
[1280] train loss: 0.5542374216020107, metric: 10.975075006484985, lr: 0.0008230703533627093
[1300] train loss: -0.04087419807910919, metric: 11.293601274490356, lr: 0.0007983447285369039
[1320] train loss: 0.6467583514750004, metric: 16.661991834640503, lr: 0.0007724298629909754
[1340] train loss: 0.0013031847774982452, metric: 11.256582617759705, lr: 0.0007454289589077234
[1360] train loss: 0.06512143462896347, metric: 13.952806949615479, lr: 0.0007174497004598379
[1380] train loss: -0.16585958749055862, metric: 8.564581513404846, lr: 0.00068860367173329
[1400] train loss: -0.026988249272108078, metric: 10.882150769233704, lr: 0.0006590057746507227
[1420] train loss: -0.2719884403049946, metric: 7.2884920835494995, lr: 0.0006287740543484688
[1440] train loss: -0.15149498730897903, metric: 6.932837009429932, lr: 0.000598029000684619
[1460] train loss: -0.15970707684755325, metric: 10.057328939437866, lr: 0.0005668931407853961
[1480] train loss: -0.27641142159700394, metric: 7.268502235412598, lr: 0.0005354906315915287
[1500] train loss: -0.22045158222317696, metric: 9.05229902267456, lr: 0.0005039466777816415
[1520] train loss: -0.2702114135026932, metric: 9.161017775535583, lr: 0.0004723869787994772
[1540] train loss: 1.3249242380261421, metric: 17.10327935218811, lr: 0.0004409373505041003
[1560] train loss: -0.09572778269648552, metric: 10.755927801132202, lr: 0.0004097231721971184
[1580] train loss: -0.16871454194188118, metric: 11.219610810279846, lr: 0.000378868862753734
[1600] train loss: -0.22327333688735962, metric: 7.61128842830658, lr: 0.00034849741496145725
[1620] train loss: -0.25140948221087456, metric: 8.339034080505371, lr: 0.0003187299007549882
[1640] train loss: -0.22235539928078651, metric: 7.594967365264893, lr: 0.0002896849764510989
[1660] train loss: -0.2751179076731205, metric: 7.259633541107178, lr: 0.0002614784170873463
[1680] train loss: -0.22646094858646393, metric: 7.644399642944336, lr: 0.00023422270896844566
[1700] train loss: -0.2418985515832901, metric: 6.784974217414856, lr: 0.00020802643848583102
[1720] train loss: -0.22768709436058998, metric: 7.573755979537964, lr: 0.00018299407383892685
[1740] train loss: -0.104823749512434, metric: 9.589087963104248, lr: 0.00015922538295853883
[1760] train loss: -0.17147168517112732, metric: 10.109346151351929, lr: 0.00013681512791663408
[1780] train loss: -0.11945414170622826, metric: 9.149260997772217, lr: 0.00011585262109292671
[1800] train loss: -0.1333029381930828, metric: 8.767889261245728, lr: 9.999999747378752e-05
[1820] train loss: -0.11628547310829163, metric: 9.99929666519165, lr: 9.999999747378752e-05
[1840] train loss: -0.06853896006941795, metric: 7.674754023551941, lr: 9.999999747378752e-05
[1860] train loss: -0.12975173443555832, metric: 8.762291193008423, lr: 9.999999747378752e-05
[1880] train loss: -0.17968814074993134, metric: 9.068385243415833, lr: 9.999999747378752e-05
[1900] train loss: -0.1579975001513958, metric: 8.779373049736023, lr: 9.999999747378752e-05
[1920] train loss: -0.18272316083312035, metric: 7.739235043525696, lr: 9.999999747378752e-05
[1940] train loss: -0.1630416065454483, metric: 9.417973756790161, lr: 9.999999747378752e-05
[1960] train loss: 0.2796427011489868, metric: 9.696837425231934, lr: 9.999999747378752e-05
[1980] train loss: -0.07768865302205086, metric: 10.183422207832336, lr: 9.999999747378752e-05
[2000] train loss: 0.051436103880405426, metric: 10.84056305885315, lr: 9.999999747378752e-05
[2020] train loss: -0.02034972608089447, metric: 9.780381917953491, lr: 0.0009994393913075328
[2040] train loss: -0.22173715755343437, metric: 8.652053713798523, lr: 0.0009969500824809074
[2060] train loss: 1.325733244419098, metric: 15.483804941177368, lr: 0.000992479850538075
[2080] train loss: -0.07986091822385788, metric: 11.650829315185547, lr: 0.000986046390607953
[2100] train loss: 0.03187112882733345, metric: 9.437814235687256, lr: 0.0009776754304766655
[2120] train loss: -0.24382959306240082, metric: 9.701271176338196, lr: 0.0009674003813415766
[2140] train loss: -0.23676557838916779, metric: 10.7480309009552, lr: 0.0009552621049806476
[2160] train loss: -0.08031607046723366, metric: 8.737409949302673, lr: 0.0009413089719600976
[2180] train loss: -0.18565497547388077, metric: 9.491608381271362, lr: 0.0009255966870114207
[2200] train loss: 0.2072875164449215, metric: 11.529226541519165, lr: 0.00090818788157776
[2220] train loss: -0.04564904421567917, metric: 10.391706347465515, lr: 0.0008891518809832633
[2240] train loss: 0.20448477566242218, metric: 7.9120811223983765, lr: 0.0008685645880177617
[2260] train loss: 0.3447229005396366, metric: 9.427221775054932, lr: 0.0008465081336908042
[2280] train loss: 0.6863613724708557, metric: 11.829294681549072, lr: 0.0008230703533627093
[2300] train loss: 0.48526278510689735, metric: 12.949195384979248, lr: 0.0007983447285369039
[2320] train loss: 0.27526528760790825, metric: 13.34337592124939, lr: 0.0007724298629909754
[2340] train loss: 2.4905247315764427, metric: 11.937402725219727, lr: 0.0007454289589077234
[2360] train loss: 1.8350364975631237, metric: 13.88451337814331, lr: 0.0007174497004598379
[2380] train loss: 1.2805257253348827, metric: 17.903362274169922, lr: 0.00068860367173329
[2400] train loss: 0.7801252976059914, metric: 18.79684805870056, lr: 0.0006590057746507227
[2420] train loss: 0.32020406052470207, metric: 12.486256837844849, lr: 0.0006287740543484688
[2440] train loss: 0.8634669259190559, metric: 12.441350221633911, lr: 0.000598029000684619
[2460] train loss: 1.0301951244473457, metric: 11.469488859176636, lr: 0.0005668931407853961
[2480] train loss: 7.61145069077611, metric: 20.911518335342407, lr: 0.0005354906315915287
[2500] train loss: 4.367561537772417, metric: 19.84183168411255, lr: 0.0005039466777816415
[2520] train loss: 0.28928157687187195, metric: 12.752198219299316, lr: 0.0004723869787994772
[2540] train loss: 0.24126002937555313, metric: 11.223610877990723, lr: 0.0004409373505041003
[2560] train loss: 0.1030408926308155, metric: 10.467123985290527, lr: 0.0004097231721971184
[2580] train loss: -0.2104099616408348, metric: 11.072365760803223, lr: 0.000378868862753734
[2600] train loss: -0.2777078188955784, metric: 10.881201267242432, lr: 0.00034849741496145725
[2620] train loss: -0.2966027483344078, metric: 10.09639286994934, lr: 0.0003187299007549882
[2640] train loss: -0.26420942693948746, metric: 11.07119882106781, lr: 0.0002896849764510989
[2660] train loss: 0.01474221795797348, metric: 12.031662225723267, lr: 0.0002614784170873463
[2680] train loss: -0.2719527631998062, metric: 10.674485921859741, lr: 0.00023422270896844566
[2700] train loss: -0.2904469035565853, metric: 10.239710330963135, lr: 0.00020802643848583102
[2720] train loss: -0.28248024359345436, metric: 10.441987156867981, lr: 0.00018299407383892685
[2740] train loss: -0.2540207728743553, metric: 9.9047532081604, lr: 0.00015922538295853883
[2760] train loss: -0.25957176834344864, metric: 9.78212833404541, lr: 0.00013681512791663408
[2780] train loss: -0.24375061318278313, metric: 9.655837774276733, lr: 0.00011585262109292671
[2800] train loss: -0.27567343786358833, metric: 9.769172191619873, lr: 9.999999747378752e-05
[2820] train loss: -0.23561331629753113, metric: 9.685600996017456, lr: 9.999999747378752e-05
[2840] train loss: -0.14407207816839218, metric: 8.84181821346283, lr: 9.999999747378752e-05
[2860] train loss: 0.06315389275550842, metric: 12.837975859642029, lr: 9.999999747378752e-05
[2880] train loss: -0.09833486750721931, metric: 12.592605352401733, lr: 9.999999747378752e-05
[2900] train loss: -0.17362884804606438, metric: 15.219151735305786, lr: 9.999999747378752e-05
[2920] train loss: -0.15982718020677567, metric: 14.929738759994507, lr: 9.999999747378752e-05
[2940] train loss: -0.21115902811288834, metric: 12.684253931045532, lr: 9.999999747378752e-05
[2960] train loss: -0.14553973823785782, metric: 11.675241947174072, lr: 9.999999747378752e-05
[2980] train loss: -0.10876775160431862, metric: 11.256425857543945, lr: 9.999999747378752e-05
[3000] train loss: -0.10322093963623047, metric: 11.346735000610352, lr: 9.999999747378752e-05
[3020] train loss: -0.25101205706596375, metric: 9.490184307098389, lr: 0.0009994393913075328
[3040] train loss: -0.28078871965408325, metric: 8.454333782196045, lr: 0.0009969500824809074
[3060] train loss: -0.31985627859830856, metric: 8.225161075592041, lr: 0.000992479850538075
[3080] train loss: 0.6677661091089249, metric: 14.84114146232605, lr: 0.000986046390607953
[3100] train loss: -0.07226591184735298, metric: 8.864356756210327, lr: 0.0009776754304766655
[3120] train loss: -0.2587929591536522, metric: 8.049445748329163, lr: 0.0009674003813415766
[3140] train loss: -0.3222391754388809, metric: 8.564353227615356, lr: 0.0009552621049806476
[3160] train loss: -0.3026640899479389, metric: 8.61885690689087, lr: 0.0009413089719600976
[3180] train loss: -0.16172238439321518, metric: 7.435998439788818, lr: 0.0009255966870114207
[3200] train loss: -0.1789896860718727, metric: 8.17631459236145, lr: 0.00090818788157776
[3220] train loss: 0.5093805715441704, metric: 10.711101055145264, lr: 0.0008891518809832633
[3240] train loss: 2.5852187126874924, metric: 19.238937735557556, lr: 0.0008685645880177617
[3260] train loss: 1.5495142117142677, metric: 14.161625862121582, lr: 0.0008465081336908042
[3280] train loss: 7.7662423849105835, metric: 22.12637424468994, lr: 0.0008230703533627093
[3300] train loss: 0.8404394537210464, metric: 14.506343603134155, lr: 0.0007983447285369039
[3320] train loss: 2.2162023559212685, metric: 15.624032974243164, lr: 0.0007724298629909754
[3340] train loss: 1.7280322052538395, metric: 14.26988172531128, lr: 0.0007454289589077234
[3360] train loss: 0.722054623067379, metric: 13.324363470077515, lr: 0.0007174497004598379
[3380] train loss: 2.8497468419373035, metric: 19.443557262420654, lr: 0.00068860367173329
[3400] train loss: 0.3964457996189594, metric: 20.463847875595093, lr: 0.0006590057746507227
[3420] train loss: 1.7568469047546387e-05, metric: 12.592567920684814, lr: 0.0006287740543484688
[3440] train loss: 0.10816343501210213, metric: 12.134061813354492, lr: 0.000598029000684619
[3460] train loss: 0.11498648673295975, metric: 11.903891563415527, lr: 0.0005668931407853961
[3480] train loss: 1.1698491051793098, metric: 13.334243059158325, lr: 0.0005354906315915287
[3500] train loss: 0.06704531610012054, metric: 14.04772400856018, lr: 0.0005039466777816415
[3520] train loss: 0.007282804697751999, metric: 10.657496213912964, lr: 0.0004723869787994772
[3540] train loss: -0.10495366528630257, metric: 11.855129480361938, lr: 0.0004409373505041003
[3560] train loss: -0.0555272176861763, metric: 12.608717679977417, lr: 0.0004097231721971184
[3580] train loss: -0.1628471240401268, metric: 8.773218989372253, lr: 0.000378868862753734
[3600] train loss: 2.519367605447769, metric: 19.443591594696045, lr: 0.00034849741496145725
[3620] train loss: 2.592044413089752, metric: 23.456397533416748, lr: 0.0003187299007549882
[3640] train loss: 4.572330716997385, metric: 21.37676453590393, lr: 0.0002896849764510989
[3660] train loss: 7.336599074304104, metric: 18.597105026245117, lr: 0.0002614784170873463
[3680] train loss: 0.7828785628080368, metric: 12.682822465896606, lr: 0.00023422270896844566
[3700] train loss: 3.8513226434588432, metric: 17.54431390762329, lr: 0.00020802643848583102
[3720] train loss: 1.9791011214256287, metric: 14.058696031570435, lr: 0.00018299407383892685
[3740] train loss: 1.0121795646846294, metric: 12.443681120872498, lr: 0.00015922538295853883
[3760] train loss: 9.569471877068281, metric: 19.80684471130371, lr: 0.00013681512791663408
[3780] train loss: 1.5898733586072922, metric: 17.274822235107422, lr: 0.00011585262109292671
[3800] train loss: 3.449157442897558, metric: 16.711537837982178, lr: 9.999999747378752e-05
[3820] train loss: 1.9471175745129585, metric: 14.26296067237854, lr: 9.999999747378752e-05
[3840] train loss: 1.0502647422254086, metric: 14.150981187820435, lr: 9.999999747378752e-05
[3860] train loss: 2.9565593600273132, metric: 18.628746032714844, lr: 9.999999747378752e-05
[3880] train loss: 14.689287602901459, metric: 32.67171239852905, lr: 9.999999747378752e-05
[3900] train loss: 14.18209594488144, metric: 25.049242973327637, lr: 9.999999747378752e-05
[3920] train loss: 0.9656751155853271, metric: 17.57227873802185, lr: 9.999999747378752e-05
[3940] train loss: 4.595312882214785, metric: 19.635480880737305, lr: 9.999999747378752e-05
[3960] train loss: 1.5469167195260525, metric: 17.661173343658447, lr: 9.999999747378752e-05
[3980] train loss: 8.445155750960112, metric: 18.74606490135193, lr: 9.999999747378752e-05
[4000] train loss: 2.3500226102769375, metric: 14.23633098602295, lr: 9.999999747378752e-05
[4020] train loss: 0.29077115654945374, metric: 14.327933549880981, lr: 0.0009994393913075328
[4040] train loss: 0.2000250555574894, metric: 13.063441276550293, lr: 0.0009969500824809074
[4060] train loss: 1.0476753935217857, metric: 16.782696962356567, lr: 0.000992479850538075
[4080] train loss: 0.9008565470576286, metric: 17.291642665863037, lr: 0.000986046390607953
[4100] train loss: 3.065428901463747, metric: 15.436808586120605, lr: 0.0009776754304766655
[4120] train loss: 0.26412881910800934, metric: 12.658118844032288, lr: 0.0009674003813415766
[4140] train loss: 0.4492834769189358, metric: 13.470821857452393, lr: 0.0009552621049806476
[4160] train loss: 0.47731268405914307, metric: 10.801453828811646, lr: 0.0009413089719600976
[4180] train loss: 0.547661554068327, metric: 11.392013907432556, lr: 0.0009255966870114207
[4200] train loss: 1.4249333441257477, metric: 11.942484378814697, lr: 0.00090818788157776
[4220] train loss: 2.5776012502610683, metric: 17.466492414474487, lr: 0.0008891518809832633
[4240] train loss: 0.2228860817849636, metric: 12.489805936813354, lr: 0.0008685645880177617
[4260] train loss: 0.17389047890901566, metric: 10.707993507385254, lr: 0.0008465081336908042
[4280] train loss: 0.22778593003749847, metric: 9.182970643043518, lr: 0.0008230703533627093
[4300] train loss: 0.5292971767485142, metric: 13.973026037216187, lr: 0.0007983447285369039
[4320] train loss: 0.0760689228773117, metric: 9.081905126571655, lr: 0.0007724298629909754
[4340] train loss: -0.07586726546287537, metric: 11.567296266555786, lr: 0.0007454289589077234
[4360] train loss: -0.2191021367907524, metric: 9.101266860961914, lr: 0.0007174497004598379
[4380] train loss: -0.22325970977544785, metric: 9.003318309783936, lr: 0.00068860367173329
[4400] train loss: -0.1540703848004341, metric: 9.104923725128174, lr: 0.0006590057746507227
[4420] train loss: -0.15458661317825317, metric: 7.582746386528015, lr: 0.0006287740543484688
[4440] train loss: 0.02412058785557747, metric: 10.910811424255371, lr: 0.000598029000684619
[4460] train loss: -0.05129750818014145, metric: 10.889535188674927, lr: 0.0005668931407853961
[4480] train loss: -0.03484198823571205, metric: 9.92195439338684, lr: 0.0005354906315915287
[4500] train loss: -0.023471873253583908, metric: 7.46125066280365, lr: 0.0005039466777816415
[4520] train loss: -0.14938249811530113, metric: 7.219783902168274, lr: 0.0004723869787994772
[4540] train loss: -0.21085350587964058, metric: 6.727856993675232, lr: 0.0004409373505041003
[4560] train loss: -0.21890424937009811, metric: 7.1212886571884155, lr: 0.0004097231721971184
[4580] train loss: -0.11071893572807312, metric: 9.43100905418396, lr: 0.000378868862753734
[4600] train loss: 0.08094765990972519, metric: 11.717971324920654, lr: 0.00034849741496145725
[4620] train loss: 1.4954667575657368, metric: 18.74907112121582, lr: 0.0003187299007549882
[4640] train loss: 0.44831397756934166, metric: 14.780959367752075, lr: 0.0002896849764510989
[4660] train loss: 0.9115723110735416, metric: 10.887059450149536, lr: 0.0002614784170873463
[4680] train loss: 1.1074773110449314, metric: 12.58281922340393, lr: 0.00023422270896844566
[4700] train loss: 1.2263951413333416, metric: 11.092697381973267, lr: 0.00020802643848583102
[4720] train loss: 0.9397150129079819, metric: 13.380501985549927, lr: 0.00018299407383892685
[4740] train loss: 0.8811474815011024, metric: 10.922613859176636, lr: 0.00015922538295853883
[4760] train loss: 1.7416415177285671, metric: 17.246731996536255, lr: 0.00013681512791663408
[4780] train loss: 0.16163814440369606, metric: 13.36531388759613, lr: 0.00011585262109292671
[4800] train loss: 0.26142513006925583, metric: 11.759916305541992, lr: 9.999999747378752e-05
[4820] train loss: 0.07731545343995094, metric: 12.753541946411133, lr: 9.999999747378752e-05
[4840] train loss: 0.42010675743222237, metric: 12.635111331939697, lr: 9.999999747378752e-05
[4860] train loss: 0.486910093575716, metric: 11.118189811706543, lr: 9.999999747378752e-05
[4880] train loss: 2.0782062597572803, metric: 12.67028796672821, lr: 9.999999747378752e-05
[4900] train loss: 0.8354163467884064, metric: 12.900458574295044, lr: 9.999999747378752e-05
[4920] train loss: 1.6819451414048672, metric: 14.683061003684998, lr: 9.999999747378752e-05
[4940] train loss: 1.1004677712917328, metric: 16.21535289287567, lr: 9.999999747378752e-05
[4960] train loss: 0.4332209713757038, metric: 15.317317843437195, lr: 9.999999747378752e-05
[4980] train loss: 0.19413963332772255, metric: 14.358595728874207, lr: 9.999999747378752e-05
[5000] train loss: 0.8389035053551197, metric: 12.849295496940613, lr: 9.999999747378752e-05
[5020] train loss: 0.02778337150812149, metric: 11.464047908782959, lr: 0.0009994393913075328
[5040] train loss: -0.06439083069562912, metric: 8.069671750068665, lr: 0.0009969500824809074
[5060] train loss: -0.17389735206961632, metric: 8.901480436325073, lr: 0.000992479850538075
[5080] train loss: -0.21809463575482368, metric: 9.261159658432007, lr: 0.000986046390607953
[5100] train loss: -0.10691430792212486, metric: 8.27023184299469, lr: 0.0009776754304766655
[5120] train loss: -0.18933314830064774, metric: 9.352699518203735, lr: 0.0009674003813415766
[5140] train loss: 0.34070830792188644, metric: 13.588877201080322, lr: 0.0009552621049806476
[5160] train loss: 0.3396119847893715, metric: 10.884736776351929, lr: 0.0009413089719600976
[5180] train loss: -0.13738606870174408, metric: 12.116009950637817, lr: 0.0009255966870114207
[5200] train loss: 0.6034768000245094, metric: 13.71033239364624, lr: 0.00090818788157776
[5220] train loss: 0.6183594539761543, metric: 13.914588212966919, lr: 0.0008891518809832633
[5240] train loss: 0.3888208493590355, metric: 13.12591552734375, lr: 0.0008685645880177617
[5260] train loss: 0.4492667242884636, metric: 15.448765277862549, lr: 0.0008465081336908042
[5280] train loss: 0.8605677671730518, metric: 15.194136381149292, lr: 0.0008230703533627093
[5300] train loss: 0.8994595259428024, metric: 12.200055599212646, lr: 0.0007983447285369039
[5320] train loss: 0.25041332095861435, metric: 10.619295358657837, lr: 0.0007724298629909754
[5340] train loss: 0.15712251141667366, metric: 14.15190577507019, lr: 0.0007454289589077234
[5360] train loss: 0.11280864849686623, metric: 10.988982439041138, lr: 0.0007174497004598379
[5380] train loss: 0.5474336817860603, metric: 10.850135684013367, lr: 0.00068860367173329
[5400] train loss: -0.11466563120484352, metric: 9.259748816490173, lr: 0.0006590057746507227
[5420] train loss: 0.3581171929836273, metric: 10.749817252159119, lr: 0.0006287740543484688
[5440] train loss: 0.7815430648624897, metric: 12.802765130996704, lr: 0.000598029000684619
[5460] train loss: 0.19557388126850128, metric: 12.977773070335388, lr: 0.0005668931407853961
[5480] train loss: -0.2343009114265442, metric: 9.442507982254028, lr: 0.0005354906315915287
[5500] train loss: -0.13627072423696518, metric: 9.134487390518188, lr: 0.0005039466777816415
[5520] train loss: -0.09125524386763573, metric: 8.0841543674469, lr: 0.0004723869787994772
[5540] train loss: -0.21822568029165268, metric: 8.821704983711243, lr: 0.0004409373505041003
[5560] train loss: -0.2994311451911926, metric: 8.467626571655273, lr: 0.0004097231721971184
[5580] train loss: 0.5318025164306164, metric: 10.420982360839844, lr: 0.000378868862753734
[5600] train loss: -0.21391159296035767, metric: 10.764298915863037, lr: 0.00034849741496145725
[5620] train loss: 0.2310059294104576, metric: 10.191095113754272, lr: 0.0003187299007549882
[5640] train loss: 1.8663580119609833, metric: 20.180599212646484, lr: 0.0002896849764510989
[5660] train loss: 0.6061435863375664, metric: 12.825422048568726, lr: 0.0002614784170873463
[5680] train loss: 0.14791056886315346, metric: 11.74424147605896, lr: 0.00023422270896844566
[5700] train loss: 0.2506479099392891, metric: 12.429284811019897, lr: 0.00020802643848583102
[5720] train loss: 3.269185408949852, metric: 16.520984649658203, lr: 0.00018299407383892685
[5740] train loss: 8.676302701234818, metric: 17.363577127456665, lr: 0.00015922538295853883
[5760] train loss: 0.6591885574162006, metric: 14.479666709899902, lr: 0.00013681512791663408
[5780] train loss: 0.46348095312714577, metric: 12.514777421951294, lr: 0.00011585262109292671
[5800] train loss: 0.23077810928225517, metric: 13.08887267112732, lr: 9.999999747378752e-05
[5820] train loss: 0.5073696747422218, metric: 10.90142035484314, lr: 9.999999747378752e-05
[5840] train loss: 0.29164504259824753, metric: 10.460941791534424, lr: 9.999999747378752e-05
[5860] train loss: 0.6173699572682381, metric: 11.751480102539062, lr: 9.999999747378752e-05
[5880] train loss: 1.7748864591121674, metric: 14.603272914886475, lr: 9.999999747378752e-05
[5900] train loss: 4.824185594916344, metric: 19.076300144195557, lr: 9.999999747378752e-05
[5920] train loss: 1.2933984473347664, metric: 20.07180690765381, lr: 9.999999747378752e-05
[5940] train loss: 6.443392466753721, metric: 22.751673221588135, lr: 9.999999747378752e-05
[5960] train loss: 13.911154814064503, metric: 23.283587217330933, lr: 9.999999747378752e-05
[5980] train loss: 3.6697076745331287, metric: 16.867892742156982, lr: 9.999999747378752e-05
[6000] train loss: 2.7535503953695297, metric: 17.792821168899536, lr: 9.999999747378752e-05
[6020] train loss: 1.6632258407771587, metric: 12.795085668563843, lr: 0.0009994393913075328
[6040] train loss: 0.2370719201862812, metric: 14.988934516906738, lr: 0.0009969500824809074
[6060] train loss: 1.4139032922685146, metric: 15.116369247436523, lr: 0.000992479850538075
[6080] train loss: 0.45145877823233604, metric: 12.856830596923828, lr: 0.000986046390607953
[6100] train loss: 0.2641165442764759, metric: 11.866222620010376, lr: 0.0009776754304766655
[6120] train loss: 0.5527349039912224, metric: 12.65727972984314, lr: 0.0009674003813415766
[6140] train loss: 0.6562709212303162, metric: 10.613488912582397, lr: 0.0009552621049806476
[6160] train loss: 0.9716368578374386, metric: 11.943505764007568, lr: 0.0009413089719600976
[6180] train loss: 1.0439649112522602, metric: 12.293775916099548, lr: 0.0009255966870114207
[6200] train loss: 0.08001932874321938, metric: 10.427114248275757, lr: 0.00090818788157776
[6220] train loss: 0.3772367909550667, metric: 11.172860741615295, lr: 0.0008891518809832633
[6240] train loss: 3.702545717358589, metric: 12.0501708984375, lr: 0.0008685645880177617
[6260] train loss: -0.1822798289358616, metric: 11.767031192779541, lr: 0.0008465081336908042
[6280] train loss: -0.10898323357105255, metric: 10.07856035232544, lr: 0.0008230703533627093
[6300] train loss: -0.10384392738342285, metric: 10.09060549736023, lr: 0.0007983447285369039
[6320] train loss: 0.7433336116373539, metric: 11.15895128250122, lr: 0.0007724298629909754
[6340] train loss: 1.6147835366427898, metric: 11.615511178970337, lr: 0.0007454289589077234
[6360] train loss: 0.5358990728855133, metric: 14.321389198303223, lr: 0.0007174497004598379
[6380] train loss: 0.6143899038434029, metric: 15.043064832687378, lr: 0.00068860367173329
[6400] train loss: 1.4697129093110561, metric: 10.29734992980957, lr: 0.0006590057746507227
[6420] train loss: 0.22354962304234505, metric: 12.137662053108215, lr: 0.0006287740543484688
[6440] train loss: -0.05277475342154503, metric: 12.322076082229614, lr: 0.000598029000684619
[6460] train loss: -0.12241312861442566, metric: 10.825984954833984, lr: 0.0005668931407853961
[6480] train loss: -0.2296813614666462, metric: 9.285012245178223, lr: 0.0005354906315915287
[6500] train loss: -0.06569306552410126, metric: 7.683242082595825, lr: 0.0005039466777816415
[6520] train loss: -0.015331897884607315, metric: 9.187651634216309, lr: 0.0004723869787994772
[6540] train loss: 0.17872455343604088, metric: 10.359125137329102, lr: 0.0004409373505041003
[6560] train loss: -0.004717111587524414, metric: 12.688496589660645, lr: 0.0004097231721971184
[6580] train loss: -0.012712199240922928, metric: 10.108141899108887, lr: 0.000378868862753734
[6600] train loss: 0.04402782395482063, metric: 7.539267897605896, lr: 0.00034849741496145725
[6620] train loss: -0.17219746857881546, metric: 8.603175640106201, lr: 0.0003187299007549882
[6640] train loss: -0.23600225523114204, metric: 10.305487871170044, lr: 0.0002896849764510989
[6660] train loss: 4.403799921274185, metric: 16.439772605895996, lr: 0.0002614784170873463
[6680] train loss: 0.9906253404915333, metric: 13.226426124572754, lr: 0.00023422270896844566
[6700] train loss: 0.4098845049738884, metric: 13.162705421447754, lr: 0.00020802643848583102
[6720] train loss: 2.555833712220192, metric: 13.529664039611816, lr: 0.00018299407383892685
[6740] train loss: 1.05079111084342, metric: 14.71964693069458, lr: 0.00015922538295853883
[6760] train loss: 0.8142550066113472, metric: 15.5773606300354, lr: 0.00013681512791663408
[6780] train loss: 3.707558061927557, metric: 19.568490982055664, lr: 0.00011585262109292671
[6800] train loss: 1.774633102118969, metric: 18.317941665649414, lr: 9.999999747378752e-05
[6820] train loss: 1.5521563366055489, metric: 16.52778911590576, lr: 9.999999747378752e-05
[6840] train loss: 0.7056452855467796, metric: 14.315642833709717, lr: 9.999999747378752e-05
[6860] train loss: 0.05515282601118088, metric: 13.190383434295654, lr: 9.999999747378752e-05
[6880] train loss: 0.4831559509038925, metric: 12.434326410293579, lr: 9.999999747378752e-05
[6900] train loss: 9.327402275055647, metric: 21.30390167236328, lr: 9.999999747378752e-05
[6920] train loss: 6.688990831375122, metric: 16.873422145843506, lr: 9.999999747378752e-05
[6940] train loss: 0.6395292282104492, metric: 13.9393630027771, lr: 9.999999747378752e-05
[6960] train loss: 0.17779189348220825, metric: 10.67324948310852, lr: 9.999999747378752e-05
[6980] train loss: 0.16754961013793945, metric: 12.151382684707642, lr: 9.999999747378752e-05
[7000] train loss: 4.418610345572233, metric: 15.659592390060425, lr: 9.999999747378752e-05
[7020] train loss: 4.646652985364199, metric: 15.31803822517395, lr: 0.0009994393913075328
[7040] train loss: 1.6494941152632236, metric: 19.603185176849365, lr: 0.0009969500824809074
[7060] train loss: 0.16898652166128159, metric: 17.725138664245605, lr: 0.000992479850538075
[7080] train loss: -0.09459024667739868, metric: 10.689195275306702, lr: 0.000986046390607953
[7100] train loss: -0.08513449504971504, metric: 11.35651159286499, lr: 0.0009776754304766655
[7120] train loss: -0.2197195403277874, metric: 10.170588970184326, lr: 0.0009674003813415766
[7140] train loss: -0.26993127912282944, metric: 10.261286973953247, lr: 0.0009552621049806476
[7160] train loss: -0.2571124769747257, metric: 9.70328414440155, lr: 0.0009413089719600976
[7180] train loss: 2.8589970022439957, metric: 20.844159603118896, lr: 0.0009255966870114207
[7200] train loss: 0.6705415099859238, metric: 18.393850803375244, lr: 0.00090818788157776
[7220] train loss: 1.3105976656079292, metric: 15.7572660446167, lr: 0.0008891518809832633
[7240] train loss: 1.4623949192464352, metric: 13.539548397064209, lr: 0.0008685645880177617
[7260] train loss: 3.7085254788398743, metric: 19.287168502807617, lr: 0.0008465081336908042
[7280] train loss: 2.6860137432813644, metric: 33.86676073074341, lr: 0.0008230703533627093
[7300] train loss: 0.7640176936984062, metric: 19.33148431777954, lr: 0.0007983447285369039
[7320] train loss: 1.270182453095913, metric: 22.05576229095459, lr: 0.0007724298629909754
[7340] train loss: 0.569797795265913, metric: 16.179895877838135, lr: 0.0007454289589077234
[7360] train loss: 0.9144490845501423, metric: 14.034062623977661, lr: 0.0007174497004598379
[7380] train loss: 2.2669517397880554, metric: 20.826575756072998, lr: 0.00068860367173329
[7400] train loss: 2.2444318532943726, metric: 15.057477951049805, lr: 0.0006590057746507227
[7420] train loss: 3.0237372517585754, metric: 14.58628511428833, lr: 0.0006287740543484688
[7440] train loss: 5.431246422231197, metric: 22.419166803359985, lr: 0.000598029000684619
[7460] train loss: 2.1891587376594543, metric: 22.100849628448486, lr: 0.0005668931407853961
[7480] train loss: 1.2926561534404755, metric: 13.615180730819702, lr: 0.0005354906315915287
[7500] train loss: 0.8557717278599739, metric: 18.825318336486816, lr: 0.0005039466777816415
[7520] train loss: 1.1283650826662779, metric: 18.788730144500732, lr: 0.0004723869787994772
[7540] train loss: 1.3546867817640305, metric: 17.648756980895996, lr: 0.0004409373505041003
[7560] train loss: 2.2796008735895157, metric: 19.530630826950073, lr: 0.0004097231721971184
[7580] train loss: 2.4681044034659863, metric: 14.904078960418701, lr: 0.000378868862753734
[7600] train loss: 3.6051058396697044, metric: 20.912814140319824, lr: 0.00034849741496145725
[7620] train loss: 2.937320314347744, metric: 14.223920822143555, lr: 0.0003187299007549882
[7640] train loss: 3.5520148128271103, metric: 16.024165153503418, lr: 0.0002896849764510989
[7660] train loss: 3.6772923581302166, metric: 23.030025005340576, lr: 0.0002614784170873463
[7680] train loss: 4.793958283960819, metric: 22.825772285461426, lr: 0.00023422270896844566
[7700] train loss: 0.9113392233848572, metric: 33.13481903076172, lr: 0.00020802643848583102
[7720] train loss: 0.15202250704169273, metric: 22.186747312545776, lr: 0.00018299407383892685
[7740] train loss: -0.014426562935113907, metric: 20.36825704574585, lr: 0.00015922538295853883
[7760] train loss: -0.02616419643163681, metric: 18.977364778518677, lr: 0.00013681512791663408
[7780] train loss: -0.05152710899710655, metric: 18.039264678955078, lr: 0.00011585262109292671
[7800] train loss: -0.031702399253845215, metric: 19.3884117603302, lr: 9.999999747378752e-05
[7820] train loss: 0.029067110270261765, metric: 19.1480450630188, lr: 9.999999747378752e-05
[7840] train loss: 0.024912554770708084, metric: 17.956193447113037, lr: 9.999999747378752e-05
[7860] train loss: -0.0516078881919384, metric: 15.579576969146729, lr: 9.999999747378752e-05
[7880] train loss: -0.0784471444785595, metric: 13.781522750854492, lr: 9.999999747378752e-05
[7900] train loss: -0.14643482863903046, metric: 13.021966695785522, lr: 9.999999747378752e-05
[7920] train loss: -0.13677611574530602, metric: 12.843869686126709, lr: 9.999999747378752e-05
[7940] train loss: -0.182900819927454, metric: 12.67265796661377, lr: 9.999999747378752e-05
[7960] train loss: -0.15998201072216034, metric: 12.380297183990479, lr: 9.999999747378752e-05
[7980] train loss: -0.12370367720723152, metric: 11.7034330368042, lr: 9.999999747378752e-05
[8000] train loss: 0.5052529573440552, metric: 13.376778364181519, lr: 9.999999747378752e-05
[8020] train loss: -0.0604802668094635, metric: 13.090202331542969, lr: 0.0009994393913075328
[8040] train loss: -0.18290487304329872, metric: 11.479661703109741, lr: 0.0009969500824809074
[8060] train loss: -0.26011090725660324, metric: 9.055062651634216, lr: 0.000992479850538075
[8080] train loss: -0.1691480241715908, metric: 9.06762170791626, lr: 0.000986046390607953
[8100] train loss: -0.02319178357720375, metric: 10.286123037338257, lr: 0.0009776754304766655
[8120] train loss: -0.22832896560430527, metric: 8.808483362197876, lr: 0.0009674003813415766
[8140] train loss: -0.02946871519088745, metric: 10.237141251564026, lr: 0.0009552621049806476
[8160] train loss: -0.21374177187681198, metric: 10.21229863166809, lr: 0.0009413089719600976
[8180] train loss: -0.25168832391500473, metric: 10.826384425163269, lr: 0.0009255966870114207
[8200] train loss: 6.580684170126915, metric: 31.58121156692505, lr: 0.00090818788157776
[8220] train loss: 2.531071439385414, metric: 27.471253395080566, lr: 0.0008891518809832633
[8240] train loss: 0.7571994662284851, metric: 17.747588396072388, lr: 0.0008685645880177617
[8260] train loss: 3.7451891377568245, metric: 18.782188415527344, lr: 0.0008465081336908042
[8280] train loss: 0.8779581859707832, metric: 25.554331064224243, lr: 0.0008230703533627093
[8300] train loss: 0.21721453964710236, metric: 15.382995128631592, lr: 0.0007983447285369039
[8320] train loss: 8.667968060821295, metric: 18.504920959472656, lr: 0.0007724298629909754
[8340] train loss: 0.825392596423626, metric: 12.35293972492218, lr: 0.0007454289589077234
[8360] train loss: 2.1317619383335114, metric: 14.081842422485352, lr: 0.0007174497004598379
[8380] train loss: 1.1324849724769592, metric: 15.50980031490326, lr: 0.00068860367173329
[8400] train loss: 6.339985176920891, metric: 22.095897674560547, lr: 0.0006590057746507227
[8420] train loss: 3.5839737318456173, metric: 22.553401470184326, lr: 0.0006287740543484688
[8440] train loss: 8.196065794676542, metric: 26.391383171081543, lr: 0.000598029000684619
[8460] train loss: 5.674966715276241, metric: 27.651344299316406, lr: 0.0005668931407853961
[8480] train loss: 1.4710546806454659, metric: 15.516178369522095, lr: 0.0005354906315915287
[8500] train loss: 0.31943347677588463, metric: 13.871112942695618, lr: 0.0005039466777816415
[8520] train loss: 0.4523112364113331, metric: 11.38446044921875, lr: 0.0004723869787994772
[8540] train loss: 0.02304621785879135, metric: 13.450494050979614, lr: 0.0004409373505041003
[8560] train loss: 0.20932523906230927, metric: 15.336270332336426, lr: 0.0004097231721971184
[8580] train loss: -0.07898387312889099, metric: 16.186184644699097, lr: 0.000378868862753734
[8600] train loss: 0.30058084055781364, metric: 17.154213905334473, lr: 0.00034849741496145725
[8620] train loss: 0.3817950077354908, metric: 15.034206628799438, lr: 0.0003187299007549882
[8640] train loss: 0.8663563504815102, metric: 17.433717489242554, lr: 0.0002896849764510989
[8660] train loss: 0.5878889672458172, metric: 17.19616413116455, lr: 0.0002614784170873463
[8680] train loss: 1.4202620349824429, metric: 11.552665710449219, lr: 0.00023422270896844566
[8700] train loss: 1.2187528610229492, metric: 15.154009819030762, lr: 0.00020802643848583102
[8720] train loss: 0.3343448005616665, metric: 21.504942178726196, lr: 0.00018299407383892685
[8740] train loss: -0.041834499686956406, metric: 16.994709968566895, lr: 0.00015922538295853883
[8760] train loss: -0.14865326508879662, metric: 14.794362545013428, lr: 0.00013681512791663408
[8780] train loss: -0.1783217005431652, metric: 14.5051589012146, lr: 0.00011585262109292671
[8800] train loss: -0.21290350332856178, metric: 14.278650999069214, lr: 9.999999747378752e-05
[8820] train loss: -0.12436274066567421, metric: 13.861944437026978, lr: 9.999999747378752e-05
[8840] train loss: -0.1911735013127327, metric: 15.09104871749878, lr: 9.999999747378752e-05
[8860] train loss: -0.20109036937355995, metric: 12.860136985778809, lr: 9.999999747378752e-05
[8880] train loss: -0.20268654078245163, metric: 12.926293849945068, lr: 9.999999747378752e-05
[8900] train loss: -0.1333315707743168, metric: 13.799922466278076, lr: 9.999999747378752e-05
[8920] train loss: -0.12628955766558647, metric: 13.250646114349365, lr: 9.999999747378752e-05
[8940] train loss: -0.15588955208659172, metric: 13.135884046554565, lr: 9.999999747378752e-05
[8960] train loss: -0.19891882687807083, metric: 11.63249659538269, lr: 9.999999747378752e-05
[8980] train loss: -0.1965520679950714, metric: 10.962554454803467, lr: 9.999999747378752e-05
[9000] train loss: -0.10407374426722527, metric: 11.935006856918335, lr: 9.999999747378752e-05
[9020] train loss: -0.23878458887338638, metric: 10.250807523727417, lr: 0.0009994393913075328
[9040] train loss: -0.1822081059217453, metric: 10.032495021820068, lr: 0.0009969500824809074
[9060] train loss: -0.14460326731204987, metric: 8.2679682970047, lr: 0.000992479850538075
[9080] train loss: -0.12150278687477112, metric: 8.991801023483276, lr: 0.000986046390607953
[9100] train loss: 0.1834680624306202, metric: 11.48650348186493, lr: 0.0009776754304766655
[9120] train loss: 0.03913382068276405, metric: 9.104929447174072, lr: 0.0009674003813415766
[9140] train loss: -0.24587692692875862, metric: 8.54540765285492, lr: 0.0009552621049806476
[20] train loss: -0.1803254373371601, metric: 11.334716320037842, lr: 0.0009994393913075328
[40] train loss: -0.22933028265833855, metric: 10.991318941116333, lr: 0.0009969500824809074
[60] train loss: -0.20913376286625862, metric: 10.311736702919006, lr: 0.000992479850538075
[80] train loss: -0.2608850821852684, metric: 8.654029369354248, lr: 0.000986046390607953
[100] train loss: -0.11119416356086731, metric: 10.472172021865845, lr: 0.0009776754304766655
[120] train loss: -0.20525938272476196, metric: 10.248293399810791, lr: 0.0009674003813415766
[140] train loss: 0.11059147492051125, metric: 10.315390229225159, lr: 0.0009552621049806476
[160] train loss: 0.5919414460659027, metric: 11.530212163925171, lr: 0.0009413089719600976
[180] train loss: 0.6067211627960205, metric: 12.906615138053894, lr: 0.0009255966870114207
[200] train loss: -0.2603060342371464, metric: 10.774399518966675, lr: 0.00090818788157776
[220] train loss: -0.3031214512884617, metric: 9.647598505020142, lr: 0.0008891518809832633
[240] train loss: -0.18562455475330353, metric: 8.16312038898468, lr: 0.0008685645880177617
[260] train loss: 0.22674165666103363, metric: 10.928833484649658, lr: 0.0008465081336908042
[280] train loss: 0.039226457476615906, metric: 11.332834601402283, lr: 0.0008230703533627093
[300] train loss: 0.7236618548631668, metric: 9.379090070724487, lr: 0.0007983447285369039
[320] train loss: -0.22198352217674255, metric: 10.11275327205658, lr: 0.0007724298629909754
[340] train loss: 0.24514934420585632, metric: 10.9356107711792, lr: 0.0007454289589077234
[360] train loss: 1.1453484781086445, metric: 9.330244541168213, lr: 0.0007174497004598379
[380] train loss: 0.23411471396684647, metric: 10.481922626495361, lr: 0.00068860367173329
[400] train loss: 1.4245784357190132, metric: 9.31500232219696, lr: 0.0006590057746507227
[420] train loss: 1.0958768539130688, metric: 11.734194159507751, lr: 0.0006287740543484688
[440] train loss: 0.2500878870487213, metric: 10.770098447799683, lr: 0.000598029000684619
[460] train loss: 3.535513535141945, metric: 13.414050817489624, lr: 0.0005668931407853961
[480] train loss: 0.014745205640792847, metric: 10.282605648040771, lr: 0.0005354906315915287
[500] train loss: 1.1044342145323753, metric: 16.288032293319702, lr: 0.0005039466777816415
[520] train loss: 8.175382897257805, metric: 24.792728900909424, lr: 0.0004723869787994772
[540] train loss: 0.7181213945150375, metric: 18.235748052597046, lr: 0.0004409373505041003
[560] train loss: 0.03966941311955452, metric: 13.428691864013672, lr: 0.0004097231721971184
[580] train loss: -0.13187791034579277, metric: 10.243552207946777, lr: 0.000378868862753734
[600] train loss: -0.1273578591644764, metric: 10.969331741333008, lr: 0.00034849741496145725
[620] train loss: -0.1871383972465992, metric: 10.398133277893066, lr: 0.0003187299007549882
[640] train loss: -0.25666726380586624, metric: 11.15514588356018, lr: 0.0002896849764510989
[660] train loss: -0.21754240989685059, metric: 7.24246346950531, lr: 0.0002614784170873463
[680] train loss: -0.217018261551857, metric: 7.580422043800354, lr: 0.00023422270896844566
[700] train loss: -0.007250551134347916, metric: 10.251296997070312, lr: 0.00020802643848583102
[720] train loss: -0.23244689032435417, metric: 9.237955451011658, lr: 0.00018299407383892685
[740] train loss: -0.17555375397205353, metric: 9.28402841091156, lr: 0.00015922538295853883
[760] train loss: -0.10296724736690521, metric: 11.724582195281982, lr: 0.00013681512791663408
[780] train loss: 1.4773012287914753, metric: 11.496915817260742, lr: 0.00011585262109292671
[800] train loss: 0.18743834272027016, metric: 13.861982822418213, lr: 9.999999747378752e-05
[820] train loss: -0.02863236889243126, metric: 14.30071771144867, lr: 9.999999747378752e-05
[840] train loss: -0.10180143639445305, metric: 11.538737297058105, lr: 9.999999747378752e-05
[860] train loss: -0.12346874549984932, metric: 10.752290964126587, lr: 9.999999747378752e-05
[880] train loss: 0.0034287460148334503, metric: 9.664927005767822, lr: 9.999999747378752e-05
[900] train loss: 2.2094411700963974, metric: 14.417555570602417, lr: 9.999999747378752e-05
[920] train loss: 2.8956251181662083, metric: 15.193110704421997, lr: 9.999999747378752e-05
[940] train loss: 0.9846132211387157, metric: 11.941542148590088, lr: 9.999999747378752e-05
[960] train loss: -0.1767439991235733, metric: 10.157049655914307, lr: 9.999999747378752e-05
[980] train loss: -0.17904159054160118, metric: 9.445898532867432, lr: 9.999999747378752e-05
[1000] train loss: -0.11301726847887039, metric: 10.556026220321655, lr: 9.999999747378752e-05
[1020] train loss: -0.19098840281367302, metric: 8.136304020881653, lr: 0.0009994393913075328
[1040] train loss: 0.11960875242948532, metric: 9.940898418426514, lr: 0.0009969500824809074
[1060] train loss: -0.13459299877285957, metric: 8.959847688674927, lr: 0.000992479850538075
[1080] train loss: -0.17417805269360542, metric: 10.453431844711304, lr: 0.000986046390607953
[1100] train loss: 0.1370684653520584, metric: 10.858943223953247, lr: 0.0009776754304766655
[1120] train loss: 0.17696620896458626, metric: 11.030582904815674, lr: 0.0009674003813415766
[1140] train loss: -0.041738640516996384, metric: 9.799331426620483, lr: 0.0009552621049806476
[1160] train loss: -0.09549470990896225, metric: 10.179035663604736, lr: 0.0009413089719600976
[1180] train loss: 0.0635695718228817, metric: 10.092259407043457, lr: 0.0009255966870114207
[1200] train loss: -0.22151002660393715, metric: 9.765215158462524, lr: 0.00090818788157776
[1220] train loss: 0.3275870829820633, metric: 9.125707626342773, lr: 0.0008891518809832633
[1240] train loss: 0.158019308000803, metric: 9.293678998947144, lr: 0.0008685645880177617
[1260] train loss: 0.04841890558600426, metric: 9.234726309776306, lr: 0.0008465081336908042
[1280] train loss: -0.03438888117671013, metric: 8.905694365501404, lr: 0.0008230703533627093
[1300] train loss: 0.09574013575911522, metric: 9.982145309448242, lr: 0.0007983447285369039
[1320] train loss: 0.4851299449801445, metric: 14.71333122253418, lr: 0.0007724298629909754
[1340] train loss: 0.13350503146648407, metric: 9.929140090942383, lr: 0.0007454289589077234
[1360] train loss: 0.2360420562326908, metric: 13.512763023376465, lr: 0.0007174497004598379
[1380] train loss: 0.06711692363023758, metric: 10.883265972137451, lr: 0.00068860367173329
[1400] train loss: -0.0834617018699646, metric: 10.982818365097046, lr: 0.0006590057746507227
[1420] train loss: -0.2613120377063751, metric: 9.55783462524414, lr: 0.0006287740543484688
[1440] train loss: -0.20409779623150826, metric: 8.706746697425842, lr: 0.000598029000684619
[1460] train loss: -0.2843567579984665, metric: 8.112933158874512, lr: 0.0005668931407853961
[1480] train loss: -0.2450014129281044, metric: 9.885308980941772, lr: 0.0005354906315915287
[1500] train loss: -0.34853291884064674, metric: 7.772290468215942, lr: 0.0005039466777816415
[1520] train loss: -0.3432129994034767, metric: 8.41100025177002, lr: 0.0004723869787994772
[1540] train loss: 0.5913306921720505, metric: 16.989709615707397, lr: 0.0004409373505041003
[1560] train loss: -0.18659443780779839, metric: 11.687575578689575, lr: 0.0004097231721971184
[1580] train loss: -0.264564823359251, metric: 10.822665452957153, lr: 0.000378868862753734
[1600] train loss: -0.18790841102600098, metric: 7.58177375793457, lr: 0.00034849741496145725
[1620] train loss: -0.3045695722103119, metric: 7.938680291175842, lr: 0.0003187299007549882
[1640] train loss: -0.17661792039871216, metric: 8.559922814369202, lr: 0.0002896849764510989
[1660] train loss: 0.02146320790052414, metric: 9.746184587478638, lr: 0.0002614784170873463
[1680] train loss: -0.17849934473633766, metric: 9.159489750862122, lr: 0.00023422270896844566
[1700] train loss: -0.17818447574973106, metric: 7.540678858757019, lr: 0.00020802643848583102
[1720] train loss: -0.1276707723736763, metric: 8.613011837005615, lr: 0.00018299407383892685
[1740] train loss: -0.14912691712379456, metric: 9.954485177993774, lr: 0.00015922538295853883
[1760] train loss: -0.21111099421977997, metric: 8.85600197315216, lr: 0.00013681512791663408
[1780] train loss: 0.23192862421274185, metric: 9.921728134155273, lr: 0.00011585262109292671
[1800] train loss: 0.19580990448594093, metric: 11.018805384635925, lr: 9.999999747378752e-05
[1820] train loss: 0.0011487528681755066, metric: 12.388657450675964, lr: 9.999999747378752e-05
[1840] train loss: -0.006177552044391632, metric: 10.46791684627533, lr: 9.999999747378752e-05
[1860] train loss: 0.0033550038933753967, metric: 10.07669973373413, lr: 9.999999747378752e-05
[1880] train loss: -0.053897347301244736, metric: 9.533721208572388, lr: 9.999999747378752e-05
[1900] train loss: -0.10461251810193062, metric: 10.005103826522827, lr: 9.999999747378752e-05
[1920] train loss: 0.4933982379734516, metric: 13.726149082183838, lr: 9.999999747378752e-05
[1940] train loss: 0.3119824603199959, metric: 14.335588574409485, lr: 9.999999747378752e-05
[1960] train loss: 0.39303217828273773, metric: 11.56146764755249, lr: 9.999999747378752e-05
[1980] train loss: 9.483471512794495e-05, metric: 11.679774284362793, lr: 9.999999747378752e-05
[2000] train loss: -0.12123124673962593, metric: 10.686385154724121, lr: 9.999999747378752e-05
[2020] train loss: 1.1499826423823833, metric: 11.504931330680847, lr: 0.0009994393913075328
[2040] train loss: -0.06753754243254662, metric: 9.637311220169067, lr: 0.0009969500824809074
[2060] train loss: -0.13399359583854675, metric: 9.502715110778809, lr: 0.000992479850538075
[2080] train loss: -0.24998274818062782, metric: 7.324469685554504, lr: 0.000986046390607953
[2100] train loss: -0.29856470972299576, metric: 7.326603651046753, lr: 0.0009776754304766655
[2120] train loss: -0.2590056098997593, metric: 6.526984453201294, lr: 0.0009674003813415766
[2140] train loss: -0.23881836608052254, metric: 7.854266166687012, lr: 0.0009552621049806476
[2160] train loss: -0.07279069721698761, metric: 6.7874367237091064, lr: 0.0009413089719600976
[2180] train loss: -0.09537344053387642, metric: 8.585518479347229, lr: 0.0009255966870114207
[2200] train loss: 0.5119642913341522, metric: 15.64010500907898, lr: 0.00090818788157776
[2220] train loss: 0.43800754472613335, metric: 9.409746766090393, lr: 0.0008891518809832633
[2240] train loss: 0.4799518622457981, metric: 9.210725545883179, lr: 0.0008685645880177617
[2260] train loss: 0.7585964053869247, metric: 9.861485123634338, lr: 0.0008465081336908042
[2280] train loss: -0.09476335719227791, metric: 10.738853216171265, lr: 0.0008230703533627093
[2300] train loss: -0.23170232400298119, metric: 8.839015364646912, lr: 0.0007983447285369039
[2320] train loss: -0.12925297394394875, metric: 8.962813377380371, lr: 0.0007724298629909754
[2340] train loss: -0.23249242454767227, metric: 8.850323915481567, lr: 0.0007454289589077234
[2360] train loss: 3.1038464307785034, metric: 12.122377514839172, lr: 0.0007174497004598379
[2380] train loss: 0.6644329056143761, metric: 13.635846376419067, lr: 0.00068860367173329
[2400] train loss: -0.19272678345441818, metric: 11.940887451171875, lr: 0.0006590057746507227
[2420] train loss: -0.06648942083120346, metric: 9.990213513374329, lr: 0.0006287740543484688
[2440] train loss: 0.22245540097355843, metric: 9.416936874389648, lr: 0.000598029000684619
[2460] train loss: 0.6353646218776703, metric: 10.602735161781311, lr: 0.0005668931407853961
[2480] train loss: 0.8256387412548065, metric: 11.986713171005249, lr: 0.0005354906315915287
[2500] train loss: 0.021836217492818832, metric: 11.062533259391785, lr: 0.0005039466777816415
[2520] train loss: 2.3143845684826374, metric: 12.274671196937561, lr: 0.0004723869787994772
[2540] train loss: 3.365028467029333, metric: 16.332412719726562, lr: 0.0004409373505041003
[2560] train loss: 5.798093494027853, metric: 18.545877695083618, lr: 0.0004097231721971184
[2580] train loss: 0.7675883136689663, metric: 13.257291555404663, lr: 0.000378868862753734
[2600] train loss: 1.6324257925152779, metric: 14.773895740509033, lr: 0.00034849741496145725
[2620] train loss: 2.63206123188138, metric: 16.35528874397278, lr: 0.0003187299007549882
[2640] train loss: 0.528154157102108, metric: 15.055944919586182, lr: 0.0002896849764510989
[2660] train loss: 1.7615459002554417, metric: 15.121318817138672, lr: 0.0002614784170873463
[2680] train loss: -0.0034337081015110016, metric: 14.129016876220703, lr: 0.00023422270896844566
[2700] train loss: 0.21910835802555084, metric: 20.370975255966187, lr: 0.00020802643848583102
[2720] train loss: -0.2456628680229187, metric: 9.88320541381836, lr: 0.00018299407383892685
[2740] train loss: -0.24972830712795258, metric: 10.885689735412598, lr: 0.00015922538295853883
[2760] train loss: -0.30146222934126854, metric: 11.15549349784851, lr: 0.00013681512791663408
[2780] train loss: -0.2034907378256321, metric: 11.893953084945679, lr: 0.00011585262109292671
[2800] train loss: -0.17693901807069778, metric: 11.522862434387207, lr: 9.999999747378752e-05
[2820] train loss: -0.109433114528656, metric: 12.590124130249023, lr: 9.999999747378752e-05
[2840] train loss: -0.14394451305270195, metric: 11.20470142364502, lr: 9.999999747378752e-05
[2860] train loss: -0.01446545124053955, metric: 11.457210063934326, lr: 9.999999747378752e-05
[2880] train loss: -0.06815792620182037, metric: 11.33965516090393, lr: 9.999999747378752e-05
[2900] train loss: -0.17968033626675606, metric: 9.922004342079163, lr: 9.999999747378752e-05
[2920] train loss: -0.11464524641633034, metric: 11.149132251739502, lr: 9.999999747378752e-05
[2940] train loss: 0.02190733700990677, metric: 14.04018759727478, lr: 9.999999747378752e-05
[2960] train loss: -0.07971597835421562, metric: 11.884417533874512, lr: 9.999999747378752e-05
[2980] train loss: 0.004775736480951309, metric: 11.958364963531494, lr: 9.999999747378752e-05
[3000] train loss: -0.044068679213523865, metric: 14.228340864181519, lr: 9.999999747378752e-05
[3020] train loss: -0.22192499414086342, metric: 8.050482749938965, lr: 0.0009994393913075328
[3040] train loss: -0.24224943295121193, metric: 10.46952748298645, lr: 0.0009969500824809074
[3060] train loss: -0.29683585464954376, metric: 7.478455066680908, lr: 0.000992479850538075
[3080] train loss: -0.07390386238694191, metric: 12.562397956848145, lr: 0.000986046390607953
[3100] train loss: -0.15636756271123886, metric: 9.03494906425476, lr: 0.0009776754304766655
[3120] train loss: -0.22972378507256508, metric: 8.321372270584106, lr: 0.0009674003813415766
[3140] train loss: -0.1779479756951332, metric: 8.845142841339111, lr: 0.0009552621049806476
[3160] train loss: -0.049713585525751114, metric: 8.906890392303467, lr: 0.0009413089719600976
[3180] train loss: -0.22129418328404427, metric: 7.877771258354187, lr: 0.0009255966870114207
[3200] train loss: -0.1882525533437729, metric: 8.592920660972595, lr: 0.00090818788157776
[3220] train loss: -0.2524542398750782, metric: 8.875543355941772, lr: 0.0008891518809832633
[3240] train loss: -0.22651147842407227, metric: 8.875595569610596, lr: 0.0008685645880177617
[3260] train loss: -0.04320485517382622, metric: 9.454431056976318, lr: 0.0008465081336908042
[3280] train loss: -0.01982763037085533, metric: 8.542155385017395, lr: 0.0008230703533627093
[3300] train loss: -0.18039937689900398, metric: 8.64147174358368, lr: 0.0007983447285369039
[3320] train loss: -0.15902522206306458, metric: 8.395447492599487, lr: 0.0007724298629909754
[3340] train loss: 0.12998438999056816, metric: 8.734819531440735, lr: 0.0007454289589077234
[3360] train loss: 1.5088255740702152, metric: 11.470960140228271, lr: 0.0007174497004598379
[3380] train loss: 0.4301007054746151, metric: 11.353395462036133, lr: 0.00068860367173329
[3400] train loss: 1.623243223875761, metric: 19.128299713134766, lr: 0.0006590057746507227
[3420] train loss: 1.2525926642119884, metric: 19.155546188354492, lr: 0.0006287740543484688
[3440] train loss: 2.4627017080783844, metric: 19.592721939086914, lr: 0.000598029000684619
[3460] train loss: 1.4544773437082767, metric: 14.286521673202515, lr: 0.0005668931407853961
[3480] train loss: 0.6055502258241177, metric: 13.930416226387024, lr: 0.0005354906315915287
[3500] train loss: -0.09067205712199211, metric: 15.586660385131836, lr: 0.0005039466777816415
[3520] train loss: -0.21855318546295166, metric: 9.730361342430115, lr: 0.0004723869787994772
[3540] train loss: -0.0007351972162723541, metric: 10.927208662033081, lr: 0.0004409373505041003
[3560] train loss: -0.22594469785690308, metric: 8.87356185913086, lr: 0.0004097231721971184
[3580] train loss: -0.30437082797288895, metric: 7.594095230102539, lr: 0.000378868862753734
[3600] train loss: 4.486018121242523, metric: 27.89573097229004, lr: 0.00034849741496145725
[3620] train loss: 16.93087137490511, metric: 30.03331470489502, lr: 0.0003187299007549882
[3640] train loss: 5.350970014929771, metric: 21.67627239227295, lr: 0.0002896849764510989
[3660] train loss: 6.458031252026558, metric: 20.854384422302246, lr: 0.0002614784170873463
[3680] train loss: 4.159456729888916, metric: 17.692689657211304, lr: 0.00023422270896844566
[3700] train loss: 4.349802579730749, metric: 17.46584129333496, lr: 0.00020802643848583102
[3720] train loss: 2.162556476891041, metric: 17.907416343688965, lr: 0.00018299407383892685
[3740] train loss: 3.4075236469507217, metric: 19.842979669570923, lr: 0.00015922538295853883
[3760] train loss: 2.7891385331749916, metric: 22.138180255889893, lr: 0.00013681512791663408
[3780] train loss: 4.573488004505634, metric: 19.582561016082764, lr: 0.00011585262109292671
[3800] train loss: 10.787732429802418, metric: 19.996814966201782, lr: 9.999999747378752e-05
[3820] train loss: 6.872953176498413, metric: 20.208569288253784, lr: 9.999999747378752e-05
[3840] train loss: 3.941960707306862, metric: 19.811771869659424, lr: 9.999999747378752e-05
[3860] train loss: 4.274058327078819, metric: 20.986737728118896, lr: 9.999999747378752e-05
[3880] train loss: 6.747211329638958, metric: 22.96470046043396, lr: 9.999999747378752e-05
[3900] train loss: 6.670563623309135, metric: 20.675850868225098, lr: 9.999999747378752e-05
[3920] train loss: 4.455665796995163, metric: 21.820651054382324, lr: 9.999999747378752e-05
[3940] train loss: 2.310959041118622, metric: 20.30426025390625, lr: 9.999999747378752e-05
[3960] train loss: 6.966778710484505, metric: 24.49235963821411, lr: 9.999999747378752e-05
[3980] train loss: 5.473090931773186, metric: 22.999755144119263, lr: 9.999999747378752e-05
[4000] train loss: 10.075241893529892, metric: 28.380095720291138, lr: 9.999999747378752e-05
[4020] train loss: 3.4438101649284363, metric: 24.98132848739624, lr: 0.0009994393913075328
[4040] train loss: 3.9983693808317184, metric: 20.71683692932129, lr: 0.0009969500824809074
[4060] train loss: 2.5444074124097824, metric: 22.589919805526733, lr: 0.000992479850538075
[4080] train loss: 1.3044682927429676, metric: 18.35991907119751, lr: 0.000986046390607953
[4100] train loss: 6.085322916507721, metric: 26.529378414154053, lr: 0.0009776754304766655
[4120] train loss: 0.7985529750585556, metric: 15.459875345230103, lr: 0.0009674003813415766
[4140] train loss: 1.0750840455293655, metric: 13.881073951721191, lr: 0.0009552621049806476
[4160] train loss: 0.8993057049810886, metric: 14.064758777618408, lr: 0.0009413089719600976
[4180] train loss: 0.6045813038945198, metric: 16.960907220840454, lr: 0.0009255966870114207
[4200] train loss: 1.1480164900422096, metric: 16.066627264022827, lr: 0.00090818788157776
[4220] train loss: 0.9938518442213535, metric: 11.988177061080933, lr: 0.0008891518809832633
[4240] train loss: 0.07777713984251022, metric: 10.012863397598267, lr: 0.0008685645880177617
[4260] train loss: -0.09241478517651558, metric: 10.642672538757324, lr: 0.0008465081336908042
[4280] train loss: 0.43381819128990173, metric: 11.806734085083008, lr: 0.0008230703533627093
[4300] train loss: 0.04860151931643486, metric: 10.713714480400085, lr: 0.0007983447285369039
[4320] train loss: 0.07961519993841648, metric: 12.38371729850769, lr: 0.0007724298629909754
[4340] train loss: 0.2052011862397194, metric: 14.316261172294617, lr: 0.0007454289589077234
[4360] train loss: -0.09090274199843407, metric: 12.44370698928833, lr: 0.0007174497004598379
[4380] train loss: -0.033960677683353424, metric: 11.714594841003418, lr: 0.00068860367173329
[4400] train loss: 1.5373613312840462, metric: 16.550259113311768, lr: 0.0006590057746507227
[4420] train loss: 4.570062939077616, metric: 17.046234369277954, lr: 0.0006287740543484688
[4440] train loss: 1.732950747013092, metric: 12.690632820129395, lr: 0.000598029000684619
[4460] train loss: 0.7396402694284916, metric: 14.925230503082275, lr: 0.0005668931407853961
[4480] train loss: 0.23840729892253876, metric: 11.672757625579834, lr: 0.0005354906315915287
[4500] train loss: 0.19515520706772804, metric: 14.172268390655518, lr: 0.0005039466777816415
[4520] train loss: 0.057741597294807434, metric: 12.172272205352783, lr: 0.0004723869787994772
[4540] train loss: -0.0033287741243839264, metric: 12.173019647598267, lr: 0.0004409373505041003
[4560] train loss: 0.6253413632512093, metric: 14.452137231826782, lr: 0.0004097231721971184
[4580] train loss: 0.024662930518388748, metric: 9.714224815368652, lr: 0.000378868862753734
[4600] train loss: -0.12249570712447166, metric: 12.21628189086914, lr: 0.00034849741496145725
[4620] train loss: 1.6183481365442276, metric: 14.999690771102905, lr: 0.0003187299007549882
[4640] train loss: 1.4030257426202297, metric: 14.9682936668396, lr: 0.0002896849764510989
[4660] train loss: 0.8965129442512989, metric: 14.538283348083496, lr: 0.0002614784170873463
[4680] train loss: 1.123863372951746, metric: 12.879613876342773, lr: 0.00023422270896844566
[4700] train loss: 0.9330088160932064, metric: 14.933127641677856, lr: 0.00020802643848583102
[4720] train loss: 0.44845985993742943, metric: 10.83934760093689, lr: 0.00018299407383892685
[4740] train loss: 0.26233474537730217, metric: 13.71580195426941, lr: 0.00015922538295853883
[4760] train loss: -0.04757167771458626, metric: 11.862603902816772, lr: 0.00013681512791663408
[4780] train loss: 0.01844816282391548, metric: 11.39581847190857, lr: 0.00011585262109292671
[4800] train loss: 0.29852623865008354, metric: 11.418830156326294, lr: 9.999999747378752e-05
[4820] train loss: 0.19684328138828278, metric: 13.4764564037323, lr: 9.999999747378752e-05
[4840] train loss: -0.0037741586565971375, metric: 14.26762342453003, lr: 9.999999747378752e-05
[4860] train loss: 0.1083170473575592, metric: 15.202000617980957, lr: 9.999999747378752e-05
[4880] train loss: 0.1920991726219654, metric: 13.843430995941162, lr: 9.999999747378752e-05
[4900] train loss: 0.14095963910222054, metric: 13.011838436126709, lr: 9.999999747378752e-05
[4920] train loss: 0.7144439853727818, metric: 12.846004962921143, lr: 9.999999747378752e-05
[4940] train loss: 0.34956197440624237, metric: 12.197453022003174, lr: 9.999999747378752e-05
[4960] train loss: 0.3877797909080982, metric: 11.52222490310669, lr: 9.999999747378752e-05
[4980] train loss: 0.19026493281126022, metric: 11.175333499908447, lr: 9.999999747378752e-05
[5000] train loss: 0.39761700853705406, metric: 10.72738265991211, lr: 9.999999747378752e-05
[5020] train loss: -0.07131623476743698, metric: 10.493420362472534, lr: 0.0009994393913075328
[5040] train loss: -0.020185507833957672, metric: 10.669058799743652, lr: 0.0009969500824809074
[5060] train loss: -0.22472627088427544, metric: 10.171497106552124, lr: 0.000992479850538075
[5080] train loss: -0.13899825885891914, metric: 10.50275182723999, lr: 0.000986046390607953
[5100] train loss: 0.08330477774143219, metric: 12.03564715385437, lr: 0.0009776754304766655
[5120] train loss: -0.08108828216791153, metric: 10.734310150146484, lr: 0.0009674003813415766
[5140] train loss: 0.47250518947839737, metric: 11.036034107208252, lr: 0.0009552621049806476
[5160] train loss: 0.25128743797540665, metric: 12.151129007339478, lr: 0.0009413089719600976
[5180] train loss: 0.013351690024137497, metric: 11.47225546836853, lr: 0.0009255966870114207
[5200] train loss: -0.01676584780216217, metric: 12.335538864135742, lr: 0.00090818788157776
[5220] train loss: -0.05502863973379135, metric: 10.67746090888977, lr: 0.0008891518809832633
[5240] train loss: 0.09082425758242607, metric: 13.035779476165771, lr: 0.0008685645880177617
[5260] train loss: 0.3817164748907089, metric: 14.360291481018066, lr: 0.0008465081336908042
[5280] train loss: 1.0383757837116718, metric: 13.241619348526001, lr: 0.0008230703533627093
[5300] train loss: -0.13938632979989052, metric: 9.89134430885315, lr: 0.0007983447285369039
[5320] train loss: -0.2029697336256504, metric: 10.397773742675781, lr: 0.0007724298629909754
[5340] train loss: -0.2690925933420658, metric: 9.935556173324585, lr: 0.0007454289589077234
[5360] train loss: -0.14222917333245277, metric: 11.235160112380981, lr: 0.0007174497004598379
[5380] train loss: 0.303820613771677, metric: 10.67696237564087, lr: 0.00068860367173329
[5400] train loss: 0.6604115180671215, metric: 10.443361282348633, lr: 0.0006590057746507227
[5420] train loss: 1.299485333263874, metric: 11.815473556518555, lr: 0.0006287740543484688
[5440] train loss: 2.1960040107369423, metric: 11.932367324829102, lr: 0.000598029000684619
[5460] train loss: 0.37973952665925026, metric: 12.635185718536377, lr: 0.0005668931407853961
[5480] train loss: 0.19442177563905716, metric: 16.579026699066162, lr: 0.0005354906315915287
[5500] train loss: -0.1630815900862217, metric: 11.189017534255981, lr: 0.0005039466777816415
[5520] train loss: -0.20719311013817787, metric: 11.698081970214844, lr: 0.0004723869787994772
[5540] train loss: -0.16093019396066666, metric: 11.917930364608765, lr: 0.0004409373505041003
[5560] train loss: -0.20829902216792107, metric: 13.183931589126587, lr: 0.0004097231721971184
[5580] train loss: -0.21937991306185722, metric: 8.995836853981018, lr: 0.000378868862753734
[5600] train loss: 0.004994090646505356, metric: 11.323350667953491, lr: 0.00034849741496145725
[5620] train loss: -0.1514681689441204, metric: 8.529651880264282, lr: 0.0003187299007549882
[5640] train loss: 8.988857746124268, metric: 20.583049058914185, lr: 0.0002896849764510989
[5660] train loss: 1.4591364115476608, metric: 19.7822208404541, lr: 0.0002614784170873463
[5680] train loss: 2.0437466204166412, metric: 18.335304737091064, lr: 0.00023422270896844566
[5700] train loss: 2.557054404169321, metric: 15.711558818817139, lr: 0.00020802643848583102
[5720] train loss: 0.7698900736868382, metric: 15.478533267974854, lr: 0.00018299407383892685
[5740] train loss: 0.8581075556576252, metric: 17.039504289627075, lr: 0.00015922538295853883
[5760] train loss: 2.7792040035128593, metric: 17.276287317276, lr: 0.00013681512791663408
[5780] train loss: 3.582681145519018, metric: 19.21241283416748, lr: 0.00011585262109292671
[5800] train loss: 0.8103114552795887, metric: 13.667205810546875, lr: 9.999999747378752e-05
[5820] train loss: 0.29441332444548607, metric: 10.879538297653198, lr: 9.999999747378752e-05
[5840] train loss: 0.20952421054244041, metric: 12.89590072631836, lr: 9.999999747378752e-05
[5860] train loss: 3.6139138527214527, metric: 17.812623023986816, lr: 9.999999747378752e-05
[5880] train loss: 4.642605006694794, metric: 18.64431071281433, lr: 9.999999747378752e-05
[5900] train loss: 1.6415199525654316, metric: 14.993515491485596, lr: 9.999999747378752e-05
[5920] train loss: 1.2970282472670078, metric: 18.204989671707153, lr: 9.999999747378752e-05
[5940] train loss: 1.0411006286740303, metric: 14.571612119674683, lr: 9.999999747378752e-05
[5960] train loss: 1.9869318157434464, metric: 18.055328607559204, lr: 9.999999747378752e-05
[5980] train loss: 1.9041796699166298, metric: 15.52076244354248, lr: 9.999999747378752e-05
[6000] train loss: 1.5591134317219257, metric: 16.161277055740356, lr: 9.999999747378752e-05
[6020] train loss: 2.3928207606077194, metric: 16.184267044067383, lr: 0.0009994393913075328
[6040] train loss: 3.791626635938883, metric: 19.955246210098267, lr: 0.0009969500824809074
[6060] train loss: 1.6665701270103455, metric: 18.421817302703857, lr: 0.000992479850538075
[6080] train loss: 2.077689953148365, metric: 12.873189210891724, lr: 0.000986046390607953
[6100] train loss: 7.055587165057659, metric: 19.43441081047058, lr: 0.0009776754304766655
[6120] train loss: 1.173389758914709, metric: 17.40338921546936, lr: 0.0009674003813415766
[6140] train loss: 0.08044949173927307, metric: 14.506470203399658, lr: 0.0009552621049806476
[6160] train loss: 0.05915260687470436, metric: 13.69547414779663, lr: 0.0009413089719600976
[6180] train loss: -0.23947511240839958, metric: 9.059290647506714, lr: 0.0009255966870114207
[6200] train loss: -0.270262461155653, metric: 10.837581872940063, lr: 0.00090818788157776
[6220] train loss: -0.27141306921839714, metric: 9.83137321472168, lr: 0.0008891518809832633
[6240] train loss: -0.23513685911893845, metric: 9.534882307052612, lr: 0.0008685645880177617
[6260] train loss: -0.26325850188732147, metric: 8.65970516204834, lr: 0.0008465081336908042
[6280] train loss: -0.2342054434120655, metric: 8.363050699234009, lr: 0.0008230703533627093
[6300] train loss: -0.2361459657549858, metric: 9.181826114654541, lr: 0.0007983447285369039
[6320] train loss: -0.2059924229979515, metric: 8.870802283287048, lr: 0.0007724298629909754
[6340] train loss: -0.2574269622564316, metric: 9.028664827346802, lr: 0.0007454289589077234
[6360] train loss: -0.3424370586872101, metric: 8.394830107688904, lr: 0.0007174497004598379
[6380] train loss: -0.32721707224845886, metric: 8.46468997001648, lr: 0.00068860367173329
[6400] train loss: -0.28974027559161186, metric: 8.367419958114624, lr: 0.0006590057746507227
[6420] train loss: -0.1929139718413353, metric: 8.622705698013306, lr: 0.0006287740543484688
[6440] train loss: -0.10976142808794975, metric: 8.927379727363586, lr: 0.000598029000684619
[6460] train loss: -0.12034644559025764, metric: 10.196035623550415, lr: 0.0005668931407853961
[6480] train loss: 0.016778647899627686, metric: 11.465516805648804, lr: 0.0005354906315915287
[6500] train loss: -0.08588606864213943, metric: 10.428917407989502, lr: 0.0005039466777816415
[6520] train loss: 0.35379188135266304, metric: 9.970741510391235, lr: 0.0004723869787994772
[6540] train loss: 0.32458552718162537, metric: 8.63601279258728, lr: 0.0004409373505041003
[6560] train loss: -0.013573188334703445, metric: 9.839024305343628, lr: 0.0004097231721971184
[6580] train loss: 0.6084684655070305, metric: 11.980289578437805, lr: 0.000378868862753734
[6600] train loss: 0.450235515832901, metric: 11.520224332809448, lr: 0.00034849741496145725
[6620] train loss: 0.09353272616863251, metric: 10.645929336547852, lr: 0.0003187299007549882
[6640] train loss: 0.45567409694194794, metric: 9.128384828567505, lr: 0.0002896849764510989
[6660] train loss: 1.6683642715215683, metric: 18.699448823928833, lr: 0.0002614784170873463
[6680] train loss: 0.5718889348208904, metric: 15.824720621109009, lr: 0.00023422270896844566
[6700] train loss: 0.9904821440577507, metric: 13.87215542793274, lr: 0.00020802643848583102
[6720] train loss: 0.851725485175848, metric: 13.545981884002686, lr: 0.00018299407383892685
[6740] train loss: 1.5392338074743748, metric: 13.714936256408691, lr: 0.00015922538295853883
[6760] train loss: 1.993196502327919, metric: 17.562377214431763, lr: 0.00013681512791663408
[6780] train loss: 5.520028330385685, metric: 18.576489448547363, lr: 0.00011585262109292671
[6800] train loss: 0.9837352521717548, metric: 15.712399005889893, lr: 9.999999747378752e-05
[6820] train loss: 4.918518077582121, metric: 15.364071607589722, lr: 9.999999747378752e-05
[6840] train loss: 4.006997834891081, metric: 19.089967489242554, lr: 9.999999747378752e-05
[6860] train loss: 2.802851192653179, metric: 17.707985162734985, lr: 9.999999747378752e-05
[6880] train loss: 0.7103623002767563, metric: 14.830678701400757, lr: 9.999999747378752e-05
[6900] train loss: 0.752590712159872, metric: 14.53577709197998, lr: 9.999999747378752e-05
[6920] train loss: 2.7103537805378437, metric: 14.111411809921265, lr: 9.999999747378752e-05
[6940] train loss: 3.5232745856046677, metric: 15.1716628074646, lr: 9.999999747378752e-05
[6960] train loss: 4.289325222373009, metric: 14.702784538269043, lr: 9.999999747378752e-05
[6980] train loss: 2.3334232605993748, metric: 14.678497791290283, lr: 9.999999747378752e-05
[7000] train loss: 0.740303136408329, metric: 16.166749000549316, lr: 9.999999747378752e-05
[7020] train loss: 0.2712755389511585, metric: 13.944678783416748, lr: 0.0009994393913075328
[7040] train loss: -0.06934849172830582, metric: 10.272561311721802, lr: 0.0009969500824809074
[7060] train loss: -0.05149521678686142, metric: 9.87818956375122, lr: 0.000992479850538075
[7080] train loss: -0.2229108326137066, metric: 10.484642148017883, lr: 0.000986046390607953
[7100] train loss: -0.2836296893656254, metric: 9.126155138015747, lr: 0.0009776754304766655
[7120] train loss: -0.25597264990210533, metric: 9.362478733062744, lr: 0.0009674003813415766
[7140] train loss: -0.23690509796142578, metric: 10.237055540084839, lr: 0.0009552621049806476
[7160] train loss: -0.16294650733470917, metric: 9.25107741355896, lr: 0.0009413089719600976
[7180] train loss: 2.1659945249557495, metric: 18.395597457885742, lr: 0.0009255966870114207
[7200] train loss: 0.31626642867922783, metric: 12.001635074615479, lr: 0.00090818788157776
[7220] train loss: 0.0635855682194233, metric: 13.006062984466553, lr: 0.0008891518809832633
[7240] train loss: 0.4881012327969074, metric: 10.77686333656311, lr: 0.0008685645880177617
[7260] train loss: 0.5595224425196648, metric: 11.749575853347778, lr: 0.0008465081336908042
[7280] train loss: 0.38688424602150917, metric: 12.08001160621643, lr: 0.0008230703533627093
[7300] train loss: 2.0594555884599686, metric: 13.679046988487244, lr: 0.0007983447285369039
[7320] train loss: 3.9886325001716614, metric: 17.39562201499939, lr: 0.0007724298629909754
[7340] train loss: 0.8454339616000652, metric: 16.09784507751465, lr: 0.0007454289589077234
[7360] train loss: 0.9753122329711914, metric: 15.298914432525635, lr: 0.0007174497004598379
[7380] train loss: 0.8616189062595367, metric: 17.016212463378906, lr: 0.00068860367173329
[7400] train loss: 0.6387630440294743, metric: 14.997390270233154, lr: 0.0006590057746507227
[7420] train loss: 0.9716389179229736, metric: 16.787172079086304, lr: 0.0006287740543484688
[7440] train loss: 1.450122106820345, metric: 14.394318342208862, lr: 0.000598029000684619
[7460] train loss: 1.179329939186573, metric: 13.770718455314636, lr: 0.0005668931407853961
[7480] train loss: 0.9555062800645828, metric: 13.879168272018433, lr: 0.0005354906315915287
[7500] train loss: 6.673743091523647, metric: 22.810896396636963, lr: 0.0005039466777816415
[7520] train loss: 4.083551798015833, metric: 22.762075424194336, lr: 0.0004723869787994772
[7540] train loss: 1.132870338857174, metric: 20.31545066833496, lr: 0.0004409373505041003
[7560] train loss: 0.3755842074751854, metric: 13.229366302490234, lr: 0.0004097231721971184
[7580] train loss: 2.916282795369625, metric: 20.80635404586792, lr: 0.000378868862753734
[7600] train loss: 1.3351400196552277, metric: 16.85912275314331, lr: 0.00034849741496145725
[7620] train loss: 0.6493855603039265, metric: 14.068622827529907, lr: 0.0003187299007549882
[7640] train loss: 2.74701851606369, metric: 15.663294553756714, lr: 0.0002896849764510989
[7660] train loss: 4.755955461412668, metric: 18.083292484283447, lr: 0.0002614784170873463
[7680] train loss: 3.4163614250719547, metric: 17.75544786453247, lr: 0.00023422270896844566
[7700] train loss: 0.24152177944779396, metric: 16.50483274459839, lr: 0.00020802643848583102
[7720] train loss: 0.42174360901117325, metric: 17.044840097427368, lr: 0.00018299407383892685
[7740] train loss: 0.1923481598496437, metric: 16.26544189453125, lr: 0.00015922538295853883
[7760] train loss: -0.07717667520046234, metric: 14.389994621276855, lr: 0.00013681512791663408
[7780] train loss: -0.008574679493904114, metric: 14.063677549362183, lr: 0.00011585262109292671
[7800] train loss: -0.03343131020665169, metric: 14.394298315048218, lr: 9.999999747378752e-05
[7820] train loss: -0.1283055730164051, metric: 14.074870109558105, lr: 9.999999747378752e-05
[7840] train loss: -0.1114269271492958, metric: 14.733869791030884, lr: 9.999999747378752e-05
[7860] train loss: -0.0845486931502819, metric: 13.198984384536743, lr: 9.999999747378752e-05
[7880] train loss: -0.11680087447166443, metric: 14.788671493530273, lr: 9.999999747378752e-05
[7900] train loss: -0.16434244439005852, metric: 12.531470537185669, lr: 9.999999747378752e-05
[7920] train loss: -0.18115804716944695, metric: 12.720121383666992, lr: 9.999999747378752e-05
[7940] train loss: -0.11102728545665741, metric: 12.53600788116455, lr: 9.999999747378752e-05
[7960] train loss: -0.2005799449980259, metric: 12.392271995544434, lr: 9.999999747378752e-05
[7980] train loss: 2.084723349660635, metric: 14.119269132614136, lr: 9.999999747378752e-05
[8000] train loss: 5.61924334987998, metric: 18.71868371963501, lr: 9.999999747378752e-05
[8020] train loss: 2.156204305589199, metric: 16.379709243774414, lr: 0.0009994393913075328
[8040] train loss: 0.20075485855340958, metric: 17.080405950546265, lr: 0.0009969500824809074
[8060] train loss: 0.0604928582906723, metric: 11.593037843704224, lr: 0.000992479850538075
[8080] train loss: 0.27496233209967613, metric: 13.838261365890503, lr: 0.000986046390607953
[8100] train loss: 0.04044995456933975, metric: 14.017613172531128, lr: 0.0009776754304766655
[8120] train loss: -0.12239474803209305, metric: 12.557891368865967, lr: 0.0009674003813415766
[8140] train loss: -0.12943707406520844, metric: 10.675074815750122, lr: 0.0009552621049806476
[8160] train loss: -0.2591123953461647, metric: 10.620782852172852, lr: 0.0009413089719600976
[8180] train loss: -0.28911780565977097, metric: 11.064739227294922, lr: 0.0009255966870114207
[8200] train loss: 2.5940049439668655, metric: 19.858905792236328, lr: 0.00090818788157776
[8220] train loss: 0.4753202646970749, metric: 11.840850353240967, lr: 0.0008891518809832633
[8240] train loss: 0.23025508970022202, metric: 9.970450639724731, lr: 0.0008685645880177617
[8260] train loss: 0.3112620785832405, metric: 14.954090356826782, lr: 0.0008465081336908042
[8280] train loss: 3.9115487597882748, metric: 18.915252208709717, lr: 0.0008230703533627093
[8300] train loss: 4.565001390874386, metric: 16.25442397594452, lr: 0.0007983447285369039
[8320] train loss: 2.7697101272642612, metric: 15.171860337257385, lr: 0.0007724298629909754
[8340] train loss: 0.8483352363109589, metric: 14.537867784500122, lr: 0.0007454289589077234
[8360] train loss: 1.3882564790546894, metric: 16.8673095703125, lr: 0.0007174497004598379
[8380] train loss: 1.9238678067922592, metric: 16.17305636405945, lr: 0.00068860367173329
[8400] train loss: 0.36787455156445503, metric: 13.95251989364624, lr: 0.0006590057746507227
[8420] train loss: 0.6598547846078873, metric: 14.601250648498535, lr: 0.0006287740543484688
[8440] train loss: 1.0977821834385395, metric: 14.37243103981018, lr: 0.000598029000684619
[8460] train loss: 0.08005259931087494, metric: 11.648601293563843, lr: 0.0005668931407853961
[8480] train loss: 0.14235728979110718, metric: 11.565038084983826, lr: 0.0005354906315915287
[8500] train loss: 0.9083698019385338, metric: 17.0094176530838, lr: 0.0005039466777816415
[8520] train loss: 0.870591301470995, metric: 14.878274202346802, lr: 0.0004723869787994772
[8540] train loss: 4.33858485519886, metric: 17.78344416618347, lr: 0.0004409373505041003
[8560] train loss: 0.9567758999764919, metric: 14.463560819625854, lr: 0.0004097231721971184
[8580] train loss: 0.2889038696885109, metric: 18.61393928527832, lr: 0.000378868862753734
[8600] train loss: 0.9678352847695351, metric: 14.386022090911865, lr: 0.00034849741496145725
[8620] train loss: 3.420368518680334, metric: 15.89021611213684, lr: 0.0003187299007549882
[8640] train loss: 3.1242452301084995, metric: 15.24452519416809, lr: 0.0002896849764510989
[8660] train loss: 0.2137831412255764, metric: 13.579637050628662, lr: 0.0002614784170873463
[8680] train loss: 0.9337823837995529, metric: 14.54666543006897, lr: 0.00023422270896844566
[8700] train loss: 3.9733637794852257, metric: 17.72510862350464, lr: 0.00020802643848583102
[8720] train loss: 0.31656254827976227, metric: 16.79163694381714, lr: 0.00018299407383892685
[8740] train loss: -0.10741159692406654, metric: 14.32658052444458, lr: 0.00015922538295853883
[8760] train loss: -0.16918254643678665, metric: 12.160308718681335, lr: 0.00013681512791663408
[8780] train loss: -0.1447259709239006, metric: 13.52592396736145, lr: 0.00011585262109292671
[8800] train loss: -0.1610868163406849, metric: 11.378175258636475, lr: 9.999999747378752e-05
[8820] train loss: -0.16650593280792236, metric: 12.444825172424316, lr: 9.999999747378752e-05
[8840] train loss: -0.21684827841818333, metric: 11.57309627532959, lr: 9.999999747378752e-05
[8860] train loss: -0.2368801198899746, metric: 11.323729276657104, lr: 9.999999747378752e-05
[8880] train loss: -0.21634098514914513, metric: 11.74489140510559, lr: 9.999999747378752e-05
[8900] train loss: -0.22363494709134102, metric: 11.465067625045776, lr: 9.999999747378752e-05
[8920] train loss: -0.22013524547219276, metric: 10.918545722961426, lr: 9.999999747378752e-05
[8940] train loss: -0.2889050357043743, metric: 11.193744421005249, lr: 9.999999747378752e-05
[8960] train loss: -0.2894839756190777, metric: 11.59575366973877, lr: 9.999999747378752e-05
[8980] train loss: -0.2872714512050152, metric: 12.275256872177124, lr: 9.999999747378752e-05
[9000] train loss: -0.2896975055336952, metric: 11.923039674758911, lr: 9.999999747378752e-05
[9020] train loss: -0.26651210710406303, metric: 11.750488996505737, lr: 0.0009994393913075328
[9040] train loss: -0.3172011449933052, metric: 12.326702117919922, lr: 0.0009969500824809074
[9060] train loss: -0.32703010365366936, metric: 11.384740114212036, lr: 0.000992479850538075
[9080] train loss: -0.3053056597709656, metric: 8.05998182296753, lr: 0.000986046390607953
[9100] train loss: -0.3055310659110546, metric: 8.339519739151001, lr: 0.0009776754304766655
[9120] train loss: -0.3410072401165962, metric: 8.849549531936646, lr: 0.0009674003813415766
[9140] train loss: -0.34498483687639236, metric: 8.58562684059143, lr: 0.0009552621049806476
[9160] train loss: -0.3109413981437683, metric: 8.478152990341187, lr: 0.0009413089719600976
[9180] train loss: -0.3243388272821903, metric: 8.571618914604187, lr: 0.0009255966870114207
[9200] train loss: -0.2557170242071152, metric: 11.118557453155518, lr: 0.00090818788157776
[9220] train loss: 5.336939442902803, metric: 21.769915103912354, lr: 0.0008891518809832633
[9240] train loss: 0.8783347494900227, metric: 14.526015758514404, lr: 0.0008685645880177617
[9260] train loss: 1.54545309394598, metric: 14.834054231643677, lr: 0.0008465081336908042
[9280] train loss: 0.4842744916677475, metric: 14.11185073852539, lr: 0.0008230703533627093
[9300] train loss: 0.37027597054839134, metric: 12.138982057571411, lr: 0.0007983447285369039
[9320] train loss: 1.9245302081108093, metric: 13.640679836273193, lr: 0.0007724298629909754
[9340] train loss: 0.31138041242957115, metric: 10.969137907028198, lr: 0.0007454289589077234
[9360] train loss: 1.8108447045087814, metric: 14.48976445198059, lr: 0.0007174497004598379
[9380] train loss: 1.6235893964767456, metric: 16.18931770324707, lr: 0.00068860367173329
[9400] train loss: 2.062550749629736, metric: 15.837633848190308, lr: 0.0006590057746507227
[9420] train loss: 0.9686589352786541, metric: 13.685580968856812, lr: 0.0006287740543484688
[9440] train loss: 0.41925451904535294, metric: 10.383651733398438, lr: 0.000598029000684619
[9460] train loss: 1.5293380208313465, metric: 13.966008186340332, lr: 0.0005668931407853961
[9480] train loss: 0.7806665152311325, metric: 13.717402935028076, lr: 0.0005354906315915287
[9500] train loss: -0.0648278184235096, metric: 10.02130901813507, lr: 0.0005039466777816415
[9520] train loss: 0.015707358717918396, metric: 15.254427433013916, lr: 0.0004723869787994772
[9540] train loss: 0.08186480775475502, metric: 9.195828318595886, lr: 0.0004409373505041003
[9560] train loss: -0.22645394876599312, metric: 8.792656302452087, lr: 0.0004097231721971184
[9580] train loss: -0.20580046623945236, metric: 8.703377723693848, lr: 0.000378868862753734
[9600] train loss: -0.01069362461566925, metric: 11.586188197135925, lr: 0.00034849741496145725
[9620] train loss: 0.09406229481101036, metric: 9.56199049949646, lr: 0.0003187299007549882
[9640] train loss: 0.041444551199674606, metric: 9.23215627670288, lr: 0.0002896849764510989
[9660] train loss: 0.6218117661774158, metric: 10.486873269081116, lr: 0.0002614784170873463
[9680] train loss: 0.8835262209177017, metric: 19.943525314331055, lr: 0.00023422270896844566
[9700] train loss: 0.22105642780661583, metric: 15.479164361953735, lr: 0.00020802643848583102
[9720] train loss: 0.09586679935455322, metric: 11.332126498222351, lr: 0.00018299407383892685
[9740] train loss: 0.8667964823544025, metric: 15.72731876373291, lr: 0.00015922538295853883
[9760] train loss: 0.4948011599481106, metric: 14.360154151916504, lr: 0.00013681512791663408
[9780] train loss: 0.9282504208385944, metric: 14.286202907562256, lr: 0.00011585262109292671
[9800] train loss: 0.663453321903944, metric: 19.193986415863037, lr: 9.999999747378752e-05
[9820] train loss: 0.5144463367760181, metric: 15.124861240386963, lr: 9.999999747378752e-05
[9840] train loss: 1.5211806781589985, metric: 17.68804359436035, lr: 9.999999747378752e-05
[9860] train loss: 0.45746900886297226, metric: 16.119967460632324, lr: 9.999999747378752e-05
[9880] train loss: 0.05127119645476341, metric: 12.636217594146729, lr: 9.999999747378752e-05
[9900] train loss: 0.5916746631264687, metric: 13.806748390197754, lr: 9.999999747378752e-05
[9920] train loss: 0.2380187064409256, metric: 16.39983820915222, lr: 9.999999747378752e-05
[9940] train loss: 1.0946127958595753, metric: 14.2014319896698, lr: 9.999999747378752e-05
[9960] train loss: 0.6642276681959629, metric: 13.969334840774536, lr: 9.999999747378752e-05
[9980] train loss: 0.30606818199157715, metric: 15.676147222518921, lr: 9.999999747378752e-05
[10000] train loss: 0.2875627428293228, metric: 13.805779457092285, lr: 9.999999747378752e-05
[10020] train loss: 0.4074888192117214, metric: 12.657050848007202, lr: 0.0009994393913075328
[10040] train loss: 0.021784145385026932, metric: 11.96311616897583, lr: 0.0009969500824809074
[10060] train loss: 0.6064850129187107, metric: 12.525165557861328, lr: 0.000992479850538075
[10080] train loss: 0.7959394566714764, metric: 14.000588655471802, lr: 0.000986046390607953
[10100] train loss: 0.3533763214945793, metric: 12.539596796035767, lr: 0.0009776754304766655
[10120] train loss: 0.4119388908147812, metric: 14.937715768814087, lr: 0.0009674003813415766
[10140] train loss: 0.5349398665130138, metric: 14.695921421051025, lr: 0.0009552621049806476
[10160] train loss: 1.2240262925624847, metric: 21.708234548568726, lr: 0.0009413089719600976
[10180] train loss: 0.5959409736096859, metric: 13.978338718414307, lr: 0.0009255966870114207
[10200] train loss: 0.2174200378358364, metric: 14.379146099090576, lr: 0.00090818788157776
[10220] train loss: 0.1932596080005169, metric: 10.073991775512695, lr: 0.0008891518809832633
[10240] train loss: 0.20908285677433014, metric: 9.630040407180786, lr: 0.0008685645880177617
[10260] train loss: 0.06573857739567757, metric: 12.487059593200684, lr: 0.0008465081336908042
[10280] train loss: 0.03429107740521431, metric: 13.34244966506958, lr: 0.0008230703533627093
[10300] train loss: -0.12282660603523254, metric: 9.587415218353271, lr: 0.0007983447285369039
[10320] train loss: -0.12976877763867378, metric: 9.805992603302002, lr: 0.0007724298629909754
[10340] train loss: 0.4248567335307598, metric: 11.16906476020813, lr: 0.0007454289589077234
[10360] train loss: -0.2164362072944641, metric: 9.478387594223022, lr: 0.0007174497004598379
[10380] train loss: 0.3401433192193508, metric: 12.670068979263306, lr: 0.00068860367173329
[10400] train loss: -0.07853039726614952, metric: 9.396452069282532, lr: 0.0006590057746507227
[10420] train loss: 0.9655247591435909, metric: 12.99527907371521, lr: 0.0006287740543484688
[10440] train loss: 0.4609967526048422, metric: 12.245264887809753, lr: 0.000598029000684619
[10460] train loss: -0.09542189911007881, metric: 10.054159164428711, lr: 0.0005668931407853961
[10480] train loss: 0.13589805737137794, metric: 9.917534112930298, lr: 0.0005354906315915287
[10500] train loss: 0.14002947323024273, metric: 11.73438024520874, lr: 0.0005039466777816415
[10520] train loss: 0.009484026581048965, metric: 8.172552943229675, lr: 0.0004723869787994772
[10540] train loss: -0.13082879036664963, metric: 8.923964023590088, lr: 0.0004409373505041003
[10560] train loss: -0.05009244382381439, metric: 10.27469277381897, lr: 0.0004097231721971184
[10580] train loss: -0.17414328828454018, metric: 9.324055075645447, lr: 0.000378868862753734
[10600] train loss: 0.007735904306173325, metric: 9.374786019325256, lr: 0.00034849741496145725
[10620] train loss: 1.643701583147049, metric: 11.011775016784668, lr: 0.0003187299007549882
[10640] train loss: 1.8827534839510918, metric: 11.497694849967957, lr: 0.0002896849764510989
[10660] train loss: 0.3219890147447586, metric: 14.704981565475464, lr: 0.0002614784170873463
[10680] train loss: 0.3217445872724056, metric: 12.337407112121582, lr: 0.00023422270896844566
[10700] train loss: 0.6655229032039642, metric: 11.278091669082642, lr: 0.00020802643848583102
[10720] train loss: 0.3113972507417202, metric: 8.457584857940674, lr: 0.00018299407383892685
[10740] train loss: 0.8643779866397381, metric: 10.288092374801636, lr: 0.00015922538295853883
[10760] train loss: 2.4224659204483032, metric: 22.231147050857544, lr: 0.00013681512791663408
[10780] train loss: 1.158818706870079, metric: 15.816703081130981, lr: 0.00011585262109292671
[10800] train loss: 1.8851064518094063, metric: 15.649611473083496, lr: 9.999999747378752e-05
[10820] train loss: 1.9462642967700958, metric: 16.00433921813965, lr: 9.999999747378752e-05
[10840] train loss: 0.7134831547737122, metric: 12.088615655899048, lr: 9.999999747378752e-05
[10860] train loss: 1.2560817077755928, metric: 13.91880750656128, lr: 9.999999747378752e-05
[10880] train loss: 1.5822284817695618, metric: 17.387235164642334, lr: 9.999999747378752e-05
[10900] train loss: 1.4101043157279491, metric: 15.712638854980469, lr: 9.999999747378752e-05
[10920] train loss: 1.691742442548275, metric: 16.446383714675903, lr: 9.999999747378752e-05
[10940] train loss: 1.7852065041661263, metric: 15.314157962799072, lr: 9.999999747378752e-05
[10960] train loss: 0.8663206249475479, metric: 12.761568784713745, lr: 9.999999747378752e-05
[10980] train loss: 0.9446092061698437, metric: 14.484743595123291, lr: 9.999999747378752e-05
[11000] train loss: 1.1199706457555294, metric: 16.203852891921997, lr: 9.999999747378752e-05
[11020] train loss: 0.15000196546316147, metric: 10.027073502540588, lr: 0.0009994393913075328
[11040] train loss: -0.14036020636558533, metric: 9.60322904586792, lr: 0.0009969500824809074
[11060] train loss: -0.13274365663528442, metric: 8.011820912361145, lr: 0.000992479850538075
[11080] train loss: -0.29502158239483833, metric: 8.91686475276947, lr: 0.000986046390607953
[11100] train loss: -0.1648705080151558, metric: 9.326176166534424, lr: 0.0009776754304766655
[11120] train loss: -0.1284070499241352, metric: 9.72952139377594, lr: 0.0009674003813415766
[11140] train loss: 0.037741683423519135, metric: 10.0896315574646, lr: 0.0009552621049806476
[11160] train loss: -0.1701047234237194, metric: 10.022172689437866, lr: 0.0009413089719600976
[11180] train loss: -0.1410549394786358, metric: 8.067066431045532, lr: 0.0009255966870114207
[11200] train loss: -0.2434690296649933, metric: 7.699948668479919, lr: 0.00090818788157776
[11220] train loss: -0.1982591152191162, metric: 8.398985624313354, lr: 0.0008891518809832633
[11240] train loss: -0.18455176427960396, metric: 8.00264310836792, lr: 0.0008685645880177617
[11260] train loss: -0.0438077449798584, metric: 9.84973692893982, lr: 0.0008465081336908042
[11280] train loss: 1.2390007451176643, metric: 18.35088014602661, lr: 0.0008230703533627093
[11300] train loss: -0.04217090457677841, metric: 12.98704743385315, lr: 0.0007983447285369039
[11320] train loss: 0.1904863715171814, metric: 11.546756505966187, lr: 0.0007724298629909754
[11340] train loss: 0.04695664718747139, metric: 10.65273380279541, lr: 0.0007454289589077234
[11360] train loss: -0.2165914922952652, metric: 9.076701998710632, lr: 0.0007174497004598379
[11380] train loss: -0.16135374084115028, metric: 9.073274493217468, lr: 0.00068860367173329
[11400] train loss: 0.28960277885198593, metric: 9.331162691116333, lr: 0.0006590057746507227
[11420] train loss: 0.1683109626173973, metric: 9.16041111946106, lr: 0.0006287740543484688
[11440] train loss: 0.40936511382460594, metric: 10.834529757499695, lr: 0.000598029000684619
[11460] train loss: 0.4676979258656502, metric: 9.610283374786377, lr: 0.0005668931407853961
[11480] train loss: 0.6275378353893757, metric: 11.867090463638306, lr: 0.0005354906315915287
[11500] train loss: -0.034707922488451004, metric: 11.79926347732544, lr: 0.0005039466777816415
[11520] train loss: -0.013554845005273819, metric: 12.595841646194458, lr: 0.0004723869787994772
[11540] train loss: -0.14439958706498146, metric: 12.592497825622559, lr: 0.0004409373505041003
[11560] train loss: -0.15792293101549149, metric: 11.184484481811523, lr: 0.0004097231721971184
[11580] train loss: -0.2424333393573761, metric: 8.034752130508423, lr: 0.000378868862753734
[11600] train loss: -0.15869305282831192, metric: 8.814674377441406, lr: 0.00034849741496145725
[11620] train loss: 1.206262931227684, metric: 12.30063283443451, lr: 0.0003187299007549882
[11640] train loss: 3.8359118960797787, metric: 16.559051990509033, lr: 0.0002896849764510989
[11660] train loss: 0.6403771676123142, metric: 12.623427629470825, lr: 0.0002614784170873463
[11680] train loss: -0.08680656924843788, metric: 10.72006356716156, lr: 0.00023422270896844566
[11700] train loss: -0.26046687364578247, metric: 11.683072090148926, lr: 0.00020802643848583102
[11720] train loss: -0.20489150285720825, metric: 9.403854727745056, lr: 0.00018299407383892685
[11740] train loss: -0.28457508981227875, metric: 9.130507946014404, lr: 0.00015922538295853883
[11760] train loss: -0.27371780574321747, metric: 10.366013765335083, lr: 0.00013681512791663408
[11780] train loss: 2.2732071802020073, metric: 18.29435920715332, lr: 0.00011585262109292671
[11800] train loss: 1.7256350368261337, metric: 17.94612979888916, lr: 9.999999747378752e-05
[11820] train loss: 2.432622890919447, metric: 18.962934970855713, lr: 9.999999747378752e-05
[11840] train loss: 0.04525834694504738, metric: 15.282910823822021, lr: 9.999999747378752e-05
[11860] train loss: 0.13284491375088692, metric: 11.852508306503296, lr: 9.999999747378752e-05
[11880] train loss: 0.5034970417618752, metric: 12.043327808380127, lr: 9.999999747378752e-05
[11900] train loss: 0.413920134305954, metric: 11.557994365692139, lr: 9.999999747378752e-05
[11920] train loss: 0.30560270324349403, metric: 12.918883562088013, lr: 9.999999747378752e-05
[11940] train loss: 2.1309128254652023, metric: 13.346297264099121, lr: 9.999999747378752e-05
[11960] train loss: 0.15242581814527512, metric: 15.54110336303711, lr: 9.999999747378752e-05
[11980] train loss: 0.3410278744995594, metric: 13.930898427963257, lr: 9.999999747378752e-05
[12000] train loss: 1.4326603934168816, metric: 12.638074159622192, lr: 9.999999747378752e-05
[12020] train loss: 0.3313537500798702, metric: 11.194114923477173, lr: 0.0009994393913075328
[12040] train loss: 0.41182510927319527, metric: 11.490016341209412, lr: 0.0009969500824809074
[12060] train loss: -0.13534165546298027, metric: 10.391492366790771, lr: 0.000992479850538075
[12080] train loss: -0.2011660858988762, metric: 8.611518621444702, lr: 0.000986046390607953
[12100] train loss: -0.18923377618193626, metric: 9.305842638015747, lr: 0.0009776754304766655
[12120] train loss: -0.1523309126496315, metric: 8.087677359580994, lr: 0.0009674003813415766
[12140] train loss: -0.19859880954027176, metric: 9.394294500350952, lr: 0.0009552621049806476
[12160] train loss: -0.04263508692383766, metric: 8.320501446723938, lr: 0.0009413089719600976
[12180] train loss: -0.017310291528701782, metric: 9.284217953681946, lr: 0.0009255966870114207
[12200] train loss: 0.08843830227851868, metric: 10.042480707168579, lr: 0.00090818788157776
[12220] train loss: -0.09877645969390869, metric: 9.467222094535828, lr: 0.0008891518809832633
[12240] train loss: 2.448909640312195, metric: 12.701832294464111, lr: 0.0008685645880177617
[12260] train loss: 0.7766604237258434, metric: 11.444754600524902, lr: 0.0008465081336908042
[12280] train loss: 0.12693781405687332, metric: 11.997209429740906, lr: 0.0008230703533627093
[12300] train loss: 3.0710083693265915, metric: 14.549570322036743, lr: 0.0007983447285369039
[12320] train loss: 0.1404663883149624, metric: 11.458648204803467, lr: 0.0007724298629909754
[12340] train loss: -0.11041832342743874, metric: 11.795646667480469, lr: 0.0007454289589077234
[12360] train loss: -0.20165403559803963, metric: 9.984044909477234, lr: 0.0007174497004598379
[12380] train loss: -0.2874538004398346, metric: 10.505948066711426, lr: 0.00068860367173329
[12400] train loss: -0.27554405853152275, metric: 10.011566400527954, lr: 0.0006590057746507227
[12420] train loss: -0.29023103415966034, metric: 10.779555320739746, lr: 0.0006287740543484688
[12440] train loss: -0.3082025721669197, metric: 11.975250959396362, lr: 0.000598029000684619
[12460] train loss: -0.28168120607733727, metric: 10.891635179519653, lr: 0.0005668931407853961
[12480] train loss: 0.3439011871814728, metric: 12.286808252334595, lr: 0.0005354906315915287
[12500] train loss: -0.2911023832857609, metric: 11.183438658714294, lr: 0.0005039466777816415
[12520] train loss: -0.30219104140996933, metric: 11.623796820640564, lr: 0.0004723869787994772
[12540] train loss: -0.22220207005739212, metric: 12.10603928565979, lr: 0.0004409373505041003
[12560] train loss: -0.2652508281171322, metric: 12.107890605926514, lr: 0.0004097231721971184
[12580] train loss: -0.14022313803434372, metric: 11.700680255889893, lr: 0.000378868862753734
[12600] train loss: -0.1825040616095066, metric: 10.718861103057861, lr: 0.00034849741496145725
[12620] train loss: -0.2940484322607517, metric: 11.240628719329834, lr: 0.0003187299007549882
[12640] train loss: -0.30281608924269676, metric: 11.767404079437256, lr: 0.0002896849764510989
[12660] train loss: -0.32456666231155396, metric: 11.138344287872314, lr: 0.0002614784170873463
[12680] train loss: -0.3179497867822647, metric: 12.362503051757812, lr: 0.00023422270896844566
[12700] train loss: -0.3190690353512764, metric: 11.423163414001465, lr: 0.00020802643848583102
[12720] train loss: -0.33479252457618713, metric: 11.311619281768799, lr: 0.00018299407383892685
[12740] train loss: -0.31001587212085724, metric: 11.104453086853027, lr: 0.00015922538295853883
[12760] train loss: -0.27961550280451775, metric: 11.289678812026978, lr: 0.00013681512791663408
[12780] train loss: -0.09331761300563812, metric: 10.684781789779663, lr: 0.00011585262109292671
[12800] train loss: -0.23054832592606544, metric: 11.0840585231781, lr: 9.999999747378752e-05
[12820] train loss: 6.504049450159073, metric: 18.30718159675598, lr: 9.999999747378752e-05
[12840] train loss: 4.9984188340604305, metric: 18.814309120178223, lr: 9.999999747378752e-05
[12860] train loss: 1.5021269395947456, metric: 14.618340969085693, lr: 9.999999747378752e-05
[12880] train loss: 2.13858437910676, metric: 17.22494888305664, lr: 9.999999747378752e-05
[12900] train loss: 0.7366094142198563, metric: 10.947375535964966, lr: 9.999999747378752e-05
[12920] train loss: 1.069960929453373, metric: 12.639957070350647, lr: 9.999999747378752e-05
[12940] train loss: 1.8639288768172264, metric: 12.447818279266357, lr: 9.999999747378752e-05
[12960] train loss: 3.445568833500147, metric: 16.474294424057007, lr: 9.999999747378752e-05
[12980] train loss: 2.6799698024988174, metric: 14.155681848526001, lr: 9.999999747378752e-05
[13000] train loss: 2.2835908867418766, metric: 15.546754837036133, lr: 9.999999747378752e-05
[13020] train loss: 0.471069160848856, metric: 16.732330322265625, lr: 0.0009994393913075328
[13040] train loss: 6.070830650627613, metric: 17.64418339729309, lr: 0.0009969500824809074
[13060] train loss: 1.3227810487151146, metric: 16.522274255752563, lr: 0.000992479850538075
[13080] train loss: 2.3696217127144337, metric: 19.290610551834106, lr: 0.000986046390607953
[13100] train loss: 3.428709838539362, metric: 20.910717487335205, lr: 0.0009776754304766655
[13120] train loss: 2.3944226875901222, metric: 29.589436531066895, lr: 0.0009674003813415766
[13140] train loss: 2.6591934487223625, metric: 18.473374724388123, lr: 0.0009552621049806476
[13160] train loss: 0.5027121268212795, metric: 18.030867338180542, lr: 0.0009413089719600976
[13180] train loss: 1.566536519676447, metric: 14.226496458053589, lr: 0.0009255966870114207
[13200] train loss: 2.863030195236206, metric: 18.241055965423584, lr: 0.00090818788157776
[13220] train loss: 5.722331494092941, metric: 23.657795429229736, lr: 0.0008891518809832633
[13240] train loss: 4.128923997282982, metric: 19.46662187576294, lr: 0.0008685645880177617
[13260] train loss: 4.0567638128995895, metric: 22.58366060256958, lr: 0.0008465081336908042
[13280] train loss: 0.7754634693264961, metric: 18.264418125152588, lr: 0.0008230703533627093
[13300] train loss: 1.4216091632843018, metric: 18.616631031036377, lr: 0.0007983447285369039
[13320] train loss: 0.4301403984427452, metric: 19.372921466827393, lr: 0.0007724298629909754
[13340] train loss: -0.03324349597096443, metric: 14.089323282241821, lr: 0.0007454289589077234
[13360] train loss: -0.23233222216367722, metric: 11.363842487335205, lr: 0.0007174497004598379
[13380] train loss: -0.25833675637841225, metric: 11.365710735321045, lr: 0.00068860367173329
[13400] train loss: -0.2701396606862545, metric: 10.379930853843689, lr: 0.0006590057746507227
[13420] train loss: -0.28556525334715843, metric: 9.517662763595581, lr: 0.0006287740543484688
[13440] train loss: -0.20815232396125793, metric: 8.73110055923462, lr: 0.000598029000684619
[13460] train loss: 0.07016736268997192, metric: 10.789082884788513, lr: 0.0005668931407853961
[13480] train loss: -0.2596323899924755, metric: 8.17443585395813, lr: 0.0005354906315915287
[13500] train loss: -0.28102951496839523, metric: 8.446277499198914, lr: 0.0005039466777816415
[13520] train loss: 0.8019597306847572, metric: 8.949380159378052, lr: 0.0004723869787994772
[13540] train loss: 0.2786600738763809, metric: 13.120782852172852, lr: 0.0004409373505041003
[13560] train loss: 1.088676005601883, metric: 10.378885269165039, lr: 0.0004097231721971184
[13580] train loss: 0.4103425554931164, metric: 13.057573914527893, lr: 0.000378868862753734
[13600] train loss: -0.06868405640125275, metric: 11.87564468383789, lr: 0.00034849741496145725
[13620] train loss: -0.07190918177366257, metric: 11.281326055526733, lr: 0.0003187299007549882
[13640] train loss: -0.0814669132232666, metric: 9.90648865699768, lr: 0.0002896849764510989
[13660] train loss: -0.16679628938436508, metric: 8.484883427619934, lr: 0.0002614784170873463
[13680] train loss: -0.26246224343776703, metric: 8.062345504760742, lr: 0.00023422270896844566
[13700] train loss: -0.2263379730284214, metric: 10.169947862625122, lr: 0.00020802643848583102
[13720] train loss: -0.2043606862425804, metric: 9.824964761734009, lr: 0.00018299407383892685
[13740] train loss: -0.17641118541359901, metric: 9.814698100090027, lr: 0.00015922538295853883
[13760] train loss: -0.1284353993833065, metric: 10.95261263847351, lr: 0.00013681512791663408
[13780] train loss: -0.06500748172402382, metric: 8.506407856941223, lr: 0.00011585262109292671
[13800] train loss: -0.03053710237145424, metric: 8.47643780708313, lr: 9.999999747378752e-05
[13820] train loss: -0.03197305276989937, metric: 9.672315239906311, lr: 9.999999747378752e-05
[13840] train loss: 3.2716417126357555, metric: 20.29508352279663, lr: 9.999999747378752e-05
[13860] train loss: 2.0549068115651608, metric: 17.03832721710205, lr: 9.999999747378752e-05
[13880] train loss: 2.2988401763141155, metric: 15.751097917556763, lr: 9.999999747378752e-05
[13900] train loss: 1.622455894947052, metric: 18.555325031280518, lr: 9.999999747378752e-05
[13920] train loss: 1.2024861574172974, metric: 20.088138580322266, lr: 9.999999747378752e-05
[13940] train loss: 0.9713436253368855, metric: 18.990053176879883, lr: 9.999999747378752e-05
[13960] train loss: 1.2354646064341068, metric: 18.657220125198364, lr: 9.999999747378752e-05
[13980] train loss: 2.2635899484157562, metric: 16.436854362487793, lr: 9.999999747378752e-05
[14000] train loss: 16.935495287179947, metric: 23.717890739440918, lr: 9.999999747378752e-05
[14020] train loss: 9.700377434492111, metric: 23.972121477127075, lr: 0.0009994393913075328
[14040] train loss: 1.7769853472709656, metric: 19.578797340393066, lr: 0.0009969500824809074
[14060] train loss: 1.2493801265954971, metric: 25.84719753265381, lr: 0.000992479850538075
[14080] train loss: 0.41113343089818954, metric: 17.74403476715088, lr: 0.000986046390607953
[14100] train loss: 0.7710759341716766, metric: 12.825792789459229, lr: 0.0009776754304766655
[14120] train loss: 3.562291242182255, metric: 15.376090049743652, lr: 0.0009674003813415766
[14140] train loss: 0.5795959196984768, metric: 15.695919036865234, lr: 0.0009552621049806476
[14160] train loss: 1.3876445926725864, metric: 13.304449915885925, lr: 0.0009413089719600976
[14180] train loss: 1.2683216519653797, metric: 15.019865036010742, lr: 0.0009255966870114207
[14200] train loss: 0.2116760089993477, metric: 13.871252298355103, lr: 0.00090818788157776
[14220] train loss: 0.27896367758512497, metric: 11.467341661453247, lr: 0.0008891518809832633
[14240] train loss: 0.9939462654292583, metric: 13.170975923538208, lr: 0.0008685645880177617
[14260] train loss: 0.4543355517089367, metric: 13.287570476531982, lr: 0.0008465081336908042
[14280] train loss: 0.04214736074209213, metric: 10.276502966880798, lr: 0.0008230703533627093
[14300] train loss: 0.07521821558475494, metric: 13.432762503623962, lr: 0.0007983447285369039
[14320] train loss: -0.1351458728313446, metric: 9.54130220413208, lr: 0.0007724298629909754
[14340] train loss: 6.098738227039576, metric: 18.22224998474121, lr: 0.0007454289589077234
[14360] train loss: 2.468070160597563, metric: 17.046332597732544, lr: 0.0007174497004598379
[14380] train loss: 2.176103960722685, metric: 19.246572256088257, lr: 0.00068860367173329
[14400] train loss: 1.6007006578147411, metric: 16.717276573181152, lr: 0.0006590057746507227
[14420] train loss: 3.188540391623974, metric: 16.20626449584961, lr: 0.0006287740543484688
[14440] train loss: 0.5452123582363129, metric: 13.921156883239746, lr: 0.000598029000684619
[14460] train loss: -0.003669366240501404, metric: 9.706210613250732, lr: 0.0005668931407853961
[14480] train loss: -0.08156359195709229, metric: 10.17973792552948, lr: 0.0005354906315915287
[14500] train loss: -0.2050546482205391, metric: 10.079305648803711, lr: 0.0005039466777816415
[14520] train loss: -0.16616461426019669, metric: 9.835713624954224, lr: 0.0004723869787994772
[14540] train loss: -0.15905657038092613, metric: 9.79354190826416, lr: 0.0004409373505041003
[14560] train loss: -0.12623018771409988, metric: 9.12266206741333, lr: 0.0004097231721971184
[14580] train loss: -0.08591188117861748, metric: 9.253076553344727, lr: 0.000378868862753734
[14600] train loss: -0.0021480731666088104, metric: 9.751381278038025, lr: 0.00034849741496145725
[14620] train loss: -0.012140635401010513, metric: 11.287134289741516, lr: 0.0003187299007549882
[14640] train loss: 0.020405899733304977, metric: 11.867371320724487, lr: 0.0002896849764510989
[14660] train loss: 0.12149187549948692, metric: 11.766071081161499, lr: 0.0002614784170873463
[14680] train loss: 0.19424264505505562, metric: 13.740662097930908, lr: 0.00023422270896844566
[14700] train loss: 1.1178458705544472, metric: 13.611676692962646, lr: 0.00020802643848583102
[14720] train loss: 6.123433593660593, metric: 19.086559295654297, lr: 0.00018299407383892685
[14740] train loss: 2.6622232869267464, metric: 17.84704065322876, lr: 0.00015922538295853883
[14760] train loss: 1.6715086549520493, metric: 16.58708906173706, lr: 0.00013681512791663408
[14780] train loss: 2.5018547773361206, metric: 19.57287621498108, lr: 0.00011585262109292671
[14800] train loss: 1.7434707581996918, metric: 21.88665270805359, lr: 9.999999747378752e-05
[14820] train loss: 0.27956923097372055, metric: 15.765235185623169, lr: 9.999999747378752e-05
[14840] train loss: 0.8122438751161098, metric: 12.18194580078125, lr: 9.999999747378752e-05
[14860] train loss: 2.4307794123888016, metric: 21.477006912231445, lr: 9.999999747378752e-05
[14880] train loss: 1.546458661556244, metric: 19.06247568130493, lr: 9.999999747378752e-05
[14900] train loss: 1.61171555519104, metric: 21.69970941543579, lr: 9.999999747378752e-05
[14920] train loss: 1.9048549979925156, metric: 19.59800100326538, lr: 9.999999747378752e-05
[14940] train loss: 1.0798733122646809, metric: 14.894125699996948, lr: 9.999999747378752e-05
[14960] train loss: 1.8650525100529194, metric: 18.618319034576416, lr: 9.999999747378752e-05
[14980] train loss: 2.168439570814371, metric: 20.07526683807373, lr: 9.999999747378752e-05
[15000] train loss: 8.344573393464088, metric: 26.756442070007324, lr: 9.999999747378752e-05
[15020] train loss: 14.750092625617981, metric: 31.1320481300354, lr: 0.0009994393913075328
[15040] train loss: 3.903450518846512, metric: 18.39458155632019, lr: 0.0009969500824809074
[15060] train loss: 1.2934058979153633, metric: 22.596468925476074, lr: 0.000992479850538075
[15080] train loss: 1.1831659898161888, metric: 20.859772205352783, lr: 0.000986046390607953
[15100] train loss: 0.4524441249668598, metric: 20.246297597885132, lr: 0.0009776754304766655
[15120] train loss: 0.6210670210421085, metric: 17.723663806915283, lr: 0.0009674003813415766
[15140] train loss: 0.5566858872771263, metric: 19.06955862045288, lr: 0.0009552621049806476
[15160] train loss: 0.2530832178890705, metric: 11.908157348632812, lr: 0.0009413089719600976
[15180] train loss: 0.34761524572968483, metric: 11.418030977249146, lr: 0.0009255966870114207
[15200] train loss: 2.8713663443922997, metric: 15.828941345214844, lr: 0.00090818788157776
[15220] train loss: 4.256475653499365, metric: 17.39711284637451, lr: 0.0008891518809832633
[15240] train loss: 0.9396327957510948, metric: 15.078910827636719, lr: 0.0008685645880177617
[15260] train loss: 0.34727367758750916, metric: 10.686559200286865, lr: 0.0008465081336908042
[15280] train loss: 0.9408429227769375, metric: 15.294342756271362, lr: 0.0008230703533627093
[15300] train loss: 4.646641124039888, metric: 15.81043815612793, lr: 0.0007983447285369039
[15320] train loss: 4.877575442194939, metric: 19.32170557975769, lr: 0.0007724298629909754
[15340] train loss: 2.334559053182602, metric: 17.292332649230957, lr: 0.0007454289589077234
[15360] train loss: 2.6590128280222416, metric: 17.679062604904175, lr: 0.0007174497004598379
[15380] train loss: -0.013578072190284729, metric: 9.193331718444824, lr: 0.00068860367173329
[15400] train loss: 0.1721671000123024, metric: 11.851484775543213, lr: 0.0006590057746507227
[15420] train loss: -0.050472892820835114, metric: 10.172298669815063, lr: 0.0006287740543484688
[15440] train loss: 0.4913788437843323, metric: 11.731807470321655, lr: 0.000598029000684619
[15460] train loss: 0.20303243026137352, metric: 13.465599060058594, lr: 0.0005668931407853961
[15480] train loss: 0.3029901348054409, metric: 14.949851751327515, lr: 0.0005354906315915287
[15500] train loss: -0.010291647166013718, metric: 12.140625953674316, lr: 0.0005039466777816415
[15520] train loss: -0.022395547479391098, metric: 9.196266412734985, lr: 0.0004723869787994772
[15540] train loss: 0.013573218137025833, metric: 10.701412439346313, lr: 0.0004409373505041003
[15560] train loss: -0.2306956760585308, metric: 9.366523742675781, lr: 0.0004097231721971184
[15580] train loss: -0.2095167264342308, metric: 9.541473150253296, lr: 0.000378868862753734
[15600] train loss: -0.07879416644573212, metric: 11.781118392944336, lr: 0.00034849741496145725
[15620] train loss: -0.04513343423604965, metric: 11.612898111343384, lr: 0.0003187299007549882
[15640] train loss: 1.053374521434307, metric: 14.167423486709595, lr: 0.0002896849764510989
[15660] train loss: 1.7037318013608456, metric: 16.70107388496399, lr: 0.0002614784170873463
[15680] train loss: 0.6905294544994831, metric: 14.515799283981323, lr: 0.00023422270896844566
[15700] train loss: 0.5985666662454605, metric: 19.102131485939026, lr: 0.00020802643848583102
[15720] train loss: 0.2957312762737274, metric: 12.41315770149231, lr: 0.00018299407383892685
[15740] train loss: 3.6475273221731186, metric: 15.507827281951904, lr: 0.00015922538295853883
[15760] train loss: 0.15367881953716278, metric: 15.7524653673172, lr: 0.00013681512791663408
[15780] train loss: 0.3004850037395954, metric: 13.570802688598633, lr: 0.00011585262109292671
[15800] train loss: 0.3093692548573017, metric: 15.422802925109863, lr: 9.999999747378752e-05
[15820] train loss: -0.03994768112897873, metric: 12.729839324951172, lr: 9.999999747378752e-05
[15840] train loss: 0.2184603475034237, metric: 11.055051565170288, lr: 9.999999747378752e-05
[15860] train loss: 0.2566666156053543, metric: 12.596501350402832, lr: 9.999999747378752e-05
[15880] train loss: 0.4071563072502613, metric: 15.110042095184326, lr: 9.999999747378752e-05
[15900] train loss: -0.031431894749403, metric: 17.43906307220459, lr: 9.999999747378752e-05
[15920] train loss: -0.09556863456964493, metric: 13.145318388938904, lr: 9.999999747378752e-05
[15940] train loss: 0.059067849069833755, metric: 11.138185501098633, lr: 9.999999747378752e-05
[15960] train loss: -0.004428364336490631, metric: 11.885550498962402, lr: 9.999999747378752e-05
[15980] train loss: -0.027655653655529022, metric: 11.94216275215149, lr: 9.999999747378752e-05
[16000] train loss: -0.08645668253302574, metric: 13.429877758026123, lr: 9.999999747378752e-05
[16020] train loss: -0.0861172154545784, metric: 10.909363269805908, lr: 0.0009994393913075328
[16040] train loss: -0.1639173924922943, metric: 9.774195432662964, lr: 0.0009969500824809074
[16060] train loss: -0.1924295872449875, metric: 8.372861742973328, lr: 0.000992479850538075
[16080] train loss: -0.24962861835956573, metric: 8.709120154380798, lr: 0.000986046390607953
[16100] train loss: -0.2860044240951538, metric: 8.935299158096313, lr: 0.0009776754304766655
[16120] train loss: -0.3174223303794861, metric: 8.3304842710495, lr: 0.0009674003813415766
[16140] train loss: -0.23042670264840126, metric: 8.992547035217285, lr: 0.0009552621049806476
[16160] train loss: -0.2598828189074993, metric: 8.165356636047363, lr: 0.0009413089719600976
[16180] train loss: -0.08069474250078201, metric: 7.858720779418945, lr: 0.0009255966870114207
[16200] train loss: -0.18982089310884476, metric: 10.631302952766418, lr: 0.00090818788157776
[16220] train loss: -0.15580957755446434, metric: 9.9402756690979, lr: 0.0008891518809832633
[16240] train loss: -0.29290635511279106, metric: 9.138877630233765, lr: 0.0008685645880177617
[16260] train loss: -0.2952904589474201, metric: 8.750460386276245, lr: 0.0008465081336908042
[16280] train loss: -0.2662026360630989, metric: 8.696566581726074, lr: 0.0008230703533627093
[16300] train loss: -0.17624100670218468, metric: 11.913343906402588, lr: 0.0007983447285369039
[16320] train loss: -0.1994682252407074, metric: 11.593557834625244, lr: 0.0007724298629909754
[16340] train loss: -0.12946690618991852, metric: 11.718786716461182, lr: 0.0007454289589077234
[16360] train loss: -0.2173241302371025, metric: 11.810887575149536, lr: 0.0007174497004598379
[16380] train loss: -0.23109149932861328, metric: 9.04062557220459, lr: 0.00068860367173329
[16400] train loss: 0.5342171005904675, metric: 10.360020875930786, lr: 0.0006590057746507227
[16420] train loss: 0.4219748377799988, metric: 9.532857179641724, lr: 0.0006287740543484688
[16440] train loss: 0.2094300463795662, metric: 9.04858112335205, lr: 0.000598029000684619
[16460] train loss: 2.3727624639868736, metric: 11.993739604949951, lr: 0.0005668931407853961
[16480] train loss: 0.0060475729405879974, metric: 10.85608196258545, lr: 0.0005354906315915287
[16500] train loss: 0.8199845626950264, metric: 9.864680051803589, lr: 0.0005039466777816415
[16520] train loss: 0.3314134329557419, metric: 11.534818649291992, lr: 0.0004723869787994772
[16540] train loss: 1.571377843618393, metric: 12.754861831665039, lr: 0.0004409373505041003
[16560] train loss: 0.7182501144707203, metric: 16.869362354278564, lr: 0.0004097231721971184
[16580] train loss: 0.3590850830078125, metric: 17.795114040374756, lr: 0.000378868862753734
[16600] train loss: 0.2631395235657692, metric: 13.186002492904663, lr: 0.00034849741496145725
[16620] train loss: 0.48048221319913864, metric: 15.366599559783936, lr: 0.0003187299007549882
[16640] train loss: 0.24404454976320267, metric: 14.214582681655884, lr: 0.0002896849764510989
[16660] train loss: 0.14468783885240555, metric: 11.51045536994934, lr: 0.0002614784170873463
[16680] train loss: 0.07341508567333221, metric: 11.967980146408081, lr: 0.00023422270896844566
[16700] train loss: 0.07308244332671165, metric: 12.50718903541565, lr: 0.00020802643848583102
[16720] train loss: -0.037927571684122086, metric: 11.74517822265625, lr: 0.00018299407383892685
[16740] train loss: -0.1209394745528698, metric: 10.693494319915771, lr: 0.00015922538295853883
[16760] train loss: -0.13661978393793106, metric: 10.077657461166382, lr: 0.00013681512791663408
[16780] train loss: -0.17835847288370132, metric: 10.616826176643372, lr: 0.00011585262109292671
[16800] train loss: -0.2006809115409851, metric: 10.238659024238586, lr: 9.999999747378752e-05
[16820] train loss: -0.01177775114774704, metric: 11.003123044967651, lr: 9.999999747378752e-05
[16840] train loss: -0.2147495597600937, metric: 8.477550268173218, lr: 9.999999747378752e-05
[16860] train loss: -0.15685853734612465, metric: 9.652437210083008, lr: 9.999999747378752e-05
[16880] train loss: -0.1820286326110363, metric: 9.026243209838867, lr: 9.999999747378752e-05
[16900] train loss: 4.693519990891218, metric: 23.377204418182373, lr: 9.999999747378752e-05
[16920] train loss: 1.6976623311638832, metric: 20.11086130142212, lr: 9.999999747378752e-05
[16940] train loss: 0.9481203630566597, metric: 14.617151021957397, lr: 9.999999747378752e-05
[16960] train loss: 1.610655002295971, metric: 12.88668417930603, lr: 9.999999747378752e-05
[16980] train loss: 1.170765146613121, metric: 13.654188871383667, lr: 9.999999747378752e-05
[17000] train loss: 0.22997963428497314, metric: 15.29369604587555, lr: 9.999999747378752e-05
[17020] train loss: 0.19030283018946648, metric: 11.291280388832092, lr: 0.0009994393913075328
[17040] train loss: 0.0051984116435050964, metric: 7.924072265625, lr: 0.0009969500824809074
[17060] train loss: -0.08610391989350319, metric: 8.870780944824219, lr: 0.000992479850538075
[17080] train loss: 0.04570380598306656, metric: 9.899761080741882, lr: 0.000986046390607953
[17100] train loss: -0.10729775577783585, metric: 9.495809078216553, lr: 0.0009776754304766655
[17120] train loss: 0.06818901002407074, metric: 11.163849711418152, lr: 0.0009674003813415766
[17140] train loss: 0.03730522468686104, metric: 9.264950275421143, lr: 0.0009552621049806476
[17160] train loss: 0.15843185037374496, metric: 11.668381929397583, lr: 0.0009413089719600976
[17180] train loss: 0.5470721460878849, metric: 11.813697814941406, lr: 0.0009255966870114207
[17200] train loss: 1.3899440355598927, metric: 15.829549670219421, lr: 0.00090818788157776
[17220] train loss: 0.7728064842522144, metric: 27.7056667804718, lr: 0.0008891518809832633
[17240] train loss: -0.028150029480457306, metric: 13.106223106384277, lr: 0.0008685645880177617
[17260] train loss: 0.15919488668441772, metric: 11.38902735710144, lr: 0.0008465081336908042
[17280] train loss: -0.11987583711743355, metric: 9.055964708328247, lr: 0.0008230703533627093
[17300] train loss: 0.2766164727509022, metric: 13.526271343231201, lr: 0.0007983447285369039
[17320] train loss: 0.12228422239422798, metric: 13.633982419967651, lr: 0.0007724298629909754
[17340] train loss: 1.3876396045088768, metric: 13.852994680404663, lr: 0.0007454289589077234
[17360] train loss: 0.21460189670324326, metric: 10.515753746032715, lr: 0.0007174497004598379
[17380] train loss: 1.0894501991569996, metric: 17.995648860931396, lr: 0.00068860367173329
[17400] train loss: 0.198553167283535, metric: 11.825886964797974, lr: 0.0006590057746507227
[17420] train loss: 1.0172691233456135, metric: 20.322657585144043, lr: 0.0006287740543484688
[17440] train loss: 0.27452629059553146, metric: 13.982651472091675, lr: 0.000598029000684619
[17460] train loss: -0.021969936788082123, metric: 13.852470397949219, lr: 0.0005668931407853961
[17480] train loss: 0.07906842604279518, metric: 13.349811553955078, lr: 0.0005354906315915287
[17500] train loss: -0.18776769191026688, metric: 10.009042501449585, lr: 0.0005039466777816415
[17520] train loss: 0.014562055468559265, metric: 14.77271556854248, lr: 0.0004723869787994772
[17540] train loss: -0.10913943871855736, metric: 10.417184829711914, lr: 0.0004409373505041003
[17560] train loss: 0.7182328589260578, metric: 15.397275924682617, lr: 0.0004097231721971184
[17580] train loss: 0.417556993663311, metric: 13.649336338043213, lr: 0.000378868862753734
[17600] train loss: 1.2668818719685078, metric: 14.499850511550903, lr: 0.00034849741496145725
[17620] train loss: 0.14381803572177887, metric: 12.308102369308472, lr: 0.0003187299007549882
[17640] train loss: 0.3160281702876091, metric: 11.108089923858643, lr: 0.0002896849764510989
[17660] train loss: 0.11744191870093346, metric: 11.188000679016113, lr: 0.0002614784170873463
[17680] train loss: -0.15829424560070038, metric: 9.755139112472534, lr: 0.00023422270896844566
[17700] train loss: -0.22458139061927795, metric: 10.827767014503479, lr: 0.00020802643848583102
[17720] train loss: -0.2412533536553383, metric: 12.06971001625061, lr: 0.00018299407383892685
[17740] train loss: -0.22847022488713264, metric: 12.211217641830444, lr: 0.00015922538295853883
[17760] train loss: -0.1740235686302185, metric: 10.953789114952087, lr: 0.00013681512791663408
[17780] train loss: -0.1547997072339058, metric: 11.515885353088379, lr: 0.00011585262109292671
[17800] train loss: -0.21784210577607155, metric: 11.02078890800476, lr: 9.999999747378752e-05
[17820] train loss: -0.21821382269263268, metric: 9.184767961502075, lr: 9.999999747378752e-05
[17840] train loss: -0.17471394315361977, metric: 10.941258430480957, lr: 9.999999747378752e-05
[17860] train loss: -0.23268534243106842, metric: 10.487846851348877, lr: 9.999999747378752e-05
[17880] train loss: 0.38912130147218704, metric: 11.836420059204102, lr: 9.999999747378752e-05
[17900] train loss: 0.011978015303611755, metric: 10.22450876235962, lr: 9.999999747378752e-05
[17920] train loss: -0.21190179511904716, metric: 10.066764831542969, lr: 9.999999747378752e-05
[17940] train loss: 0.8432044833898544, metric: 19.481087684631348, lr: 9.999999747378752e-05
[17960] train loss: 0.26108547300100327, metric: 16.443929433822632, lr: 9.999999747378752e-05
[17980] train loss: 0.08779535070061684, metric: 11.926153182983398, lr: 9.999999747378752e-05
[18000] train loss: 0.13617536053061485, metric: 14.604012727737427, lr: 9.999999747378752e-05
[18020] train loss: -0.16517379879951477, metric: 11.679089784622192, lr: 0.0009994393913075328
[18040] train loss: -0.2088763453066349, metric: 11.608339667320251, lr: 0.0009969500824809074
[18060] train loss: -0.18765952438116074, metric: 10.460512161254883, lr: 0.000992479850538075
[18080] train loss: -0.12537257000803947, metric: 9.562503218650818, lr: 0.000986046390607953
[18100] train loss: -0.1521696001291275, metric: 10.219101667404175, lr: 0.0009776754304766655
[18120] train loss: -0.018943320959806442, metric: 10.419060945510864, lr: 0.0009674003813415766
[18140] train loss: -0.2291511967778206, metric: 11.586646318435669, lr: 0.0009552621049806476
[18160] train loss: -0.29779327660799026, metric: 9.747538089752197, lr: 0.0009413089719600976
[18180] train loss: -0.23205436021089554, metric: 8.344222784042358, lr: 0.0009255966870114207
[18200] train loss: -0.2477426454424858, metric: 8.555709719657898, lr: 0.00090818788157776
[18220] train loss: 0.06485003978013992, metric: 11.07820749282837, lr: 0.0008891518809832633
[18240] train loss: 1.55844428204, metric: 14.586404800415039, lr: 0.0008685645880177617
[18260] train loss: 1.082680556923151, metric: 13.934377670288086, lr: 0.0008465081336908042
[18280] train loss: 0.6494157128036022, metric: 14.93295693397522, lr: 0.0008230703533627093
[18300] train loss: 0.5176101848483086, metric: 13.371731758117676, lr: 0.0007983447285369039
[18320] train loss: -0.1134435310959816, metric: 13.470907807350159, lr: 0.0007724298629909754
[18340] train loss: -0.16554901748895645, metric: 10.772068500518799, lr: 0.0007454289589077234
[18360] train loss: -0.23918762058019638, metric: 11.005999684333801, lr: 0.0007174497004598379
[18380] train loss: -0.20616325363516808, metric: 11.205625057220459, lr: 0.00068860367173329
[18400] train loss: -0.07802771031856537, metric: 12.59474802017212, lr: 0.0006590057746507227
[18420] train loss: 0.07187163084745407, metric: 12.898353815078735, lr: 0.0006287740543484688
[18440] train loss: 0.9747016839683056, metric: 18.33619475364685, lr: 0.000598029000684619
[18460] train loss: 0.08296282961964607, metric: 12.10614275932312, lr: 0.0005668931407853961
[18480] train loss: 0.6638927981257439, metric: 15.955770015716553, lr: 0.0005354906315915287
[18500] train loss: -0.07658946141600609, metric: 11.522542238235474, lr: 0.0005039466777816415
[18520] train loss: -0.22742680460214615, metric: 9.773468494415283, lr: 0.0004723869787994772
[18540] train loss: -0.2551681622862816, metric: 8.99760365486145, lr: 0.0004409373505041003
[18560] train loss: -0.041396960616111755, metric: 9.750274181365967, lr: 0.0004097231721971184
[18580] train loss: -0.12810562551021576, metric: 10.261316061019897, lr: 0.000378868862753734
[18600] train loss: -0.15200084447860718, metric: 10.90379285812378, lr: 0.00034849741496145725
[18620] train loss: 0.2415148988366127, metric: 12.328017711639404, lr: 0.0003187299007549882
[18640] train loss: 0.36272047832608223, metric: 12.889926433563232, lr: 0.0002896849764510989
[18660] train loss: 0.9338772594928741, metric: 13.164592981338501, lr: 0.0002614784170873463
[18680] train loss: 1.3355908803641796, metric: 14.281554460525513, lr: 0.00023422270896844566
[18700] train loss: 1.9343725331127644, metric: 14.580899953842163, lr: 0.00020802643848583102
[18720] train loss: 1.3706300482153893, metric: 13.6520357131958, lr: 0.00018299407383892685
[18740] train loss: 0.2974996939301491, metric: 11.861557960510254, lr: 0.00015922538295853883
[18760] train loss: 2.154260005801916, metric: 14.111961364746094, lr: 0.00013681512791663408
[18780] train loss: 9.127398438751698, metric: 17.577995777130127, lr: 0.00011585262109292671
[18800] train loss: 3.423028666526079, metric: 13.884737491607666, lr: 9.999999747378752e-05
[18820] train loss: 0.3676213510334492, metric: 11.324584126472473, lr: 9.999999747378752e-05
[18840] train loss: 0.1451553851366043, metric: 9.766882538795471, lr: 9.999999747378752e-05
[18860] train loss: 4.529151950031519, metric: 16.927332639694214, lr: 9.999999747378752e-05
[18880] train loss: 1.291426982730627, metric: 15.438378810882568, lr: 9.999999747378752e-05
[18900] train loss: 3.5320026502013206, metric: 17.05134081840515, lr: 9.999999747378752e-05
[18920] train loss: 0.5777287222445011, metric: 14.473650217056274, lr: 9.999999747378752e-05
[18940] train loss: 3.5012140162289143, metric: 16.877999782562256, lr: 9.999999747378752e-05
[18960] train loss: 0.30389904603362083, metric: 11.289042234420776, lr: 9.999999747378752e-05
[18980] train loss: 0.0704989992082119, metric: 11.975507974624634, lr: 9.999999747378752e-05
[19000] train loss: 0.24365373328328133, metric: 11.11850094795227, lr: 9.999999747378752e-05
[19020] train loss: -0.26566048339009285, metric: 8.89021372795105, lr: 0.0009994393913075328
[19040] train loss: -0.2974902167916298, metric: 7.931930780410767, lr: 0.0009969500824809074
[19060] train loss: -0.31394725292921066, metric: 6.814840316772461, lr: 0.000992479850538075
[19080] train loss: -0.34184712171554565, metric: 6.789501428604126, lr: 0.000986046390607953
[19100] train loss: -0.3352145031094551, metric: 6.844985127449036, lr: 0.0009776754304766655
[19120] train loss: -0.3096085749566555, metric: 7.079344630241394, lr: 0.0009674003813415766
[19140] train loss: -0.31387846916913986, metric: 8.094375252723694, lr: 0.0009552621049806476
[19160] train loss: -0.33378471434116364, metric: 6.795032262802124, lr: 0.0009413089719600976
[19180] train loss: -0.3478803187608719, metric: 6.714273691177368, lr: 0.0009255966870114207
[19200] train loss: -0.31425150483846664, metric: 7.052242159843445, lr: 0.00090818788157776
[19220] train loss: -0.3494977802038193, metric: 6.6882137060165405, lr: 0.0008891518809832633
[19240] train loss: -0.35659489035606384, metric: 6.944084048271179, lr: 0.0008685645880177617
[19260] train loss: -0.3549278527498245, metric: 7.24611496925354, lr: 0.0008465081336908042
[19280] train loss: -0.38355039805173874, metric: 6.347429394721985, lr: 0.0008230703533627093
[19300] train loss: -0.3821549043059349, metric: 6.6467626094818115, lr: 0.0007983447285369039
[19320] train loss: -0.35827066004276276, metric: 6.676221966743469, lr: 0.0007724298629909754
[19340] train loss: -0.36883705854415894, metric: 6.6946693658828735, lr: 0.0007454289589077234
[19360] train loss: -0.3518417999148369, metric: 6.859886884689331, lr: 0.0007174497004598379
[19380] train loss: -0.3561481684446335, metric: 7.132658004760742, lr: 0.00068860367173329
[19400] train loss: -0.353446401655674, metric: 7.810981512069702, lr: 0.0006590057746507227
[19420] train loss: -0.3616892471909523, metric: 7.494451999664307, lr: 0.0006287740543484688
[19440] train loss: -0.3406580165028572, metric: 7.855701804161072, lr: 0.000598029000684619
[19460] train loss: 0.6301308572292328, metric: 15.860527992248535, lr: 0.0005668931407853961
[19480] train loss: 0.054134078323841095, metric: 9.544495344161987, lr: 0.0005354906315915287
[19500] train loss: -0.1957005113363266, metric: 10.103364109992981, lr: 0.0005039466777816415
[19520] train loss: -0.027313679456710815, metric: 9.970477104187012, lr: 0.0004723869787994772
[19540] train loss: 0.4266761615872383, metric: 10.500537157058716, lr: 0.0004409373505041003
[19560] train loss: -0.04049217328429222, metric: 9.96353530883789, lr: 0.0004097231721971184
[19580] train loss: -0.0035286173224449158, metric: 10.253648281097412, lr: 0.000378868862753734
[19600] train loss: 0.23190838098526, metric: 11.090487480163574, lr: 0.00034849741496145725
[19620] train loss: 0.4923790916800499, metric: 11.98485279083252, lr: 0.0003187299007549882
[19640] train loss: 0.19029948115348816, metric: 11.142150402069092, lr: 0.0002896849764510989
[19660] train loss: -0.15321137383580208, metric: 10.58649492263794, lr: 0.0002614784170873463
[19680] train loss: 0.016155071556568146, metric: 12.420351028442383, lr: 0.00023422270896844566
[19700] train loss: -0.10802125930786133, metric: 11.189201593399048, lr: 0.00020802643848583102
[19720] train loss: -0.2293885573744774, metric: 9.933679819107056, lr: 0.00018299407383892685
[19740] train loss: -0.24939924106001854, metric: 9.292674899101257, lr: 0.00015922538295853883
[19760] train loss: -0.2993275187909603, metric: 7.647859811782837, lr: 0.00013681512791663408
[19780] train loss: -0.29991229623556137, metric: 8.903363108634949, lr: 0.00011585262109292671
[19800] train loss: -0.18513613939285278, metric: 8.5779869556427, lr: 9.999999747378752e-05
[19820] train loss: -0.08640880137681961, metric: 8.9021155834198, lr: 9.999999747378752e-05
[19840] train loss: -0.14700965583324432, metric: 8.088585019111633, lr: 9.999999747378752e-05
[19860] train loss: -0.16902534663677216, metric: 8.870716094970703, lr: 9.999999747378752e-05
[19880] train loss: -0.25853998586535454, metric: 7.610477447509766, lr: 9.999999747378752e-05
[19900] train loss: -0.20712973549962044, metric: 8.62633490562439, lr: 9.999999747378752e-05
[19920] train loss: -0.2079179435968399, metric: 8.523560881614685, lr: 9.999999747378752e-05
[19940] train loss: -0.26803888380527496, metric: 8.555717825889587, lr: 9.999999747378752e-05
[19960] train loss: -0.2988253980875015, metric: 10.429408311843872, lr: 9.999999747378752e-05
[19980] train loss: 3.6153392493724823, metric: 20.429909229278564, lr: 9.999999747378752e-05
[20000] train loss: 1.2972413785755634, metric: 15.079971551895142, lr: 9.999999747378752e-05
[20020] train loss: 0.31196435168385506, metric: 14.698126792907715, lr: 0.0009994393913075328
[20040] train loss: 0.4160122983157635, metric: 11.841840505599976, lr: 0.0009969500824809074
[20060] train loss: 0.5508795715868473, metric: 13.583436250686646, lr: 0.000992479850538075
[20080] train loss: 0.1211613230407238, metric: 16.112037181854248, lr: 0.000986046390607953
[20100] train loss: -0.007870372384786606, metric: 14.334511995315552, lr: 0.0009776754304766655
[20120] train loss: -0.0569884218275547, metric: 13.536012172698975, lr: 0.0009674003813415766
[20140] train loss: -0.17119713127613068, metric: 11.039162158966064, lr: 0.0009552621049806476
[20160] train loss: -0.0775420181453228, metric: 9.952452182769775, lr: 0.0009413089719600976
[20180] train loss: 0.08090008422732353, metric: 12.874288558959961, lr: 0.0009255966870114207
[20200] train loss: 0.022167719900608063, metric: 14.849884510040283, lr: 0.00090818788157776
[20220] train loss: 0.020639769732952118, metric: 13.67025876045227, lr: 0.0008891518809832633
[20240] train loss: -0.03398485109210014, metric: 12.192633867263794, lr: 0.0008685645880177617
[20260] train loss: -0.15915470570325851, metric: 11.682405471801758, lr: 0.0008465081336908042
[20280] train loss: -0.09776237607002258, metric: 10.786370038986206, lr: 0.0008230703533627093
[20300] train loss: -0.20527811348438263, metric: 7.841923356056213, lr: 0.0007983447285369039
[20320] train loss: 0.021056171506643295, metric: 12.619221925735474, lr: 0.0007724298629909754
[20340] train loss: 1.2913093492388725, metric: 11.15107011795044, lr: 0.0007454289589077234
[20360] train loss: 0.09719856083393097, metric: 12.324899196624756, lr: 0.0007174497004598379
[20380] train loss: 0.09244231134653091, metric: 10.914237022399902, lr: 0.00068860367173329
[20400] train loss: -0.11066005378961563, metric: 9.206546545028687, lr: 0.0006590057746507227
[20420] train loss: -0.1035478226840496, metric: 11.50110387802124, lr: 0.0006287740543484688
[20440] train loss: -0.1207818016409874, metric: 11.514568328857422, lr: 0.000598029000684619
[20460] train loss: -0.07326588407158852, metric: 10.095332622528076, lr: 0.0005668931407853961
[20480] train loss: -0.23087414167821407, metric: 9.798750042915344, lr: 0.0005354906315915287
[20500] train loss: 0.5470281131565571, metric: 11.316723346710205, lr: 0.0005039466777816415
[20520] train loss: 0.06505004316568375, metric: 8.732231140136719, lr: 0.0004723869787994772
[20540] train loss: -0.11888664960861206, metric: 9.124335527420044, lr: 0.0004409373505041003
[20560] train loss: -0.07055186107754707, metric: 8.57755696773529, lr: 0.0004097231721971184
[20580] train loss: 0.07351389527320862, metric: 9.687777400016785, lr: 0.000378868862753734
[20600] train loss: 0.0790468230843544, metric: 9.912648797035217, lr: 0.00034849741496145725
[20620] train loss: 0.6967642270028591, metric: 9.82469892501831, lr: 0.0003187299007549882
[20640] train loss: 0.35605014488101006, metric: 12.08644700050354, lr: 0.0002896849764510989
[20660] train loss: 0.7635772451758385, metric: 10.55612587928772, lr: 0.0002614784170873463
[20680] train loss: 1.4161053523421288, metric: 12.163791418075562, lr: 0.00023422270896844566
[20700] train loss: 1.6104144975543022, metric: 13.26312780380249, lr: 0.00020802643848583102
[20720] train loss: 0.5375283509492874, metric: 10.94690203666687, lr: 0.00018299407383892685
[20740] train loss: 0.7393742762506008, metric: 9.849469661712646, lr: 0.00015922538295853883
[20760] train loss: 3.6723606176674366, metric: 14.963456392288208, lr: 0.00013681512791663408
[20780] train loss: 3.992498006671667, metric: 15.802570343017578, lr: 0.00011585262109292671
[20800] train loss: 4.509263761341572, metric: 18.47142720222473, lr: 9.999999747378752e-05
[20820] train loss: 0.47485895082354546, metric: 9.76998257637024, lr: 9.999999747378752e-05
[20840] train loss: 0.6645925305783749, metric: 14.032202243804932, lr: 9.999999747378752e-05
[20860] train loss: 0.6053303331136703, metric: 12.299829483032227, lr: 9.999999747378752e-05
[20880] train loss: 0.9246784336864948, metric: 11.492403984069824, lr: 9.999999747378752e-05
[20900] train loss: 1.3844338469207287, metric: 17.01668405532837, lr: 9.999999747378752e-05
[20920] train loss: 3.137673530727625, metric: 17.54620862007141, lr: 9.999999747378752e-05
[20940] train loss: 3.2433425188064575, metric: 15.62704610824585, lr: 9.999999747378752e-05
[20960] train loss: 2.3106711953878403, metric: 15.290915966033936, lr: 9.999999747378752e-05
[20980] train loss: 0.5890933275222778, metric: 15.380383968353271, lr: 9.999999747378752e-05
[21000] train loss: 1.7723426222801208, metric: 18.255991220474243, lr: 9.999999747378752e-05
[21020] train loss: 0.4934038184583187, metric: 11.210282325744629, lr: 0.0009994393913075328
[21040] train loss: -0.09808738902211189, metric: 11.068570613861084, lr: 0.0009969500824809074
[21060] train loss: 0.32204999029636383, metric: 9.841285943984985, lr: 0.000992479850538075
[21080] train loss: 0.04422133415937424, metric: 9.859207391738892, lr: 0.000986046390607953
[21100] train loss: -0.043582733720541, metric: 10.219371557235718, lr: 0.0009776754304766655
[21120] train loss: 2.057115573436022, metric: 13.162971019744873, lr: 0.0009674003813415766
[21140] train loss: 2.3281882405281067, metric: 11.320621013641357, lr: 0.0009552621049806476
[21160] train loss: 2.0049028508365154, metric: 11.63396418094635, lr: 0.0009413089719600976
[21180] train loss: 0.9887004680931568, metric: 17.16661036014557, lr: 0.0009255966870114207
[21200] train loss: 1.6627643890678883, metric: 15.645159006118774, lr: 0.00090818788157776
[21220] train loss: 0.4396452233195305, metric: 13.39845323562622, lr: 0.0008891518809832633
[21240] train loss: 1.2255020923912525, metric: 13.804490327835083, lr: 0.0008685645880177617
[21260] train loss: 1.4247093722224236, metric: 12.78628158569336, lr: 0.0008465081336908042
[21280] train loss: 0.3953132629394531, metric: 13.334864020347595, lr: 0.0008230703533627093
[21300] train loss: 1.74029890447855, metric: 13.194785594940186, lr: 0.0007983447285369039
[21320] train loss: 1.1188043057918549, metric: 12.019493818283081, lr: 0.0007724298629909754
[21340] train loss: 0.5855469219386578, metric: 15.523036241531372, lr: 0.0007454289589077234
[21360] train loss: 0.9966567978262901, metric: 14.942379474639893, lr: 0.0007174497004598379
[21380] train loss: 1.2080189883708954, metric: 14.079969882965088, lr: 0.00068860367173329
[21400] train loss: 1.7758829146623611, metric: 15.161768913269043, lr: 0.0006590057746507227
[21420] train loss: 3.6442648842930794, metric: 19.136152982711792, lr: 0.0006287740543484688
[21440] train loss: 2.3076013028621674, metric: 17.93031632900238, lr: 0.000598029000684619
[21460] train loss: 2.96992127597332, metric: 16.734724521636963, lr: 0.0005668931407853961
[21480] train loss: 0.5570634007453918, metric: 17.013001203536987, lr: 0.0005354906315915287
[21500] train loss: 2.5174838304519653, metric: 15.398903608322144, lr: 0.0005039466777816415
[21520] train loss: 3.088804602622986, metric: 21.174981594085693, lr: 0.0004723869787994772
[21540] train loss: 9.061604034155607, metric: 21.34017324447632, lr: 0.0004409373505041003
[21560] train loss: 1.3876415938138962, metric: 14.190629959106445, lr: 0.0004097231721971184
[21580] train loss: 8.472825676202774, metric: 24.985710620880127, lr: 0.000378868862753734
[21600] train loss: 5.9221896678209305, metric: 16.967068672180176, lr: 0.00034849741496145725
[21620] train loss: 3.017684645950794, metric: 15.095555782318115, lr: 0.0003187299007549882
[21640] train loss: 0.9348628185689449, metric: 15.770060062408447, lr: 0.0002896849764510989
[21660] train loss: 0.4012921713292599, metric: 15.34195327758789, lr: 0.0002614784170873463
[21680] train loss: 1.0515263229608536, metric: 13.261708498001099, lr: 0.00023422270896844566
[21700] train loss: 1.6551572941243649, metric: 19.71762466430664, lr: 0.00020802643848583102
[21720] train loss: 4.1970987394452095, metric: 18.440110206604004, lr: 0.00018299407383892685
[21740] train loss: 0.42798155173659325, metric: 13.971319198608398, lr: 0.00015922538295853883
[21760] train loss: 1.570710502564907, metric: 15.440362215042114, lr: 0.00013681512791663408
[21780] train loss: 0.746242068707943, metric: 15.77773380279541, lr: 0.00011585262109292671
[21800] train loss: 1.8266734667122364, metric: 21.29943323135376, lr: 9.999999747378752e-05
[21820] train loss: 2.083954893052578, metric: 19.320550680160522, lr: 9.999999747378752e-05
[21840] train loss: 1.6815896704792976, metric: 16.19644594192505, lr: 9.999999747378752e-05
[21860] train loss: 0.606220331043005, metric: 13.691644430160522, lr: 9.999999747378752e-05
[21880] train loss: 0.4712267257273197, metric: 14.227832078933716, lr: 9.999999747378752e-05
[21900] train loss: 1.0354484915733337, metric: 14.159356355667114, lr: 9.999999747378752e-05
[21920] train loss: 0.2951716296374798, metric: 12.623663902282715, lr: 9.999999747378752e-05
[21940] train loss: 0.022909753024578094, metric: 11.756803035736084, lr: 9.999999747378752e-05
[21960] train loss: 0.32426873594522476, metric: 10.086579322814941, lr: 9.999999747378752e-05
[21980] train loss: 0.5954243093729019, metric: 11.359519481658936, lr: 9.999999747378752e-05
[22000] train loss: 3.2293342016637325, metric: 14.025755643844604, lr: 9.999999747378752e-05
[20] train loss: 0.03380591422319412, metric: 12.781654834747314, lr: 0.0009994393913075328
[40] train loss: -0.2339312918484211, metric: 10.307808518409729, lr: 0.0009969500824809074
[60] train loss: 0.42570869997143745, metric: 10.708899736404419, lr: 0.000992479850538075
[80] train loss: -0.14646915346384048, metric: 9.013716340065002, lr: 0.000986046390607953
[100] train loss: 0.11208588629961014, metric: 12.007896900177002, lr: 0.0009776754304766655
[120] train loss: 0.19270772114396095, metric: 11.408053398132324, lr: 0.0009674003813415766
[140] train loss: 1.4231700003147125, metric: 11.297620296478271, lr: 0.0009552621049806476
[160] train loss: 0.07006605714559555, metric: 11.449561595916748, lr: 0.0009413089719600976
[180] train loss: -0.16307619214057922, metric: 12.246611833572388, lr: 0.0009255966870114207
[200] train loss: -0.23654939979314804, metric: 9.83516788482666, lr: 0.00090818788157776
[220] train loss: -0.3200036287307739, metric: 9.146978378295898, lr: 0.0008891518809832633
[240] train loss: -0.29403330385684967, metric: 8.762109756469727, lr: 0.0008685645880177617
[260] train loss: 5.045609705150127, metric: 22.10697078704834, lr: 0.0008465081336908042
[280] train loss: 0.4622627906501293, metric: 12.447097539901733, lr: 0.0008230703533627093
[300] train loss: 0.5160956345498562, metric: 11.599363327026367, lr: 0.0007983447285369039
[320] train loss: 0.04957566037774086, metric: 13.426220655441284, lr: 0.0007724298629909754
[340] train loss: -0.09728263691067696, metric: 9.722309350967407, lr: 0.0007454289589077234
[360] train loss: 0.4712245389819145, metric: 10.652686595916748, lr: 0.0007174497004598379
[380] train loss: 0.18670319393277168, metric: 14.238810539245605, lr: 0.00068860367173329
[400] train loss: 0.2790635675191879, metric: 11.61492109298706, lr: 0.0006590057746507227
[420] train loss: 0.010010816156864166, metric: 10.782794952392578, lr: 0.0006287740543484688
[440] train loss: 0.09635286405682564, metric: 10.556579351425171, lr: 0.000598029000684619
[460] train loss: -0.012037351727485657, metric: 10.576863288879395, lr: 0.0005668931407853961
[480] train loss: -0.1270044557750225, metric: 11.652996063232422, lr: 0.0005354906315915287
[500] train loss: -0.15196707472205162, metric: 8.774307489395142, lr: 0.0005039466777816415
[520] train loss: 1.1649833172559738, metric: 16.29274010658264, lr: 0.0004723869787994772
[540] train loss: 0.37098683789372444, metric: 14.088086247444153, lr: 0.0004409373505041003
[560] train loss: -0.027330301702022552, metric: 11.504356622695923, lr: 0.0004097231721971184
[580] train loss: -0.08776787668466568, metric: 12.564579725265503, lr: 0.000378868862753734
[600] train loss: -0.2525259032845497, metric: 10.590343236923218, lr: 0.00034849741496145725
[620] train loss: -0.25458307564258575, metric: 11.067901253700256, lr: 0.0003187299007549882
[640] train loss: -0.2920869216322899, metric: 11.415796279907227, lr: 0.0002896849764510989
[660] train loss: -0.2756946422159672, metric: 10.52534556388855, lr: 0.0002614784170873463
[680] train loss: -0.32229533791542053, metric: 10.74910306930542, lr: 0.00023422270896844566
[700] train loss: -0.3067081458866596, metric: 11.188522815704346, lr: 0.00020802643848583102
[720] train loss: -0.2332019917666912, metric: 12.071115970611572, lr: 0.00018299407383892685
[740] train loss: -0.2963963449001312, metric: 11.8533296585083, lr: 0.00015922538295853883
[760] train loss: -0.29092393070459366, metric: 11.966265439987183, lr: 0.00013681512791663408
[780] train loss: 0.16145367920398712, metric: 15.180103063583374, lr: 0.00011585262109292671
[800] train loss: -0.19864482060074806, metric: 10.25934886932373, lr: 9.999999747378752e-05
[820] train loss: -0.1633525714278221, metric: 10.491230487823486, lr: 9.999999747378752e-05
[840] train loss: -0.16829859092831612, metric: 10.238602876663208, lr: 9.999999747378752e-05
[860] train loss: -0.20019033551216125, metric: 9.421278357505798, lr: 9.999999747378752e-05
[880] train loss: -0.22900070995092392, metric: 9.72397756576538, lr: 9.999999747378752e-05
[900] train loss: -0.30013061687350273, metric: 10.45169472694397, lr: 9.999999747378752e-05
[920] train loss: -0.29306192696094513, metric: 9.276373624801636, lr: 9.999999747378752e-05
[940] train loss: -0.23337161168456078, metric: 8.859544277191162, lr: 9.999999747378752e-05
[960] train loss: -0.0951249711215496, metric: 9.947039127349854, lr: 9.999999747378752e-05
[980] train loss: -0.07400021329522133, metric: 9.855827331542969, lr: 9.999999747378752e-05
[1000] train loss: -0.23883258923888206, metric: 8.655317544937134, lr: 9.999999747378752e-05
[1020] train loss: -0.31306274235248566, metric: 9.212865352630615, lr: 0.0009994393913075328
[1040] train loss: 0.03564368933439255, metric: 10.092082262039185, lr: 0.0009969500824809074
[1060] train loss: -0.11669032648205757, metric: 10.492305517196655, lr: 0.000992479850538075
[1080] train loss: -0.25396787002682686, metric: 8.632020831108093, lr: 0.000986046390607953
[1100] train loss: -0.2803991213440895, metric: 8.923062682151794, lr: 0.0009776754304766655
[1120] train loss: -0.16820164769887924, metric: 7.864263534545898, lr: 0.0009674003813415766
[1140] train loss: -0.15344449132680893, metric: 8.770913362503052, lr: 0.0009552621049806476
[1160] train loss: 0.09137468039989471, metric: 9.902585744857788, lr: 0.0009413089719600976
[1180] train loss: 0.242071732878685, metric: 13.825368165969849, lr: 0.0009255966870114207
[1200] train loss: -0.15669255331158638, metric: 12.531112790107727, lr: 0.00090818788157776
[1220] train loss: -0.07706399261951447, metric: 9.732950687408447, lr: 0.0008891518809832633
[1240] train loss: -0.030297480523586273, metric: 10.35261869430542, lr: 0.0008685645880177617
[1260] train loss: 0.8175212889909744, metric: 9.18521761894226, lr: 0.0008465081336908042
[1280] train loss: 0.009582530707120895, metric: 10.440466165542603, lr: 0.0008230703533627093
[1300] train loss: -0.10493160411715508, metric: 12.011903285980225, lr: 0.0007983447285369039
[1320] train loss: -0.27444958314299583, metric: 8.19678521156311, lr: 0.0007724298629909754
[1340] train loss: -0.2557222209870815, metric: 8.532105922698975, lr: 0.0007454289589077234
[1360] train loss: -0.30770812183618546, metric: 8.30094313621521, lr: 0.0007174497004598379
[1380] train loss: -0.31206315755844116, metric: 8.306426644325256, lr: 0.00068860367173329
[1400] train loss: -0.28966574370861053, metric: 10.302950978279114, lr: 0.0006590057746507227
[1420] train loss: -0.2813786342740059, metric: 11.998120546340942, lr: 0.0006287740543484688
[1440] train loss: -0.21979328617453575, metric: 9.993475198745728, lr: 0.000598029000684619
[1460] train loss: -0.03884759545326233, metric: 9.572998762130737, lr: 0.0005668931407853961
[1480] train loss: 0.20305204764008522, metric: 10.231249570846558, lr: 0.0005354906315915287
[1500] train loss: 0.11443318799138069, metric: 11.188590049743652, lr: 0.0005039466777816415
[1520] train loss: 0.14770249649882317, metric: 10.500394344329834, lr: 0.0004723869787994772
[1540] train loss: 9.857862077653408, metric: 21.86428666114807, lr: 0.0004409373505041003
[1560] train loss: 4.844907786697149, metric: 13.67985725402832, lr: 0.0004097231721971184
[1580] train loss: 2.266150940209627, metric: 13.368967056274414, lr: 0.000378868862753734
[1600] train loss: 2.2343404963612556, metric: 12.42747163772583, lr: 0.00034849741496145725
[1620] train loss: 3.2424583435058594, metric: 14.221361637115479, lr: 0.0003187299007549882
[1640] train loss: 0.36122188717126846, metric: 15.003570556640625, lr: 0.0002896849764510989
[1660] train loss: -0.16848434507846832, metric: 11.109484076499939, lr: 0.0002614784170873463
[1680] train loss: -0.08175938576459885, metric: 9.822005987167358, lr: 0.00023422270896844566
[1700] train loss: -0.1425226554274559, metric: 9.871394634246826, lr: 0.00020802643848583102
[1720] train loss: 0.4386945106089115, metric: 9.481907606124878, lr: 0.00018299407383892685
[1740] train loss: -0.0628700964152813, metric: 9.133074522018433, lr: 0.00015922538295853883
[1760] train loss: 0.12760647013783455, metric: 9.189547777175903, lr: 0.00013681512791663408
[1780] train loss: -0.13681327551603317, metric: 8.581376552581787, lr: 0.00011585262109292671
[1800] train loss: 5.130282565951347, metric: 20.309245109558105, lr: 9.999999747378752e-05
[1820] train loss: 2.861721456050873, metric: 20.40535342693329, lr: 9.999999747378752e-05
[1840] train loss: 10.078487906605005, metric: 20.894991755485535, lr: 9.999999747378752e-05
[1860] train loss: 3.2666166871786118, metric: 16.22517681121826, lr: 9.999999747378752e-05
[1880] train loss: 1.6056257598102093, metric: 14.183947563171387, lr: 9.999999747378752e-05
[1900] train loss: 0.6078933104872704, metric: 15.039776802062988, lr: 9.999999747378752e-05
[1920] train loss: 3.135381445288658, metric: 17.589642763137817, lr: 9.999999747378752e-05
[1940] train loss: 4.507089961320162, metric: 15.589594602584839, lr: 9.999999747378752e-05
[1960] train loss: 3.312245760113001, metric: 18.745460510253906, lr: 9.999999747378752e-05
[1980] train loss: 1.1181747056543827, metric: 18.224874019622803, lr: 9.999999747378752e-05
[2000] train loss: 11.035237696021795, metric: 25.075564861297607, lr: 9.999999747378752e-05
[2020] train loss: 2.2862622141838074, metric: 20.13998317718506, lr: 0.0009994393913075328
[2040] train loss: 2.6342408508062363, metric: 17.73845100402832, lr: 0.0009969500824809074
[2060] train loss: 0.8664363622665405, metric: 16.884541511535645, lr: 0.000992479850538075
[2080] train loss: 0.09710737690329552, metric: 12.307666301727295, lr: 0.000986046390607953
[2100] train loss: 2.540206853300333, metric: 13.86124849319458, lr: 0.0009776754304766655
[2120] train loss: 0.19124162569642067, metric: 15.158538818359375, lr: 0.0009674003813415766
[2140] train loss: 0.018021173775196075, metric: 10.48904037475586, lr: 0.0009552621049806476
[2160] train loss: 2.463680800050497, metric: 16.50475525856018, lr: 0.0009413089719600976
[2180] train loss: 0.7761404998600483, metric: 13.776847839355469, lr: 0.0009255966870114207
[2200] train loss: 4.52141122892499, metric: 22.28399157524109, lr: 0.00090818788157776
[2220] train loss: 0.4107348620891571, metric: 15.32947850227356, lr: 0.0008891518809832633
[2240] train loss: 0.37526337802410126, metric: 16.93062400817871, lr: 0.0008685645880177617
[2260] train loss: 0.4929288476705551, metric: 14.254969835281372, lr: 0.0008465081336908042
[2280] train loss: -0.018664207309484482, metric: 13.515764236450195, lr: 0.0008230703533627093
[2300] train loss: 0.19245924055576324, metric: 13.127582788467407, lr: 0.0007983447285369039
[2320] train loss: 0.6590363904833794, metric: 16.337637186050415, lr: 0.0007724298629909754
[2340] train loss: 0.6446524001657963, metric: 14.244986772537231, lr: 0.0007454289589077234
[2360] train loss: 0.3232879675924778, metric: 13.917726039886475, lr: 0.0007174497004598379
[2380] train loss: 0.31278395280241966, metric: 14.318200826644897, lr: 0.00068860367173329
[2400] train loss: 0.08011556044220924, metric: 10.858327150344849, lr: 0.0006590057746507227
[2420] train loss: -0.07844427227973938, metric: 10.547933340072632, lr: 0.0006287740543484688
[2440] train loss: -0.11050017550587654, metric: 10.43351674079895, lr: 0.000598029000684619
[2460] train loss: 0.32044441625475883, metric: 13.901915788650513, lr: 0.0005668931407853961
[2480] train loss: 0.4355399049818516, metric: 13.41927433013916, lr: 0.0005354906315915287
[2500] train loss: 0.0691404715180397, metric: 11.115022897720337, lr: 0.0005039466777816415
[2520] train loss: 0.22338685765862465, metric: 13.258388757705688, lr: 0.0004723869787994772
[2540] train loss: 0.8514698259532452, metric: 18.555604457855225, lr: 0.0004409373505041003
[2560] train loss: 1.2500807605683804, metric: 13.81769609451294, lr: 0.0004097231721971184
[2580] train loss: 0.5111934058368206, metric: 22.173545837402344, lr: 0.000378868862753734
[2600] train loss: 0.13252003863453865, metric: 20.45128870010376, lr: 0.00034849741496145725
[2620] train loss: -0.013680517673492432, metric: 14.888766288757324, lr: 0.0003187299007549882
[2640] train loss: 0.12977521494030952, metric: 13.60317349433899, lr: 0.0002896849764510989
[2660] train loss: 0.21683109924197197, metric: 12.555976390838623, lr: 0.0002614784170873463
[2680] train loss: -0.0023132115602493286, metric: 13.976392984390259, lr: 0.00023422270896844566
[2700] train loss: -0.1427416056394577, metric: 11.842082500457764, lr: 0.00020802643848583102
[2720] train loss: -0.15697312727570534, metric: 12.902065992355347, lr: 0.00018299407383892685
[2740] train loss: -0.0025412291288375854, metric: 12.24656343460083, lr: 0.00015922538295853883
[2760] train loss: 0.3521027937531471, metric: 12.546301364898682, lr: 0.00013681512791663408
[2780] train loss: 0.24991277232766151, metric: 14.055423736572266, lr: 0.00011585262109292671
[2800] train loss: 0.016234371811151505, metric: 13.002301692962646, lr: 9.999999747378752e-05
[2820] train loss: 4.94054502248764, metric: 24.122649669647217, lr: 9.999999747378752e-05
[2840] train loss: 1.2507588937878609, metric: 17.21201252937317, lr: 9.999999747378752e-05
[2860] train loss: 0.7726212590932846, metric: 16.418789386749268, lr: 9.999999747378752e-05
[2880] train loss: 0.7447634935379028, metric: 17.910093784332275, lr: 9.999999747378752e-05
[2900] train loss: 2.7152232825756073, metric: 18.567429542541504, lr: 9.999999747378752e-05
[2920] train loss: 6.795233186334372, metric: 19.09047293663025, lr: 9.999999747378752e-05
[2940] train loss: 4.443819474428892, metric: 20.41559934616089, lr: 9.999999747378752e-05
[2960] train loss: 2.428672008216381, metric: 18.647969722747803, lr: 9.999999747378752e-05
[2980] train loss: 1.010920636355877, metric: 15.659469604492188, lr: 9.999999747378752e-05
[3000] train loss: 1.4976701699197292, metric: 14.556342601776123, lr: 9.999999747378752e-05
[3020] train loss: 1.1931849606335163, metric: 13.153889417648315, lr: 0.0009994393913075328
[3040] train loss: 0.9228731077164412, metric: 12.457438468933105, lr: 0.0009969500824809074
[3060] train loss: 0.8855327479541302, metric: 13.12699842453003, lr: 0.000992479850538075
[3080] train loss: 0.7180787995457649, metric: 14.617539167404175, lr: 0.000986046390607953
[3100] train loss: -0.010335549712181091, metric: 10.683855533599854, lr: 0.0009776754304766655
[3120] train loss: -0.15315604209899902, metric: 11.066157579421997, lr: 0.0009674003813415766
[3140] train loss: -0.20491625741124153, metric: 13.886562585830688, lr: 0.0009552621049806476
[3160] train loss: -0.11052283272147179, metric: 13.707210063934326, lr: 0.0009413089719600976
[3180] train loss: -0.22405871748924255, metric: 11.556224584579468, lr: 0.0009255966870114207
[3200] train loss: -0.12890223786234856, metric: 10.188133239746094, lr: 0.00090818788157776
[3220] train loss: -0.0014783143997192383, metric: 11.043412685394287, lr: 0.0008891518809832633
[3240] train loss: -0.170235738158226, metric: 11.746952533721924, lr: 0.0008685645880177617
[3260] train loss: -0.05732687562704086, metric: 13.541202068328857, lr: 0.0008465081336908042
[3280] train loss: -0.06186055764555931, metric: 10.814380884170532, lr: 0.0008230703533627093
[3300] train loss: 0.43425116315484047, metric: 11.691833257675171, lr: 0.0007983447285369039
[3320] train loss: 0.07049035653471947, metric: 10.660861730575562, lr: 0.0007724298629909754
[3340] train loss: 0.15855764970183372, metric: 15.06877851486206, lr: 0.0007454289589077234
[3360] train loss: 0.016457784920930862, metric: 14.275217294692993, lr: 0.0007174497004598379
[3380] train loss: -0.21478596702218056, metric: 12.345376253128052, lr: 0.00068860367173329
[3400] train loss: -0.0243813619017601, metric: 12.57449984550476, lr: 0.0006590057746507227
[3420] train loss: 0.055362097918987274, metric: 13.009392261505127, lr: 0.0006287740543484688
[3440] train loss: 0.0557207316160202, metric: 11.948332786560059, lr: 0.000598029000684619
[3460] train loss: 0.6285099983215332, metric: 12.160192966461182, lr: 0.0005668931407853961
[3480] train loss: 0.39121808111667633, metric: 13.231046915054321, lr: 0.0005354906315915287
[3500] train loss: 2.6321600526571274, metric: 15.192833423614502, lr: 0.0005039466777816415
[3520] train loss: 0.7983297407627106, metric: 13.580893516540527, lr: 0.0004723869787994772
[3540] train loss: 1.6345075853168964, metric: 14.609130382537842, lr: 0.0004409373505041003
[3560] train loss: 1.49695460870862, metric: 14.610389709472656, lr: 0.0004097231721971184
[3580] train loss: -0.02543216198682785, metric: 12.329323768615723, lr: 0.000378868862753734
[3600] train loss: 1.5054747462272644, metric: 23.46224021911621, lr: 0.00034849741496145725
[3620] train loss: 0.671039305627346, metric: 14.047353744506836, lr: 0.0003187299007549882
[3640] train loss: 0.9103746190667152, metric: 18.278439044952393, lr: 0.0002896849764510989
[3660] train loss: 1.738694280385971, metric: 18.662853956222534, lr: 0.0002614784170873463
[3680] train loss: 1.2788905575871468, metric: 12.856785535812378, lr: 0.00023422270896844566
[3700] train loss: 1.3092332109808922, metric: 13.950387001037598, lr: 0.00020802643848583102
[3720] train loss: 1.1782789081335068, metric: 11.375198364257812, lr: 0.00018299407383892685
[3740] train loss: 1.6859421581029892, metric: 13.608594417572021, lr: 0.00015922538295853883
[3760] train loss: 1.9997441321611404, metric: 18.798392295837402, lr: 0.00013681512791663408
[3780] train loss: 0.6681317761540413, metric: 16.45815134048462, lr: 0.00011585262109292671
[3800] train loss: 0.9924874827265739, metric: 13.146698951721191, lr: 9.999999747378752e-05
[3820] train loss: 0.7827641069889069, metric: 14.315139293670654, lr: 9.999999747378752e-05
[3840] train loss: 2.502263128757477, metric: 14.696868896484375, lr: 9.999999747378752e-05
[3860] train loss: 0.24513273686170578, metric: 16.164267539978027, lr: 9.999999747378752e-05
[3880] train loss: 0.017142977565526962, metric: 15.129209280014038, lr: 9.999999747378752e-05
[3900] train loss: -0.044226109981536865, metric: 14.139646530151367, lr: 9.999999747378752e-05
[3920] train loss: -0.016548801213502884, metric: 14.606495141983032, lr: 9.999999747378752e-05
[3940] train loss: -0.10904289036989212, metric: 14.28058409690857, lr: 9.999999747378752e-05
[3960] train loss: -0.09574775770306587, metric: 14.104260444641113, lr: 9.999999747378752e-05
[3980] train loss: -0.06335268542170525, metric: 15.187872886657715, lr: 9.999999747378752e-05
[4000] train loss: 0.05476213991641998, metric: 14.053847789764404, lr: 9.999999747378752e-05
[4020] train loss: -0.13530146330595016, metric: 10.906259775161743, lr: 0.0009994393913075328
[4040] train loss: -0.2014874443411827, metric: 10.080250024795532, lr: 0.0009969500824809074
[4060] train loss: -0.27635369822382927, metric: 10.445588111877441, lr: 0.000992479850538075
[4080] train loss: -0.24602992087602615, metric: 9.644521832466125, lr: 0.000986046390607953
[4100] train loss: 6.732866406440735, metric: 20.790826320648193, lr: 0.0009776754304766655
[4120] train loss: 1.0999109707772732, metric: 14.049152851104736, lr: 0.0009674003813415766
[4140] train loss: 0.060914553701877594, metric: 9.942938327789307, lr: 0.0009552621049806476
[4160] train loss: -0.010040201246738434, metric: 10.307465314865112, lr: 0.0009413089719600976
[4180] train loss: 2.268037535250187, metric: 12.951614379882812, lr: 0.0009255966870114207
[4200] train loss: 2.201690275222063, metric: 15.708951473236084, lr: 0.00090818788157776
[4220] train loss: 0.020824264734983444, metric: 11.559125900268555, lr: 0.0008891518809832633
[4240] train loss: -0.18299845233559608, metric: 9.608601927757263, lr: 0.0008685645880177617
[4260] train loss: -0.2875510938465595, metric: 9.576761722564697, lr: 0.0008465081336908042
[4280] train loss: -0.28774038329720497, metric: 9.803822994232178, lr: 0.0008230703533627093
[4300] train loss: -0.0801955908536911, metric: 8.812098026275635, lr: 0.0007983447285369039
[4320] train loss: -0.1608218289911747, metric: 11.61503553390503, lr: 0.0007724298629909754
[4340] train loss: 0.31301965564489365, metric: 10.026551246643066, lr: 0.0007454289589077234
[4360] train loss: 0.31335438042879105, metric: 15.382673025131226, lr: 0.0007174497004598379
[4380] train loss: 0.061111804097890854, metric: 12.31558609008789, lr: 0.00068860367173329
[4400] train loss: 0.014522448182106018, metric: 12.356384992599487, lr: 0.0006590057746507227
[4420] train loss: 0.038416143506765366, metric: 12.532238960266113, lr: 0.0006287740543484688
[4440] train loss: 0.21661245450377464, metric: 12.295172214508057, lr: 0.000598029000684619
[4460] train loss: 0.18412622809410095, metric: 12.342018365859985, lr: 0.0005668931407853961
[4480] train loss: 0.0739828497171402, metric: 10.874352216720581, lr: 0.0005354906315915287
[4500] train loss: -0.024912193417549133, metric: 15.391728639602661, lr: 0.0005039466777816415
[4520] train loss: 0.01607643812894821, metric: 13.361779689788818, lr: 0.0004723869787994772
[4540] train loss: -0.18172447755932808, metric: 11.243293523788452, lr: 0.0004409373505041003
[4560] train loss: -0.17273514345288277, metric: 12.595884561538696, lr: 0.0004097231721971184
[4580] train loss: -0.2163647562265396, metric: 10.804725170135498, lr: 0.000378868862753734
[4600] train loss: -0.22955391556024551, metric: 11.299532413482666, lr: 0.00034849741496145725
[4620] train loss: 0.9226328618824482, metric: 14.375498056411743, lr: 0.0003187299007549882
[4640] train loss: 0.08887917548418045, metric: 12.131264686584473, lr: 0.0002896849764510989
[4660] train loss: 0.009435378015041351, metric: 12.911993026733398, lr: 0.0002614784170873463
[4680] train loss: 3.4230643436312675, metric: 20.597940683364868, lr: 0.00023422270896844566
[4700] train loss: 5.162243414670229, metric: 16.75961446762085, lr: 0.00020802643848583102
[4720] train loss: 0.17838335409760475, metric: 13.125596046447754, lr: 0.00018299407383892685
[4740] train loss: 0.5884236320853233, metric: 13.737536668777466, lr: 0.00015922538295853883
[4760] train loss: 1.4423023462295532, metric: 12.212345838546753, lr: 0.00013681512791663408
[4780] train loss: 0.46561001241207123, metric: 9.711891293525696, lr: 0.00011585262109292671
[4800] train loss: 0.3070683442056179, metric: 12.692919969558716, lr: 9.999999747378752e-05
[4820] train loss: 1.7646480090916157, metric: 12.47004747390747, lr: 9.999999747378752e-05
[4840] train loss: 0.7051244266331196, metric: 12.6244375705719, lr: 9.999999747378752e-05
[4860] train loss: 3.8969532921910286, metric: 15.839898109436035, lr: 9.999999747378752e-05
[4880] train loss: 1.2518090046942234, metric: 20.275908946990967, lr: 9.999999747378752e-05
[4900] train loss: 0.3596341945230961, metric: 13.948690414428711, lr: 9.999999747378752e-05
[4920] train loss: 0.7465901970863342, metric: 16.171034336090088, lr: 9.999999747378752e-05
[4940] train loss: 0.21262123063206673, metric: 13.254842758178711, lr: 9.999999747378752e-05
[4960] train loss: 1.040464349091053, metric: 13.911337852478027, lr: 9.999999747378752e-05
[4980] train loss: 0.29275694116950035, metric: 11.946925401687622, lr: 9.999999747378752e-05
[5000] train loss: 0.37490423768758774, metric: 11.866785526275635, lr: 9.999999747378752e-05
[5020] train loss: 0.042001545429229736, metric: 13.687659621238708, lr: 0.0009994393913075328
[5040] train loss: -0.10851393267512321, metric: 11.442708253860474, lr: 0.0009969500824809074
[5060] train loss: -0.05993043631315231, metric: 12.841848731040955, lr: 0.000992479850538075
[5080] train loss: 0.040278077125549316, metric: 9.749120950698853, lr: 0.000986046390607953
[5100] train loss: -0.06372000649571419, metric: 10.570200443267822, lr: 0.0009776754304766655
[5120] train loss: 0.09249388799071312, metric: 10.797088742256165, lr: 0.0009674003813415766
[5140] train loss: 0.13987793400883675, metric: 11.890095233917236, lr: 0.0009552621049806476
[5160] train loss: 0.017313290387392044, metric: 10.704824447631836, lr: 0.0009413089719600976
[5180] train loss: -0.08304489403963089, metric: 10.855498790740967, lr: 0.0009255966870114207
[5200] train loss: -0.22601912170648575, metric: 8.619508624076843, lr: 0.00090818788157776
[5220] train loss: 0.0456855446100235, metric: 11.531638860702515, lr: 0.0008891518809832633
[5240] train loss: -0.10921742022037506, metric: 9.605252981185913, lr: 0.0008685645880177617
[5260] train loss: 0.0859999917447567, metric: 11.848764181137085, lr: 0.0008465081336908042
[5280] train loss: 0.1821717917919159, metric: 9.248953104019165, lr: 0.0008230703533627093
[5300] train loss: 0.7356558591127396, metric: 10.510422468185425, lr: 0.0007983447285369039
[5320] train loss: 0.03609282895922661, metric: 11.152276992797852, lr: 0.0007724298629909754
[5340] train loss: -0.014485187828540802, metric: 11.04626202583313, lr: 0.0007454289589077234
[5360] train loss: 0.008266694843769073, metric: 9.852182149887085, lr: 0.0007174497004598379
[5380] train loss: 5.296668563038111, metric: 18.712438106536865, lr: 0.00068860367173329
[5400] train loss: 0.4824371337890625, metric: 14.43910813331604, lr: 0.0006590057746507227
[5420] train loss: 0.4381399266421795, metric: 14.092233896255493, lr: 0.0006287740543484688
[5440] train loss: 0.3832209035754204, metric: 12.8452730178833, lr: 0.000598029000684619
[5460] train loss: 0.00658731535077095, metric: 13.592395305633545, lr: 0.0005668931407853961
[5480] train loss: 0.15773510932922363, metric: 10.133508682250977, lr: 0.0005354906315915287
[5500] train loss: 0.4787171371281147, metric: 11.270753860473633, lr: 0.0005039466777816415
[5520] train loss: 0.974727213382721, metric: 14.515994548797607, lr: 0.0004723869787994772
[5540] train loss: 0.7200096994638443, metric: 14.222416520118713, lr: 0.0004409373505041003
[5560] train loss: 0.6434738524258137, metric: 12.324222207069397, lr: 0.0004097231721971184
[5580] train loss: 0.8994570411741734, metric: 15.15857982635498, lr: 0.000378868862753734
[5600] train loss: 1.3348461836576462, metric: 16.669931411743164, lr: 0.00034849741496145725
[5620] train loss: 0.633792981505394, metric: 13.158250093460083, lr: 0.0003187299007549882
[5640] train loss: 2.828082550317049, metric: 20.865318536758423, lr: 0.0002896849764510989
[5660] train loss: 4.698099348694086, metric: 20.493876934051514, lr: 0.0002614784170873463
[5680] train loss: 0.7687829211354256, metric: 15.828514814376831, lr: 0.00023422270896844566
[5700] train loss: 0.6589346565306187, metric: 19.27970552444458, lr: 0.00020802643848583102
[5720] train loss: 0.1561070680618286, metric: 15.562898397445679, lr: 0.00018299407383892685
[5740] train loss: 0.047296978533267975, metric: 14.968517541885376, lr: 0.00015922538295853883
[5760] train loss: 0.1000264473259449, metric: 11.916436910629272, lr: 0.00013681512791663408
[5780] train loss: 0.01669607311487198, metric: 13.095125436782837, lr: 0.00011585262109292671
[5800] train loss: 0.9124413505196571, metric: 15.512099504470825, lr: 9.999999747378752e-05
[5820] train loss: 0.15822091698646545, metric: 14.409595966339111, lr: 9.999999747378752e-05
[5840] train loss: 0.007431119680404663, metric: 13.220253467559814, lr: 9.999999747378752e-05
[5860] train loss: -0.00999407097697258, metric: 12.791676998138428, lr: 9.999999747378752e-05
[5880] train loss: 0.4218597933650017, metric: 12.430830717086792, lr: 9.999999747378752e-05
[5900] train loss: 0.10210863500833511, metric: 18.97248411178589, lr: 9.999999747378752e-05
[5920] train loss: 2.539339527487755, metric: 17.649463891983032, lr: 9.999999747378752e-05
[5940] train loss: 1.596094023436308, metric: 17.456518411636353, lr: 9.999999747378752e-05
[5960] train loss: 1.1012740656733513, metric: 14.831412315368652, lr: 9.999999747378752e-05
[5980] train loss: 1.0680688619613647, metric: 13.737008333206177, lr: 9.999999747378752e-05
[6000] train loss: 0.6563722975552082, metric: 15.569180250167847, lr: 9.999999747378752e-05
[6020] train loss: 0.2125822976231575, metric: 19.73671245574951, lr: 0.0009994393913075328
[6040] train loss: 0.476584754884243, metric: 13.960298299789429, lr: 0.0009969500824809074
[6060] train loss: 0.19117673859000206, metric: 14.297556638717651, lr: 0.000992479850538075
[6080] train loss: -0.10864701494574547, metric: 12.633220911026001, lr: 0.000986046390607953
[6100] train loss: -0.1587299406528473, metric: 12.040326595306396, lr: 0.0009776754304766655
[6120] train loss: -0.14041968062520027, metric: 13.688716888427734, lr: 0.0009674003813415766
[6140] train loss: -0.15278369560837746, metric: 11.807672262191772, lr: 0.0009552621049806476
[6160] train loss: -0.14420180022716522, metric: 11.642751455307007, lr: 0.0009413089719600976
[6180] train loss: -0.2538079060614109, metric: 11.16661286354065, lr: 0.0009255966870114207
[6200] train loss: -0.2556290663778782, metric: 11.347321271896362, lr: 0.00090818788157776
[6220] train loss: -0.31082167476415634, metric: 10.517391681671143, lr: 0.0008891518809832633
[6240] train loss: -0.24484427645802498, metric: 10.6806161403656, lr: 0.0008685645880177617
[6260] train loss: -0.10627976059913635, metric: 12.68784761428833, lr: 0.0008465081336908042
[6280] train loss: -0.26408248022198677, metric: 12.248684167861938, lr: 0.0008230703533627093
[6300] train loss: -0.29516221582889557, metric: 10.43652868270874, lr: 0.0007983447285369039
[6320] train loss: -0.27794942632317543, metric: 10.587398290634155, lr: 0.0007724298629909754
[6340] train loss: -0.24593216553330421, metric: 10.106828212738037, lr: 0.0007454289589077234
[6360] train loss: -0.2559593468904495, metric: 9.505611896514893, lr: 0.0007174497004598379
[6380] train loss: -0.2663075141608715, metric: 9.516920804977417, lr: 0.00068860367173329
[6400] train loss: -0.31137804314494133, metric: 10.581114172935486, lr: 0.0006590057746507227
[6420] train loss: 0.3026052713394165, metric: 14.393386840820312, lr: 0.0006287740543484688
[6440] train loss: 0.6762828603386879, metric: 10.175473928451538, lr: 0.000598029000684619
[6460] train loss: -0.05958255007863045, metric: 10.106467247009277, lr: 0.0005668931407853961
[6480] train loss: 0.32374606281518936, metric: 11.093549132347107, lr: 0.0005354906315915287
[6500] train loss: 0.7743880972266197, metric: 12.526288747787476, lr: 0.0005039466777816415
[6520] train loss: 0.7793513052165508, metric: 11.7245774269104, lr: 0.0004723869787994772
[6540] train loss: 0.7226479351520538, metric: 11.001911878585815, lr: 0.0004409373505041003
[6560] train loss: 0.18332017958164215, metric: 10.221110582351685, lr: 0.0004097231721971184
[6580] train loss: 1.7575398832559586, metric: 18.311388969421387, lr: 0.000378868862753734
[6600] train loss: 1.8265597075223923, metric: 15.499173164367676, lr: 0.00034849741496145725
[6620] train loss: 3.019952714443207, metric: 18.78968906402588, lr: 0.0003187299007549882
[6640] train loss: 1.2390656918287277, metric: 14.807480573654175, lr: 0.0002896849764510989
[6660] train loss: 0.2861226238310337, metric: 12.779295444488525, lr: 0.0002614784170873463
[6680] train loss: -0.12624530121684074, metric: 12.243743658065796, lr: 0.00023422270896844566
[6700] train loss: -0.15810316428542137, metric: 10.130375862121582, lr: 0.00020802643848583102
[6720] train loss: -0.14118822291493416, metric: 9.590996265411377, lr: 0.00018299407383892685
[6740] train loss: -0.10595518164336681, metric: 11.617815613746643, lr: 0.00015922538295853883
[6760] train loss: -0.01692488044500351, metric: 9.148635268211365, lr: 0.00013681512791663408
[6780] train loss: 0.5918897278606892, metric: 11.633389711380005, lr: 0.00011585262109292671
[6800] train loss: 21.343550480902195, metric: 25.651695013046265, lr: 9.999999747378752e-05
[6820] train loss: 7.413526184856892, metric: 21.119296312332153, lr: 9.999999747378752e-05
[6840] train loss: 0.37399864196777344, metric: 11.597354173660278, lr: 9.999999747378752e-05
[6860] train loss: 0.2577730566263199, metric: 9.3687584400177, lr: 9.999999747378752e-05
[6880] train loss: -0.013201601803302765, metric: 10.489397048950195, lr: 9.999999747378752e-05
[6900] train loss: 0.1398056261241436, metric: 12.520851850509644, lr: 9.999999747378752e-05
[6920] train loss: 7.228686526417732, metric: 25.795443058013916, lr: 9.999999747378752e-05
[6940] train loss: 5.91119883581996, metric: 28.226227283477783, lr: 9.999999747378752e-05
[6960] train loss: 24.12577534839511, metric: 27.27287197113037, lr: 9.999999747378752e-05
[6980] train loss: 5.951208859682083, metric: 18.929428339004517, lr: 9.999999747378752e-05
[7000] train loss: 4.200163893401623, metric: 20.464178800582886, lr: 9.999999747378752e-05
[7020] train loss: 2.3177346289157867, metric: 14.205725193023682, lr: 0.0009994393913075328
[7040] train loss: -0.08326961100101471, metric: 11.727140188217163, lr: 0.0009969500824809074
[7060] train loss: -0.04073365777730942, metric: 11.11489200592041, lr: 0.000992479850538075
[7080] train loss: -0.17951039224863052, metric: 9.46040678024292, lr: 0.000986046390607953
[7100] train loss: -0.20721051841974258, metric: 9.64663052558899, lr: 0.0009776754304766655
[7120] train loss: -0.25858520716428757, metric: 9.6426362991333, lr: 0.0009674003813415766
[7140] train loss: -0.22007034346461296, metric: 10.255422592163086, lr: 0.0009552621049806476
[7160] train loss: 0.8800670132040977, metric: 12.573565244674683, lr: 0.0009413089719600976
[7180] train loss: 1.2614977732300758, metric: 19.580256700515747, lr: 0.0009255966870114207
[7200] train loss: 0.45188137888908386, metric: 15.845755338668823, lr: 0.00090818788157776
[7220] train loss: -0.07727905735373497, metric: 14.143004894256592, lr: 0.0008891518809832633
[7240] train loss: 0.823869526386261, metric: 13.63206934928894, lr: 0.0008685645880177617
[7260] train loss: 1.1064893901348114, metric: 13.362443447113037, lr: 0.0008465081336908042
[7280] train loss: 1.4651014022529125, metric: 14.099406003952026, lr: 0.0008230703533627093
[7300] train loss: 0.13997125625610352, metric: 12.91097640991211, lr: 0.0007983447285369039
[7320] train loss: -0.06724124774336815, metric: 12.026094198226929, lr: 0.0007724298629909754
[7340] train loss: 0.970524575561285, metric: 14.459786176681519, lr: 0.0007454289589077234
[7360] train loss: 1.3552267141640186, metric: 13.409249782562256, lr: 0.0007174497004598379
[7380] train loss: 0.5446083582937717, metric: 11.696991920471191, lr: 0.00068860367173329
[7400] train loss: 0.11777174472808838, metric: 11.342106580734253, lr: 0.0006590057746507227
[7420] train loss: 1.1766785345971584, metric: 11.244774580001831, lr: 0.0006287740543484688
[7440] train loss: 0.5078047104179859, metric: 13.424314260482788, lr: 0.000598029000684619
[7460] train loss: 0.08067011833190918, metric: 10.33898663520813, lr: 0.0005668931407853961
[7480] train loss: 0.320222832262516, metric: 13.686393976211548, lr: 0.0005354906315915287
[7500] train loss: 0.12431447207927704, metric: 11.879751324653625, lr: 0.0005039466777816415
[7520] train loss: -0.011920798569917679, metric: 10.177886247634888, lr: 0.0004723869787994772
[7540] train loss: -0.05887184292078018, metric: 12.615054845809937, lr: 0.0004409373505041003
[7560] train loss: 0.6437655612826347, metric: 11.324154138565063, lr: 0.0004097231721971184
[7580] train loss: 1.0304379425942898, metric: 12.175752758979797, lr: 0.000378868862753734
[7600] train loss: 6.3631104826927185, metric: 15.36757516860962, lr: 0.00034849741496145725
[7620] train loss: 2.4145293086767197, metric: 16.505815267562866, lr: 0.0003187299007549882
[7640] train loss: 2.4318439066410065, metric: 17.68138325214386, lr: 0.0002896849764510989
[7660] train loss: 11.761260133236647, metric: 20.800302505493164, lr: 0.0002614784170873463
[7680] train loss: 2.0775148272514343, metric: 15.614577531814575, lr: 0.00023422270896844566
[7700] train loss: 0.475752804428339, metric: 14.893152713775635, lr: 0.00020802643848583102
[7720] train loss: 0.43720730766654015, metric: 15.560336589813232, lr: 0.00018299407383892685
[7740] train loss: 0.4140438325703144, metric: 17.08381223678589, lr: 0.00015922538295853883
[7760] train loss: 0.20860043540596962, metric: 16.977181911468506, lr: 0.00013681512791663408
[7780] train loss: 0.5691564232110977, metric: 16.703416109085083, lr: 0.00011585262109292671
[7800] train loss: 0.15708516910672188, metric: 15.807493925094604, lr: 9.999999747378752e-05
[7820] train loss: 0.1287764348089695, metric: 13.284715414047241, lr: 9.999999747378752e-05
[7840] train loss: 0.1519465632736683, metric: 13.498680114746094, lr: 9.999999747378752e-05
[7860] train loss: -0.06046652793884277, metric: 12.484840393066406, lr: 9.999999747378752e-05
[7880] train loss: 0.11591647192835808, metric: 12.441837310791016, lr: 9.999999747378752e-05
[7900] train loss: 0.5019143708050251, metric: 12.760082006454468, lr: 9.999999747378752e-05
[7920] train loss: 1.369706641882658, metric: 14.81155800819397, lr: 9.999999747378752e-05
[7940] train loss: 0.10012168809771538, metric: 18.608022928237915, lr: 9.999999747378752e-05
[7960] train loss: 0.04931782931089401, metric: 14.995296001434326, lr: 9.999999747378752e-05
[7980] train loss: -0.08067287504673004, metric: 14.176879167556763, lr: 9.999999747378752e-05
[8000] train loss: -0.0601486898958683, metric: 13.147615671157837, lr: 9.999999747378752e-05
[8020] train loss: 0.0890350453555584, metric: 9.949479222297668, lr: 0.0009994393913075328
[8040] train loss: -0.15695297345519066, metric: 7.967777490615845, lr: 0.0009969500824809074
[8060] train loss: -0.23043860122561455, metric: 9.483729362487793, lr: 0.000992479850538075
[8080] train loss: -0.27610916644334793, metric: 9.963783025741577, lr: 0.000986046390607953
[8100] train loss: -0.30031828582286835, metric: 7.677709937095642, lr: 0.0009776754304766655
[8120] train loss: -0.2592259608209133, metric: 8.392594933509827, lr: 0.0009674003813415766
[8140] train loss: -0.24029851332306862, metric: 8.222354531288147, lr: 0.0009552621049806476
[8160] train loss: -0.2932235971093178, metric: 9.6232590675354, lr: 0.0009413089719600976
[8180] train loss: -0.1900940164923668, metric: 11.480295658111572, lr: 0.0009255966870114207
[8200] train loss: 1.980460800230503, metric: 20.712982892990112, lr: 0.00090818788157776
[8220] train loss: 0.37988653406500816, metric: 11.41485321521759, lr: 0.0008891518809832633
[8240] train loss: 0.19124820455908775, metric: 8.456734418869019, lr: 0.0008685645880177617
[8260] train loss: 0.7997219599783421, metric: 12.370755910873413, lr: 0.0008465081336908042
[8280] train loss: 0.3082558773458004, metric: 12.55717658996582, lr: 0.0008230703533627093
[8300] train loss: 0.05104818195104599, metric: 11.736281037330627, lr: 0.0007983447285369039
[8320] train loss: 0.18706541880965233, metric: 9.859524369239807, lr: 0.0007724298629909754
[8340] train loss: -0.06580928340554237, metric: 8.605322241783142, lr: 0.0007454289589077234
[8360] train loss: 0.20636144652962685, metric: 8.473137855529785, lr: 0.0007174497004598379
[8380] train loss: 0.39708922430872917, metric: 13.544054508209229, lr: 0.00068860367173329
[8400] train loss: 0.36414842307567596, metric: 10.843746423721313, lr: 0.0006590057746507227
[8420] train loss: -0.06448604539036751, metric: 11.228467226028442, lr: 0.0006287740543484688
[8440] train loss: 1.2478461004793644, metric: 13.594449400901794, lr: 0.000598029000684619
[8460] train loss: 1.238787166774273, metric: 16.783897638320923, lr: 0.0005668931407853961
[8480] train loss: 0.039306364953517914, metric: 14.957983016967773, lr: 0.0005354906315915287
[8500] train loss: 0.8461213260889053, metric: 12.371977806091309, lr: 0.0005039466777816415
[8520] train loss: 0.7569750025868416, metric: 11.267096996307373, lr: 0.0004723869787994772
[8540] train loss: 0.8701087050139904, metric: 13.04840874671936, lr: 0.0004409373505041003
[8560] train loss: 0.29588910564780235, metric: 11.210552215576172, lr: 0.0004097231721971184
[8580] train loss: 0.08679765090346336, metric: 11.341783285140991, lr: 0.000378868862753734
[8600] train loss: -0.13244149461388588, metric: 10.859826564788818, lr: 0.00034849741496145725
[8620] train loss: -0.2123943790793419, metric: 9.281005382537842, lr: 0.0003187299007549882
[8640] train loss: -0.2526591941714287, metric: 9.330672979354858, lr: 0.0002896849764510989
[8660] train loss: -0.1968168504536152, metric: 9.851703643798828, lr: 0.0002614784170873463
[8680] train loss: -0.12050498276948929, metric: 9.084181070327759, lr: 0.00023422270896844566
[8700] train loss: -0.24832097813487053, metric: 10.604381680488586, lr: 0.00020802643848583102
[8720] train loss: 1.0202375128865242, metric: 16.463000774383545, lr: 0.00018299407383892685
[8740] train loss: 0.38676321879029274, metric: 14.925820589065552, lr: 0.00015922538295853883
[8760] train loss: 0.12371775135397911, metric: 10.181642293930054, lr: 0.00013681512791663408
[8780] train loss: -0.015645567327737808, metric: 10.78782856464386, lr: 0.00011585262109292671
[8800] train loss: 0.2541487216949463, metric: 12.668112993240356, lr: 9.999999747378752e-05
[8820] train loss: 0.13340159878134727, metric: 12.769271850585938, lr: 9.999999747378752e-05
[8840] train loss: -0.047045085579156876, metric: 12.137113332748413, lr: 9.999999747378752e-05
[8860] train loss: 0.07741918787360191, metric: 11.97831654548645, lr: 9.999999747378752e-05
[8880] train loss: 2.2156338170170784, metric: 15.069663405418396, lr: 9.999999747378752e-05
[8900] train loss: 3.4008107632398605, metric: 15.520222663879395, lr: 9.999999747378752e-05
[8920] train loss: 5.157988388091326, metric: 14.656274795532227, lr: 9.999999747378752e-05
[8940] train loss: 0.8647643588483334, metric: 13.937461853027344, lr: 9.999999747378752e-05
[8960] train loss: -0.04851746931672096, metric: 12.994346141815186, lr: 9.999999747378752e-05
[8980] train loss: 1.3758857175707817, metric: 17.802803993225098, lr: 9.999999747378752e-05
[9000] train loss: 0.45409343019127846, metric: 17.578023672103882, lr: 9.999999747378752e-05
[9020] train loss: 0.2086058035492897, metric: 11.480024695396423, lr: 0.0009994393913075328
[9040] train loss: -0.2042602300643921, metric: 9.87317156791687, lr: 0.0009969500824809074
[9060] train loss: -0.28261958435177803, metric: 8.134849071502686, lr: 0.000992479850538075
[9080] train loss: -0.1710035502910614, metric: 7.034165024757385, lr: 0.000986046390607953
[9100] train loss: -0.28060542047023773, metric: 6.687778830528259, lr: 0.0009776754304766655
[9120] train loss: -0.17269820719957352, metric: 7.713943004608154, lr: 0.0009674003813415766
[9140] train loss: -0.053856443613767624, metric: 10.454218626022339, lr: 0.0009552621049806476
[9160] train loss: -0.19977367669343948, metric: 8.892549276351929, lr: 0.0009413089719600976
[9180] train loss: -0.19577470421791077, metric: 7.828263878822327, lr: 0.0009255966870114207
[9200] train loss: -0.22238142415881157, metric: 8.06750202178955, lr: 0.00090818788157776
[9220] train loss: 0.08897720649838448, metric: 13.693436861038208, lr: 0.0008891518809832633
[9240] train loss: -0.18040547147393227, metric: 10.411574244499207, lr: 0.0008685645880177617
[9260] train loss: -0.07739569619297981, metric: 9.098310708999634, lr: 0.0008465081336908042
[9280] train loss: -0.23962752893567085, metric: 8.280852556228638, lr: 0.0008230703533627093
[9300] train loss: -0.237575002014637, metric: 7.461679458618164, lr: 0.0007983447285369039
[9320] train loss: -0.23137422278523445, metric: 8.017352104187012, lr: 0.0007724298629909754
[9340] train loss: -0.22254088148474693, metric: 8.425409197807312, lr: 0.0007454289589077234
[9360] train loss: -0.11599888280034065, metric: 8.219239711761475, lr: 0.0007174497004598379
[9380] train loss: -0.14789362996816635, metric: 9.59407377243042, lr: 0.00068860367173329
[9400] train loss: -0.21061065047979355, metric: 10.548327684402466, lr: 0.0006590057746507227
[9420] train loss: -0.22711565718054771, metric: 8.246699094772339, lr: 0.0006287740543484688
[9440] train loss: -0.24579955637454987, metric: 7.316230297088623, lr: 0.000598029000684619
[9460] train loss: -0.16882679611444473, metric: 7.509320855140686, lr: 0.0005668931407853961
[9480] train loss: 0.659162137657404, metric: 10.789345026016235, lr: 0.0005354906315915287
[9500] train loss: 0.11593684181571007, metric: 10.951210260391235, lr: 0.0005039466777816415
[9520] train loss: 0.06023285537958145, metric: 10.569724559783936, lr: 0.0004723869787994772
[9540] train loss: -0.011897832155227661, metric: 11.588337898254395, lr: 0.0004409373505041003
[9560] train loss: 0.4615560322999954, metric: 10.885398864746094, lr: 0.0004097231721971184
[9580] train loss: 0.33969415724277496, metric: 10.42775011062622, lr: 0.000378868862753734
[9600] train loss: -0.20669906586408615, metric: 8.96979570388794, lr: 0.00034849741496145725
[9620] train loss: 0.060530904680490494, metric: 12.352380633354187, lr: 0.0003187299007549882
[9640] train loss: -0.09449366107583046, metric: 9.750284910202026, lr: 0.0002896849764510989
[9660] train loss: 0.698605053126812, metric: 11.16710376739502, lr: 0.0002614784170873463
[9680] train loss: 0.8805703110992908, metric: 12.719070672988892, lr: 0.00023422270896844566
[9700] train loss: 0.5872934982180595, metric: 14.730186462402344, lr: 0.00020802643848583102
[9720] train loss: 0.5834368169307709, metric: 13.871498823165894, lr: 0.00018299407383892685
[9740] train loss: 0.2002105824649334, metric: 20.699626445770264, lr: 0.00015922538295853883
[9760] train loss: 0.0006914548575878143, metric: 17.635395050048828, lr: 0.00013681512791663408
[9780] train loss: -0.12101534381508827, metric: 15.94002389907837, lr: 0.00011585262109292671
[9800] train loss: -0.13631387799978256, metric: 14.274832010269165, lr: 9.999999747378752e-05
[9820] train loss: -0.08546658977866173, metric: 15.126140117645264, lr: 9.999999747378752e-05
[9840] train loss: -0.18384463340044022, metric: 12.744150876998901, lr: 9.999999747378752e-05
[9860] train loss: -0.19016091525554657, metric: 11.898173570632935, lr: 9.999999747378752e-05
[9880] train loss: -0.20437468215823174, metric: 10.801618576049805, lr: 9.999999747378752e-05
[9900] train loss: -0.15882153436541557, metric: 9.776781797409058, lr: 9.999999747378752e-05
[9920] train loss: -0.08817458525300026, metric: 10.402761459350586, lr: 9.999999747378752e-05
[9940] train loss: -0.07795953005552292, metric: 10.18050491809845, lr: 9.999999747378752e-05
[9960] train loss: -0.017367027699947357, metric: 13.563738584518433, lr: 9.999999747378752e-05
[9980] train loss: -0.055277109146118164, metric: 10.771824359893799, lr: 9.999999747378752e-05
[10000] train loss: 0.8869301974773407, metric: 15.326107263565063, lr: 9.999999747378752e-05
[10020] train loss: 0.2320481762290001, metric: 12.118876218795776, lr: 0.0009994393913075328
[10040] train loss: 0.161368265748024, metric: 11.07944631576538, lr: 0.0009969500824809074
[10060] train loss: 0.10631198063492775, metric: 11.034684658050537, lr: 0.000992479850538075
[10080] train loss: -0.18675881624221802, metric: 10.304683685302734, lr: 0.000986046390607953
[10100] train loss: -0.09329519048333168, metric: 9.788287281990051, lr: 0.0009776754304766655
[10120] train loss: -0.08763293921947479, metric: 10.325373888015747, lr: 0.0009674003813415766
[10140] train loss: 0.6815745942294598, metric: 12.724079847335815, lr: 0.0009552621049806476
[10160] train loss: 0.024283837527036667, metric: 11.713387250900269, lr: 0.0009413089719600976
[10180] train loss: -0.11142681166529655, metric: 10.756815671920776, lr: 0.0009255966870114207
[10200] train loss: -0.08147550374269485, metric: 11.177923440933228, lr: 0.00090818788157776
[10220] train loss: -0.03131469711661339, metric: 13.560768842697144, lr: 0.0008891518809832633
[10240] train loss: -0.1460333913564682, metric: 11.832781314849854, lr: 0.0008685645880177617
[10260] train loss: 0.20086024701595306, metric: 11.532753467559814, lr: 0.0008465081336908042
[10280] train loss: -0.18276356905698776, metric: 8.150121092796326, lr: 0.0008230703533627093
[10300] train loss: -0.24086570367217064, metric: 7.79086434841156, lr: 0.0007983447285369039
[10320] train loss: -0.22299321740865707, metric: 8.171232223510742, lr: 0.0007724298629909754
[10340] train loss: -0.20178521797060966, metric: 8.878113508224487, lr: 0.0007454289589077234
[10360] train loss: -0.017170090228319168, metric: 10.024029970169067, lr: 0.0007174497004598379
[10380] train loss: 0.19746242091059685, metric: 12.520094156265259, lr: 0.00068860367173329
[10400] train loss: -0.05036595091223717, metric: 12.922283172607422, lr: 0.0006590057746507227
[10420] train loss: 0.35622582770884037, metric: 12.740681171417236, lr: 0.0006287740543484688
[10440] train loss: -0.030745111405849457, metric: 10.067139863967896, lr: 0.000598029000684619
[10460] train loss: 0.08315972238779068, metric: 11.740907669067383, lr: 0.0005668931407853961
[10480] train loss: 0.32973845675587654, metric: 12.165287256240845, lr: 0.0005354906315915287
[10500] train loss: 7.218471676111221, metric: 23.426587104797363, lr: 0.0005039466777816415
[10520] train loss: 1.67853581905365, metric: 14.912202596664429, lr: 0.0004723869787994772
[10540] train loss: 1.341404840350151, metric: 15.048012971878052, lr: 0.0004409373505041003
[10560] train loss: 1.0941790528595448, metric: 14.175360441207886, lr: 0.0004097231721971184
[10580] train loss: 2.7182949744164944, metric: 16.941662788391113, lr: 0.000378868862753734
[10600] train loss: 1.2699718959629536, metric: 14.226548671722412, lr: 0.00034849741496145725
[10620] train loss: 1.0030708983540535, metric: 12.783448696136475, lr: 0.0003187299007549882
[10640] train loss: 0.5970615297555923, metric: 10.102970600128174, lr: 0.0002896849764510989
[10660] train loss: 0.6504271849989891, metric: 11.572020769119263, lr: 0.0002614784170873463
[10680] train loss: 0.6987640000879765, metric: 10.84783673286438, lr: 0.00023422270896844566
[10700] train loss: 2.7350348830223083, metric: 20.473613262176514, lr: 0.00020802643848583102
[10720] train loss: 9.041393283754587, metric: 19.76875329017639, lr: 0.00018299407383892685
[10740] train loss: 1.603240244090557, metric: 15.70259404182434, lr: 0.00015922538295853883
[10760] train loss: 2.2976071313023567, metric: 20.367677450180054, lr: 0.00013681512791663408
[10780] train loss: 2.3657462894916534, metric: 16.10066318511963, lr: 0.00011585262109292671
[10800] train loss: 0.3755847364664078, metric: 16.4443199634552, lr: 9.999999747378752e-05
[10820] train loss: 0.17982403561472893, metric: 11.753325700759888, lr: 9.999999747378752e-05
[10840] train loss: -0.06714590266346931, metric: 9.800648212432861, lr: 9.999999747378752e-05
[10860] train loss: 0.5781445894390345, metric: 12.941983461380005, lr: 9.999999747378752e-05
[10880] train loss: -0.18600325658917427, metric: 10.867911338806152, lr: 9.999999747378752e-05
[10900] train loss: -0.16218958422541618, metric: 12.782230615615845, lr: 9.999999747378752e-05
[10920] train loss: -0.09591277688741684, metric: 11.969379901885986, lr: 9.999999747378752e-05
[10940] train loss: -0.12544145062565804, metric: 9.44178819656372, lr: 9.999999747378752e-05
[10960] train loss: -0.13541147485375404, metric: 10.786099910736084, lr: 9.999999747378752e-05
[10980] train loss: -0.04391436651349068, metric: 10.636390089988708, lr: 9.999999747378752e-05
[11000] train loss: -0.053609080612659454, metric: 10.024637460708618, lr: 9.999999747378752e-05
[11020] train loss: 0.9435859397053719, metric: 15.025583505630493, lr: 0.0009994393913075328
[11040] train loss: 1.8275661431252956, metric: 14.286062955856323, lr: 0.0009969500824809074
[11060] train loss: 3.139035854488611, metric: 15.402709245681763, lr: 0.000992479850538075
[11080] train loss: 1.161449994891882, metric: 16.374305486679077, lr: 0.000986046390607953
[11100] train loss: 2.4469023160636425, metric: 14.860468626022339, lr: 0.0009776754304766655
[11120] train loss: 1.7745409235358238, metric: 13.809956789016724, lr: 0.0009674003813415766
[11140] train loss: 1.409253865480423, metric: 18.134227752685547, lr: 0.0009552621049806476
[11160] train loss: 1.617611326277256, metric: 12.299296855926514, lr: 0.0009413089719600976
[11180] train loss: 3.3550635129213333, metric: 21.231879711151123, lr: 0.0009255966870114207
[11200] train loss: 5.31082995608449, metric: 16.457048177719116, lr: 0.00090818788157776
[11220] train loss: 1.5791567973792553, metric: 14.80033016204834, lr: 0.0008891518809832633
[11240] train loss: 0.9038019478321075, metric: 14.600051760673523, lr: 0.0008685645880177617
[11260] train loss: 0.08267857879400253, metric: 13.729760527610779, lr: 0.0008465081336908042
[11280] train loss: 0.25289005041122437, metric: 13.32008981704712, lr: 0.0008230703533627093
[11300] train loss: -0.22952428460121155, metric: 10.761184334754944, lr: 0.0007983447285369039
[11320] train loss: -0.25119228288531303, metric: 9.688247561454773, lr: 0.0007724298629909754
[11340] train loss: -0.2656826190650463, metric: 10.673505306243896, lr: 0.0007454289589077234
[11360] train loss: -0.26854050904512405, metric: 9.299321413040161, lr: 0.0007174497004598379
[11380] train loss: -0.2180759273469448, metric: 10.405196189880371, lr: 0.00068860367173329
[11400] train loss: -0.2484118454158306, metric: 9.055962443351746, lr: 0.0006590057746507227
[11420] train loss: -0.21797498688101768, metric: 8.682907819747925, lr: 0.0006287740543484688
[11440] train loss: -0.29937053844332695, metric: 8.122720122337341, lr: 0.000598029000684619
[11460] train loss: -0.29347512498497963, metric: 8.057754278182983, lr: 0.0005668931407853961
[11480] train loss: -0.2745455205440521, metric: 8.360813856124878, lr: 0.0005354906315915287
[11500] train loss: -0.1503869704902172, metric: 9.188740253448486, lr: 0.0005039466777816415
[11520] train loss: -0.09103399515151978, metric: 9.25323486328125, lr: 0.0004723869787994772
[11540] train loss: 0.5050060488283634, metric: 14.96039628982544, lr: 0.0004409373505041003
[11560] train loss: 0.8291452117264271, metric: 14.684047818183899, lr: 0.0004097231721971184
[11580] train loss: 1.6097829267382622, metric: 13.492590188980103, lr: 0.000378868862753734
[11600] train loss: 1.8761309459805489, metric: 13.347935438156128, lr: 0.00034849741496145725
[11620] train loss: 0.40584131702780724, metric: 11.647329568862915, lr: 0.0003187299007549882
[11640] train loss: 0.8252594284713268, metric: 11.897490978240967, lr: 0.0002896849764510989
[11660] train loss: 1.5881104469299316, metric: 16.450915575027466, lr: 0.0002614784170873463
[11680] train loss: 0.6457581035792828, metric: 15.325141906738281, lr: 0.00023422270896844566
[11700] train loss: 1.0993414409458637, metric: 15.00580358505249, lr: 0.00020802643848583102
[11720] train loss: 3.137631982564926, metric: 22.082330465316772, lr: 0.00018299407383892685
[11740] train loss: 2.923882581293583, metric: 18.689340591430664, lr: 0.00015922538295853883
[11760] train loss: 1.2503616102039814, metric: 15.49707818031311, lr: 0.00013681512791663408
[11780] train loss: 7.193443834781647, metric: 25.620758056640625, lr: 0.00011585262109292671
[11800] train loss: 1.4461846314370632, metric: 18.15147590637207, lr: 9.999999747378752e-05
[11820] train loss: 0.7938493303954601, metric: 17.51477813720703, lr: 9.999999747378752e-05
[11840] train loss: 0.2392711043357849, metric: 14.49092698097229, lr: 9.999999747378752e-05
[11860] train loss: 0.3527993783354759, metric: 12.223437547683716, lr: 9.999999747378752e-05
[11880] train loss: 0.5498963892459869, metric: 13.544007539749146, lr: 9.999999747378752e-05
[11900] train loss: 0.3972455784678459, metric: 15.871950149536133, lr: 9.999999747378752e-05
[11920] train loss: 1.7923741973936558, metric: 18.563658237457275, lr: 9.999999747378752e-05
[11940] train loss: 1.5536886304616928, metric: 17.388640880584717, lr: 9.999999747378752e-05
[11960] train loss: 3.215985167771578, metric: 18.77989912033081, lr: 9.999999747378752e-05
[11980] train loss: 1.9625891111791134, metric: 17.55838441848755, lr: 9.999999747378752e-05
[12000] train loss: 1.3821106478571892, metric: 17.60866355895996, lr: 9.999999747378752e-05
[12020] train loss: 0.9154472462832928, metric: 14.220170497894287, lr: 0.0009994393913075328
[12040] train loss: 2.860055163502693, metric: 17.268667221069336, lr: 0.0009969500824809074
[12060] train loss: 0.8692066371440887, metric: 16.016014337539673, lr: 0.000992479850538075
[12080] train loss: 0.9698155745863914, metric: 12.976439952850342, lr: 0.000986046390607953
[12100] train loss: 0.8392950221896172, metric: 17.965877056121826, lr: 0.0009776754304766655
[12120] train loss: 0.2634573020040989, metric: 16.486130356788635, lr: 0.0009674003813415766
[12140] train loss: 0.2435537837445736, metric: 10.923510670661926, lr: 0.0009552621049806476
[12160] train loss: -0.08989379927515984, metric: 11.201987266540527, lr: 0.0009413089719600976
[12180] train loss: -0.20536169409751892, metric: 10.210882663726807, lr: 0.0009255966870114207
[12200] train loss: -0.1757395975291729, metric: 11.81045389175415, lr: 0.00090818788157776
[12220] train loss: -0.21793806552886963, metric: 13.098133563995361, lr: 0.0008891518809832633
[12240] train loss: 0.028362981975078583, metric: 11.883670091629028, lr: 0.0008685645880177617
[12260] train loss: -0.0741061307489872, metric: 13.546300411224365, lr: 0.0008465081336908042
[12280] train loss: -0.17511499300599098, metric: 11.462239265441895, lr: 0.0008230703533627093
[12300] train loss: 0.08780056238174438, metric: 12.407116174697876, lr: 0.0007983447285369039
[12320] train loss: -0.171156607568264, metric: 9.934849500656128, lr: 0.0007724298629909754
[12340] train loss: -0.18423257023096085, metric: 8.965742707252502, lr: 0.0007454289589077234
[12360] train loss: 0.3065186031162739, metric: 11.289745807647705, lr: 0.0007174497004598379
[12380] train loss: 0.12965477257966995, metric: 11.753590106964111, lr: 0.00068860367173329
[12400] train loss: 1.4559068568050861, metric: 13.125932693481445, lr: 0.0006590057746507227
[12420] train loss: 0.9529202431440353, metric: 11.09074330329895, lr: 0.0006287740543484688
[12440] train loss: 0.04970866069197655, metric: 9.770007729530334, lr: 0.000598029000684619
[12460] train loss: 0.41191093996167183, metric: 12.409613609313965, lr: 0.0005668931407853961
[12480] train loss: 0.005051247775554657, metric: 13.391178369522095, lr: 0.0005354906315915287
[12500] train loss: -0.17446784302592278, metric: 8.790441513061523, lr: 0.0005039466777816415
[12520] train loss: -0.07312768325209618, metric: 11.548804759979248, lr: 0.0004723869787994772
[12540] train loss: -0.12512080743908882, metric: 13.16587781906128, lr: 0.0004409373505041003
[12560] train loss: 0.4733572192490101, metric: 10.67750883102417, lr: 0.0004097231721971184
[12580] train loss: 0.4287078455090523, metric: 8.797760725021362, lr: 0.000378868862753734
[12600] train loss: 0.08762038499116898, metric: 11.295730590820312, lr: 0.00034849741496145725
[12620] train loss: 0.02433917671442032, metric: 8.815350651741028, lr: 0.0003187299007549882
[12640] train loss: 0.3764849789440632, metric: 10.235430717468262, lr: 0.0002896849764510989
[12660] train loss: 0.5753195472061634, metric: 12.223592758178711, lr: 0.0002614784170873463
[12680] train loss: 0.9930784925818443, metric: 11.539099931716919, lr: 0.00023422270896844566
[12700] train loss: 2.052494067698717, metric: 15.330775260925293, lr: 0.00020802643848583102
[12720] train loss: 2.6426383666694164, metric: 14.73272442817688, lr: 0.00018299407383892685
[12740] train loss: 0.7156809568405151, metric: 14.935261726379395, lr: 0.00015922538295853883
[12760] train loss: 0.01206132024526596, metric: 12.361822843551636, lr: 0.00013681512791663408
[12780] train loss: 0.10001559183001518, metric: 12.005932807922363, lr: 0.00011585262109292671
[12800] train loss: 0.5913650579750538, metric: 10.379313588142395, lr: 9.999999747378752e-05
[12820] train loss: -0.002614155411720276, metric: 14.77694058418274, lr: 9.999999747378752e-05
[12840] train loss: -0.1472272202372551, metric: 12.779166221618652, lr: 9.999999747378752e-05
[12860] train loss: -0.17201439663767815, metric: 13.407886028289795, lr: 9.999999747378752e-05
[12880] train loss: -0.17344019562005997, metric: 10.695188283920288, lr: 9.999999747378752e-05
[12900] train loss: -0.11128111183643341, metric: 10.131507158279419, lr: 9.999999747378752e-05
[12920] train loss: -0.2813895680010319, metric: 10.727596282958984, lr: 9.999999747378752e-05
[12940] train loss: -0.2713322602212429, metric: 8.567371010780334, lr: 9.999999747378752e-05
[12960] train loss: -0.27811089903116226, metric: 10.79858922958374, lr: 9.999999747378752e-05
[12980] train loss: -0.2220776602625847, metric: 12.689346075057983, lr: 9.999999747378752e-05
[13000] train loss: -0.24971969053149223, metric: 12.117767572402954, lr: 9.999999747378752e-05
[13020] train loss: -0.33808351308107376, metric: 8.492634057998657, lr: 0.0009994393913075328
[13040] train loss: -0.38732559233903885, metric: 7.979349970817566, lr: 0.0009969500824809074
[13060] train loss: 1.1773658022284508, metric: 14.238330602645874, lr: 0.000992479850538075
[13080] train loss: 0.10078238695859909, metric: 10.455522060394287, lr: 0.000986046390607953
[13100] train loss: 0.5854917988181114, metric: 10.154243230819702, lr: 0.0009776754304766655
[13120] train loss: 0.3208588548004627, metric: 11.722747564315796, lr: 0.0009674003813415766
[13140] train loss: 0.10327399522066116, metric: 9.874104261398315, lr: 0.0009552621049806476
[13160] train loss: 0.3235117122530937, metric: 9.072007536888123, lr: 0.0009413089719600976
[13180] train loss: 0.3540925607085228, metric: 10.092937469482422, lr: 0.0009255966870114207
[13200] train loss: 0.8807799033820629, metric: 13.382587432861328, lr: 0.00090818788157776
[13220] train loss: 1.2989999540150166, metric: 16.847148180007935, lr: 0.0008891518809832633
[13240] train loss: 6.243103064596653, metric: 14.507548809051514, lr: 0.0008685645880177617
[13260] train loss: 0.8781682103872299, metric: 16.12666654586792, lr: 0.0008465081336908042
[13280] train loss: -0.018018636852502823, metric: 11.428821325302124, lr: 0.0008230703533627093
[13300] train loss: 0.12439470365643501, metric: 9.452351450920105, lr: 0.0007983447285369039
[13320] train loss: 0.4911034442484379, metric: 18.09833574295044, lr: 0.0007724298629909754
[13340] train loss: 0.9330720268189907, metric: 12.14814043045044, lr: 0.0007454289589077234
[13360] train loss: 0.22662090882658958, metric: 11.30599844455719, lr: 0.0007174497004598379
[13380] train loss: 0.3293302208185196, metric: 10.701357245445251, lr: 0.00068860367173329
[13400] train loss: 1.0463359616696835, metric: 11.404287576675415, lr: 0.0006590057746507227
[13420] train loss: 0.2845032140612602, metric: 11.266371011734009, lr: 0.0006287740543484688
[13440] train loss: 1.3042228147387505, metric: 11.91376543045044, lr: 0.000598029000684619
[13460] train loss: 0.5873339399695396, metric: 11.972394227981567, lr: 0.0005668931407853961
[13480] train loss: 1.6459032855927944, metric: 13.584984064102173, lr: 0.0005354906315915287
[13500] train loss: 0.003728613257408142, metric: 12.716655969619751, lr: 0.0005039466777816415
[13520] train loss: 6.301010936498642, metric: 15.615578174591064, lr: 0.0004723869787994772
[13540] train loss: 0.2732072025537491, metric: 12.539825916290283, lr: 0.0004409373505041003
[13560] train loss: -0.06506412103772163, metric: 12.328397989273071, lr: 0.0004097231721971184
[13580] train loss: 0.4730028361082077, metric: 15.24332857131958, lr: 0.000378868862753734
[13600] train loss: -0.1405467577278614, metric: 13.423712968826294, lr: 0.00034849741496145725
[13620] train loss: -0.12525881081819534, metric: 13.490375995635986, lr: 0.0003187299007549882
[13640] train loss: -0.18382925912737846, metric: 11.79501748085022, lr: 0.0002896849764510989
[13660] train loss: -0.24115747585892677, metric: 10.597624063491821, lr: 0.0002614784170873463
[13680] train loss: -0.27099237963557243, metric: 9.514214754104614, lr: 0.00023422270896844566
[13700] train loss: -0.2382666990160942, metric: 8.724064469337463, lr: 0.00020802643848583102
[13720] train loss: -0.25402307510375977, metric: 10.770486831665039, lr: 0.00018299407383892685
[13740] train loss: -0.15804564766585827, metric: 11.392794370651245, lr: 0.00015922538295853883
[13760] train loss: -0.2131832130253315, metric: 10.489413022994995, lr: 0.00013681512791663408
[13780] train loss: -0.1460067369043827, metric: 10.95326018333435, lr: 0.00011585262109292671
[13800] train loss: -0.007542133331298828, metric: 11.154276371002197, lr: 9.999999747378752e-05
[13820] train loss: 1.3398386128246784, metric: 12.719115257263184, lr: 9.999999747378752e-05
[13840] train loss: 2.318982779979706, metric: 19.920342445373535, lr: 9.999999747378752e-05
[13860] train loss: 1.6428019851446152, metric: 19.01789951324463, lr: 9.999999747378752e-05
[13880] train loss: 4.943155072629452, metric: 19.401140928268433, lr: 9.999999747378752e-05
[13900] train loss: 1.0088526532053947, metric: 16.710798263549805, lr: 9.999999747378752e-05
[13920] train loss: 1.78043545037508, metric: 16.84956407546997, lr: 9.999999747378752e-05
[13940] train loss: 1.4045712314546108, metric: 17.904059410095215, lr: 9.999999747378752e-05
[13960] train loss: 1.3443311266601086, metric: 17.912784099578857, lr: 9.999999747378752e-05
[13980] train loss: 0.6763841658830643, metric: 17.26444983482361, lr: 9.999999747378752e-05
[14000] train loss: 1.0546252131462097, metric: 16.90922212600708, lr: 9.999999747378752e-05
[14020] train loss: 0.23034705966711044, metric: 14.892207860946655, lr: 0.0009994393913075328
[14040] train loss: 0.012281540781259537, metric: 12.736008644104004, lr: 0.0009969500824809074
[14060] train loss: 0.02052006870508194, metric: 12.38840913772583, lr: 0.000992479850538075
[14080] train loss: 0.23300915956497192, metric: 10.755168676376343, lr: 0.000986046390607953
[14100] train loss: 1.3963387161493301, metric: 12.09347939491272, lr: 0.0009776754304766655
[14120] train loss: 0.27499449998140335, metric: 14.429422855377197, lr: 0.0009674003813415766
[14140] train loss: 0.5743026360869408, metric: 14.025872588157654, lr: 0.0009552621049806476
[14160] train loss: 0.25345294922590256, metric: 9.595524072647095, lr: 0.0009413089719600976
[14180] train loss: -0.023729152977466583, metric: 12.02161955833435, lr: 0.0009255966870114207
[14200] train loss: -0.017518211156129837, metric: 12.576471328735352, lr: 0.00090818788157776
[14220] train loss: -0.07030843198299408, metric: 12.126650214195251, lr: 0.0008891518809832633
[14240] train loss: -0.09500586986541748, metric: 14.01141369342804, lr: 0.0008685645880177617
[14260] train loss: -0.0064002349972724915, metric: 12.122219920158386, lr: 0.0008465081336908042
[14280] train loss: -0.17680270969867706, metric: 8.137923955917358, lr: 0.0008230703533627093
[14300] train loss: -0.057621560990810394, metric: 10.981907367706299, lr: 0.0007983447285369039
[14320] train loss: 0.26495587825775146, metric: 11.315852403640747, lr: 0.0007724298629909754
[14340] train loss: 1.9048532880842686, metric: 19.8449125289917, lr: 0.0007454289589077234
[14360] train loss: 0.5278234984725714, metric: 13.256095886230469, lr: 0.0007174497004598379
[14380] train loss: 1.033759593963623, metric: 13.600974559783936, lr: 0.00068860367173329
[14400] train loss: 0.24516814574599266, metric: 12.480858087539673, lr: 0.0006590057746507227
[14420] train loss: 1.8350475765764713, metric: 11.638429880142212, lr: 0.0006287740543484688
[14440] train loss: 0.3438832499086857, metric: 11.111615896224976, lr: 0.000598029000684619
[14460] train loss: 1.8481251448392868, metric: 13.645092248916626, lr: 0.0005668931407853961
[14480] train loss: 0.8392613604664803, metric: 11.448460578918457, lr: 0.0005354906315915287
[14500] train loss: 0.5497415997087955, metric: 12.365491151809692, lr: 0.0005039466777816415
[14520] train loss: 0.8970681764185429, metric: 13.400512218475342, lr: 0.0004723869787994772
[14540] train loss: 0.400656346231699, metric: 11.975786685943604, lr: 0.0004409373505041003
[14560] train loss: 0.7925581485033035, metric: 16.486534118652344, lr: 0.0004097231721971184
[14580] train loss: 2.0827162824571133, metric: 18.440589427947998, lr: 0.000378868862753734
[14600] train loss: 0.8369136415421963, metric: 22.219712734222412, lr: 0.00034849741496145725
[14620] train loss: 0.03872080147266388, metric: 16.183187246322632, lr: 0.0003187299007549882
[14640] train loss: -0.166914701461792, metric: 16.79440188407898, lr: 0.0002896849764510989
[14660] train loss: -0.19825667887926102, metric: 16.167831897735596, lr: 0.0002614784170873463
[14680] train loss: -0.05639643967151642, metric: 16.694689512252808, lr: 0.00023422270896844566
[14700] train loss: 0.018569253385066986, metric: 15.637961387634277, lr: 0.00020802643848583102
[14720] train loss: 0.005477335304021835, metric: 16.981767654418945, lr: 0.00018299407383892685
[14740] train loss: 0.017749708145856857, metric: 16.087740421295166, lr: 0.00015922538295853883
[14760] train loss: 0.3185305707156658, metric: 15.504979133605957, lr: 0.00013681512791663408
[14780] train loss: 1.2088366821408272, metric: 15.838919162750244, lr: 0.00011585262109292671
[14800] train loss: 2.727447036653757, metric: 22.007047176361084, lr: 9.999999747378752e-05
[14820] train loss: 0.5463603883981705, metric: 17.29463291168213, lr: 9.999999747378752e-05
[14840] train loss: 2.035785313695669, metric: 19.108529806137085, lr: 9.999999747378752e-05
[14860] train loss: 0.49219800159335136, metric: 14.896690607070923, lr: 9.999999747378752e-05
[14880] train loss: -0.0543268620967865, metric: 13.313965082168579, lr: 9.999999747378752e-05
[14900] train loss: -0.1817491203546524, metric: 14.524604320526123, lr: 9.999999747378752e-05
[14920] train loss: -0.1133643388748169, metric: 14.462655544281006, lr: 9.999999747378752e-05
[14940] train loss: 0.03761963173747063, metric: 15.578272342681885, lr: 9.999999747378752e-05
[14960] train loss: 0.24185000360012054, metric: 12.679733276367188, lr: 9.999999747378752e-05
[14980] train loss: 0.5631724931299686, metric: 12.198307037353516, lr: 9.999999747378752e-05
[15000] train loss: 0.4322889819741249, metric: 14.892459392547607, lr: 9.999999747378752e-05
[15020] train loss: 0.26911574974656105, metric: 14.850245952606201, lr: 0.0009994393913075328
[15040] train loss: 0.09039867669343948, metric: 14.043012380599976, lr: 0.0009969500824809074
[15060] train loss: 0.35456935688853264, metric: 12.271500825881958, lr: 0.000992479850538075
[15080] train loss: 0.071356862783432, metric: 14.02000641822815, lr: 0.000986046390607953
[15100] train loss: 0.02373826876282692, metric: 11.711909770965576, lr: 0.0009776754304766655
[15120] train loss: 2.6796298660337925, metric: 17.824390649795532, lr: 0.0009674003813415766
[15140] train loss: 0.4411376789212227, metric: 13.011493444442749, lr: 0.0009552621049806476
[15160] train loss: 0.5452982150018215, metric: 15.399486541748047, lr: 0.0009413089719600976
[15180] train loss: 0.5435006693005562, metric: 12.417935848236084, lr: 0.0009255966870114207
[15200] train loss: 0.7625737339258194, metric: 12.926019191741943, lr: 0.00090818788157776
[15220] train loss: 0.023321382701396942, metric: 13.558602809906006, lr: 0.0008891518809832633
[15240] train loss: 0.028862960636615753, metric: 13.020218133926392, lr: 0.0008685645880177617
[15260] train loss: 0.5272877067327499, metric: 12.167092561721802, lr: 0.0008465081336908042
[15280] train loss: 0.09280198067426682, metric: 11.05051851272583, lr: 0.0008230703533627093
[15300] train loss: 1.5894763432443142, metric: 13.999687433242798, lr: 0.0007983447285369039
[15320] train loss: 0.6658500283956528, metric: 14.064783334732056, lr: 0.0007724298629909754
[15340] train loss: 0.42679132893681526, metric: 18.891554355621338, lr: 0.0007454289589077234
[15360] train loss: 0.3108922466635704, metric: 12.487841844558716, lr: 0.0007174497004598379
[15380] train loss: 0.10848221555352211, metric: 18.109521865844727, lr: 0.00068860367173329
[15400] train loss: 0.005647599697113037, metric: 16.564457416534424, lr: 0.0006590057746507227
[15420] train loss: -0.1360834389925003, metric: 16.380326747894287, lr: 0.0006287740543484688
[15440] train loss: -0.08608365431427956, metric: 16.717973709106445, lr: 0.000598029000684619
[15460] train loss: 0.01995590701699257, metric: 17.049105644226074, lr: 0.0005668931407853961
[15480] train loss: 0.6606936827301979, metric: 20.281590938568115, lr: 0.0005354906315915287
[15500] train loss: 0.39155005291104317, metric: 17.598905324935913, lr: 0.0005039466777816415
[15520] train loss: 0.37008948251605034, metric: 17.267168521881104, lr: 0.0004723869787994772
[15540] train loss: 0.1156889833509922, metric: 16.814784049987793, lr: 0.0004409373505041003
[15560] train loss: 0.32644250243902206, metric: 17.419671773910522, lr: 0.0004097231721971184
[15580] train loss: -0.06357532739639282, metric: 15.690310001373291, lr: 0.000378868862753734
[15600] train loss: 0.2795282006263733, metric: 16.27364182472229, lr: 0.00034849741496145725
[15620] train loss: 0.5392328575253487, metric: 17.51766347885132, lr: 0.0003187299007549882
[15640] train loss: 0.18933355808258057, metric: 17.971231698989868, lr: 0.0002896849764510989
[15660] train loss: -0.07936518639326096, metric: 16.197341918945312, lr: 0.0002614784170873463
[15680] train loss: -0.17767126858234406, metric: 14.629769086837769, lr: 0.00023422270896844566
[15700] train loss: -0.2045326977968216, metric: 13.97978138923645, lr: 0.00020802643848583102
[15720] train loss: -0.14537394791841507, metric: 15.003206968307495, lr: 0.00018299407383892685
[15740] train loss: -0.09624423086643219, metric: 13.843731164932251, lr: 0.00015922538295853883
[15760] train loss: 0.9801542870700359, metric: 19.03961992263794, lr: 0.00013681512791663408
[15780] train loss: 0.20196985080838203, metric: 17.397759914398193, lr: 0.00011585262109292671
[15800] train loss: 0.03183857724070549, metric: 17.026680946350098, lr: 9.999999747378752e-05
[15820] train loss: 0.11951395869255066, metric: 14.692871570587158, lr: 9.999999747378752e-05
[15840] train loss: -0.14964601024985313, metric: 15.023664951324463, lr: 9.999999747378752e-05
[15860] train loss: -0.1028682291507721, metric: 15.369372844696045, lr: 9.999999747378752e-05
[15880] train loss: 1.244470253586769, metric: 20.730236768722534, lr: 9.999999747378752e-05
[15900] train loss: 0.23274896666407585, metric: 18.885494232177734, lr: 9.999999747378752e-05
[15920] train loss: -0.037301842123270035, metric: 15.753160238265991, lr: 9.999999747378752e-05
[15940] train loss: -0.14353765174746513, metric: 15.602863073348999, lr: 9.999999747378752e-05
[15960] train loss: -0.15393539890646935, metric: 12.876715660095215, lr: 9.999999747378752e-05
[15980] train loss: -0.17825444042682648, metric: 12.592052459716797, lr: 9.999999747378752e-05
[16000] train loss: -0.1553264670073986, metric: 13.340639114379883, lr: 9.999999747378752e-05
[20] train loss: -0.21754878014326096, metric: 12.705005526542664, lr: 0.0009994393913075328
[40] train loss: -0.2533998303115368, metric: 9.92216420173645, lr: 0.0009969500824809074
[60] train loss: -0.30874089151620865, metric: 7.698668479919434, lr: 0.000992479850538075
[80] train loss: -0.29141508787870407, metric: 7.577997326850891, lr: 0.000986046390607953
[100] train loss: -0.2583331950008869, metric: 8.646888017654419, lr: 0.0009776754304766655
[120] train loss: 0.21520066261291504, metric: 10.10905647277832, lr: 0.0009674003813415766
[140] train loss: -0.01951037347316742, metric: 10.395645141601562, lr: 0.0009552621049806476
[160] train loss: 0.14762765169143677, metric: 10.53351354598999, lr: 0.0009413089719600976
[180] train loss: -0.138650082051754, metric: 7.362547755241394, lr: 0.0009255966870114207
[200] train loss: -0.2529272697865963, metric: 9.227229714393616, lr: 0.00090818788157776
[220] train loss: -0.30815090239048004, metric: 8.581923842430115, lr: 0.0008891518809832633
[240] train loss: 0.031302399933338165, metric: 9.146317958831787, lr: 0.0008685645880177617
[260] train loss: 0.47516652196645737, metric: 12.35092842578888, lr: 0.0008465081336908042
[280] train loss: 1.162335604429245, metric: 10.071420192718506, lr: 0.0008230703533627093
[300] train loss: 0.6673693284392357, metric: 11.125593185424805, lr: 0.0007983447285369039
[320] train loss: -0.0701712816953659, metric: 9.251442074775696, lr: 0.0007724298629909754
[340] train loss: 0.42166946083307266, metric: 10.685992002487183, lr: 0.0007454289589077234
[360] train loss: 0.7344706729054451, metric: 14.264834880828857, lr: 0.0007174497004598379
[380] train loss: 0.15411541238427162, metric: 10.526118278503418, lr: 0.00068860367173329
[400] train loss: 1.667010247707367, metric: 10.66566014289856, lr: 0.0006590057746507227
[420] train loss: 2.3930554762482643, metric: 13.145837783813477, lr: 0.0006287740543484688
[440] train loss: 2.664780665189028, metric: 16.468044757843018, lr: 0.000598029000684619
[460] train loss: 1.5745310261845589, metric: 12.914798021316528, lr: 0.0005668931407853961
[480] train loss: 0.40680910274386406, metric: 13.196610450744629, lr: 0.0005354906315915287
[500] train loss: 0.36057040840387344, metric: 21.966089248657227, lr: 0.0005039466777816415
[520] train loss: 5.8338221944868565, metric: 18.761833429336548, lr: 0.0004723869787994772
[540] train loss: 0.8582390658557415, metric: 14.727909088134766, lr: 0.0004409373505041003
[560] train loss: 0.014314237982034683, metric: 11.85008978843689, lr: 0.0004097231721971184
[580] train loss: -0.0975956991314888, metric: 9.344194173812866, lr: 0.000378868862753734
[600] train loss: 0.7103821076452732, metric: 11.015401601791382, lr: 0.00034849741496145725
[620] train loss: 0.07078327611088753, metric: 16.11396098136902, lr: 0.0003187299007549882
[640] train loss: -0.042450204491615295, metric: 10.45423936843872, lr: 0.0002896849764510989
[660] train loss: 0.587919544428587, metric: 10.954516172409058, lr: 0.0002614784170873463
[680] train loss: 0.3096223287284374, metric: 11.693374872207642, lr: 0.00023422270896844566
[700] train loss: 0.046117886900901794, metric: 12.659900188446045, lr: 0.00020802643848583102
[720] train loss: -0.0030976496636867523, metric: 13.170332431793213, lr: 0.00018299407383892685
[740] train loss: 0.01974860206246376, metric: 10.530059576034546, lr: 0.00015922538295853883
[760] train loss: -0.08352764695882797, metric: 8.556596636772156, lr: 0.00013681512791663408
[780] train loss: 0.07804514840245247, metric: 12.0398508310318, lr: 0.00011585262109292671
[800] train loss: 0.004954792559146881, metric: 10.754907965660095, lr: 9.999999747378752e-05
[820] train loss: 0.401615247130394, metric: 9.577906727790833, lr: 9.999999747378752e-05
[840] train loss: 0.3077210560441017, metric: 8.28712272644043, lr: 9.999999747378752e-05
[860] train loss: 0.09121815487742424, metric: 7.002656817436218, lr: 9.999999747378752e-05
[880] train loss: 0.10546420142054558, metric: 9.730990886688232, lr: 9.999999747378752e-05
[900] train loss: 1.2102830708026886, metric: 11.29492473602295, lr: 9.999999747378752e-05
[920] train loss: 0.4348633326590061, metric: 11.48872709274292, lr: 9.999999747378752e-05
[940] train loss: 0.1507764868438244, metric: 14.27233374118805, lr: 9.999999747378752e-05
[960] train loss: 0.06107057258486748, metric: 12.673041343688965, lr: 9.999999747378752e-05
[980] train loss: 0.1703873910009861, metric: 13.664350748062134, lr: 9.999999747378752e-05
[1000] train loss: 0.32348721101880074, metric: 11.90852689743042, lr: 9.999999747378752e-05
[1020] train loss: 1.114390879869461, metric: 12.36412239074707, lr: 0.0009994393913075328
[1040] train loss: -0.1273968368768692, metric: 11.864283800125122, lr: 0.0009969500824809074
[1060] train loss: -0.2831561677157879, metric: 8.699937343597412, lr: 0.000992479850538075
[1080] train loss: -0.31992268934845924, metric: 9.069919347763062, lr: 0.000986046390607953
[1100] train loss: -0.2933819070458412, metric: 9.716400623321533, lr: 0.0009776754304766655
[1120] train loss: -0.3022603578865528, metric: 9.465640306472778, lr: 0.0009674003813415766
[1140] train loss: -0.3170221894979477, metric: 9.990508556365967, lr: 0.0009552621049806476
[1160] train loss: -0.32453858479857445, metric: 10.804428100585938, lr: 0.0009413089719600976
[1180] train loss: -0.3390664905309677, metric: 8.438331961631775, lr: 0.0009255966870114207
[1200] train loss: -0.353727113455534, metric: 7.818821668624878, lr: 0.00090818788157776
[1220] train loss: -0.3704874515533447, metric: 8.00925874710083, lr: 0.0008891518809832633
[1240] train loss: -0.3857019618153572, metric: 7.981659173965454, lr: 0.0008685645880177617
[1260] train loss: -0.2863779701292515, metric: 9.171337842941284, lr: 0.0008465081336908042
[1280] train loss: -0.3445768356323242, metric: 8.731086254119873, lr: 0.0008230703533627093
[1300] train loss: -0.3622376620769501, metric: 8.14386785030365, lr: 0.0007983447285369039
[1320] train loss: -0.3378003239631653, metric: 7.863055467605591, lr: 0.0007724298629909754
[1340] train loss: -0.3080822415649891, metric: 7.025432825088501, lr: 0.0007454289589077234
[1360] train loss: -0.3332129046320915, metric: 6.467144250869751, lr: 0.0007174497004598379
[1380] train loss: -0.3837640956044197, metric: 6.658999800682068, lr: 0.00068860367173329
[1400] train loss: -0.3903333619236946, metric: 6.768303036689758, lr: 0.0006590057746507227
[1420] train loss: -0.3906969726085663, metric: 7.222053408622742, lr: 0.0006287740543484688
[1440] train loss: -0.37322214990854263, metric: 7.3529675006866455, lr: 0.000598029000684619
[1460] train loss: -0.3586183711886406, metric: 7.963481068611145, lr: 0.0005668931407853961
[1480] train loss: -0.32096582278609276, metric: 8.11364233493805, lr: 0.0005354906315915287
[1500] train loss: -0.31429052725434303, metric: 8.67325234413147, lr: 0.0005039466777816415
[1520] train loss: -0.2874701954424381, metric: 10.071135878562927, lr: 0.0004723869787994772
[1540] train loss: -0.03684074431657791, metric: 11.90558135509491, lr: 0.0004409373505041003
[1560] train loss: -0.3093918152153492, metric: 8.845454216003418, lr: 0.0004097231721971184
[1580] train loss: -0.2928676903247833, metric: 9.158805131912231, lr: 0.000378868862753734
[1600] train loss: -0.3282269947230816, metric: 7.4973098039627075, lr: 0.00034849741496145725
[1620] train loss: -0.3279000222682953, metric: 8.456368684768677, lr: 0.0003187299007549882
[1640] train loss: -0.17049125581979752, metric: 9.780461192131042, lr: 0.0002896849764510989
[1660] train loss: 0.005134783685207367, metric: 10.417348623275757, lr: 0.0002614784170873463
[1680] train loss: 0.01570810377597809, metric: 10.05992341041565, lr: 0.00023422270896844566
[1700] train loss: -0.08925340324640274, metric: 11.407602548599243, lr: 0.00020802643848583102
[1720] train loss: -0.16104865074157715, metric: 8.928167581558228, lr: 0.00018299407383892685
[1740] train loss: -0.20489978790283203, metric: 10.014533519744873, lr: 0.00015922538295853883
[1760] train loss: -0.15768034756183624, metric: 9.734904527664185, lr: 0.00013681512791663408
[1780] train loss: -0.102754145860672, metric: 10.121443033218384, lr: 0.00011585262109292671
[1800] train loss: -0.15619910135865211, metric: 9.60132908821106, lr: 9.999999747378752e-05
[1820] train loss: -0.03749403730034828, metric: 11.246521711349487, lr: 9.999999747378752e-05
[1840] train loss: -0.04599112272262573, metric: 9.610333442687988, lr: 9.999999747378752e-05
[1860] train loss: -0.14897673577070236, metric: 9.83318018913269, lr: 9.999999747378752e-05
[1880] train loss: -0.2014143168926239, metric: 9.3754563331604, lr: 9.999999747378752e-05
[1900] train loss: -0.24880634248256683, metric: 10.324626803398132, lr: 9.999999747378752e-05
[1920] train loss: -0.13268673047423363, metric: 10.847976088523865, lr: 9.999999747378752e-05
[1940] train loss: -0.11229456216096878, metric: 9.850030422210693, lr: 9.999999747378752e-05
[1960] train loss: -0.21927160397171974, metric: 9.025530934333801, lr: 9.999999747378752e-05
[1980] train loss: -0.09463196992874146, metric: 7.9509230852127075, lr: 9.999999747378752e-05
[2000] train loss: -0.23053409159183502, metric: 10.75536572933197, lr: 9.999999747378752e-05
[2020] train loss: -0.24410351738333702, metric: 8.038051128387451, lr: 0.0009994393913075328
[2040] train loss: 0.24916860461235046, metric: 10.088238954544067, lr: 0.0009969500824809074
[2060] train loss: 0.4718904048204422, metric: 15.48967981338501, lr: 0.000992479850538075
[2080] train loss: -0.15880055353045464, metric: 13.57480263710022, lr: 0.000986046390607953
[2100] train loss: -0.249437365680933, metric: 9.520045042037964, lr: 0.0009776754304766655
[2120] train loss: -0.20924071222543716, metric: 8.387368202209473, lr: 0.0009674003813415766
[2140] train loss: -0.32136087864637375, metric: 8.150325417518616, lr: 0.0009552621049806476
[2160] train loss: -0.34717385470867157, metric: 7.901589870452881, lr: 0.0009413089719600976
[2180] train loss: -0.3271568939089775, metric: 8.851818799972534, lr: 0.0009255966870114207
[2200] train loss: -0.2214125283062458, metric: 8.438419818878174, lr: 0.00090818788157776
[2220] train loss: -0.2618005834519863, metric: 8.061155200004578, lr: 0.0008891518809832633
[2240] train loss: -0.2696204073727131, metric: 6.878767490386963, lr: 0.0008685645880177617
[2260] train loss: 0.2338663823902607, metric: 8.646852135658264, lr: 0.0008465081336908042
[2280] train loss: -0.13063734769821167, metric: 7.921950936317444, lr: 0.0008230703533627093
[2300] train loss: -0.16762595623731613, metric: 8.133729815483093, lr: 0.0007983447285369039
[2320] train loss: -0.10982827842235565, metric: 7.887875080108643, lr: 0.0007724298629909754
[2340] train loss: -0.2874160632491112, metric: 7.427611351013184, lr: 0.0007454289589077234
[2360] train loss: -0.028159774839878082, metric: 11.612495422363281, lr: 0.0007174497004598379
[2380] train loss: -0.10656788572669029, metric: 8.965152740478516, lr: 0.00068860367173329
[2400] train loss: -0.1464274786412716, metric: 8.505938053131104, lr: 0.0006590057746507227
[2420] train loss: 0.8024210035800934, metric: 12.045421957969666, lr: 0.0006287740543484688
[2440] train loss: 0.7209313102066517, metric: 10.23024868965149, lr: 0.000598029000684619
[2460] train loss: 2.2536644339561462, metric: 12.415215969085693, lr: 0.0005668931407853961
[2480] train loss: 1.302047025412321, metric: 12.779710292816162, lr: 0.0005354906315915287
[2500] train loss: 0.674143522977829, metric: 9.880363941192627, lr: 0.0005039466777816415
[2520] train loss: 0.2750348038971424, metric: 11.416422009468079, lr: 0.0004723869787994772
[2540] train loss: 0.35326024144887924, metric: 10.870577335357666, lr: 0.0004409373505041003
[2560] train loss: 0.2927112653851509, metric: 9.71122682094574, lr: 0.0004097231721971184
[2580] train loss: -0.18749020993709564, metric: 10.547844648361206, lr: 0.000378868862753734
[2600] train loss: -0.2593151368200779, metric: 10.541614055633545, lr: 0.00034849741496145725
[2620] train loss: -0.27499499544501305, metric: 9.028821349143982, lr: 0.0003187299007549882
[2640] train loss: -0.2317321076989174, metric: 8.719560623168945, lr: 0.0002896849764510989
[2660] train loss: -0.2972583621740341, metric: 7.925013303756714, lr: 0.0002614784170873463
[2680] train loss: -0.21207455173134804, metric: 7.4186753034591675, lr: 0.00023422270896844566
[2700] train loss: -0.17653975635766983, metric: 9.659970998764038, lr: 0.00020802643848583102
[2720] train loss: -0.26682280749082565, metric: 7.8049681186676025, lr: 0.00018299407383892685
[2740] train loss: -0.2736143209040165, metric: 7.4334716796875, lr: 0.00015922538295853883
[2760] train loss: -0.29064154252409935, metric: 7.844593167304993, lr: 0.00013681512791663408
[2780] train loss: -0.289884228259325, metric: 8.55553674697876, lr: 0.00011585262109292671
[2800] train loss: -0.2714282423257828, metric: 10.39587938785553, lr: 9.999999747378752e-05
[2820] train loss: -0.2618645429611206, metric: 9.402950525283813, lr: 9.999999747378752e-05
[2840] train loss: -0.2457059621810913, metric: 8.86668837070465, lr: 9.999999747378752e-05
[2860] train loss: -0.18235166743397713, metric: 10.10909104347229, lr: 9.999999747378752e-05
[2880] train loss: 0.14157719537615776, metric: 13.297220706939697, lr: 9.999999747378752e-05
[2900] train loss: -0.04118933528661728, metric: 11.857621669769287, lr: 9.999999747378752e-05
[2920] train loss: -0.19346625357866287, metric: 9.089353561401367, lr: 9.999999747378752e-05
[2940] train loss: -0.05901765823364258, metric: 10.308602809906006, lr: 9.999999747378752e-05
[2960] train loss: -0.09141984209418297, metric: 12.870120525360107, lr: 9.999999747378752e-05
[2980] train loss: -0.1621793769299984, metric: 11.788213729858398, lr: 9.999999747378752e-05
[3000] train loss: -0.16967997327446938, metric: 8.121476411819458, lr: 9.999999747378752e-05
[3020] train loss: -0.26407670229673386, metric: 7.763269066810608, lr: 0.0009994393913075328
[3040] train loss: -0.33925987780094147, metric: 7.207183480262756, lr: 0.0009969500824809074
[3060] train loss: -0.3486485853791237, metric: 6.975210428237915, lr: 0.000992479850538075
[3080] train loss: 0.4516098164021969, metric: 14.638403415679932, lr: 0.000986046390607953
[3100] train loss: -0.042417291551828384, metric: 9.174414992332458, lr: 0.0009776754304766655
[3120] train loss: -0.11651651561260223, metric: 10.01902961730957, lr: 0.0009674003813415766
[3140] train loss: -0.2845671810209751, metric: 8.378809332847595, lr: 0.0009552621049806476
[3160] train loss: -0.30426938086748123, metric: 8.601631164550781, lr: 0.0009413089719600976
[3180] train loss: -0.18437368422746658, metric: 10.164840459823608, lr: 0.0009255966870114207
[3200] train loss: 0.24999945238232613, metric: 11.882188320159912, lr: 0.00090818788157776
[3220] train loss: 1.2907795272767544, metric: 15.208723068237305, lr: 0.0008891518809832633
[3240] train loss: 0.677690889686346, metric: 13.727324485778809, lr: 0.0008685645880177617
[3260] train loss: 0.14587202668190002, metric: 14.671993017196655, lr: 0.0008465081336908042
[3280] train loss: -0.15765253826975822, metric: 9.684947490692139, lr: 0.0008230703533627093
[3300] train loss: -0.26331308484077454, metric: 8.945802211761475, lr: 0.0007983447285369039
[3320] train loss: -0.2822030670940876, metric: 7.418320536613464, lr: 0.0007724298629909754
[3340] train loss: -0.179091677069664, metric: 9.013229370117188, lr: 0.0007454289589077234
[3360] train loss: 0.27466949075460434, metric: 11.423288822174072, lr: 0.0007174497004598379
[3380] train loss: 4.1989086121320724, metric: 17.30979824066162, lr: 0.00068860367173329
[3400] train loss: 0.40516698360443115, metric: 13.269041776657104, lr: 0.0006590057746507227
[3420] train loss: 0.15014493092894554, metric: 10.516240119934082, lr: 0.0006287740543484688
[3440] train loss: -0.08840415254235268, metric: 9.36167573928833, lr: 0.000598029000684619
[3460] train loss: -0.18478793650865555, metric: 8.790503740310669, lr: 0.0005668931407853961
[3480] train loss: -0.17314520478248596, metric: 9.697398900985718, lr: 0.0005354906315915287
[3500] train loss: -0.1765742003917694, metric: 8.661640405654907, lr: 0.0005039466777816415
[3520] train loss: -0.20815736055374146, metric: 8.974225640296936, lr: 0.0004723869787994772
[3540] train loss: -0.265600323677063, metric: 8.544286966323853, lr: 0.0004409373505041003
[3560] train loss: -0.22038456052541733, metric: 6.9550275802612305, lr: 0.0004097231721971184
[3580] train loss: -0.18654946610331535, metric: 7.870280861854553, lr: 0.000378868862753734
[3600] train loss: 4.28133037686348, metric: 22.686134576797485, lr: 0.00034849741496145725
[3620] train loss: 1.1712988838553429, metric: 20.606285572052002, lr: 0.0003187299007549882
[3640] train loss: 0.9594425410032272, metric: 14.487884044647217, lr: 0.0002896849764510989
[3660] train loss: 1.0944372192025185, metric: 16.56264090538025, lr: 0.0002614784170873463
[3680] train loss: 2.398141548037529, metric: 16.59977960586548, lr: 0.00023422270896844566
[3700] train loss: 4.5558867529034615, metric: 23.036842823028564, lr: 0.00020802643848583102
[3720] train loss: 6.548934891819954, metric: 27.24784564971924, lr: 0.00018299407383892685
[3740] train loss: 5.393459379673004, metric: 29.438803672790527, lr: 0.00015922538295853883
[3760] train loss: 3.858071967959404, metric: 18.70245623588562, lr: 0.00013681512791663408
[3780] train loss: 5.406699031591415, metric: 26.14333486557007, lr: 0.00011585262109292671
[3800] train loss: 5.281934514641762, metric: 21.54987382888794, lr: 9.999999747378752e-05
[3820] train loss: 3.7276139855384827, metric: 23.284295082092285, lr: 9.999999747378752e-05
[3840] train loss: 2.053079217672348, metric: 18.955605506896973, lr: 9.999999747378752e-05
[3860] train loss: 10.082067176699638, metric: 24.068501234054565, lr: 9.999999747378752e-05
[3880] train loss: 2.751919165253639, metric: 19.48689866065979, lr: 9.999999747378752e-05
[3900] train loss: 3.58261039853096, metric: 20.164888381958008, lr: 9.999999747378752e-05
[3920] train loss: 1.6111661195755005, metric: 16.967827558517456, lr: 9.999999747378752e-05
[3940] train loss: 3.722476877272129, metric: 19.478878259658813, lr: 9.999999747378752e-05
[3960] train loss: 7.597509626299143, metric: 19.885215282440186, lr: 9.999999747378752e-05
[3980] train loss: 5.20351168140769, metric: 18.691155195236206, lr: 9.999999747378752e-05
[4000] train loss: 5.812798172235489, metric: 24.320247173309326, lr: 9.999999747378752e-05
[4020] train loss: 1.7475703656673431, metric: 22.00263023376465, lr: 0.0009994393913075328
[4040] train loss: 1.2520118951797485, metric: 22.239277362823486, lr: 0.0009969500824809074
[4060] train loss: 0.6048373468220234, metric: 17.328294038772583, lr: 0.000992479850538075
[4080] train loss: 1.6408866457641125, metric: 15.898731470108032, lr: 0.000986046390607953
[4100] train loss: 0.6750499829649925, metric: 20.078317642211914, lr: 0.0009776754304766655
[4120] train loss: 1.5380617193877697, metric: 12.891731262207031, lr: 0.0009674003813415766
[4140] train loss: 1.4492055140435696, metric: 13.811874151229858, lr: 0.0009552621049806476
[4160] train loss: 0.41289476677775383, metric: 14.26631784439087, lr: 0.0009413089719600976
[4180] train loss: -0.011035196483135223, metric: 14.581137776374817, lr: 0.0009255966870114207
[4200] train loss: -0.1594901643693447, metric: 11.377907514572144, lr: 0.00090818788157776
[4220] train loss: -0.2370617650449276, metric: 9.763067126274109, lr: 0.0008891518809832633
[4240] train loss: -0.2899537421762943, metric: 9.19120168685913, lr: 0.0008685645880177617
[4260] train loss: -0.20817341282963753, metric: 8.2096848487854, lr: 0.0008465081336908042
[4280] train loss: -0.1770910955965519, metric: 9.023745059967041, lr: 0.0008230703533627093
[4300] train loss: -0.12928404659032822, metric: 9.040138006210327, lr: 0.0007983447285369039
[4320] train loss: -0.19946077838540077, metric: 8.948999881744385, lr: 0.0007724298629909754
[4340] train loss: -0.22240815684199333, metric: 8.824790596961975, lr: 0.0007454289589077234
[4360] train loss: -0.24598367884755135, metric: 9.255019664764404, lr: 0.0007174497004598379
[4380] train loss: -0.20400956273078918, metric: 7.548787355422974, lr: 0.00068860367173329
[4400] train loss: 0.548380047082901, metric: 11.468313455581665, lr: 0.0006590057746507227
[4420] train loss: -0.04232541099190712, metric: 11.420058608055115, lr: 0.0006287740543484688
[4440] train loss: 0.5375365503132343, metric: 12.146991729736328, lr: 0.000598029000684619
[4460] train loss: 0.21561171486973763, metric: 12.54240083694458, lr: 0.0005668931407853961
[4480] train loss: 0.08659754320979118, metric: 13.029001951217651, lr: 0.0005354906315915287
[4500] train loss: 0.1673641800880432, metric: 13.771612882614136, lr: 0.0005039466777816415
[4520] train loss: 0.33754486963152885, metric: 12.178907871246338, lr: 0.0004723869787994772
[4540] train loss: 0.3604864254593849, metric: 10.077650547027588, lr: 0.0004409373505041003
[4560] train loss: 0.14645720273256302, metric: 11.37276554107666, lr: 0.0004097231721971184
[4580] train loss: 0.06890727579593658, metric: 10.532709836959839, lr: 0.000378868862753734
[4600] train loss: 0.06408217176795006, metric: 10.927268028259277, lr: 0.00034849741496145725
[4620] train loss: 4.204916298389435, metric: 21.217660427093506, lr: 0.0003187299007549882
[4640] train loss: 0.496493574231863, metric: 11.925266981124878, lr: 0.0002896849764510989
[4660] train loss: 0.09882864356040955, metric: 11.782102108001709, lr: 0.0002614784170873463
[4680] train loss: 0.002566225826740265, metric: 11.252663135528564, lr: 0.00023422270896844566
[4700] train loss: 0.19970044493675232, metric: 11.034840106964111, lr: 0.00020802643848583102
[4720] train loss: 0.043441638350486755, metric: 12.319026827812195, lr: 0.00018299407383892685
[4740] train loss: -0.11914142221212387, metric: 12.335877418518066, lr: 0.00015922538295853883
[4760] train loss: -0.14129118248820305, metric: 10.755700588226318, lr: 0.00013681512791663408
[4780] train loss: -0.1677612029016018, metric: 9.69905710220337, lr: 0.00011585262109292671
[4800] train loss: -0.07871444895863533, metric: 9.797072649002075, lr: 9.999999747378752e-05
[4820] train loss: 0.34561607986688614, metric: 11.393109798431396, lr: 9.999999747378752e-05
[4840] train loss: 0.684081619605422, metric: 10.241080522537231, lr: 9.999999747378752e-05
[4860] train loss: 0.08579587563872337, metric: 12.6891508102417, lr: 9.999999747378752e-05
[4880] train loss: -0.09282460808753967, metric: 10.959934949874878, lr: 9.999999747378752e-05
[4900] train loss: -0.17045184969902039, metric: 9.427582502365112, lr: 9.999999747378752e-05
[4920] train loss: -0.06965554133057594, metric: 10.442020535469055, lr: 9.999999747378752e-05
[4940] train loss: -0.10046019032597542, metric: 11.61587405204773, lr: 9.999999747378752e-05
[4960] train loss: -0.17335769161581993, metric: 10.157488584518433, lr: 9.999999747378752e-05
[4980] train loss: -0.08785266056656837, metric: 8.776236653327942, lr: 9.999999747378752e-05
[5000] train loss: -0.18350813537836075, metric: 10.61271595954895, lr: 9.999999747378752e-05
[5020] train loss: 0.16946912929415703, metric: 11.735620737075806, lr: 0.0009994393913075328
[5040] train loss: 0.01573134958744049, metric: 12.114807844161987, lr: 0.0009969500824809074
[5060] train loss: 1.564394373446703, metric: 16.28432536125183, lr: 0.000992479850538075
[5080] train loss: 1.6614564023911953, metric: 13.049638986587524, lr: 0.000986046390607953
[5100] train loss: 1.5032726302742958, metric: 14.54191541671753, lr: 0.0009776754304766655
[5120] train loss: 0.23063846677541733, metric: 11.386800765991211, lr: 0.0009674003813415766
[5140] train loss: 0.6025070771574974, metric: 15.735465049743652, lr: 0.0009552621049806476
[5160] train loss: -0.032634638249874115, metric: 11.548375129699707, lr: 0.0009413089719600976
[5180] train loss: -0.005524963140487671, metric: 11.146254301071167, lr: 0.0009255966870114207
[5200] train loss: -0.20029088109731674, metric: 11.545437335968018, lr: 0.00090818788157776
[5220] train loss: 0.32002612203359604, metric: 11.54400110244751, lr: 0.0008891518809832633
[5240] train loss: 0.2525121681392193, metric: 12.434397220611572, lr: 0.0008685645880177617
[5260] train loss: 0.17531928792595863, metric: 13.306691408157349, lr: 0.0008465081336908042
[5280] train loss: 0.32186589017510414, metric: 15.51602840423584, lr: 0.0008230703533627093
[5300] train loss: -0.011349305510520935, metric: 12.457860946655273, lr: 0.0007983447285369039
[5320] train loss: 0.039904650300741196, metric: 10.026588320732117, lr: 0.0007724298629909754
[5340] train loss: -0.1429421305656433, metric: 12.368057012557983, lr: 0.0007454289589077234
[5360] train loss: -0.1655414216220379, metric: 10.967811822891235, lr: 0.0007174497004598379
[5380] train loss: 0.06198596581816673, metric: 12.998646020889282, lr: 0.00068860367173329
[5400] train loss: 0.10141238942742348, metric: 11.773033380508423, lr: 0.0006590057746507227
[5420] train loss: 0.12597762048244476, metric: 9.672312140464783, lr: 0.0006287740543484688
[5440] train loss: 0.8288760595023632, metric: 12.831242680549622, lr: 0.000598029000684619
[5460] train loss: 1.0222179628908634, metric: 10.975092887878418, lr: 0.0005668931407853961
[5480] train loss: 0.9732328206300735, metric: 13.472671031951904, lr: 0.0005354906315915287
[5500] train loss: -0.000995393842458725, metric: 10.915005445480347, lr: 0.0005039466777816415
[5520] train loss: 0.6796238012611866, metric: 10.209123849868774, lr: 0.0004723869787994772
[5540] train loss: 0.4957696348428726, metric: 10.354468703269958, lr: 0.0004409373505041003
[5560] train loss: 0.32150135189294815, metric: 11.369524955749512, lr: 0.0004097231721971184
[5580] train loss: 4.491758279502392, metric: 19.491570949554443, lr: 0.000378868862753734
[5600] train loss: 1.4180698283016682, metric: 12.557746171951294, lr: 0.00034849741496145725
[5620] train loss: 0.10703803598880768, metric: 14.063232183456421, lr: 0.0003187299007549882
[5640] train loss: 1.2541719153523445, metric: 14.296719074249268, lr: 0.0002896849764510989
[5660] train loss: 0.5372755974531174, metric: 15.847071647644043, lr: 0.0002614784170873463
[5680] train loss: 0.40955033898353577, metric: 12.136463403701782, lr: 0.00023422270896844566
[5700] train loss: 0.5175860449671745, metric: 12.817802667617798, lr: 0.00020802643848583102
[5720] train loss: 1.2608587257564068, metric: 14.266370296478271, lr: 0.00018299407383892685
[5740] train loss: 2.0235992036759853, metric: 13.642581224441528, lr: 0.00015922538295853883
[5760] train loss: 3.4030431769788265, metric: 17.91231679916382, lr: 0.00013681512791663408
[5780] train loss: 3.3600680828094482, metric: 14.61251974105835, lr: 0.00011585262109292671
[5800] train loss: 1.302766613662243, metric: 13.804056644439697, lr: 9.999999747378752e-05
[5820] train loss: 1.4778246320784092, metric: 16.4586021900177, lr: 9.999999747378752e-05
[5840] train loss: 3.1351946219801903, metric: 16.68984031677246, lr: 9.999999747378752e-05
[5860] train loss: 2.482325442135334, metric: 17.75759506225586, lr: 9.999999747378752e-05
[5880] train loss: 1.3227696679532528, metric: 22.93211531639099, lr: 9.999999747378752e-05
[5900] train loss: 0.6475233696401119, metric: 19.82572627067566, lr: 9.999999747378752e-05
[5920] train loss: 0.13620540499687195, metric: 17.127288103103638, lr: 9.999999747378752e-05
[5940] train loss: 0.19834883883595467, metric: 14.426577091217041, lr: 9.999999747378752e-05
[5960] train loss: 0.4207213297486305, metric: 10.85657787322998, lr: 9.999999747378752e-05
[5980] train loss: 2.598326627165079, metric: 14.84632420539856, lr: 9.999999747378752e-05
[6000] train loss: 1.8587386794388294, metric: 15.97868824005127, lr: 9.999999747378752e-05
[6020] train loss: 2.1921693198382854, metric: 17.749191761016846, lr: 0.0009994393913075328
[6040] train loss: 1.9195262677967548, metric: 20.138730764389038, lr: 0.0009969500824809074
[6060] train loss: 1.267681572586298, metric: 17.079620838165283, lr: 0.000992479850538075
[6080] train loss: 1.0676323808729649, metric: 13.843661785125732, lr: 0.000986046390607953
[6100] train loss: 0.35236602649092674, metric: 15.981959342956543, lr: 0.0009776754304766655
[6120] train loss: 0.8802215680480003, metric: 13.791052341461182, lr: 0.0009674003813415766
[6140] train loss: 1.753583885729313, metric: 16.956302404403687, lr: 0.0009552621049806476
[6160] train loss: 0.4094245061278343, metric: 11.442466139793396, lr: 0.0009413089719600976
[6180] train loss: 0.09590242058038712, metric: 12.960724115371704, lr: 0.0009255966870114207
[6200] train loss: 0.04879792779684067, metric: 10.978477239608765, lr: 0.00090818788157776
[6220] train loss: 0.014726851135492325, metric: 13.222640037536621, lr: 0.0008891518809832633
[6240] train loss: 0.35742050409317017, metric: 16.435941696166992, lr: 0.0008685645880177617
[6260] train loss: 7.185731180012226, metric: 23.253615379333496, lr: 0.0008465081336908042
[6280] train loss: 0.27700668200850487, metric: 16.028464794158936, lr: 0.0008230703533627093
[6300] train loss: 0.00035545602440834045, metric: 15.290099143981934, lr: 0.0007983447285369039
[6320] train loss: -0.18710491433739662, metric: 11.422399759292603, lr: 0.0007724298629909754
[6340] train loss: -0.0213603675365448, metric: 12.551037788391113, lr: 0.0007454289589077234
[6360] train loss: -0.10244640335440636, metric: 12.758132457733154, lr: 0.0007174497004598379
[6380] train loss: -0.09559733048081398, metric: 12.351913690567017, lr: 0.00068860367173329
[6400] train loss: -0.0774165615439415, metric: 12.196027278900146, lr: 0.0006590057746507227
[6420] train loss: -0.004778482019901276, metric: 10.648766040802002, lr: 0.0006287740543484688
[6440] train loss: -0.013386324048042297, metric: 11.634793400764465, lr: 0.000598029000684619
[6460] train loss: -0.21437809616327286, metric: 9.020565390586853, lr: 0.0005668931407853961
[6480] train loss: -0.19340652227401733, metric: 11.109959363937378, lr: 0.0005354906315915287
[6500] train loss: -0.19911089912056923, metric: 10.08077585697174, lr: 0.0005039466777816415
[6520] train loss: -0.19390590861439705, metric: 10.344518423080444, lr: 0.0004723869787994772
[6540] train loss: 0.0704488530755043, metric: 10.759326338768005, lr: 0.0004409373505041003
[6560] train loss: -0.09583073481917381, metric: 10.994220495223999, lr: 0.0004097231721971184
[6580] train loss: -0.14714393764734268, metric: 10.148004412651062, lr: 0.000378868862753734
[6600] train loss: -0.23692692816257477, metric: 9.34632408618927, lr: 0.00034849741496145725
[6620] train loss: -0.24407035112380981, metric: 9.703336000442505, lr: 0.0003187299007549882
[6640] train loss: -0.27530428767204285, metric: 9.785314083099365, lr: 0.0002896849764510989
[6660] train loss: 0.9566591866314411, metric: 19.188530921936035, lr: 0.0002614784170873463
[6680] train loss: 0.14043725281953812, metric: 15.958627700805664, lr: 0.00023422270896844566
[6700] train loss: -0.03886844590306282, metric: 14.78191614151001, lr: 0.00020802643848583102
[6720] train loss: 0.03092338517308235, metric: 15.444965124130249, lr: 0.00018299407383892685
[6740] train loss: 0.42364098876714706, metric: 15.95733094215393, lr: 0.00015922538295853883
[6760] train loss: 0.5015571340918541, metric: 18.259210109710693, lr: 0.00013681512791663408
[6780] train loss: 0.41983744129538536, metric: 16.509475469589233, lr: 0.00011585262109292671
[6800] train loss: 1.941439114511013, metric: 18.620296001434326, lr: 9.999999747378752e-05
[6820] train loss: 2.554340861737728, metric: 15.237127304077148, lr: 9.999999747378752e-05
[6840] train loss: 3.0460048280656338, metric: 17.200729846954346, lr: 9.999999747378752e-05
[6860] train loss: 0.6039737612009048, metric: 13.129028558731079, lr: 9.999999747378752e-05
[6880] train loss: 1.8575317114591599, metric: 15.229777336120605, lr: 9.999999747378752e-05
[6900] train loss: 1.7174683585762978, metric: 17.635494470596313, lr: 9.999999747378752e-05
[6920] train loss: 0.22466301545500755, metric: 11.79480791091919, lr: 9.999999747378752e-05
[6940] train loss: 0.493115596473217, metric: 13.015187621116638, lr: 9.999999747378752e-05
[6960] train loss: 0.2822471037507057, metric: 11.432869911193848, lr: 9.999999747378752e-05
[6980] train loss: -0.060929134488105774, metric: 10.775994539260864, lr: 9.999999747378752e-05
[7000] train loss: 1.8124395944178104, metric: 14.663304805755615, lr: 9.999999747378752e-05
[7020] train loss: 0.4231957234442234, metric: 19.776063919067383, lr: 0.0009994393913075328
[7040] train loss: 0.4747246988117695, metric: 14.04515266418457, lr: 0.0009969500824809074
[7060] train loss: 1.742594338953495, metric: 15.728512287139893, lr: 0.000992479850538075
[7080] train loss: 0.7510583661496639, metric: 14.471339464187622, lr: 0.000986046390607953
[7100] train loss: 0.7005874812602997, metric: 15.38865327835083, lr: 0.0009776754304766655
[7120] train loss: 0.8381506726145744, metric: 14.043760061264038, lr: 0.0009674003813415766
[7140] train loss: 1.2336047515273094, metric: 14.8163423538208, lr: 0.0009552621049806476
[7160] train loss: 0.9112979844212532, metric: 14.811408758163452, lr: 0.0009413089719600976
[7180] train loss: 0.19483618438243866, metric: 15.78433895111084, lr: 0.0009255966870114207
[7200] train loss: -0.042962681502103806, metric: 11.430755138397217, lr: 0.00090818788157776
[7220] train loss: -0.051033396273851395, metric: 12.91822338104248, lr: 0.0008891518809832633
[7240] train loss: 0.06782186403870583, metric: 10.159802436828613, lr: 0.0008685645880177617
[7260] train loss: -0.11113773286342621, metric: 8.333730578422546, lr: 0.0008465081336908042
[7280] train loss: 0.6379644870758057, metric: 15.252460956573486, lr: 0.0008230703533627093
[7300] train loss: 0.07985514774918556, metric: 10.984825372695923, lr: 0.0007983447285369039
[7320] train loss: 0.5901062190532684, metric: 13.083508849143982, lr: 0.0007724298629909754
[7340] train loss: 0.37595435604453087, metric: 13.229896783828735, lr: 0.0007454289589077234
[7360] train loss: 0.48595548793673515, metric: 11.940613269805908, lr: 0.0007174497004598379
[7380] train loss: 0.47743987664580345, metric: 13.895660758018494, lr: 0.00068860367173329
[7400] train loss: 0.8543726876378059, metric: 10.192625522613525, lr: 0.0006590057746507227
[7420] train loss: 0.3395047076046467, metric: 14.108926773071289, lr: 0.0006287740543484688
[7440] train loss: 0.7758192233741283, metric: 17.376245141029358, lr: 0.000598029000684619
[7460] train loss: 2.0704239830374718, metric: 21.370527029037476, lr: 0.0005668931407853961
[7480] train loss: 3.1909394934773445, metric: 17.02903962135315, lr: 0.0005354906315915287
[7500] train loss: 1.6537989228963852, metric: 18.02598547935486, lr: 0.0005039466777816415
[7520] train loss: 2.294221181422472, metric: 16.66329050064087, lr: 0.0004723869787994772
[7540] train loss: 0.786456111818552, metric: 13.31675660610199, lr: 0.0004409373505041003
[7560] train loss: 1.2694525718688965, metric: 15.448715448379517, lr: 0.0004097231721971184
[7580] train loss: 0.6909815892577171, metric: 14.936702251434326, lr: 0.000378868862753734
[7600] train loss: 0.735518291592598, metric: 15.354500770568848, lr: 0.00034849741496145725
[7620] train loss: 1.2973485589027405, metric: 14.707715511322021, lr: 0.0003187299007549882
[7640] train loss: 1.9365103505551815, metric: 13.639522075653076, lr: 0.0002896849764510989
[7660] train loss: 1.3969983644783497, metric: 14.217020988464355, lr: 0.0002614784170873463
[7680] train loss: 1.3229676224291325, metric: 13.006651639938354, lr: 0.00023422270896844566
[7700] train loss: 0.22279899567365646, metric: 16.255380630493164, lr: 0.00020802643848583102
[7720] train loss: 0.11120110005140305, metric: 15.147972822189331, lr: 0.00018299407383892685
[7740] train loss: -0.05058443918824196, metric: 12.944589853286743, lr: 0.00015922538295853883
[7760] train loss: -0.06273983791470528, metric: 12.747993469238281, lr: 0.00013681512791663408
[7780] train loss: -0.09416952356696129, metric: 13.42882490158081, lr: 0.00011585262109292671
[7800] train loss: -0.03126712515950203, metric: 14.175684452056885, lr: 9.999999747378752e-05
[7820] train loss: -0.03267579525709152, metric: 14.030650854110718, lr: 9.999999747378752e-05
[7840] train loss: -0.1376262940466404, metric: 13.805417776107788, lr: 9.999999747378752e-05
[7860] train loss: -0.16834328323602676, metric: 13.382714986801147, lr: 9.999999747378752e-05
[7880] train loss: -0.19003507494926453, metric: 12.390196323394775, lr: 9.999999747378752e-05
[7900] train loss: -0.16759750619530678, metric: 12.26915192604065, lr: 9.999999747378752e-05
[7920] train loss: -0.13652588427066803, metric: 12.855706691741943, lr: 9.999999747378752e-05
[7940] train loss: -0.17303895950317383, metric: 12.531750679016113, lr: 9.999999747378752e-05
[7960] train loss: -0.16366181150078773, metric: 12.290832757949829, lr: 9.999999747378752e-05
[7980] train loss: 0.013911522924900055, metric: 13.497421264648438, lr: 9.999999747378752e-05
[8000] train loss: 0.15659209713339806, metric: 12.411941051483154, lr: 9.999999747378752e-05
[8020] train loss: -0.15516797825694084, metric: 12.565817594528198, lr: 0.0009994393913075328
[8040] train loss: -0.12433099374175072, metric: 13.623548984527588, lr: 0.0009969500824809074
[8060] train loss: 0.07320083677768707, metric: 13.478301048278809, lr: 0.000992479850538075
[8080] train loss: 2.8795705810189247, metric: 13.96549367904663, lr: 0.000986046390607953
[8100] train loss: 0.2816208340227604, metric: 12.618507146835327, lr: 0.0009776754304766655
[8120] train loss: 0.2020750418305397, metric: 12.649624347686768, lr: 0.0009674003813415766
[8140] train loss: 0.6486588716506958, metric: 11.11256217956543, lr: 0.0009552621049806476
[8160] train loss: 0.32352302968502045, metric: 10.580666303634644, lr: 0.0009413089719600976
[8180] train loss: 0.479425847530365, metric: 10.116430640220642, lr: 0.0009255966870114207
[8200] train loss: 2.4663451090455055, metric: 18.425697803497314, lr: 0.00090818788157776
[8220] train loss: 0.9579687900841236, metric: 15.135260343551636, lr: 0.0008891518809832633
[8240] train loss: 2.12945094704628, metric: 13.911442041397095, lr: 0.0008685645880177617
[8260] train loss: 3.1356127224862576, metric: 17.600762367248535, lr: 0.0008465081336908042
[8280] train loss: 0.17014651745557785, metric: 12.120908260345459, lr: 0.0008230703533627093
[8300] train loss: 0.48874927312135696, metric: 13.495247602462769, lr: 0.0007983447285369039
[8320] train loss: 0.4513118416070938, metric: 13.523263216018677, lr: 0.0007724298629909754
[8340] train loss: 2.203332707285881, metric: 14.306525945663452, lr: 0.0007454289589077234
[8360] train loss: 1.1452465951442719, metric: 13.231860160827637, lr: 0.0007174497004598379
[8380] train loss: 0.8547144569456577, metric: 12.370832920074463, lr: 0.00068860367173329
[8400] train loss: 0.06065085530281067, metric: 9.777484059333801, lr: 0.0006590057746507227
[8420] train loss: 1.4510545022785664, metric: 14.94629430770874, lr: 0.0006287740543484688
[8440] train loss: 1.348597127944231, metric: 11.947014808654785, lr: 0.000598029000684619
[8460] train loss: 0.76934714615345, metric: 10.952613115310669, lr: 0.0005668931407853961
[8480] train loss: 0.6629887744784355, metric: 11.907269835472107, lr: 0.0005354906315915287
[8500] train loss: 1.5313482731580734, metric: 11.225423574447632, lr: 0.0005039466777816415
[8520] train loss: 4.160160303115845, metric: 15.185251474380493, lr: 0.0004723869787994772
[8540] train loss: 1.1838466599583626, metric: 15.584511041641235, lr: 0.0004409373505041003
[8560] train loss: 1.6527919992804527, metric: 14.556582689285278, lr: 0.0004097231721971184
[8580] train loss: 2.854926135390997, metric: 13.56086778640747, lr: 0.000378868862753734
[8600] train loss: 3.1711474508047104, metric: 14.782755494117737, lr: 0.00034849741496145725
[8620] train loss: 1.495320226997137, metric: 14.507018089294434, lr: 0.0003187299007549882
[8640] train loss: 5.036505896598101, metric: 22.40669345855713, lr: 0.0002896849764510989
[8660] train loss: 1.7988088242709637, metric: 14.314294338226318, lr: 0.0002614784170873463
[8680] train loss: 2.2100581899285316, metric: 13.82160222530365, lr: 0.00023422270896844566
[8700] train loss: 1.103866070508957, metric: 12.011978387832642, lr: 0.00020802643848583102
[8720] train loss: 0.9059074819087982, metric: 18.04833173751831, lr: 0.00018299407383892685
[8740] train loss: -0.059380028396844864, metric: 14.780892372131348, lr: 0.00015922538295853883
[8760] train loss: -0.16005146503448486, metric: 13.641471862792969, lr: 0.00013681512791663408
[8780] train loss: -0.13646136596798897, metric: 13.570514917373657, lr: 0.00011585262109292671
[8800] train loss: 0.03553009405732155, metric: 13.268232583999634, lr: 9.999999747378752e-05
[8820] train loss: -0.2286226898431778, metric: 12.000977039337158, lr: 9.999999747378752e-05
[8840] train loss: -0.1864081546664238, metric: 12.803725242614746, lr: 9.999999747378752e-05
[8860] train loss: -0.22323736175894737, metric: 12.149478912353516, lr: 9.999999747378752e-05
[8880] train loss: -0.14833365008234978, metric: 13.0816011428833, lr: 9.999999747378752e-05
[8900] train loss: 0.07076423615217209, metric: 13.091202974319458, lr: 9.999999747378752e-05
[8920] train loss: -0.11796114593744278, metric: 12.12262749671936, lr: 9.999999747378752e-05
[8940] train loss: -0.24001432210206985, metric: 11.810917377471924, lr: 9.999999747378752e-05
[8960] train loss: -0.18033155798912048, metric: 12.481690406799316, lr: 9.999999747378752e-05
[8980] train loss: -0.23055964335799217, metric: 11.186867475509644, lr: 9.999999747378752e-05
[9000] train loss: -0.2280176468193531, metric: 12.22088873386383, lr: 9.999999747378752e-05
[9020] train loss: -0.27616171911358833, metric: 10.225908279418945, lr: 0.0009994393913075328
[9040] train loss: -0.2916805036365986, metric: 11.166388511657715, lr: 0.0009969500824809074
[9060] train loss: -0.24990153312683105, metric: 10.020802736282349, lr: 0.000992479850538075
[9080] train loss: -0.32210002839565277, metric: 10.088664293289185, lr: 0.000986046390607953
[9100] train loss: -0.30369430780410767, metric: 9.86744999885559, lr: 0.0009776754304766655
[9120] train loss: -0.33156388998031616, metric: 9.83431851863861, lr: 0.0009674003813415766
[9140] train loss: -0.350874662399292, metric: 10.222128987312317, lr: 0.0009552621049806476
[9160] train loss: -0.33386024087667465, metric: 9.908597230911255, lr: 0.0009413089719600976
[9180] train loss: -0.32898634672164917, metric: 10.123652219772339, lr: 0.0009255966870114207
[9200] train loss: -0.3200603723526001, metric: 8.770402193069458, lr: 0.00090818788157776
[9220] train loss: 0.6006675064563751, metric: 11.762632131576538, lr: 0.0008891518809832633
[20] train loss: [0.70524305 0.70648235], metric: 17.71833848953247, lr: 0.0009994393913075328
[40] train loss: [0.34846872 0.34892017], metric: 19.989273071289062, lr: 0.0009969500824809074
[20] train loss: 0.6357361748814583, metric: 13.763306856155396, lr: 0.0009994393913075328
[40] train loss: 0.5386194139719009, metric: 16.379966259002686, lr: 0.0009969500824809074
[60] train loss: 0.4785538651049137, metric: 19.20600700378418, lr: 0.000992479850538075
[80] train loss: 0.39332090690732, metric: 22.912541389465332, lr: 0.000986046390607953
[100] train loss: 0.4949258007109165, metric: 15.48856782913208, lr: 0.0009776754304766655
[120] train loss: 0.3547859564423561, metric: 15.233253002166748, lr: 0.0009674003813415766
[140] train loss: 0.38449304923415184, metric: 16.738585710525513, lr: 0.0009552621049806476
[160] train loss: 0.8384782448410988, metric: 16.65492868423462, lr: 0.0009413089719600976
[180] train loss: 0.8723783940076828, metric: 17.66885542869568, lr: 0.0009255966870114207
[200] train loss: 1.1868996247649193, metric: 17.695526123046875, lr: 0.00090818788157776
[220] train loss: 0.40066422522068024, metric: 17.416404962539673, lr: 0.0008891518809832633
[240] train loss: 0.29331016540527344, metric: 16.292264461517334, lr: 0.0008685645880177617
[260] train loss: 1.1928818821907043, metric: 16.471343278884888, lr: 0.0008465081336908042
[280] train loss: 1.5208051037043333, metric: 17.25133752822876, lr: 0.0008230703533627093
[300] train loss: 0.9539150334894657, metric: 15.089245080947876, lr: 0.0007983447285369039
[320] train loss: 1.0836706794798374, metric: 15.377432346343994, lr: 0.0007724298629909754
[340] train loss: 0.5997954681515694, metric: 17.48604917526245, lr: 0.0007454289589077234
[360] train loss: 1.13676131144166, metric: 19.832523822784424, lr: 0.0007174497004598379
[380] train loss: 1.0395553819835186, metric: 27.59360408782959, lr: 0.00068860367173329
[400] train loss: 0.9980132766067982, metric: 21.06165909767151, lr: 0.0006590057746507227
[420] train loss: 1.9882294051349163, metric: 19.89649486541748, lr: 0.0006287740543484688
[440] train loss: 1.5422615744173527, metric: 24.21740412712097, lr: 0.000598029000684619
[460] train loss: 0.7777811735868454, metric: 22.16921091079712, lr: 0.0005668931407853961
[480] train loss: 1.1472577303647995, metric: 22.93820571899414, lr: 0.0005354906315915287
[500] train loss: 0.5481773130595684, metric: 36.3837890625, lr: 0.0005039466777816415
[520] train loss: 15.309582024812698, metric: 40.94466733932495, lr: 0.0004723869787994772
[540] train loss: 1.6840015947818756, metric: 65.11084938049316, lr: 0.0004409373505041003
[560] train loss: 0.7558687180280685, metric: 47.30474376678467, lr: 0.0004097231721971184
[580] train loss: 0.7314105778932571, metric: 41.23294973373413, lr: 0.000378868862753734
[600] train loss: 0.547115869820118, metric: 43.120956897735596, lr: 0.00034849741496145725
[620] train loss: 1.1452324613928795, metric: 38.940093994140625, lr: 0.0003187299007549882
[640] train loss: 0.8491455540060997, metric: 37.45827770233154, lr: 0.0002896849764510989
[660] train loss: 0.8221703469753265, metric: 34.56681156158447, lr: 0.0002614784170873463
[680] train loss: 0.6280593127012253, metric: 30.927076816558838, lr: 0.00023422270896844566
[700] train loss: 0.6397963911294937, metric: 31.952433586120605, lr: 0.00020802643848583102
[720] train loss: 0.7126812189817429, metric: 35.9139609336853, lr: 0.00018299407383892685
[740] train loss: 1.024489976465702, metric: 35.761091232299805, lr: 0.00015922538295853883
[760] train loss: 1.9813070446252823, metric: 32.38162183761597, lr: 0.00013681512791663408
[780] train loss: 2.1422569006681442, metric: 34.79554557800293, lr: 0.00011585262109292671
[800] train loss: 1.0182866379618645, metric: 34.83765125274658, lr: 9.999999747378752e-05
[820] train loss: 0.7793155908584595, metric: 35.10768795013428, lr: 9.999999747378752e-05
[840] train loss: 1.1141687035560608, metric: 31.665194511413574, lr: 9.999999747378752e-05
[860] train loss: 0.6452435478568077, metric: 30.175599098205566, lr: 9.999999747378752e-05
[880] train loss: 2.4215154349803925, metric: 32.02162265777588, lr: 9.999999747378752e-05
[900] train loss: 19.931819021701813, metric: 38.87407445907593, lr: 9.999999747378752e-05
[920] train loss: 1.4039983451366425, metric: 31.30643129348755, lr: 9.999999747378752e-05
[940] train loss: 1.3048510327935219, metric: 31.733152866363525, lr: 9.999999747378752e-05
[960] train loss: 0.7103070616722107, metric: 31.260823249816895, lr: 9.999999747378752e-05
[980] train loss: 0.6680743396282196, metric: 30.902464389801025, lr: 9.999999747378752e-05
[1000] train loss: 0.6309249997138977, metric: 29.208320140838623, lr: 9.999999747378752e-05
[1020] train loss: 0.5928380712866783, metric: 28.129784107208252, lr: 0.0009994393913075328
[1040] train loss: 1.8250506073236465, metric: 35.1595573425293, lr: 0.0009969500824809074
[1060] train loss: 0.9901925474405289, metric: 25.1095552444458, lr: 0.000992479850538075
[1080] train loss: 0.7131731882691383, metric: 25.86392593383789, lr: 0.000986046390607953
[1100] train loss: 0.3724275268614292, metric: 34.79727029800415, lr: 0.0009776754304766655
[1120] train loss: 0.6637935191392899, metric: 35.96629619598389, lr: 0.0009674003813415766
[1140] train loss: 0.546056117862463, metric: 28.94027853012085, lr: 0.0009552621049806476
[1160] train loss: 0.3141728490591049, metric: 25.77643918991089, lr: 0.0009413089719600976
[1180] train loss: 0.2523718271404505, metric: 21.69481611251831, lr: 0.0009255966870114207
[1200] train loss: 0.18918597884476185, metric: 24.071940422058105, lr: 0.00090818788157776
[1220] train loss: 0.31331754848361015, metric: 19.287240028381348, lr: 0.0008891518809832633
[1240] train loss: 0.3322562873363495, metric: 21.998722553253174, lr: 0.0008685645880177617
[1260] train loss: 0.39710498228669167, metric: 20.45453929901123, lr: 0.0008465081336908042
[1280] train loss: 0.3297796659171581, metric: 20.429708003997803, lr: 0.0008230703533627093
[1300] train loss: 0.2315238192677498, metric: 24.737030506134033, lr: 0.0007983447285369039
[1320] train loss: 0.2239457294344902, metric: 25.658326625823975, lr: 0.0007724298629909754
[1340] train loss: 0.3105369731783867, metric: 24.261468410491943, lr: 0.0007454289589077234
[1360] train loss: 0.26438936963677406, metric: 22.29719591140747, lr: 0.0007174497004598379
[1380] train loss: 0.2753308117389679, metric: 24.812510013580322, lr: 0.00068860367173329
[1400] train loss: 0.2780655361711979, metric: 23.82121515274048, lr: 0.0006590057746507227
[1420] train loss: 0.2700209580361843, metric: 22.116616249084473, lr: 0.0006287740543484688
[1440] train loss: 0.24440762773156166, metric: 20.441471576690674, lr: 0.000598029000684619
[1460] train loss: 0.20998502895236015, metric: 20.164631366729736, lr: 0.0005668931407853961
[1480] train loss: 0.2787545584142208, metric: 21.561882734298706, lr: 0.0005354906315915287
[1500] train loss: 0.31169452518224716, metric: 20.772500038146973, lr: 0.0005039466777816415
[1520] train loss: 0.2655075490474701, metric: 20.935592651367188, lr: 0.0004723869787994772
[1540] train loss: 1.4990014135837555, metric: 20.18249750137329, lr: 0.0004409373505041003
[1560] train loss: 0.41998910903930664, metric: 23.296255111694336, lr: 0.0004097231721971184
[1580] train loss: 0.4880438335239887, metric: 25.611406803131104, lr: 0.000378868862753734
[1600] train loss: 0.5933704227209091, metric: 23.481183528900146, lr: 0.00034849741496145725
[1620] train loss: 0.3281487189233303, metric: 25.059054374694824, lr: 0.0003187299007549882
[1640] train loss: 0.3701784685254097, metric: 25.561809539794922, lr: 0.0002896849764510989
[1660] train loss: 0.4333484470844269, metric: 25.16346788406372, lr: 0.0002614784170873463
[1680] train loss: 0.3915512189269066, metric: 24.552836894989014, lr: 0.00023422270896844566
[1700] train loss: 0.4232328496873379, metric: 27.6428861618042, lr: 0.00020802643848583102
[1720] train loss: 0.3863372802734375, metric: 25.419119119644165, lr: 0.00018299407383892685
[1740] train loss: 0.4936673976480961, metric: 26.17096757888794, lr: 0.00015922538295853883
[1760] train loss: 0.37973497435450554, metric: 29.024277210235596, lr: 0.00013681512791663408
[1780] train loss: 0.44659294188022614, metric: 27.338729858398438, lr: 0.00011585262109292671
[1800] train loss: 0.8532574400305748, metric: 24.607041597366333, lr: 9.999999747378752e-05
[1820] train loss: 1.6678572073578835, metric: 24.453341007232666, lr: 9.999999747378752e-05
[1840] train loss: 1.3620571792125702, metric: 20.708663940429688, lr: 9.999999747378752e-05
[1860] train loss: 1.913110438734293, metric: 21.687723636627197, lr: 9.999999747378752e-05
[1880] train loss: 1.805022418498993, metric: 23.886066913604736, lr: 9.999999747378752e-05
[1900] train loss: 1.2261100932955742, metric: 23.43351125717163, lr: 9.999999747378752e-05
[1920] train loss: 0.5820414796471596, metric: 22.418494701385498, lr: 9.999999747378752e-05
[1940] train loss: 1.158099077641964, metric: 18.72189474105835, lr: 9.999999747378752e-05
[1960] train loss: 0.7489204220473766, metric: 16.12560796737671, lr: 9.999999747378752e-05
[1980] train loss: 0.5908180773258209, metric: 18.16704797744751, lr: 9.999999747378752e-05
[2000] train loss: 0.5578920394182205, metric: 18.387453079223633, lr: 9.999999747378752e-05
[2020] train loss: 0.5474089197814465, metric: 23.491077423095703, lr: 0.0009994393913075328
[2040] train loss: 0.4166015237569809, metric: 19.09286403656006, lr: 0.0009969500824809074
[2060] train loss: 4.504807695746422, metric: 35.36423397064209, lr: 0.000992479850538075
[2080] train loss: 0.8210688158869743, metric: 26.51323175430298, lr: 0.000986046390607953
[2100] train loss: 0.928537804633379, metric: 17.59022569656372, lr: 0.0009776754304766655
[2120] train loss: 2.423831932246685, metric: 17.000701904296875, lr: 0.0009674003813415766
[2140] train loss: 4.977190680801868, metric: 23.86466407775879, lr: 0.0009552621049806476
[2160] train loss: 2.3007478043437004, metric: 29.66536235809326, lr: 0.0009413089719600976
[2180] train loss: 3.423395771533251, metric: 29.098504066467285, lr: 0.0009255966870114207
[2200] train loss: 4.263155460357666, metric: 26.05830192565918, lr: 0.00090818788157776
[2220] train loss: 0.7439725920557976, metric: 28.622090816497803, lr: 0.0008891518809832633
[2240] train loss: 0.5154423601925373, metric: 27.413832664489746, lr: 0.0008685645880177617
[2260] train loss: 7.294429957866669, metric: 38.55513000488281, lr: 0.0008465081336908042
[2280] train loss: 8.412814311683178, metric: 38.5645809173584, lr: 0.0008230703533627093
[2300] train loss: 2.2422379180788994, metric: 35.19422912597656, lr: 0.0007983447285369039
[2320] train loss: 1.3590066581964493, metric: 27.662765502929688, lr: 0.0007724298629909754
[2340] train loss: 10.379536300897598, metric: 44.80887222290039, lr: 0.0007454289589077234
[2360] train loss: 0.9303556680679321, metric: 39.95656967163086, lr: 0.0007174497004598379
[2380] train loss: 3.1301303282380104, metric: 42.07590675354004, lr: 0.00068860367173329
[2400] train loss: 1.9899740144610405, metric: 34.62482690811157, lr: 0.0006590057746507227
[2420] train loss: 0.9936032220721245, metric: 31.435181617736816, lr: 0.0006287740543484688
[2440] train loss: 1.616623230278492, metric: 23.944014072418213, lr: 0.000598029000684619
[2460] train loss: 1.5203998796641827, metric: 28.336250066757202, lr: 0.0005668931407853961
[2480] train loss: 0.512847650796175, metric: 33.64730739593506, lr: 0.0005354906315915287
[2500] train loss: 0.5110129415988922, metric: 28.4356427192688, lr: 0.0005039466777816415
[2520] train loss: 0.39109912514686584, metric: 30.66394281387329, lr: 0.0004723869787994772
[2540] train loss: 0.3745698779821396, metric: 28.40978717803955, lr: 0.0004409373505041003
[2560] train loss: 0.5193899422883987, metric: 25.134507656097412, lr: 0.0004097231721971184
[2580] train loss: 0.8895461857318878, metric: 27.626879692077637, lr: 0.000378868862753734
[2600] train loss: 0.8478060662746429, metric: 29.050870895385742, lr: 0.00034849741496145725
[2620] train loss: 0.6600302085280418, metric: 26.439987659454346, lr: 0.0003187299007549882
[2640] train loss: 0.4526333324611187, metric: 25.894848346710205, lr: 0.0002896849764510989
[2660] train loss: 0.4498795419931412, metric: 24.859329223632812, lr: 0.0002614784170873463
[2680] train loss: 0.5421870648860931, metric: 28.361827850341797, lr: 0.00023422270896844566
[2700] train loss: 0.4745001085102558, metric: 27.078845024108887, lr: 0.00020802643848583102
[2720] train loss: 0.36626100540161133, metric: 24.81050157546997, lr: 0.00018299407383892685
[2740] train loss: 0.4012574255466461, metric: 20.44940996170044, lr: 0.00015922538295853883
[2760] train loss: 0.6693658754229546, metric: 20.681493282318115, lr: 0.00013681512791663408
[2780] train loss: 0.434318944811821, metric: 21.996371746063232, lr: 0.00011585262109292671
[2800] train loss: 0.4784676022827625, metric: 20.247600555419922, lr: 9.999999747378752e-05
[2820] train loss: 0.6104416511952877, metric: 23.569908142089844, lr: 9.999999747378752e-05
[2840] train loss: 0.5318099744617939, metric: 18.889692306518555, lr: 9.999999747378752e-05
[2860] train loss: 0.47789930924773216, metric: 16.552752256393433, lr: 9.999999747378752e-05
[2880] train loss: 0.969606064260006, metric: 18.55567717552185, lr: 9.999999747378752e-05
[2900] train loss: 0.7650628350675106, metric: 23.302978038787842, lr: 9.999999747378752e-05
[2920] train loss: 0.5838527977466583, metric: 24.373836040496826, lr: 9.999999747378752e-05
[2940] train loss: 0.36210014298558235, metric: 23.224852085113525, lr: 9.999999747378752e-05
[2960] train loss: 0.382468368858099, metric: 23.2544527053833, lr: 9.999999747378752e-05
[2980] train loss: 0.3022373728454113, metric: 21.568345546722412, lr: 9.999999747378752e-05
[3000] train loss: 0.27600058168172836, metric: 20.72224473953247, lr: 9.999999747378752e-05
[3020] train loss: 0.2765268422663212, metric: 19.34958291053772, lr: 0.0009994393913075328
[3040] train loss: 0.3863721527159214, metric: 19.862602710723877, lr: 0.0009969500824809074
[3060] train loss: 0.263667318969965, metric: 19.55322551727295, lr: 0.000992479850538075
[3080] train loss: 4.195173032581806, metric: 24.207494735717773, lr: 0.000986046390607953
[3100] train loss: 1.0085939094424248, metric: 24.979307651519775, lr: 0.0009776754304766655
[3120] train loss: 0.9161929711699486, metric: 28.05474328994751, lr: 0.0009674003813415766
[3140] train loss: 1.4563287794589996, metric: 35.99281120300293, lr: 0.0009552621049806476
[3160] train loss: 0.7234582640230656, metric: 26.41061019897461, lr: 0.0009413089719600976
[3180] train loss: 0.6361082121729851, metric: 24.265360832214355, lr: 0.0009255966870114207
[3200] train loss: 0.34794847667217255, metric: 26.695348739624023, lr: 0.00090818788157776
[3220] train loss: 0.6519490852952003, metric: 28.138670921325684, lr: 0.0008891518809832633
[3240] train loss: 0.3217583931982517, metric: 27.894662857055664, lr: 0.0008685645880177617
[3260] train loss: 0.2981649786233902, metric: 28.21443462371826, lr: 0.0008465081336908042
[3280] train loss: 0.3474694862961769, metric: 26.499104022979736, lr: 0.0008230703533627093
[3300] train loss: 0.924103394150734, metric: 23.321724891662598, lr: 0.0007983447285369039
[3320] train loss: 0.48397791385650635, metric: 24.22751760482788, lr: 0.0007724298629909754
[3340] train loss: 0.37516069039702415, metric: 19.602538585662842, lr: 0.0007454289589077234
[3360] train loss: 0.6608744263648987, metric: 23.159775733947754, lr: 0.0007174497004598379
[3380] train loss: 0.8760936856269836, metric: 22.59272861480713, lr: 0.00068860367173329
[3400] train loss: 0.331804595887661, metric: 39.5284309387207, lr: 0.0006590057746507227
[3420] train loss: 1.645826268941164, metric: 30.28187131881714, lr: 0.0006287740543484688
[3440] train loss: 0.5879233479499817, metric: 24.563228607177734, lr: 0.000598029000684619
[3460] train loss: 0.6752713769674301, metric: 22.589128017425537, lr: 0.0005668931407853961
[3480] train loss: 0.5324124395847321, metric: 21.381712436676025, lr: 0.0005354906315915287
[3500] train loss: 0.44036364555358887, metric: 27.659574508666992, lr: 0.0005039466777816415
[3520] train loss: 0.42041489854454994, metric: 25.891571044921875, lr: 0.0004723869787994772
[3540] train loss: 0.3759804219007492, metric: 29.955069541931152, lr: 0.0004409373505041003
[3560] train loss: 3.873092520982027, metric: 26.22007989883423, lr: 0.0004097231721971184
[3580] train loss: 5.9557821080088615, metric: 27.558650493621826, lr: 0.000378868862753734
[3600] train loss: 4.651269227266312, metric: 46.90283155441284, lr: 0.00034849741496145725
[3620] train loss: 2.420025944709778, metric: 44.23959732055664, lr: 0.0003187299007549882
[3640] train loss: 5.558192804455757, metric: 36.77049112319946, lr: 0.0002896849764510989
[3660] train loss: 9.199723295867443, metric: 38.41085481643677, lr: 0.0002614784170873463
[3680] train loss: 2.2948937714099884, metric: 26.294922351837158, lr: 0.00023422270896844566
[3700] train loss: 9.6728974878788, metric: 36.47219944000244, lr: 0.00020802643848583102
[3720] train loss: 9.161211229860783, metric: 38.02981662750244, lr: 0.00018299407383892685
[3740] train loss: 10.848140716552734, metric: 39.594332695007324, lr: 0.00015922538295853883
[3760] train loss: 2.5375018641352654, metric: 36.5177001953125, lr: 0.00013681512791663408
[3780] train loss: 2.335965245962143, metric: 28.67660427093506, lr: 0.00011585262109292671
[3800] train loss: 2.155833661556244, metric: 35.09337377548218, lr: 9.999999747378752e-05
[3820] train loss: 1.7404207363724709, metric: 36.43682622909546, lr: 9.999999747378752e-05
[3840] train loss: 10.817988470196724, metric: 33.80371308326721, lr: 9.999999747378752e-05
[3860] train loss: 3.3269932940602303, metric: 33.02177810668945, lr: 9.999999747378752e-05
[3880] train loss: 3.67440003156662, metric: 37.50148010253906, lr: 9.999999747378752e-05
[3900] train loss: 5.610325962305069, metric: 38.295968532562256, lr: 9.999999747378752e-05
[3920] train loss: 3.61157563328743, metric: 38.950411319732666, lr: 9.999999747378752e-05
[3940] train loss: 3.1225261092185974, metric: 41.797800064086914, lr: 9.999999747378752e-05
[3960] train loss: 2.858547255396843, metric: 39.3530387878418, lr: 9.999999747378752e-05
[3980] train loss: 1.51069575548172, metric: 37.021130084991455, lr: 9.999999747378752e-05
[4000] train loss: 3.9067191183567047, metric: 38.276872634887695, lr: 9.999999747378752e-05
[4020] train loss: 1.2901616096496582, metric: 46.703453063964844, lr: 0.0009994393913075328
[4040] train loss: 1.2983700260519981, metric: 38.062994956970215, lr: 0.0009969500824809074
[4060] train loss: 0.7583429142832756, metric: 35.83898448944092, lr: 0.000992479850538075
[4080] train loss: 4.446909576654434, metric: 31.776187896728516, lr: 0.000986046390607953
[4100] train loss: 4.562195956707001, metric: 29.629840850830078, lr: 0.0009776754304766655
[4120] train loss: 3.20983824133873, metric: 32.47270584106445, lr: 0.0009674003813415766
[4140] train loss: 0.7596904784440994, metric: 36.930049896240234, lr: 0.0009552621049806476
[4160] train loss: 0.6772525683045387, metric: 34.255327224731445, lr: 0.0009413089719600976
[4180] train loss: 1.3271989077329636, metric: 34.63890314102173, lr: 0.0009255966870114207
[4200] train loss: 0.7408630549907684, metric: 27.24584436416626, lr: 0.00090818788157776
[4220] train loss: 2.4626850932836533, metric: 28.57774543762207, lr: 0.0008891518809832633
[4240] train loss: 1.0004794225096703, metric: 25.388200283050537, lr: 0.0008685645880177617
[4260] train loss: 1.3712492361664772, metric: 30.107047080993652, lr: 0.0008465081336908042
[4280] train loss: 0.6493037194013596, metric: 24.80183982849121, lr: 0.0008230703533627093
[4300] train loss: 0.7213952392339706, metric: 29.217232704162598, lr: 0.0007983447285369039
[4320] train loss: 1.422383889555931, metric: 28.61821746826172, lr: 0.0007724298629909754
[4340] train loss: 0.7311595752835274, metric: 31.20159912109375, lr: 0.0007454289589077234
[4360] train loss: 0.8959553241729736, metric: 34.34977054595947, lr: 0.0007174497004598379
[4380] train loss: 0.562192939221859, metric: 31.89631462097168, lr: 0.00068860367173329
[4400] train loss: 0.5657229349017143, metric: 25.610974311828613, lr: 0.0006590057746507227
[4420] train loss: 0.4780823811888695, metric: 24.901700496673584, lr: 0.0006287740543484688
[4440] train loss: 0.3902997300028801, metric: 27.494136810302734, lr: 0.000598029000684619
[4460] train loss: 0.6649095043540001, metric: 29.239739418029785, lr: 0.0005668931407853961
[4480] train loss: 0.5002762898802757, metric: 33.81245994567871, lr: 0.0005354906315915287
[4500] train loss: 0.46438118070364, metric: 34.18917798995972, lr: 0.0005039466777816415
[4520] train loss: 0.4858811981976032, metric: 33.30945062637329, lr: 0.0004723869787994772
[4540] train loss: 0.42904888093471527, metric: 36.90778732299805, lr: 0.0004409373505041003
[4560] train loss: 0.4996010959148407, metric: 33.7420711517334, lr: 0.0004097231721971184
[4580] train loss: 0.42321670055389404, metric: 31.062317848205566, lr: 0.000378868862753734
[4600] train loss: 0.7978949062526226, metric: 29.402833461761475, lr: 0.00034849741496145725
[4620] train loss: 5.843136221170425, metric: 39.44906949996948, lr: 0.0003187299007549882
[4640] train loss: 1.142759084701538, metric: 30.965445041656494, lr: 0.0002896849764510989
[4660] train loss: 1.3356505781412125, metric: 30.204166412353516, lr: 0.0002614784170873463
[4680] train loss: 2.0221018493175507, metric: 30.45243191719055, lr: 0.00023422270896844566
[4700] train loss: 0.8032947555184364, metric: 36.01020574569702, lr: 0.00020802643848583102
[4720] train loss: 2.354857623577118, metric: 41.65690898895264, lr: 0.00018299407383892685
[4740] train loss: 1.0727968364953995, metric: 45.63014030456543, lr: 0.00015922538295853883
[4760] train loss: 1.2290244027972221, metric: 39.50577449798584, lr: 0.00013681512791663408
[4780] train loss: 1.6197866648435593, metric: 40.7403039932251, lr: 0.00011585262109292671
[4800] train loss: 7.038119398057461, metric: 41.59451675415039, lr: 9.999999747378752e-05
[4820] train loss: 10.509172931313515, metric: 54.009639739990234, lr: 9.999999747378752e-05
[4840] train loss: 7.268615961074829, metric: 56.308470726013184, lr: 9.999999747378752e-05
[4860] train loss: 2.073785662651062, metric: 59.94599914550781, lr: 9.999999747378752e-05
[4880] train loss: 1.2340854182839394, metric: 51.49941682815552, lr: 9.999999747378752e-05
[4900] train loss: 0.9113965705037117, metric: 50.710506439208984, lr: 9.999999747378752e-05
[4920] train loss: 0.7669996619224548, metric: 53.92477321624756, lr: 9.999999747378752e-05
[4940] train loss: 0.7320224717259407, metric: 48.26961135864258, lr: 9.999999747378752e-05
[4960] train loss: 0.6326626464724541, metric: 49.27214241027832, lr: 9.999999747378752e-05
[4980] train loss: 0.6303872466087341, metric: 48.992751598358154, lr: 9.999999747378752e-05
[5000] train loss: 0.7364822775125504, metric: 43.84854602813721, lr: 9.999999747378752e-05
[5020] train loss: 0.632787711918354, metric: 37.82201671600342, lr: 0.0009994393913075328
[5040] train loss: 1.6779116913676262, metric: 36.236586570739746, lr: 0.0009969500824809074
[5060] train loss: 1.4140752702951431, metric: 36.512807846069336, lr: 0.000992479850538075
[5080] train loss: 3.8174543604254723, metric: 34.24930715560913, lr: 0.000986046390607953
[5100] train loss: 3.2816589549183846, metric: 36.537755489349365, lr: 0.0009776754304766655
[5120] train loss: 3.719799779355526, metric: 42.54187774658203, lr: 0.0009674003813415766
[5140] train loss: 0.7894904464483261, metric: 38.06844902038574, lr: 0.0009552621049806476
[5160] train loss: 0.4938574805855751, metric: 38.315510749816895, lr: 0.0009413089719600976
[5180] train loss: 0.9343751817941666, metric: 37.00928020477295, lr: 0.0009255966870114207
[5200] train loss: 1.4372710138559341, metric: 38.74772882461548, lr: 0.00090818788157776
[5220] train loss: 0.7064303755760193, metric: 37.64825773239136, lr: 0.0008891518809832633
[5240] train loss: 0.9727354720234871, metric: 42.37710094451904, lr: 0.0008685645880177617
[5260] train loss: 1.3788288235664368, metric: 32.2143611907959, lr: 0.0008465081336908042
[5280] train loss: 1.2339931353926659, metric: 36.85083723068237, lr: 0.0008230703533627093
[5300] train loss: 0.5714403092861176, metric: 46.700464725494385, lr: 0.0007983447285369039
[5320] train loss: 0.4466320052742958, metric: 40.00660705566406, lr: 0.0007724298629909754
[5340] train loss: 0.47538504004478455, metric: 41.35355854034424, lr: 0.0007454289589077234
[5360] train loss: 0.5493935793638229, metric: 41.869473457336426, lr: 0.0007174497004598379
[5380] train loss: 0.30771511420607567, metric: 37.9240083694458, lr: 0.00068860367173329
[5400] train loss: 0.5910601615905762, metric: 33.86258316040039, lr: 0.0006590057746507227
[5420] train loss: 0.5863685086369514, metric: 30.98095941543579, lr: 0.0006287740543484688
[5440] train loss: 0.606097087264061, metric: 32.43885898590088, lr: 0.000598029000684619
[5460] train loss: 0.42768820375204086, metric: 32.604153633117676, lr: 0.0005668931407853961
[5480] train loss: 0.8582529872655869, metric: 34.88737773895264, lr: 0.0005354906315915287
[5500] train loss: 1.7582429870963097, metric: 33.96260643005371, lr: 0.0005039466777816415
[5520] train loss: 1.843808338046074, metric: 34.508562088012695, lr: 0.0004723869787994772
[5540] train loss: 6.257419295608997, metric: 44.86412334442139, lr: 0.0004409373505041003
[5560] train loss: 1.1538074128329754, metric: 40.9775333404541, lr: 0.0004097231721971184
[5580] train loss: 1.2393300980329514, metric: 43.84794282913208, lr: 0.000378868862753734
[5600] train loss: 0.7479761242866516, metric: 39.540770530700684, lr: 0.00034849741496145725
[5620] train loss: 0.6565966978669167, metric: 39.43367624282837, lr: 0.0003187299007549882
[5640] train loss: 2.7523870766162872, metric: 41.158803939819336, lr: 0.0002896849764510989
[5660] train loss: 4.2915318459272385, metric: 35.16204881668091, lr: 0.0002614784170873463
[5680] train loss: 7.821063131093979, metric: 38.01831579208374, lr: 0.00023422270896844566
[5700] train loss: 3.393476590514183, metric: 45.30082988739014, lr: 0.00020802643848583102
[5720] train loss: 13.884952545166016, metric: 44.57888889312744, lr: 0.00018299407383892685
[5740] train loss: 3.280775621533394, metric: 40.77064609527588, lr: 0.00015922538295853883
[5760] train loss: 1.4202698543667793, metric: 37.448275089263916, lr: 0.00013681512791663408
[5780] train loss: 1.385854810476303, metric: 39.49760055541992, lr: 0.00011585262109292671
[5800] train loss: 5.368331670761108, metric: 34.95719385147095, lr: 9.999999747378752e-05
[5820] train loss: 6.856330797076225, metric: 35.640207290649414, lr: 9.999999747378752e-05
[5840] train loss: 9.833614900708199, metric: 33.330355644226074, lr: 9.999999747378752e-05
[5860] train loss: 2.4456699192523956, metric: 32.42134141921997, lr: 9.999999747378752e-05
[5880] train loss: 2.8191111758351326, metric: 34.06787586212158, lr: 9.999999747378752e-05
[5900] train loss: 3.6776372641324997, metric: 36.362706661224365, lr: 9.999999747378752e-05
[5920] train loss: 4.902172774076462, metric: 36.89944362640381, lr: 9.999999747378752e-05
[5940] train loss: 4.035973876714706, metric: 38.99495267868042, lr: 9.999999747378752e-05
[5960] train loss: 6.501080021262169, metric: 43.40603971481323, lr: 9.999999747378752e-05
[5980] train loss: 4.842683956027031, metric: 45.32788801193237, lr: 9.999999747378752e-05
[6000] train loss: 5.944216936826706, metric: 38.19271421432495, lr: 9.999999747378752e-05
[6020] train loss: 2.0792109966278076, metric: 47.06003284454346, lr: 0.0009994393913075328
[6040] train loss: 1.362422525882721, metric: 49.83041858673096, lr: 0.0009969500824809074
[6060] train loss: 3.798464298248291, metric: 55.82071113586426, lr: 0.000992479850538075
[6080] train loss: 1.8617351651191711, metric: 50.0778751373291, lr: 0.000986046390607953
[6100] train loss: 4.742851763963699, metric: 45.11156463623047, lr: 0.0009776754304766655
[6120] train loss: 1.1067856401205063, metric: 49.671629905700684, lr: 0.0009674003813415766
[6140] train loss: 0.9926354065537453, metric: 49.9591007232666, lr: 0.0009552621049806476
[6160] train loss: 0.6928626000881195, metric: 52.77612113952637, lr: 0.0009413089719600976
[6180] train loss: 0.4444655478000641, metric: 51.88712739944458, lr: 0.0009255966870114207
[6200] train loss: 0.4947686344385147, metric: 50.43595600128174, lr: 0.00090818788157776
[6220] train loss: 0.33092429488897324, metric: 48.32477855682373, lr: 0.0008891518809832633
[6240] train loss: 0.5001624822616577, metric: 47.085988998413086, lr: 0.0008685645880177617
[6260] train loss: 0.3352869376540184, metric: 44.18841743469238, lr: 0.0008465081336908042
[6280] train loss: 0.4877444952726364, metric: 46.54072856903076, lr: 0.0008230703533627093
[6300] train loss: 0.4621710553765297, metric: 47.173216342926025, lr: 0.0007983447285369039
[6320] train loss: 0.3288882225751877, metric: 48.1124792098999, lr: 0.0007724298629909754
[6340] train loss: 0.4930248260498047, metric: 47.60302972793579, lr: 0.0007454289589077234
[6360] train loss: 0.3300982005894184, metric: 47.633864402770996, lr: 0.0007174497004598379
[6380] train loss: 0.3139313794672489, metric: 46.77652549743652, lr: 0.00068860367173329
[6400] train loss: 0.31509967148303986, metric: 48.42009735107422, lr: 0.0006590057746507227
[6420] train loss: 0.45622503012418747, metric: 48.81000900268555, lr: 0.0006287740543484688
[6440] train loss: 0.31307370960712433, metric: 46.4732460975647, lr: 0.000598029000684619
[6460] train loss: 0.42479632422327995, metric: 42.87039756774902, lr: 0.0005668931407853961
[6480] train loss: 0.7554630562663078, metric: 47.23096704483032, lr: 0.0005354906315915287
[6500] train loss: 0.869287520647049, metric: 58.881500244140625, lr: 0.0005039466777816415
[6520] train loss: 0.5835427194833755, metric: 57.96150875091553, lr: 0.0004723869787994772
[6540] train loss: 0.7581146210432053, metric: 44.72088432312012, lr: 0.0004409373505041003
[6560] train loss: 0.7359524630010128, metric: 37.8356032371521, lr: 0.0004097231721971184
[6580] train loss: 0.7648291066288948, metric: 40.293039321899414, lr: 0.000378868862753734
[6600] train loss: 0.8274471536278725, metric: 38.55887413024902, lr: 0.00034849741496145725
[6620] train loss: 1.4801177084445953, metric: 33.140345096588135, lr: 0.0003187299007549882
[6640] train loss: 1.284057043492794, metric: 36.408443450927734, lr: 0.0002896849764510989
[6660] train loss: 12.627074807882309, metric: 58.50013065338135, lr: 0.0002614784170873463
[6680] train loss: 2.0883809626102448, metric: 50.7578706741333, lr: 0.00023422270896844566
[6700] train loss: 1.7514596655964851, metric: 50.586971282958984, lr: 0.00020802643848583102
[6720] train loss: 1.7733270227909088, metric: 50.704440116882324, lr: 0.00018299407383892685
[6740] train loss: 2.3451435565948486, metric: 54.510268211364746, lr: 0.00015922538295853883
[6760] train loss: 1.716230683028698, metric: 54.81944465637207, lr: 0.00013681512791663408
[6780] train loss: 3.9492397643625736, metric: 56.62491989135742, lr: 0.00011585262109292671
[6800] train loss: 2.862538233399391, metric: 54.96042060852051, lr: 9.999999747378752e-05
[6820] train loss: 1.453761339187622, metric: 62.72413444519043, lr: 9.999999747378752e-05
[6840] train loss: 0.5242462493479252, metric: 60.53545570373535, lr: 9.999999747378752e-05
[6860] train loss: 0.38394753262400627, metric: 58.65411949157715, lr: 9.999999747378752e-05
[6880] train loss: 0.45297422260046005, metric: 56.33846569061279, lr: 9.999999747378752e-05
[6900] train loss: 0.5549730733036995, metric: 57.611578941345215, lr: 9.999999747378752e-05
[6920] train loss: 0.5324324257671833, metric: 59.65189552307129, lr: 9.999999747378752e-05
[6940] train loss: 0.4087841212749481, metric: 59.96248435974121, lr: 9.999999747378752e-05
[6960] train loss: 0.7683837078511715, metric: 61.87735366821289, lr: 9.999999747378752e-05
[6980] train loss: 0.912258330732584, metric: 56.31499671936035, lr: 9.999999747378752e-05
[7000] train loss: 3.263599678874016, metric: 55.276326179504395, lr: 9.999999747378752e-05
[7020] train loss: 3.0458744689822197, metric: 61.51118469238281, lr: 0.0009994393913075328
[7040] train loss: 0.7407052293419838, metric: 52.62241744995117, lr: 0.0009969500824809074
[7060] train loss: 0.7174380496144295, metric: 47.80263710021973, lr: 0.000992479850538075
[7080] train loss: 0.7679801657795906, metric: 48.50157642364502, lr: 0.000986046390607953
[7100] train loss: 0.35282205790281296, metric: 49.796003341674805, lr: 0.0009776754304766655
[7120] train loss: 0.43571455404162407, metric: 46.130292892456055, lr: 0.0009674003813415766
[7140] train loss: 0.44921181350946426, metric: 39.38546848297119, lr: 0.0009552621049806476
[7160] train loss: 0.3865673653781414, metric: 44.01394557952881, lr: 0.0009413089719600976
[7180] train loss: 2.543300673365593, metric: 49.48812198638916, lr: 0.0009255966870114207
[7200] train loss: 3.5860599875450134, metric: 51.37415790557861, lr: 0.00090818788157776
[7220] train loss: 2.7363347709178925, metric: 43.61991357803345, lr: 0.0008891518809832633
[7240] train loss: 1.2307645082473755, metric: 50.90371227264404, lr: 0.0008685645880177617
[7260] train loss: 1.1924344524741173, metric: 30.181857585906982, lr: 0.0008465081336908042
[7280] train loss: 0.9483381099998951, metric: 33.360472679138184, lr: 0.0008230703533627093
[7300] train loss: 1.2960176654160023, metric: 29.13063144683838, lr: 0.0007983447285369039
[7320] train loss: 1.1445059403777122, metric: 30.834528923034668, lr: 0.0007724298629909754
[7340] train loss: 2.91583614051342, metric: 35.553592681884766, lr: 0.0007454289589077234
[7360] train loss: 3.082062989473343, metric: 26.00951623916626, lr: 0.0007174497004598379
[7380] train loss: 3.0859871208667755, metric: 27.93134117126465, lr: 0.00068860367173329
[7400] train loss: 2.216590829193592, metric: 23.795328617095947, lr: 0.0006590057746507227
[7420] train loss: 2.4636435508728027, metric: 25.77219581604004, lr: 0.0006287740543484688
[7440] train loss: 2.4240111261606216, metric: 24.390475273132324, lr: 0.000598029000684619
[7460] train loss: 5.131194889545441, metric: 30.35299777984619, lr: 0.0005668931407853961
[7480] train loss: 2.6995785385370255, metric: 25.415757656097412, lr: 0.0005354906315915287
[7500] train loss: 2.183393709361553, metric: 21.973153114318848, lr: 0.0005039466777816415
[7520] train loss: 2.099745824933052, metric: 20.796011447906494, lr: 0.0004723869787994772
[7540] train loss: 4.806794434785843, metric: 21.808578491210938, lr: 0.0004409373505041003
[7560] train loss: 1.5885111093521118, metric: 23.96347665786743, lr: 0.0004097231721971184
[7580] train loss: 2.0984702333807945, metric: 27.555837392807007, lr: 0.000378868862753734
[7600] train loss: 2.057200640439987, metric: 30.508777618408203, lr: 0.00034849741496145725
[7620] train loss: 2.370410181581974, metric: 27.920053958892822, lr: 0.0003187299007549882
[7640] train loss: 2.1644059121608734, metric: 31.182957649230957, lr: 0.0002896849764510989
[7660] train loss: 3.7910787761211395, metric: 32.41949653625488, lr: 0.0002614784170873463
[7680] train loss: 4.093160331249237, metric: 34.64156198501587, lr: 0.00023422270896844566
[7700] train loss: 1.2568021714687347, metric: 53.632155418395996, lr: 0.00020802643848583102
[7720] train loss: 1.0395549461245537, metric: 52.09670400619507, lr: 0.00018299407383892685
[7740] train loss: 0.7041654363274574, metric: 49.52666091918945, lr: 0.00015922538295853883
[7760] train loss: 0.7262264788150787, metric: 50.51506328582764, lr: 0.00013681512791663408
[7780] train loss: 0.4100959971547127, metric: 50.77818775177002, lr: 0.00011585262109292671
[7800] train loss: 0.5283409021794796, metric: 50.560513973236084, lr: 9.999999747378752e-05
[7820] train loss: 0.5488278865814209, metric: 51.04548740386963, lr: 9.999999747378752e-05
[7840] train loss: 0.46431369706988335, metric: 49.69873046875, lr: 9.999999747378752e-05
[7860] train loss: 0.43240825086832047, metric: 47.67285442352295, lr: 9.999999747378752e-05
[7880] train loss: 0.4484458640217781, metric: 46.01138973236084, lr: 9.999999747378752e-05
[7900] train loss: 0.4270683638751507, metric: 48.4980731010437, lr: 9.999999747378752e-05
[7920] train loss: 0.5338441357016563, metric: 51.71770000457764, lr: 9.999999747378752e-05
[7940] train loss: 0.4763171896338463, metric: 51.78191947937012, lr: 9.999999747378752e-05
[7960] train loss: 0.5240681543946266, metric: 51.119712829589844, lr: 9.999999747378752e-05
[7980] train loss: 0.4791151285171509, metric: 49.767640113830566, lr: 9.999999747378752e-05
[8000] train loss: 0.4006175324320793, metric: 46.35361671447754, lr: 9.999999747378752e-05
[8020] train loss: 0.2949095144867897, metric: 43.68373203277588, lr: 0.0009994393913075328
[8040] train loss: 0.2580544203519821, metric: 41.992849349975586, lr: 0.0009969500824809074
[8060] train loss: 0.22801071032881737, metric: 40.204803466796875, lr: 0.000992479850538075
[8080] train loss: 0.2338540367782116, metric: 40.13812065124512, lr: 0.000986046390607953
[8100] train loss: 0.2219615802168846, metric: 35.8056206703186, lr: 0.0009776754304766655
[8120] train loss: 0.23090330883860588, metric: 31.025397300720215, lr: 0.0009674003813415766
[8140] train loss: 0.20658434182405472, metric: 29.648459911346436, lr: 0.0009552621049806476
[8160] train loss: 0.17899370938539505, metric: 28.113829612731934, lr: 0.0009413089719600976
[8180] train loss: 0.20804773271083832, metric: 30.6939959526062, lr: 0.0009255966870114207
[8200] train loss: 1.3931334912776947, metric: 51.9427490234375, lr: 0.00090818788157776
[8220] train loss: 6.208983890712261, metric: 48.81876182556152, lr: 0.0008891518809832633
[8240] train loss: 1.1618512123823166, metric: 35.8625545501709, lr: 0.0008685645880177617
[8260] train loss: 1.169797658920288, metric: 40.09225368499756, lr: 0.0008465081336908042
[8280] train loss: 0.9798332005739212, metric: 42.45910930633545, lr: 0.0008230703533627093
[8300] train loss: 1.9649974033236504, metric: 39.63413763046265, lr: 0.0007983447285369039
[8320] train loss: 4.072745770215988, metric: 39.441741943359375, lr: 0.0007724298629909754
[8340] train loss: 0.9810254983603954, metric: 37.66982078552246, lr: 0.0007454289589077234
[8360] train loss: 1.1177816428244114, metric: 38.939940452575684, lr: 0.0007174497004598379
[8380] train loss: 1.1641184985637665, metric: 30.868669986724854, lr: 0.00068860367173329
[8400] train loss: 1.6641979366540909, metric: 29.93667507171631, lr: 0.0006590057746507227
[8420] train loss: 1.450553685426712, metric: 30.516382217407227, lr: 0.0006287740543484688
[8440] train loss: 3.988649383187294, metric: 37.0698184967041, lr: 0.000598029000684619
[8460] train loss: 2.3167239278554916, metric: 34.93093776702881, lr: 0.0005668931407853961
[8480] train loss: 3.71969985216856, metric: 31.181435585021973, lr: 0.0005354906315915287
[8500] train loss: 1.5438338816165924, metric: 27.843128204345703, lr: 0.0005039466777816415
[8520] train loss: 2.196505770087242, metric: 26.58583974838257, lr: 0.0004723869787994772
[8540] train loss: 4.049698285758495, metric: 27.20953130722046, lr: 0.0004409373505041003
[8560] train loss: 4.46384784579277, metric: 36.33365488052368, lr: 0.0004097231721971184
[8580] train loss: 1.5136309005320072, metric: 37.962435722351074, lr: 0.000378868862753734
[8600] train loss: 1.3782201930880547, metric: 31.18421173095703, lr: 0.00034849741496145725
[8620] train loss: 0.7140941768884659, metric: 30.451825618743896, lr: 0.0003187299007549882
[8640] train loss: 0.7055898308753967, metric: 31.90544605255127, lr: 0.0002896849764510989
[8660] train loss: 0.8642331436276436, metric: 32.836371421813965, lr: 0.0002614784170873463
[8680] train loss: 0.6736373528838158, metric: 27.565321445465088, lr: 0.00023422270896844566
[8700] train loss: 1.9020402878522873, metric: 30.098597049713135, lr: 0.00020802643848583102
[8720] train loss: 1.3392245918512344, metric: 48.470309257507324, lr: 0.00018299407383892685
[8740] train loss: 0.6961349323391914, metric: 50.58535385131836, lr: 0.00015922538295853883
[8760] train loss: 0.7815954387187958, metric: 51.71932506561279, lr: 0.00013681512791663408
[8780] train loss: 0.6689438596367836, metric: 51.907426834106445, lr: 0.00011585262109292671
[8800] train loss: 0.6455549597740173, metric: 53.27423810958862, lr: 9.999999747378752e-05
[8820] train loss: 0.5782341957092285, metric: 54.69109916687012, lr: 9.999999747378752e-05
[8840] train loss: 0.5849561244249344, metric: 56.079710960388184, lr: 9.999999747378752e-05
[8860] train loss: 0.5393248423933983, metric: 53.570659160614014, lr: 9.999999747378752e-05
[8880] train loss: 0.5099177397787571, metric: 50.372596740722656, lr: 9.999999747378752e-05
[8900] train loss: 0.6282536908984184, metric: 48.51462411880493, lr: 9.999999747378752e-05
[8920] train loss: 0.4382571130990982, metric: 47.48723840713501, lr: 9.999999747378752e-05
[8940] train loss: 0.37481676042079926, metric: 51.967227935791016, lr: 9.999999747378752e-05
[8960] train loss: 0.33890867233276367, metric: 50.98347568511963, lr: 9.999999747378752e-05
[8980] train loss: 0.38086535781621933, metric: 49.72651767730713, lr: 9.999999747378752e-05
[9000] train loss: 0.4484628140926361, metric: 49.3880672454834, lr: 9.999999747378752e-05
[9020] train loss: 0.28464701399207115, metric: 45.534268379211426, lr: 0.0009994393913075328
[9040] train loss: 0.2953108921647072, metric: 43.05866813659668, lr: 0.0009969500824809074
[9060] train loss: 0.24645835533738136, metric: 39.55592918395996, lr: 0.000992479850538075
[9080] train loss: 0.312863826751709, metric: 40.43326377868652, lr: 0.000986046390607953
[9100] train loss: 0.3313719183206558, metric: 41.861825942993164, lr: 0.0009776754304766655
[9120] train loss: 0.5179267264902592, metric: 40.75296115875244, lr: 0.0009674003813415766
[9140] train loss: 0.41371775418519974, metric: 40.63725185394287, lr: 0.0009552621049806476
[9160] train loss: 0.40538639947772026, metric: 41.812320709228516, lr: 0.0009413089719600976
[9180] train loss: 0.6508418619632721, metric: 43.50184345245361, lr: 0.0009255966870114207
[9200] train loss: 0.2574111744761467, metric: 46.0896635055542, lr: 0.00090818788157776
[9220] train loss: 2.5428071916103363, metric: 28.97440814971924, lr: 0.0008891518809832633
[9240] train loss: 1.6428737342357635, metric: 41.397621154785156, lr: 0.0008685645880177617
[9260] train loss: 0.7408555969595909, metric: 46.171669006347656, lr: 0.0008465081336908042
[9280] train loss: 0.7702103182673454, metric: 53.54043960571289, lr: 0.0008230703533627093
[9300] train loss: 0.9327913224697113, metric: 55.39422035217285, lr: 0.0007983447285369039
[9320] train loss: 0.6463516987860203, metric: 46.89761257171631, lr: 0.0007724298629909754
[9340] train loss: 0.6424227952957153, metric: 42.46463918685913, lr: 0.0007454289589077234
[9360] train loss: 0.6623786315321922, metric: 41.0504035949707, lr: 0.0007174497004598379
[9380] train loss: 0.9018276035785675, metric: 34.597999572753906, lr: 0.00068860367173329
[9400] train loss: 1.2501315474510193, metric: 40.07474613189697, lr: 0.0006590057746507227
[9420] train loss: 1.8220951184630394, metric: 35.154507637023926, lr: 0.0006287740543484688
[9440] train loss: 2.048658788204193, metric: 34.49184322357178, lr: 0.000598029000684619
[9460] train loss: 2.1404832899570465, metric: 37.779873847961426, lr: 0.0005668931407853961
[9480] train loss: 1.8036123365163803, metric: 34.62232303619385, lr: 0.0005354906315915287
[9500] train loss: 0.8270986676216125, metric: 39.2999529838562, lr: 0.0005039466777816415
[9520] train loss: 2.685796156525612, metric: 38.05117416381836, lr: 0.0004723869787994772
[9540] train loss: 1.8063081204891205, metric: 37.14993190765381, lr: 0.0004409373505041003
[9560] train loss: 1.399746134877205, metric: 37.67809867858887, lr: 0.0004097231721971184
[9580] train loss: 1.0266959071159363, metric: 38.26752233505249, lr: 0.000378868862753734
[9600] train loss: 1.735094964504242, metric: 41.19280195236206, lr: 0.00034849741496145725
[9620] train loss: 1.9947310835123062, metric: 37.6693549156189, lr: 0.0003187299007549882
[9640] train loss: 5.326493337750435, metric: 42.46896266937256, lr: 0.0002896849764510989
[9660] train loss: 1.098757080733776, metric: 44.9111967086792, lr: 0.0002614784170873463
[9680] train loss: 1.2189375087618828, metric: 44.95343494415283, lr: 0.00023422270896844566
[9700] train loss: 2.6476630344986916, metric: 49.134318590164185, lr: 0.00020802643848583102
[9720] train loss: 15.408568799495697, metric: 53.72733974456787, lr: 0.00018299407383892685
[9740] train loss: 2.506405770778656, metric: 49.42974328994751, lr: 0.00015922538295853883
[9760] train loss: 1.89433191716671, metric: 45.11936283111572, lr: 0.00013681512791663408
[9780] train loss: 1.546164184808731, metric: 43.95235824584961, lr: 0.00011585262109292671
[9800] train loss: 1.1578505113720894, metric: 39.53296232223511, lr: 9.999999747378752e-05
[9820] train loss: 1.6554922312498093, metric: 39.487178802490234, lr: 9.999999747378752e-05
[9840] train loss: 0.8888416886329651, metric: 40.66165113449097, lr: 9.999999747378752e-05
[9860] train loss: 0.9689313843846321, metric: 37.30168342590332, lr: 9.999999747378752e-05
[9880] train loss: 0.8871471285820007, metric: 42.10014343261719, lr: 9.999999747378752e-05
[9900] train loss: 0.60538050532341, metric: 40.17933893203735, lr: 9.999999747378752e-05
[9920] train loss: 0.4600747972726822, metric: 37.097811222076416, lr: 9.999999747378752e-05
[9940] train loss: 0.5336759760975838, metric: 37.91503667831421, lr: 9.999999747378752e-05
[9960] train loss: 0.4275160878896713, metric: 44.24548053741455, lr: 9.999999747378752e-05
[9980] train loss: 0.7483717352151871, metric: 42.65018081665039, lr: 9.999999747378752e-05
[10000] train loss: 0.548847496509552, metric: 42.45987367630005, lr: 9.999999747378752e-05
[10020] train loss: 0.5915977135300636, metric: 42.353821754455566, lr: 0.0009994393913075328
[10040] train loss: 1.2173152193427086, metric: 43.54983043670654, lr: 0.0009969500824809074
[10060] train loss: 0.6859792619943619, metric: 52.533522605895996, lr: 0.000992479850538075
[10080] train loss: 2.62412016838789, metric: 54.849493980407715, lr: 0.000986046390607953
[10100] train loss: 4.5117606818675995, metric: 53.04175138473511, lr: 0.0009776754304766655
[10120] train loss: 0.714944951236248, metric: 46.7962384223938, lr: 0.0009674003813415766
[10140] train loss: 1.1330967023968697, metric: 49.887479305267334, lr: 0.0009552621049806476
[10160] train loss: 0.7972536236047745, metric: 57.68690872192383, lr: 0.0009413089719600976
[10180] train loss: 0.834473542869091, metric: 53.456918716430664, lr: 0.0009255966870114207
[10200] train loss: 0.5158033818006516, metric: 45.2115740776062, lr: 0.00090818788157776
[10220] train loss: 0.7353295683860779, metric: 41.719648361206055, lr: 0.0008891518809832633
[10240] train loss: 0.49011652916669846, metric: 39.417869567871094, lr: 0.0008685645880177617
[10260] train loss: 2.350829154253006, metric: 44.541924476623535, lr: 0.0008465081336908042
[10280] train loss: 1.641222521662712, metric: 40.687583446502686, lr: 0.0008230703533627093
[10300] train loss: 1.2108116298913956, metric: 41.35033893585205, lr: 0.0007983447285369039
[10320] train loss: 0.8715771287679672, metric: 42.4151725769043, lr: 0.0007724298629909754
[10340] train loss: 1.1040397211909294, metric: 42.56402397155762, lr: 0.0007454289589077234
[10360] train loss: 1.3402631431818008, metric: 50.72750186920166, lr: 0.0007174497004598379
[10380] train loss: 1.1579269543290138, metric: 43.52811574935913, lr: 0.00068860367173329
[10400] train loss: 0.6509921997785568, metric: 39.428061723709106, lr: 0.0006590057746507227
[10420] train loss: 0.8075075373053551, metric: 35.79130792617798, lr: 0.0006287740543484688
[10440] train loss: 0.43030936270952225, metric: 38.51408863067627, lr: 0.000598029000684619
[10460] train loss: 0.292976263910532, metric: 39.37838649749756, lr: 0.0005668931407853961
[10480] train loss: 0.31220297142863274, metric: 40.647319316864014, lr: 0.0005354906315915287
[10500] train loss: 0.19928069785237312, metric: 40.39557409286499, lr: 0.0005039466777816415
[10520] train loss: 0.24889756739139557, metric: 41.40975618362427, lr: 0.0004723869787994772
[10540] train loss: 0.21101311966776848, metric: 43.01280975341797, lr: 0.0004409373505041003
[10560] train loss: 0.24025006592273712, metric: 42.59275150299072, lr: 0.0004097231721971184
[10580] train loss: 0.27009185776114464, metric: 42.55256175994873, lr: 0.000378868862753734
[10600] train loss: 0.27694059535861015, metric: 42.06671667098999, lr: 0.00034849741496145725
[10620] train loss: 0.3070602975785732, metric: 40.62197780609131, lr: 0.0003187299007549882
[10640] train loss: 0.3112938813865185, metric: 43.287343978881836, lr: 0.0002896849764510989
[10660] train loss: 0.48086533695459366, metric: 46.583882331848145, lr: 0.0002614784170873463
[10680] train loss: 0.44861069321632385, metric: 45.41976070404053, lr: 0.00023422270896844566
[10700] train loss: 0.42457275837659836, metric: 45.23344612121582, lr: 0.00020802643848583102
[10720] train loss: 0.4993492215871811, metric: 48.6432523727417, lr: 0.00018299407383892685
[10740] train loss: 0.3496226593852043, metric: 46.1292200088501, lr: 0.00015922538295853883
[10760] train loss: 2.5417424142360687, metric: 35.96785068511963, lr: 0.00013681512791663408
[10780] train loss: 1.4084926471114159, metric: 28.55959415435791, lr: 0.00011585262109292671
[10800] train loss: 1.0647800788283348, metric: 29.53850269317627, lr: 9.999999747378752e-05
[10820] train loss: 0.8645017966628075, metric: 25.66141176223755, lr: 9.999999747378752e-05
[10840] train loss: 1.4129128903150558, metric: 26.039848804473877, lr: 9.999999747378752e-05
[10860] train loss: 1.4439584948122501, metric: 26.441355228424072, lr: 9.999999747378752e-05
[10880] train loss: 3.1382139921188354, metric: 27.828750133514404, lr: 9.999999747378752e-05
[10900] train loss: 2.1436420157551765, metric: 27.780725479125977, lr: 9.999999747378752e-05
[10920] train loss: 1.1499954834580421, metric: 28.71447229385376, lr: 9.999999747378752e-05
[10940] train loss: 1.354533739387989, metric: 33.25849485397339, lr: 9.999999747378752e-05
[10960] train loss: 0.8576792925596237, metric: 32.04652976989746, lr: 9.999999747378752e-05
[10980] train loss: 1.486884355545044, metric: 31.190803050994873, lr: 9.999999747378752e-05
[11000] train loss: 2.5412238389253616, metric: 41.72957992553711, lr: 9.999999747378752e-05
[11020] train loss: 0.7764195948839188, metric: 42.25559425354004, lr: 0.0009994393913075328
[11040] train loss: 0.9470966160297394, metric: 37.45010757446289, lr: 0.0009969500824809074
[11060] train loss: 0.6082790642976761, metric: 37.211745262145996, lr: 0.000992479850538075
[11080] train loss: 0.3471851274371147, metric: 33.54020309448242, lr: 0.000986046390607953
[11100] train loss: 0.6170353256165981, metric: 37.26523447036743, lr: 0.0009776754304766655
[11120] train loss: 0.4396052211523056, metric: 30.318100929260254, lr: 0.0009674003813415766
[11140] train loss: 0.3657453656196594, metric: 33.86443090438843, lr: 0.0009552621049806476
[11160] train loss: 0.44682102277874947, metric: 35.32313871383667, lr: 0.0009413089719600976
[11180] train loss: 0.42807623744010925, metric: 36.30773878097534, lr: 0.0009255966870114207
[11200] train loss: 0.8892301917076111, metric: 31.708993911743164, lr: 0.00090818788157776
[11220] train loss: 0.7268103510141373, metric: 35.62478590011597, lr: 0.0008891518809832633
[11240] train loss: 0.5961519703269005, metric: 34.68073272705078, lr: 0.0008685645880177617
[11260] train loss: 0.7355337888002396, metric: 32.1201868057251, lr: 0.0008465081336908042
[11280] train loss: 1.1713998466730118, metric: 63.177369117736816, lr: 0.0008230703533627093
[11300] train loss: 0.7764892056584358, metric: 58.059701919555664, lr: 0.0007983447285369039
[11320] train loss: 0.6610436365008354, metric: 54.790788650512695, lr: 0.0007724298629909754
[11340] train loss: 0.6866028904914856, metric: 53.25687122344971, lr: 0.0007454289589077234
[11360] train loss: 0.38512592762708664, metric: 52.464393615722656, lr: 0.0007174497004598379
[11380] train loss: 0.32842205837368965, metric: 52.96010398864746, lr: 0.00068860367173329
[11400] train loss: 0.3627907931804657, metric: 44.96818733215332, lr: 0.0006590057746507227
[11420] train loss: 0.6669143028557301, metric: 41.556376457214355, lr: 0.0006287740543484688
[11440] train loss: 0.23762311041355133, metric: 38.450927734375, lr: 0.000598029000684619
[11460] train loss: 0.19952472299337387, metric: 40.68736553192139, lr: 0.0005668931407853961
[11480] train loss: 0.24096310138702393, metric: 42.220160484313965, lr: 0.0005354906315915287
[11500] train loss: 0.2626229524612427, metric: 44.823869705200195, lr: 0.0005039466777816415
[11520] train loss: 0.2396830879151821, metric: 44.174163818359375, lr: 0.0004723869787994772
[11540] train loss: 0.2764727734029293, metric: 43.92112922668457, lr: 0.0004409373505041003
[11560] train loss: 0.5534191802144051, metric: 40.81221866607666, lr: 0.0004097231721971184
[11580] train loss: 0.45090802013874054, metric: 43.51161861419678, lr: 0.000378868862753734
[11600] train loss: 0.4989887475967407, metric: 39.616214752197266, lr: 0.00034849741496145725
[11620] train loss: 2.649992521852255, metric: 41.491241455078125, lr: 0.0003187299007549882
[11640] train loss: 1.261285688728094, metric: 41.365211486816406, lr: 0.0002896849764510989
[11660] train loss: 0.936881884932518, metric: 41.84822463989258, lr: 0.0002614784170873463
[11680] train loss: 0.37833331525325775, metric: 40.94658184051514, lr: 0.00023422270896844566
[11700] train loss: 0.322643231600523, metric: 41.857787132263184, lr: 0.00020802643848583102
[11720] train loss: 0.386009618639946, metric: 39.33658790588379, lr: 0.00018299407383892685
[11740] train loss: 0.32003654167056084, metric: 37.49625873565674, lr: 0.00015922538295853883
[11760] train loss: 0.3459012284874916, metric: 39.076979637145996, lr: 0.00013681512791663408
[11780] train loss: 4.177544042468071, metric: 28.762776851654053, lr: 0.00011585262109292671
[11800] train loss: 2.576648622751236, metric: 30.261988639831543, lr: 9.999999747378752e-05
[11820] train loss: 1.1108804270625114, metric: 36.21284008026123, lr: 9.999999747378752e-05
[11840] train loss: 2.325719580054283, metric: 32.4589147567749, lr: 9.999999747378752e-05
[11860] train loss: 3.885952353477478, metric: 33.02146244049072, lr: 9.999999747378752e-05
[11880] train loss: 4.31260746717453, metric: 36.96717929840088, lr: 9.999999747378752e-05
[11900] train loss: 2.480648711323738, metric: 38.5878643989563, lr: 9.999999747378752e-05
[11920] train loss: 1.3956677913665771, metric: 35.754194259643555, lr: 9.999999747378752e-05
[11940] train loss: 1.0695345029234886, metric: 33.32496356964111, lr: 9.999999747378752e-05
[11960] train loss: 1.1326333358883858, metric: 40.30732822418213, lr: 9.999999747378752e-05
[11980] train loss: 0.58188396692276, metric: 37.198975563049316, lr: 9.999999747378752e-05
[12000] train loss: 0.4740440845489502, metric: 34.351441383361816, lr: 9.999999747378752e-05
[12020] train loss: 0.30529094114899635, metric: 34.89126205444336, lr: 0.0009994393913075328
[12040] train loss: 0.5280450470745564, metric: 33.920217514038086, lr: 0.0009969500824809074
[12060] train loss: 0.3301052786409855, metric: 33.57037353515625, lr: 0.000992479850538075
[12080] train loss: 0.23696294054389, metric: 31.024126529693604, lr: 0.000986046390607953
[12100] train loss: 0.2969033755362034, metric: 30.654319286346436, lr: 0.0009776754304766655
[12120] train loss: 0.254569161683321, metric: 36.73212242126465, lr: 0.0009674003813415766
[12140] train loss: 0.5178215056657791, metric: 36.30601501464844, lr: 0.0009552621049806476
[12160] train loss: 0.3996160216629505, metric: 36.994643688201904, lr: 0.0009413089719600976
[12180] train loss: 2.6886817924678326, metric: 35.44669723510742, lr: 0.0009255966870114207
[12200] train loss: 1.635009951889515, metric: 36.11672496795654, lr: 0.00090818788157776
[12220] train loss: 2.6251206770539284, metric: 36.39547348022461, lr: 0.0008891518809832633
[12240] train loss: 1.9344343319535255, metric: 35.30894136428833, lr: 0.0008685645880177617
[12260] train loss: 1.957448810338974, metric: 38.615628242492676, lr: 0.0008465081336908042
[12280] train loss: 5.318055488169193, metric: 29.70161485671997, lr: 0.0008230703533627093
[12300] train loss: 0.8056751042604446, metric: 46.48360538482666, lr: 0.0007983447285369039
[12320] train loss: 0.47949280589818954, metric: 42.96700668334961, lr: 0.0007724298629909754
[12340] train loss: 0.26663804426789284, metric: 39.29507350921631, lr: 0.0007454289589077234
[12360] train loss: 0.23543201386928558, metric: 33.50440502166748, lr: 0.0007174497004598379
[12380] train loss: 0.26290617138147354, metric: 31.890482902526855, lr: 0.00068860367173329
[12400] train loss: 0.24288390204310417, metric: 31.441590309143066, lr: 0.0006590057746507227
[12420] train loss: 0.22185587882995605, metric: 32.384188652038574, lr: 0.0006287740543484688
[12440] train loss: 0.18048447743058205, metric: 33.52380180358887, lr: 0.000598029000684619
[12460] train loss: 0.2369302622973919, metric: 33.92509651184082, lr: 0.0005668931407853961
[12480] train loss: 0.37361014261841774, metric: 36.54103660583496, lr: 0.0005354906315915287
[12500] train loss: 0.3921298682689667, metric: 33.64746952056885, lr: 0.0005039466777816415
[12520] train loss: 0.49133405834436417, metric: 37.36952018737793, lr: 0.0004723869787994772
[12540] train loss: 0.6811027973890305, metric: 47.312705993652344, lr: 0.0004409373505041003
[12560] train loss: 0.5770472064614296, metric: 42.11141586303711, lr: 0.0004097231721971184
[12580] train loss: 0.8227376341819763, metric: 37.9268102645874, lr: 0.000378868862753734
[12600] train loss: 0.631457969546318, metric: 35.39255952835083, lr: 0.00034849741496145725
[12620] train loss: 0.40301481634378433, metric: 34.56234407424927, lr: 0.0003187299007549882
[12640] train loss: 0.4614354372024536, metric: 30.639473915100098, lr: 0.0002896849764510989
[12660] train loss: 0.42480801045894623, metric: 32.193387031555176, lr: 0.0002614784170873463
[12680] train loss: 0.35059908404946327, metric: 34.23877954483032, lr: 0.00023422270896844566
[12700] train loss: 0.33145373687148094, metric: 35.35359573364258, lr: 0.00020802643848583102
[12720] train loss: 0.4711660370230675, metric: 38.17058753967285, lr: 0.00018299407383892685
[12740] train loss: 0.5590032711625099, metric: 39.12327575683594, lr: 0.00015922538295853883
[12760] train loss: 0.6296160742640495, metric: 40.05636787414551, lr: 0.00013681512791663408
[12780] train loss: 0.36626432090997696, metric: 38.21774768829346, lr: 0.00011585262109292671
[12800] train loss: 0.2877930924296379, metric: 37.700196266174316, lr: 9.999999747378752e-05
[12820] train loss: 7.680914372205734, metric: 32.13717555999756, lr: 9.999999747378752e-05
[12840] train loss: 9.563805177807808, metric: 35.586092472076416, lr: 9.999999747378752e-05
[12860] train loss: 7.276857599616051, metric: 31.024725914001465, lr: 9.999999747378752e-05
[12880] train loss: 2.4399804025888443, metric: 31.648812294006348, lr: 9.999999747378752e-05
[12900] train loss: 2.9241819083690643, metric: 28.98122215270996, lr: 9.999999747378752e-05
[12920] train loss: 3.9710900709033012, metric: 28.01932382583618, lr: 9.999999747378752e-05
[12940] train loss: 2.1889513731002808, metric: 31.425264835357666, lr: 9.999999747378752e-05
[12960] train loss: 1.9800496697425842, metric: 38.22023010253906, lr: 9.999999747378752e-05
[12980] train loss: 1.1487576812505722, metric: 36.47313117980957, lr: 9.999999747378752e-05
[13000] train loss: 1.854629009962082, metric: 33.59301280975342, lr: 9.999999747378752e-05
[13020] train loss: 1.423606887459755, metric: 33.65466499328613, lr: 0.0009994393913075328
[13040] train loss: 1.4950656965374947, metric: 32.58597755432129, lr: 0.0009969500824809074
[13060] train loss: 1.4731449633836746, metric: 43.4720983505249, lr: 0.000992479850538075
[13080] train loss: 2.297125965356827, metric: 41.49716901779175, lr: 0.000986046390607953
[13100] train loss: 2.526216246187687, metric: 36.7279372215271, lr: 0.0009776754304766655
[13120] train loss: 2.4121222645044327, metric: 37.66162347793579, lr: 0.0009674003813415766
[13140] train loss: 8.002539463341236, metric: 40.6169228553772, lr: 0.0009552621049806476
[13160] train loss: 1.5063664242625237, metric: 37.9757137298584, lr: 0.0009413089719600976
[13180] train loss: 3.754425033926964, metric: 34.3068265914917, lr: 0.0009255966870114207
[13200] train loss: 1.8983172103762627, metric: 40.61326217651367, lr: 0.00090818788157776
[13220] train loss: 3.8086210265755653, metric: 33.30971145629883, lr: 0.0008891518809832633
[13240] train loss: 2.49806110560894, metric: 49.36734676361084, lr: 0.0008685645880177617
[13260] train loss: 0.996808834373951, metric: 40.91858386993408, lr: 0.0008465081336908042
[13280] train loss: 1.4827132150530815, metric: 28.162044048309326, lr: 0.0008230703533627093
[13300] train loss: 1.182362262159586, metric: 28.98283576965332, lr: 0.0007983447285369039
[13320] train loss: 1.1204099655151367, metric: 35.13656759262085, lr: 0.0007724298629909754
[13340] train loss: 0.3460097908973694, metric: 34.01661777496338, lr: 0.0007454289589077234
[13360] train loss: 0.2820758782327175, metric: 31.480173587799072, lr: 0.0007174497004598379
[13380] train loss: 0.27981314063072205, metric: 34.29373550415039, lr: 0.00068860367173329
[13400] train loss: 0.2326018065214157, metric: 34.53421401977539, lr: 0.0006590057746507227
[13420] train loss: 0.25933273881673813, metric: 34.59052038192749, lr: 0.0006287740543484688
[13440] train loss: 0.34949592873454094, metric: 33.97760772705078, lr: 0.000598029000684619
[13460] train loss: 0.24762115627527237, metric: 32.90494441986084, lr: 0.0005668931407853961
[13480] train loss: 0.26005054637789726, metric: 33.66595220565796, lr: 0.0005354906315915287
[13500] train loss: 0.22388924285769463, metric: 36.91410827636719, lr: 0.0005039466777816415
[13520] train loss: 0.3179965242743492, metric: 37.2171688079834, lr: 0.0004723869787994772
[13540] train loss: 0.32138989493250847, metric: 33.23495626449585, lr: 0.0004409373505041003
[13560] train loss: 0.49311091378331184, metric: 32.74827194213867, lr: 0.0004097231721971184
[13580] train loss: 0.4551522620022297, metric: 33.96391153335571, lr: 0.000378868862753734
[13600] train loss: 0.5753368996083736, metric: 35.42264413833618, lr: 0.00034849741496145725
[13620] train loss: 0.7946767285466194, metric: 33.854722023010254, lr: 0.0003187299007549882
[13640] train loss: 0.5380911380052567, metric: 33.40150547027588, lr: 0.0002896849764510989
[13660] train loss: 0.8496307879686356, metric: 32.74704313278198, lr: 0.0002614784170873463
[13680] train loss: 1.747425813227892, metric: 30.175434112548828, lr: 0.00023422270896844566
[13700] train loss: 2.100010011345148, metric: 29.232483863830566, lr: 0.00020802643848583102
[13720] train loss: 9.45532501861453, metric: 30.975414276123047, lr: 0.00018299407383892685
[13740] train loss: 4.537372510880232, metric: 32.54437971115112, lr: 0.00015922538295853883
[13760] train loss: 2.792787216603756, metric: 29.39442014694214, lr: 0.00013681512791663408
[13780] train loss: 1.2682503946125507, metric: 28.95222759246826, lr: 0.00011585262109292671
[13800] train loss: 0.8494628928601742, metric: 28.68162250518799, lr: 9.999999747378752e-05
[13820] train loss: 0.3818671703338623, metric: 27.792631149291992, lr: 9.999999747378752e-05
[13840] train loss: 4.4076650738716125, metric: 27.66678237915039, lr: 9.999999747378752e-05
[13860] train loss: 3.1146626621484756, metric: 28.322654247283936, lr: 9.999999747378752e-05
[13880] train loss: 2.4998562932014465, metric: 30.805240154266357, lr: 9.999999747378752e-05
[13900] train loss: 2.0147625356912613, metric: 28.197285652160645, lr: 9.999999747378752e-05
[13920] train loss: 1.4257943332195282, metric: 22.46571159362793, lr: 9.999999747378752e-05
[13940] train loss: 1.5664701610803604, metric: 23.390987873077393, lr: 9.999999747378752e-05
[13960] train loss: 1.2569895461201668, metric: 26.943478107452393, lr: 9.999999747378752e-05
[13980] train loss: 2.571857139468193, metric: 28.954806327819824, lr: 9.999999747378752e-05
[14000] train loss: 1.0126774981617928, metric: 27.4302020072937, lr: 9.999999747378752e-05
[14020] train loss: 0.5658015087246895, metric: 28.681604862213135, lr: 0.0009994393913075328
[14040] train loss: 0.3775518834590912, metric: 26.305543422698975, lr: 0.0009969500824809074
[14060] train loss: 0.5361356511712074, metric: 28.323899745941162, lr: 0.000992479850538075
[14080] train loss: 0.3475121036171913, metric: 28.200283527374268, lr: 0.000986046390607953
[14100] train loss: 0.5060470066964626, metric: 24.760013103485107, lr: 0.0009776754304766655
[14120] train loss: 0.3972039185464382, metric: 28.61565923690796, lr: 0.0009674003813415766
[14140] train loss: 0.728133961558342, metric: 29.30270528793335, lr: 0.0009552621049806476
[14160] train loss: 0.4621661975979805, metric: 31.396150588989258, lr: 0.0009413089719600976
[14180] train loss: 0.48916642740368843, metric: 32.44895696640015, lr: 0.0009255966870114207
[14200] train loss: 0.7525647878646851, metric: 36.21414661407471, lr: 0.00090818788157776
[14220] train loss: 1.1449896693229675, metric: 38.439212799072266, lr: 0.0008891518809832633
[14240] train loss: 0.5749365016818047, metric: 35.19139862060547, lr: 0.0008685645880177617
[14260] train loss: 1.3325802497565746, metric: 37.08342170715332, lr: 0.0008465081336908042
[14280] train loss: 0.8072878792881966, metric: 32.3663125038147, lr: 0.0008230703533627093
[14300] train loss: 0.6378389075398445, metric: 34.35862636566162, lr: 0.0007983447285369039
[14320] train loss: 1.003931000828743, metric: 38.65264701843262, lr: 0.0007724298629909754
[14340] train loss: 0.8652770519256592, metric: 37.391847133636475, lr: 0.0007454289589077234
[14360] train loss: 0.3078620806336403, metric: 36.35788869857788, lr: 0.0007174497004598379
[14380] train loss: 0.29956525936722755, metric: 32.495205879211426, lr: 0.00068860367173329
[14400] train loss: 0.2171376682817936, metric: 35.39174699783325, lr: 0.0006590057746507227
[14420] train loss: 0.31669802218675613, metric: 37.05192947387695, lr: 0.0006287740543484688
[14440] train loss: 0.30026520416140556, metric: 37.620845794677734, lr: 0.000598029000684619
[14460] train loss: 0.3287538141012192, metric: 37.7137451171875, lr: 0.0005668931407853961
[14480] train loss: 0.37681566923856735, metric: 37.278207778930664, lr: 0.0005354906315915287
[14500] train loss: 0.4774508774280548, metric: 35.87508964538574, lr: 0.0005039466777816415
[14520] train loss: 0.5579018518328667, metric: 34.597869873046875, lr: 0.0004723869787994772
[14540] train loss: 1.616852156817913, metric: 35.123374938964844, lr: 0.0004409373505041003
[14560] train loss: 0.9572872631251812, metric: 33.054826736450195, lr: 0.0004097231721971184
[14580] train loss: 1.983031202107668, metric: 35.600117206573486, lr: 0.000378868862753734
[14600] train loss: 2.3645614720880985, metric: 32.873538970947266, lr: 0.00034849741496145725
[14620] train loss: 1.3998169675469398, metric: 33.927433013916016, lr: 0.0003187299007549882
[14640] train loss: 0.7684667035937309, metric: 31.88512897491455, lr: 0.0002896849764510989
[14660] train loss: 0.7809196747839451, metric: 32.76774978637695, lr: 0.0002614784170873463
[14680] train loss: 0.6206596828997135, metric: 32.42653703689575, lr: 0.00023422270896844566
[14700] train loss: 1.3634740598499775, metric: 35.12357521057129, lr: 0.00020802643848583102
[14720] train loss: 1.706369198858738, metric: 34.260141372680664, lr: 0.00018299407383892685
[14740] train loss: 1.7870769314467907, metric: 34.74222469329834, lr: 0.00015922538295853883
[14760] train loss: 4.667509593069553, metric: 36.19752788543701, lr: 0.00013681512791663408
[14780] train loss: 5.197789892554283, metric: 33.722569942474365, lr: 0.00011585262109292671
[14800] train loss: 1.563354216516018, metric: 30.368062019348145, lr: 9.999999747378752e-05
[14820] train loss: 1.564254805445671, metric: 36.069772720336914, lr: 9.999999747378752e-05
[14840] train loss: 2.971649780869484, metric: 40.778263092041016, lr: 9.999999747378752e-05
[14860] train loss: 2.504326745867729, metric: 39.0370888710022, lr: 9.999999747378752e-05
[14880] train loss: 1.7992957383394241, metric: 30.290555477142334, lr: 9.999999747378752e-05
[14900] train loss: 3.271229535341263, metric: 26.651862621307373, lr: 9.999999747378752e-05
[14920] train loss: 1.6388942897319794, metric: 30.61565637588501, lr: 9.999999747378752e-05
[14940] train loss: 1.9799405932426453, metric: 30.654207229614258, lr: 9.999999747378752e-05
[14960] train loss: 1.896190270781517, metric: 24.953691959381104, lr: 9.999999747378752e-05
[14980] train loss: 1.8572607189416885, metric: 25.749000787734985, lr: 9.999999747378752e-05
[15000] train loss: 3.308703199028969, metric: 23.668800830841064, lr: 9.999999747378752e-05
[15020] train loss: 2.5844993889331818, metric: 33.08028697967529, lr: 0.0009994393913075328
[15040] train loss: 1.3584744483232498, metric: 30.058603286743164, lr: 0.0009969500824809074
[15060] train loss: 0.7832833677530289, metric: 40.5637788772583, lr: 0.000992479850538075
[15080] train loss: 1.5014252811670303, metric: 26.01995825767517, lr: 0.000986046390607953
[15100] train loss: 1.8599426746368408, metric: 26.062936305999756, lr: 0.0009776754304766655
[15120] train loss: 1.1175799369812012, metric: 26.36685800552368, lr: 0.0009674003813415766
[15140] train loss: 1.3964584171772003, metric: 35.418370723724365, lr: 0.0009552621049806476
[15160] train loss: 1.1067595928907394, metric: 35.42365884780884, lr: 0.0009413089719600976
[15180] train loss: 1.8449088633060455, metric: 50.126919746398926, lr: 0.0009255966870114207
[15200] train loss: 4.97099182009697, metric: 61.72305679321289, lr: 0.00090818788157776
[15220] train loss: 10.41187533736229, metric: 46.436970710754395, lr: 0.0008891518809832633
[15240] train loss: 4.099036127328873, metric: 42.62731170654297, lr: 0.0008685645880177617
[15260] train loss: 1.4649279415607452, metric: 39.528489112854004, lr: 0.0008465081336908042
[15280] train loss: 2.677244618535042, metric: 40.07299613952637, lr: 0.0008230703533627093
[15300] train loss: 1.2146522551774979, metric: 36.27714729309082, lr: 0.0007983447285369039
[15320] train loss: 7.520238220691681, metric: 33.69204521179199, lr: 0.0007724298629909754
[15340] train loss: 2.83082315325737, metric: 35.47908592224121, lr: 0.0007454289589077234
[15360] train loss: 2.3061322160065174, metric: 49.07934284210205, lr: 0.0007174497004598379
[15380] train loss: 0.737537793815136, metric: 38.04301834106445, lr: 0.00068860367173329
[15400] train loss: 0.8873700127005577, metric: 37.408430099487305, lr: 0.0006590057746507227
[15420] train loss: 1.2784374058246613, metric: 37.047672271728516, lr: 0.0006287740543484688
[15440] train loss: 0.8511231020092964, metric: 35.39908504486084, lr: 0.000598029000684619
[15460] train loss: 0.9496073052287102, metric: 38.437976360321045, lr: 0.0005668931407853961
[15480] train loss: 0.5129711925983429, metric: 40.5971941947937, lr: 0.0005354906315915287
[15500] train loss: 0.5522814318537712, metric: 42.368711948394775, lr: 0.0005039466777816415
[15520] train loss: 0.48556261509656906, metric: 46.82443332672119, lr: 0.0004723869787994772
[15540] train loss: 0.4277132973074913, metric: 43.64656352996826, lr: 0.0004409373505041003
[15560] train loss: 0.3744369074702263, metric: 38.405343532562256, lr: 0.0004097231721971184
[15580] train loss: 1.4767407327890396, metric: 33.89565324783325, lr: 0.000378868862753734
[15600] train loss: 2.7875973656773567, metric: 38.59495735168457, lr: 0.00034849741496145725
[15620] train loss: 2.3215796127915382, metric: 55.64269399642944, lr: 0.0003187299007549882
[15640] train loss: 0.4734404385089874, metric: 43.72060298919678, lr: 0.0002896849764510989
[15660] train loss: 1.8886027857661247, metric: 35.97068786621094, lr: 0.0002614784170873463
[15680] train loss: 4.834017604589462, metric: 37.51955509185791, lr: 0.00023422270896844566
[15700] train loss: 1.1877304390072823, metric: 42.250446796417236, lr: 0.00020802643848583102
[15720] train loss: 0.7516157180070877, metric: 48.90570402145386, lr: 0.00018299407383892685
[15740] train loss: 0.57718675583601, metric: 44.43021774291992, lr: 0.00015922538295853883
[15760] train loss: 0.7553287744522095, metric: 35.650461196899414, lr: 0.00013681512791663408
[15780] train loss: 0.6223345398902893, metric: 35.30656719207764, lr: 0.00011585262109292671
[15800] train loss: 0.4783528670668602, metric: 39.60326337814331, lr: 9.999999747378752e-05
[15820] train loss: 0.6279461085796356, metric: 35.10084629058838, lr: 9.999999747378752e-05
[15840] train loss: 0.6241471618413925, metric: 40.7435998916626, lr: 9.999999747378752e-05
[15860] train loss: 0.5446302518248558, metric: 43.459519386291504, lr: 9.999999747378752e-05
[15880] train loss: 1.5057381093502045, metric: 36.46714496612549, lr: 9.999999747378752e-05
[15900] train loss: 0.9595860093832016, metric: 33.85961055755615, lr: 9.999999747378752e-05
[15920] train loss: 3.670856937766075, metric: 32.12969493865967, lr: 9.999999747378752e-05
[15940] train loss: 1.2514728009700775, metric: 34.538514137268066, lr: 9.999999747378752e-05
[15960] train loss: 0.6075939685106277, metric: 36.59911346435547, lr: 9.999999747378752e-05
[15980] train loss: 0.6093066483736038, metric: 34.99238872528076, lr: 9.999999747378752e-05
[16000] train loss: 0.5769237726926804, metric: 33.68896198272705, lr: 9.999999747378752e-05
[16020] train loss: 0.42197589576244354, metric: 31.711383819580078, lr: 0.0009994393913075328
[16040] train loss: 0.4497547671198845, metric: 35.30369567871094, lr: 0.0009969500824809074
[16060] train loss: 0.4842243939638138, metric: 31.529563903808594, lr: 0.000992479850538075
[16080] train loss: 0.444314569234848, metric: 35.230531215667725, lr: 0.000986046390607953
[16100] train loss: 0.3872286081314087, metric: 33.837281227111816, lr: 0.0009776754304766655
[16120] train loss: 0.3094249367713928, metric: 37.17094039916992, lr: 0.0009674003813415766
[16140] train loss: 0.3609703555703163, metric: 37.93532752990723, lr: 0.0009552621049806476
[16160] train loss: 0.4700867161154747, metric: 37.26091384887695, lr: 0.0009413089719600976
[16180] train loss: 0.2732444927096367, metric: 38.086331367492676, lr: 0.0009255966870114207
[16200] train loss: 0.32833074033260345, metric: 38.25411319732666, lr: 0.00090818788157776
[16220] train loss: 0.34290802106261253, metric: 39.721935749053955, lr: 0.0008891518809832633
[16240] train loss: 0.4487275928258896, metric: 41.66145992279053, lr: 0.0008685645880177617
[16260] train loss: 0.3891400843858719, metric: 35.35624694824219, lr: 0.0008465081336908042
[16280] train loss: 0.4300863519310951, metric: 35.867008209228516, lr: 0.0008230703533627093
[16300] train loss: 0.3590387962758541, metric: 35.106088638305664, lr: 0.0007983447285369039
[16320] train loss: 0.34114353358745575, metric: 36.496140480041504, lr: 0.0007724298629909754
[16340] train loss: 0.5214954279363155, metric: 32.01830196380615, lr: 0.0007454289589077234
[16360] train loss: 0.423014085739851, metric: 34.84746265411377, lr: 0.0007174497004598379
[16380] train loss: 0.3601689487695694, metric: 35.00494384765625, lr: 0.00068860367173329
[16400] train loss: 1.25167266279459, metric: 36.764004707336426, lr: 0.0006590057746507227
[16420] train loss: 0.7907871529459953, metric: 37.6278657913208, lr: 0.0006287740543484688
[16440] train loss: 2.0424664095044136, metric: 46.40808439254761, lr: 0.000598029000684619
[16460] train loss: 1.7772295847535133, metric: 41.972211837768555, lr: 0.0005668931407853961
[16480] train loss: 0.5324002131819725, metric: 41.39114856719971, lr: 0.0005354906315915287
[16500] train loss: 0.5412087179720402, metric: 41.98623085021973, lr: 0.0005039466777816415
[16520] train loss: 0.4094507396221161, metric: 43.03499364852905, lr: 0.0004723869787994772
[16540] train loss: 0.39744842424988747, metric: 39.275630950927734, lr: 0.0004409373505041003
[16560] train loss: 0.610172376036644, metric: 44.22787570953369, lr: 0.0004097231721971184
[16580] train loss: 0.8459473177790642, metric: 41.41066265106201, lr: 0.000378868862753734
[16600] train loss: 1.0754807069897652, metric: 42.047110080718994, lr: 0.00034849741496145725
[16620] train loss: 1.8101088367402554, metric: 49.34373092651367, lr: 0.0003187299007549882
[16640] train loss: 2.5087853260338306, metric: 47.29891872406006, lr: 0.0002896849764510989
[16660] train loss: 0.8414522334933281, metric: 44.02219104766846, lr: 0.0002614784170873463
[16680] train loss: 1.4251623637974262, metric: 42.34867572784424, lr: 0.00023422270896844566
[16700] train loss: 0.6376782730221748, metric: 44.61497402191162, lr: 0.00020802643848583102
[16720] train loss: 0.543254129588604, metric: 41.45144271850586, lr: 0.00018299407383892685
[16740] train loss: 0.5637203603982925, metric: 43.32304668426514, lr: 0.00015922538295853883
[16760] train loss: 0.5626186057925224, metric: 45.614004135131836, lr: 0.00013681512791663408
[16780] train loss: 0.7332670837640762, metric: 48.100178718566895, lr: 0.00011585262109292671
[16800] train loss: 0.7204070389270782, metric: 43.04040718078613, lr: 9.999999747378752e-05
[16820] train loss: 0.5144351571798325, metric: 39.68382120132446, lr: 9.999999747378752e-05
[16840] train loss: 0.30763017758727074, metric: 42.63704967498779, lr: 9.999999747378752e-05
[16860] train loss: 0.418524369597435, metric: 43.78592395782471, lr: 9.999999747378752e-05
[16880] train loss: 0.47959455102682114, metric: 45.39010047912598, lr: 9.999999747378752e-05
[16900] train loss: 3.350991800427437, metric: 39.99443435668945, lr: 9.999999747378752e-05
[16920] train loss: 4.1256954446434975, metric: 40.787864685058594, lr: 9.999999747378752e-05
[16940] train loss: 1.4196119606494904, metric: 39.643452167510986, lr: 9.999999747378752e-05
[16960] train loss: 2.1645151302218437, metric: 36.19087314605713, lr: 9.999999747378752e-05
[16980] train loss: 7.992710471153259, metric: 42.41813850402832, lr: 9.999999747378752e-05
[17000] train loss: 5.5497927740216255, metric: 46.73250198364258, lr: 9.999999747378752e-05
[17020] train loss: 1.8506318926811218, metric: 39.668020248413086, lr: 0.0009994393913075328
[17040] train loss: 1.6422921046614647, metric: 38.82472896575928, lr: 0.0009969500824809074
[17060] train loss: 1.485912248492241, metric: 30.340896606445312, lr: 0.000992479850538075
[17080] train loss: 1.0202939584851265, metric: 33.3179144859314, lr: 0.000986046390607953
[17100] train loss: 2.525993950664997, metric: 32.14640712738037, lr: 0.0009776754304766655
[17120] train loss: 1.2819277346134186, metric: 40.64625549316406, lr: 0.0009674003813415766
[17140] train loss: 1.4221457093954086, metric: 41.4051628112793, lr: 0.0009552621049806476
[17160] train loss: 2.374205395579338, metric: 45.48710918426514, lr: 0.0009413089719600976
[17180] train loss: 0.7437128573656082, metric: 44.25538873672485, lr: 0.0009255966870114207
[17200] train loss: 0.9824441820383072, metric: 52.40777015686035, lr: 0.00090818788157776
[17220] train loss: 0.46003977209329605, metric: 49.29068470001221, lr: 0.0008891518809832633
[17240] train loss: 0.674933698028326, metric: 44.68276071548462, lr: 0.0008685645880177617
[17260] train loss: 1.6601793020963669, metric: 37.619081020355225, lr: 0.0008465081336908042
[17280] train loss: 2.1429093554615974, metric: 38.18382930755615, lr: 0.0008230703533627093
[17300] train loss: 1.4695335552096367, metric: 45.01792621612549, lr: 0.0007983447285369039
[17320] train loss: 0.9777211919426918, metric: 36.945194244384766, lr: 0.0007724298629909754
[17340] train loss: 0.6352836675941944, metric: 36.048285484313965, lr: 0.0007454289589077234
[17360] train loss: 1.1108273640275002, metric: 40.63640213012695, lr: 0.0007174497004598379
[17380] train loss: 1.1527652740478516, metric: 32.03390884399414, lr: 0.00068860367173329
[17400] train loss: 0.8998747579753399, metric: 30.81728744506836, lr: 0.0006590057746507227
[17420] train loss: 1.1692021042108536, metric: 43.078378677368164, lr: 0.0006287740543484688
[17440] train loss: 0.7304571643471718, metric: 50.63338565826416, lr: 0.000598029000684619
[17460] train loss: 0.592298150062561, metric: 42.6379280090332, lr: 0.0005668931407853961
[17480] train loss: 0.5252995565533638, metric: 42.430123805999756, lr: 0.0005354906315915287
[17500] train loss: 1.951705440878868, metric: 32.35790395736694, lr: 0.0005039466777816415
[17520] train loss: 0.5952382460236549, metric: 30.201311588287354, lr: 0.0004723869787994772
[17540] train loss: 1.0592710860073566, metric: 39.28771495819092, lr: 0.0004409373505041003
[17560] train loss: 0.7021670714020729, metric: 34.96359395980835, lr: 0.0004097231721971184
[17580] train loss: 0.45100804418325424, metric: 35.04728412628174, lr: 0.000378868862753734
[17600] train loss: 0.5670667178928852, metric: 36.858216762542725, lr: 0.00034849741496145725
[17620] train loss: 0.38821643590927124, metric: 41.59278869628906, lr: 0.0003187299007549882
[17640] train loss: 0.4924256503582001, metric: 42.36557865142822, lr: 0.0002896849764510989
[17660] train loss: 0.3856584057211876, metric: 44.40069389343262, lr: 0.0002614784170873463
[17680] train loss: 0.2329055368900299, metric: 42.29874038696289, lr: 0.00023422270896844566
[17700] train loss: 0.2429642155766487, metric: 40.686984062194824, lr: 0.00020802643848583102
[17720] train loss: 0.24607951939105988, metric: 43.2624568939209, lr: 0.00018299407383892685
[17740] train loss: 0.27449241653084755, metric: 41.49429225921631, lr: 0.00015922538295853883
[17760] train loss: 0.3445202186703682, metric: 43.70948600769043, lr: 0.00013681512791663408
[17780] train loss: 0.274626474827528, metric: 45.56375694274902, lr: 0.00011585262109292671
[17800] train loss: 0.385148324072361, metric: 45.47541332244873, lr: 9.999999747378752e-05
[17820] train loss: 0.35230738297104836, metric: 44.82387733459473, lr: 9.999999747378752e-05
[17840] train loss: 0.35441954433918, metric: 42.531142234802246, lr: 9.999999747378752e-05
[17860] train loss: 0.6027631610631943, metric: 43.727681159973145, lr: 9.999999747378752e-05
[17880] train loss: 0.6033000275492668, metric: 45.414329528808594, lr: 9.999999747378752e-05
[17900] train loss: 0.3698451891541481, metric: 44.0346999168396, lr: 9.999999747378752e-05
[17920] train loss: 0.5441028624773026, metric: 45.81126308441162, lr: 9.999999747378752e-05
[17940] train loss: 1.5851686000823975, metric: 33.17859697341919, lr: 9.999999747378752e-05
[17960] train loss: 0.7011134773492813, metric: 32.898191928863525, lr: 9.999999747378752e-05
[17980] train loss: 0.5304602608084679, metric: 33.05264854431152, lr: 9.999999747378752e-05
[18000] train loss: 0.8343764021992683, metric: 34.56974697113037, lr: 9.999999747378752e-05
[18020] train loss: 0.33798906207084656, metric: 35.22075939178467, lr: 0.0009994393913075328
[18040] train loss: 0.43832483142614365, metric: 28.32678508758545, lr: 0.0009969500824809074
[18060] train loss: 0.48515021055936813, metric: 30.554346084594727, lr: 0.000992479850538075
[18080] train loss: 0.30030108243227005, metric: 31.322272777557373, lr: 0.000986046390607953
[18100] train loss: 0.4752526432275772, metric: 30.1773624420166, lr: 0.0009776754304766655
[18120] train loss: 0.5544092655181885, metric: 29.598384857177734, lr: 0.0009674003813415766
[18140] train loss: 0.8433572724461555, metric: 28.02620267868042, lr: 0.0009552621049806476
[18160] train loss: 0.4887921027839184, metric: 30.132493019104004, lr: 0.0009413089719600976
[18180] train loss: 0.9084038212895393, metric: 29.77547836303711, lr: 0.0009255966870114207
[18200] train loss: 1.212295114994049, metric: 27.3407621383667, lr: 0.00090818788157776
[18220] train loss: 2.1767634227871895, metric: 30.055702209472656, lr: 0.0008891518809832633
[18240] train loss: 1.0117479413747787, metric: 27.842273235321045, lr: 0.0008685645880177617
[18260] train loss: 0.8765385374426842, metric: 33.64469051361084, lr: 0.0008465081336908042
[18280] train loss: 1.4913422837853432, metric: 34.78898334503174, lr: 0.0008230703533627093
[18300] train loss: 0.7929779514670372, metric: 32.965250968933105, lr: 0.0007983447285369039
[18320] train loss: 0.7523961514234543, metric: 35.28491020202637, lr: 0.0007724298629909754
[18340] train loss: 0.4361288696527481, metric: 30.94156312942505, lr: 0.0007454289589077234
[18360] train loss: 0.456499420106411, metric: 30.18523931503296, lr: 0.0007174497004598379
[18380] train loss: 0.48243508487939835, metric: 32.39610242843628, lr: 0.00068860367173329
[18400] train loss: 0.4773987606167793, metric: 31.5381498336792, lr: 0.0006590057746507227
[18420] train loss: 0.49774982035160065, metric: 31.84587287902832, lr: 0.0006287740543484688
[18440] train loss: 3.743956759572029, metric: 46.40995121002197, lr: 0.000598029000684619
[18460] train loss: 1.209274761378765, metric: 41.10896301269531, lr: 0.0005668931407853961
[18480] train loss: 0.641397200524807, metric: 37.270631313323975, lr: 0.0005354906315915287
[18500] train loss: 0.4496648833155632, metric: 36.390422344207764, lr: 0.0005039466777816415
[18520] train loss: 0.405363529920578, metric: 41.83013153076172, lr: 0.0004723869787994772
[18540] train loss: 0.6300693973898888, metric: 39.96380805969238, lr: 0.0004409373505041003
[18560] train loss: 0.5436950512230396, metric: 40.60730838775635, lr: 0.0004097231721971184
[18580] train loss: 0.43413129448890686, metric: 36.70085000991821, lr: 0.000378868862753734
[18600] train loss: 0.644319973886013, metric: 36.94398832321167, lr: 0.00034849741496145725
[18620] train loss: 1.7021659389138222, metric: 40.64858627319336, lr: 0.0003187299007549882
[18640] train loss: 1.65646518394351, metric: 34.77599620819092, lr: 0.0002896849764510989
[18660] train loss: 1.1802902407944202, metric: 39.42213249206543, lr: 0.0002614784170873463
[18680] train loss: 1.4109803810715675, metric: 41.27638816833496, lr: 0.00023422270896844566
[18700] train loss: 2.7292696572840214, metric: 45.645442962646484, lr: 0.00020802643848583102
[18720] train loss: 0.5370622761547565, metric: 42.61495876312256, lr: 0.00018299407383892685
[18740] train loss: 2.303148254752159, metric: 42.291531562805176, lr: 0.00015922538295853883
[18760] train loss: 3.0326511040329933, metric: 40.19383144378662, lr: 0.00013681512791663408
[18780] train loss: 2.1121859960258007, metric: 46.3969612121582, lr: 0.00011585262109292671
[18800] train loss: 0.9089427217841148, metric: 46.10187911987305, lr: 9.999999747378752e-05
[18820] train loss: 1.4437346383929253, metric: 42.17334747314453, lr: 9.999999747378752e-05
[18840] train loss: 1.4838793203234673, metric: 39.40799903869629, lr: 9.999999747378752e-05
[18860] train loss: 3.463181398808956, metric: 40.79587697982788, lr: 9.999999747378752e-05
[18880] train loss: 5.239177271723747, metric: 37.98471260070801, lr: 9.999999747378752e-05
[18900] train loss: 5.22682947665453, metric: 40.646738052368164, lr: 9.999999747378752e-05
[18920] train loss: 10.179621867835522, metric: 48.63360118865967, lr: 9.999999747378752e-05
[18940] train loss: 3.029912881553173, metric: 40.41552543640137, lr: 9.999999747378752e-05
[18960] train loss: 0.8756468743085861, metric: 44.09506034851074, lr: 9.999999747378752e-05
[18980] train loss: 0.5956065282225609, metric: 44.364351749420166, lr: 9.999999747378752e-05
[19000] train loss: 0.42735232412815094, metric: 49.29718017578125, lr: 9.999999747378752e-05
[19020] train loss: 0.3283282555639744, metric: 47.73814868927002, lr: 0.0009994393913075328
[19040] train loss: 0.2542484924197197, metric: 43.899460792541504, lr: 0.0009969500824809074
[19060] train loss: 0.21659200638532639, metric: 44.709670543670654, lr: 0.000992479850538075
[19080] train loss: 0.2492191344499588, metric: 42.16934108734131, lr: 0.000986046390607953
[19100] train loss: 0.2291429415345192, metric: 42.08404541015625, lr: 0.0009776754304766655
[19120] train loss: 0.2584672309458256, metric: 40.52621650695801, lr: 0.0009674003813415766
[19140] train loss: 0.2605568915605545, metric: 39.33957481384277, lr: 0.0009552621049806476
[19160] train loss: 0.21387411467731, metric: 37.04432487487793, lr: 0.0009413089719600976
[19180] train loss: 0.19597475603222847, metric: 34.815412521362305, lr: 0.0009255966870114207
[19200] train loss: 0.18309430219233036, metric: 34.954430103302, lr: 0.00090818788157776
[19220] train loss: 0.2185763344168663, metric: 34.11384916305542, lr: 0.0008891518809832633
[19240] train loss: 0.1568717323243618, metric: 34.46216058731079, lr: 0.0008685645880177617
[19260] train loss: 0.1589425429701805, metric: 33.6076774597168, lr: 0.0008465081336908042
[19280] train loss: 0.17030564323067665, metric: 33.29874277114868, lr: 0.0008230703533627093
[19300] train loss: 0.15907980129122734, metric: 33.26789855957031, lr: 0.0007983447285369039
[19320] train loss: 0.18155077658593655, metric: 35.417311668395996, lr: 0.0007724298629909754
[19340] train loss: 0.17934159003198147, metric: 34.11616897583008, lr: 0.0007454289589077234
[19360] train loss: 0.1549459584057331, metric: 33.96411895751953, lr: 0.0007174497004598379
[19380] train loss: 0.1770787350833416, metric: 35.39881086349487, lr: 0.00068860367173329
[19400] train loss: 0.15171314030885696, metric: 34.48210334777832, lr: 0.0006590057746507227
[19420] train loss: 0.3602292276918888, metric: 35.949381828308105, lr: 0.0006287740543484688
[19440] train loss: 0.1708836406469345, metric: 35.76979160308838, lr: 0.000598029000684619
[19460] train loss: 1.9808405339717865, metric: 43.916043281555176, lr: 0.0005668931407853961
[19480] train loss: 0.976154513657093, metric: 39.556395530700684, lr: 0.0005354906315915287
[19500] train loss: 0.6176013201475143, metric: 42.2687873840332, lr: 0.0005039466777816415
[19520] train loss: 0.5849805623292923, metric: 46.762206077575684, lr: 0.0004723869787994772
[19540] train loss: 1.005709059536457, metric: 47.261606216430664, lr: 0.0004409373505041003
[19560] train loss: 0.7947620674967766, metric: 46.979572772979736, lr: 0.0004097231721971184
[19580] train loss: 0.563494861125946, metric: 45.41092586517334, lr: 0.000378868862753734
[19600] train loss: 0.6882201209664345, metric: 42.07458305358887, lr: 0.00034849741496145725
[19620] train loss: 0.8276893198490143, metric: 42.62527084350586, lr: 0.0003187299007549882
[19640] train loss: 1.0269794762134552, metric: 45.645925521850586, lr: 0.0002896849764510989
[19660] train loss: 0.6752966195344925, metric: 37.65446329116821, lr: 0.0002614784170873463
[19680] train loss: 0.5368754342198372, metric: 40.9818115234375, lr: 0.00023422270896844566
[19700] train loss: 0.5722215622663498, metric: 43.49801063537598, lr: 0.00020802643848583102
[19720] train loss: 0.554880753159523, metric: 42.96325063705444, lr: 0.00018299407383892685
[19740] train loss: 0.3709757402539253, metric: 45.237643241882324, lr: 0.00015922538295853883
[19760] train loss: 0.42605162411928177, metric: 41.76475763320923, lr: 0.00013681512791663408
[19780] train loss: 0.5251088589429855, metric: 42.600568771362305, lr: 0.00011585262109292671
[19800] train loss: 0.38289985060691833, metric: 42.41233825683594, lr: 9.999999747378752e-05
[19820] train loss: 0.3766295164823532, metric: 43.413371086120605, lr: 9.999999747378752e-05
[19840] train loss: 0.5434087477624416, metric: 46.08918380737305, lr: 9.999999747378752e-05
[19860] train loss: 0.5964022986590862, metric: 46.90879535675049, lr: 9.999999747378752e-05
[19880] train loss: 0.48003721982240677, metric: 46.54626178741455, lr: 9.999999747378752e-05
[19900] train loss: 0.5244884938001633, metric: 48.89635944366455, lr: 9.999999747378752e-05
[19920] train loss: 0.3735642172396183, metric: 46.17040729522705, lr: 9.999999747378752e-05
[19940] train loss: 0.32431038096547127, metric: 48.87937927246094, lr: 9.999999747378752e-05
[19960] train loss: 0.3001868613064289, metric: 48.6114387512207, lr: 9.999999747378752e-05
[19980] train loss: 2.6216609105467796, metric: 43.867127418518066, lr: 9.999999747378752e-05
[20000] train loss: 3.290428303182125, metric: 39.39438247680664, lr: 9.999999747378752e-05
[20020] train loss: 0.8554166182875633, metric: 36.56277942657471, lr: 0.0009994393913075328
[20040] train loss: 0.5555732026696205, metric: 38.963393211364746, lr: 0.0009969500824809074
[20060] train loss: 0.6301575377583504, metric: 38.18549203872681, lr: 0.000992479850538075
[20080] train loss: 0.9801990538835526, metric: 38.685880184173584, lr: 0.000986046390607953
[20100] train loss: 0.5357067175209522, metric: 40.23336172103882, lr: 0.0009776754304766655
[20120] train loss: 0.6623842753469944, metric: 37.89656591415405, lr: 0.0009674003813415766
[20140] train loss: 0.9529784992337227, metric: 39.79218530654907, lr: 0.0009552621049806476
[20160] train loss: 1.2375645637512207, metric: 45.97741365432739, lr: 0.0009413089719600976
[20180] train loss: 0.9759978353977203, metric: 45.609028816223145, lr: 0.0009255966870114207
[20200] train loss: 0.8768469169735909, metric: 50.28115224838257, lr: 0.00090818788157776
[20220] train loss: 1.7969617396593094, metric: 40.24040651321411, lr: 0.0008891518809832633
[20240] train loss: 2.66623792052269, metric: 38.69699954986572, lr: 0.0008685645880177617
[20260] train loss: 3.166809529066086, metric: 41.25450325012207, lr: 0.0008465081336908042
[20280] train loss: 1.8525429293513298, metric: 43.20597505569458, lr: 0.0008230703533627093
[20300] train loss: 0.6660681255161762, metric: 39.244672775268555, lr: 0.0007983447285369039
[20320] train loss: 0.46792370826005936, metric: 42.95920372009277, lr: 0.0007724298629909754
[20340] train loss: 0.38476666808128357, metric: 36.241347312927246, lr: 0.0007454289589077234
[20360] train loss: 0.6096594519913197, metric: 31.76659345626831, lr: 0.0007174497004598379
[20380] train loss: 0.4083695262670517, metric: 35.15174102783203, lr: 0.00068860367173329
[20400] train loss: 0.3175988495349884, metric: 34.529221534729004, lr: 0.0006590057746507227
[20420] train loss: 0.40172722563147545, metric: 33.414695739746094, lr: 0.0006287740543484688
[20440] train loss: 0.4334535077214241, metric: 38.24529552459717, lr: 0.000598029000684619
[20460] train loss: 0.5083802565932274, metric: 37.80323839187622, lr: 0.0005668931407853961
[20480] train loss: 0.4190348982810974, metric: 37.582828760147095, lr: 0.0005354906315915287
[20500] train loss: 1.0216612815856934, metric: 53.18782329559326, lr: 0.0005039466777816415
[20520] train loss: 1.2170369327068329, metric: 63.96635818481445, lr: 0.0004723869787994772
[20540] train loss: 1.2341751456260681, metric: 62.06651592254639, lr: 0.0004409373505041003
[20560] train loss: 1.0881534963846207, metric: 61.809414863586426, lr: 0.0004097231721971184
[20580] train loss: 1.0593073442578316, metric: 59.03884506225586, lr: 0.000378868862753734
[20600] train loss: 0.5555770769715309, metric: 49.63702392578125, lr: 0.00034849741496145725
[20620] train loss: 0.8255190178751945, metric: 47.33298349380493, lr: 0.0003187299007549882
[20640] train loss: 0.9490062072873116, metric: 45.20990562438965, lr: 0.0002896849764510989
[20660] train loss: 0.8521958887577057, metric: 46.10723686218262, lr: 0.0002614784170873463
[20680] train loss: 1.1259196400642395, metric: 49.133127212524414, lr: 0.00023422270896844566
[20700] train loss: 1.2838505953550339, metric: 55.07412052154541, lr: 0.00020802643848583102
[20720] train loss: 2.113207295536995, metric: 46.66607904434204, lr: 0.00018299407383892685
[20740] train loss: 1.7296566292643547, metric: 36.14812088012695, lr: 0.00015922538295853883
[20760] train loss: 1.6431959569454193, metric: 34.642069816589355, lr: 0.00013681512791663408
[20780] train loss: 2.2194595262408257, metric: 39.95419216156006, lr: 0.00011585262109292671
[20800] train loss: 1.766706146299839, metric: 45.73482704162598, lr: 9.999999747378752e-05
[20820] train loss: 2.7107724025845528, metric: 46.888997077941895, lr: 9.999999747378752e-05
[20840] train loss: 4.169926635921001, metric: 49.069984436035156, lr: 9.999999747378752e-05
[20860] train loss: 1.2320074886083603, metric: 47.496280670166016, lr: 9.999999747378752e-05
[20880] train loss: 0.7436463162302971, metric: 41.661184310913086, lr: 9.999999747378752e-05
[20900] train loss: 1.290458858013153, metric: 39.95348644256592, lr: 9.999999747378752e-05
[20920] train loss: 1.2532795071601868, metric: 35.88804912567139, lr: 9.999999747378752e-05
[20940] train loss: 2.2890254259109497, metric: 31.916400909423828, lr: 9.999999747378752e-05
[20960] train loss: 1.3880983367562294, metric: 34.720927238464355, lr: 9.999999747378752e-05
[20980] train loss: 0.9908317215740681, metric: 35.06673240661621, lr: 9.999999747378752e-05
[21000] train loss: 2.8696563839912415, metric: 41.40908241271973, lr: 9.999999747378752e-05
[21020] train loss: 1.145178660750389, metric: 40.7771053314209, lr: 0.0009994393913075328
[21040] train loss: 0.7672047689557076, metric: 42.181222915649414, lr: 0.0009969500824809074
[21060] train loss: 4.210866749286652, metric: 41.19328022003174, lr: 0.000992479850538075
[21080] train loss: 1.5206163600087166, metric: 40.23189687728882, lr: 0.000986046390607953
[21100] train loss: 9.396543383598328, metric: 53.014644145965576, lr: 0.0009776754304766655
[21120] train loss: 1.7216434925794601, metric: 44.724679470062256, lr: 0.0009674003813415766
[21140] train loss: 0.49065760523080826, metric: 51.54337215423584, lr: 0.0009552621049806476
[21160] train loss: 1.4510771296918392, metric: 47.43178081512451, lr: 0.0009413089719600976
[21180] train loss: 0.9889684841036797, metric: 44.347466468811035, lr: 0.0009255966870114207
[21200] train loss: 1.335661493241787, metric: 46.643056869506836, lr: 0.00090818788157776
[21220] train loss: 0.6888684555888176, metric: 44.783040046691895, lr: 0.0008891518809832633
[21240] train loss: 1.2243638560175896, metric: 36.7941837310791, lr: 0.0008685645880177617
[21260] train loss: 1.9508925750851631, metric: 42.283504486083984, lr: 0.0008465081336908042
[21280] train loss: 2.0790432542562485, metric: 43.54844808578491, lr: 0.0008230703533627093
[21300] train loss: 1.1872584000229836, metric: 40.09055805206299, lr: 0.0007983447285369039
[21320] train loss: 1.1426387205719948, metric: 37.9746732711792, lr: 0.0007724298629909754
[21340] train loss: 1.19264155626297, metric: 33.75035381317139, lr: 0.0007454289589077234
[21360] train loss: 1.4577416069805622, metric: 35.35323238372803, lr: 0.0007174497004598379
[21380] train loss: 1.0629014559090137, metric: 41.26972818374634, lr: 0.00068860367173329
[21400] train loss: 1.6512633748352528, metric: 37.17695188522339, lr: 0.0006590057746507227
[21420] train loss: 0.9556339420378208, metric: 40.14845514297485, lr: 0.0006287740543484688
[21440] train loss: 1.128547228872776, metric: 44.2938871383667, lr: 0.000598029000684619
[21460] train loss: 1.2261198088526726, metric: 39.9267578125, lr: 0.0005668931407853961
[21480] train loss: 9.616912998259068, metric: 44.51691770553589, lr: 0.0005354906315915287
[21500] train loss: 1.3655758053064346, metric: 32.430190563201904, lr: 0.0005039466777816415
[21520] train loss: 2.00034499168396, metric: 40.37723922729492, lr: 0.0004723869787994772
[21540] train loss: 1.2983841970562935, metric: 36.276671409606934, lr: 0.0004409373505041003
[21560] train loss: 1.3228821903467178, metric: 34.700618743896484, lr: 0.0004097231721971184
[21580] train loss: 1.1068878173828125, metric: 29.429153442382812, lr: 0.000378868862753734
[21600] train loss: 1.4305324405431747, metric: 29.74609899520874, lr: 0.00034849741496145725
[21620] train loss: 1.3980410769581795, metric: 36.097453117370605, lr: 0.0003187299007549882
[21640] train loss: 2.513372950255871, metric: 33.713538646698, lr: 0.0002896849764510989
[21660] train loss: 1.7831506356596947, metric: 39.214101791381836, lr: 0.0002614784170873463
[21680] train loss: 1.6011716201901436, metric: 37.6191987991333, lr: 0.00023422270896844566
[21700] train loss: 3.3121184036135674, metric: 37.4764404296875, lr: 0.00020802643848583102
[21720] train loss: 1.9864420369267464, metric: 38.950127601623535, lr: 0.00018299407383892685
[21740] train loss: 2.114060364663601, metric: 45.37300252914429, lr: 0.00015922538295853883
[21760] train loss: 1.1118429452180862, metric: 46.838417053222656, lr: 0.00013681512791663408
[21780] train loss: 0.9197304472327232, metric: 36.057579040527344, lr: 0.00011585262109292671
[21800] train loss: 2.388865999877453, metric: 38.17744302749634, lr: 9.999999747378752e-05
[21820] train loss: 1.3716043680906296, metric: 35.95735549926758, lr: 9.999999747378752e-05
[21840] train loss: 2.03579131513834, metric: 35.04697513580322, lr: 9.999999747378752e-05
[21860] train loss: 3.8142331689596176, metric: 32.47336196899414, lr: 9.999999747378752e-05
[21880] train loss: 3.0064760744571686, metric: 34.95835208892822, lr: 9.999999747378752e-05
[21900] train loss: 8.024818524718285, metric: 40.73298263549805, lr: 9.999999747378752e-05
[21920] train loss: 5.607457548379898, metric: 35.0781946182251, lr: 9.999999747378752e-05
[21940] train loss: 3.3531582579016685, metric: 37.736653327941895, lr: 9.999999747378752e-05
[21960] train loss: 1.4110831022262573, metric: 44.856329917907715, lr: 9.999999747378752e-05
[21980] train loss: 0.9582386016845703, metric: 42.51279926300049, lr: 9.999999747378752e-05
[22000] train loss: 0.6759950295090675, metric: 38.40692138671875, lr: 9.999999747378752e-05
[22020] train loss: 2.019130662083626, metric: 44.9810676574707, lr: 0.0009994393913075328
[22040] train loss: 4.233464598655701, metric: 46.309401512145996, lr: 0.0009969500824809074
[22060] train loss: 1.2915364019572735, metric: 43.32090950012207, lr: 0.000992479850538075
[22080] train loss: 2.0793288722634315, metric: 43.66048812866211, lr: 0.000986046390607953
[22100] train loss: 0.6438546478748322, metric: 40.925647258758545, lr: 0.0009776754304766655
[22120] train loss: 1.1301488019526005, metric: 37.61529302597046, lr: 0.0009674003813415766
[22140] train loss: 2.049315884709358, metric: 44.87540340423584, lr: 0.0009552621049806476
[22160] train loss: 1.2926851212978363, metric: 51.66801738739014, lr: 0.0009413089719600976
[22180] train loss: 0.49642564728856087, metric: 55.64297008514404, lr: 0.0009255966870114207
[22200] train loss: 1.8059714287519455, metric: 52.608327865600586, lr: 0.00090818788157776
[22220] train loss: 3.437846787273884, metric: 50.118632316589355, lr: 0.0008891518809832633
[22240] train loss: 1.8633934780955315, metric: 55.200225830078125, lr: 0.0008685645880177617
[22260] train loss: 2.992843672633171, metric: 51.32687282562256, lr: 0.0008465081336908042
[22280] train loss: 1.4690141528844833, metric: 45.56452417373657, lr: 0.0008230703533627093
[22300] train loss: 1.9215579591691494, metric: 44.80989074707031, lr: 0.0007983447285369039
[22320] train loss: 2.2021907530725002, metric: 51.79191017150879, lr: 0.0007724298629909754
[22340] train loss: 2.274692542850971, metric: 62.29996681213379, lr: 0.0007454289589077234
[22360] train loss: 2.1736021637916565, metric: 47.997365951538086, lr: 0.0007174497004598379
[22380] train loss: 2.4587867818772793, metric: 45.95979070663452, lr: 0.00068860367173329
[22400] train loss: 4.542699847370386, metric: 49.24576473236084, lr: 0.0006590057746507227
[22420] train loss: 2.0681277215480804, metric: 49.34565734863281, lr: 0.0006287740543484688
[22440] train loss: 1.6293861120939255, metric: 57.933573722839355, lr: 0.000598029000684619
[22460] train loss: 0.7920968197286129, metric: 58.04098701477051, lr: 0.0005668931407853961
[22480] train loss: 1.866914726793766, metric: 51.46879577636719, lr: 0.0005354906315915287
[22500] train loss: 2.0248958542943, metric: 57.82921600341797, lr: 0.0005039466777816415
[22520] train loss: 3.997796580195427, metric: 47.012654304504395, lr: 0.0004723869787994772
[22540] train loss: 0.9206922650337219, metric: 35.55388689041138, lr: 0.0004409373505041003
[22560] train loss: 0.5087040439248085, metric: 39.83965349197388, lr: 0.0004097231721971184
[22580] train loss: 0.496835432946682, metric: 37.03048753738403, lr: 0.000378868862753734
[22600] train loss: 0.2961333692073822, metric: 37.44145107269287, lr: 0.00034849741496145725
[22620] train loss: 0.3979374021291733, metric: 39.17770051956177, lr: 0.0003187299007549882
[22640] train loss: 0.42731328308582306, metric: 31.06484317779541, lr: 0.0002896849764510989
[22660] train loss: 0.3631819002330303, metric: 27.0761239528656, lr: 0.0002614784170873463
[22680] train loss: 0.4304841496050358, metric: 34.69238996505737, lr: 0.00023422270896844566
[22700] train loss: 0.5538887828588486, metric: 35.25524663925171, lr: 0.00020802643848583102
[22720] train loss: 2.509214662015438, metric: 30.717923164367676, lr: 0.00018299407383892685
[22740] train loss: 5.4189315512776375, metric: 40.886380195617676, lr: 0.00015922538295853883
[22760] train loss: 4.489154830574989, metric: 34.88476276397705, lr: 0.00013681512791663408
[22780] train loss: 2.025501996278763, metric: 33.61784219741821, lr: 0.00011585262109292671
[22800] train loss: 1.0041580572724342, metric: 31.51020097732544, lr: 9.999999747378752e-05
[22820] train loss: 0.7677255868911743, metric: 28.401495933532715, lr: 9.999999747378752e-05
[22840] train loss: 1.1278899163007736, metric: 26.766477584838867, lr: 9.999999747378752e-05
[22860] train loss: 1.022282026708126, metric: 24.50939130783081, lr: 9.999999747378752e-05
[22880] train loss: 0.4631849601864815, metric: 25.629267692565918, lr: 9.999999747378752e-05
[22900] train loss: 0.7956026569008827, metric: 29.14881658554077, lr: 9.999999747378752e-05
[22920] train loss: 0.7700233906507492, metric: 28.16974401473999, lr: 9.999999747378752e-05
[22940] train loss: 0.7671002894639969, metric: 30.796011447906494, lr: 9.999999747378752e-05
[22960] train loss: 0.7208194434642792, metric: 33.01092052459717, lr: 9.999999747378752e-05
[22980] train loss: 1.0624616146087646, metric: 34.0677375793457, lr: 9.999999747378752e-05
[23000] train loss: 1.1953579634428024, metric: 37.4162073135376, lr: 9.999999747378752e-05
[23020] train loss: 0.6898763179779053, metric: 40.14907741546631, lr: 0.0009994393913075328
[23040] train loss: 0.4315539076924324, metric: 46.58792686462402, lr: 0.0009969500824809074
[23060] train loss: 1.8827341943979263, metric: 41.13490009307861, lr: 0.000992479850538075
[23080] train loss: 1.2972123995423317, metric: 42.30546855926514, lr: 0.000986046390607953
[23100] train loss: 1.107729583978653, metric: 42.40699005126953, lr: 0.0009776754304766655
[23120] train loss: 2.524583373218775, metric: 48.20884037017822, lr: 0.0009674003813415766
[23140] train loss: 0.8760864213109016, metric: 36.34428310394287, lr: 0.0009552621049806476
[23160] train loss: 1.440043155103922, metric: 40.55841827392578, lr: 0.0009413089719600976
[23180] train loss: 1.1996418982744217, metric: 42.97701072692871, lr: 0.0009255966870114207
[23200] train loss: 1.4364631958305836, metric: 34.454896450042725, lr: 0.00090818788157776
[23220] train loss: 0.8042303957045078, metric: 38.127967834472656, lr: 0.0008891518809832633
[23240] train loss: 1.2077833451330662, metric: 35.700753688812256, lr: 0.0008685645880177617
[23260] train loss: 1.4076255485415459, metric: 44.8460693359375, lr: 0.0008465081336908042
[23280] train loss: 2.7116417214274406, metric: 37.79134559631348, lr: 0.0008230703533627093
[23300] train loss: 0.9838364720344543, metric: 37.07903718948364, lr: 0.0007983447285369039
[23320] train loss: 0.4101073443889618, metric: 31.562411308288574, lr: 0.0007724298629909754
[23340] train loss: 1.6772417947649956, metric: 32.1682014465332, lr: 0.0007454289589077234
[23360] train loss: 3.4498779326677322, metric: 33.612542152404785, lr: 0.0007174497004598379
[23380] train loss: 1.4893513955175877, metric: 42.506834983825684, lr: 0.00068860367173329
[23400] train loss: 1.3121059089899063, metric: 48.78618144989014, lr: 0.0006590057746507227
[23420] train loss: 1.3053695261478424, metric: 41.57154655456543, lr: 0.0006287740543484688
[23440] train loss: 2.74483023583889, metric: 39.03107690811157, lr: 0.000598029000684619
[23460] train loss: 1.2340648770332336, metric: 35.387410163879395, lr: 0.0005668931407853961
[23480] train loss: 2.542497992515564, metric: 37.91029167175293, lr: 0.0005354906315915287
[23500] train loss: 1.9711682051420212, metric: 31.61669683456421, lr: 0.0005039466777816415
[23520] train loss: 5.064065769314766, metric: 42.12196636199951, lr: 0.0004723869787994772
[23540] train loss: 1.8373125791549683, metric: 36.66317319869995, lr: 0.0004409373505041003
[23560] train loss: 2.0882217064499855, metric: 28.25442934036255, lr: 0.0004097231721971184
[23580] train loss: 1.0823384448885918, metric: 31.806922435760498, lr: 0.000378868862753734
[23600] train loss: 1.023331232368946, metric: 37.325950145721436, lr: 0.00034849741496145725
[23620] train loss: 0.6455332972109318, metric: 34.171552658081055, lr: 0.0003187299007549882
[23640] train loss: 0.9563989862799644, metric: 31.496533393859863, lr: 0.0002896849764510989
[23660] train loss: 4.233380667865276, metric: 32.96238708496094, lr: 0.0002614784170873463
[23680] train loss: 0.9417504146695137, metric: 30.33457612991333, lr: 0.00023422270896844566
[23700] train loss: 1.1581012904644012, metric: 30.777194023132324, lr: 0.00020802643848583102
[23720] train loss: 2.246867746114731, metric: 35.38198375701904, lr: 0.00018299407383892685
[23740] train loss: 2.359317570924759, metric: 35.90913724899292, lr: 0.00015922538295853883
[23760] train loss: 2.6212957948446274, metric: 36.36642026901245, lr: 0.00013681512791663408
[23780] train loss: 2.9528903514146805, metric: 40.92936658859253, lr: 0.00011585262109292671
[23800] train loss: 1.6886069476604462, metric: 42.224332332611084, lr: 9.999999747378752e-05
[23820] train loss: 3.8996439650654793, metric: 40.76412057876587, lr: 9.999999747378752e-05
[23840] train loss: 1.238532394170761, metric: 41.52768278121948, lr: 9.999999747378752e-05
[23860] train loss: 0.9571531116962433, metric: 40.255308628082275, lr: 9.999999747378752e-05
[23880] train loss: 1.223153606057167, metric: 38.56447792053223, lr: 9.999999747378752e-05
[23900] train loss: 1.1036176905035973, metric: 40.68229341506958, lr: 9.999999747378752e-05
[23920] train loss: 2.2521466463804245, metric: 41.42034125328064, lr: 9.999999747378752e-05
[23940] train loss: 2.001390717923641, metric: 44.557518005371094, lr: 9.999999747378752e-05
[23960] train loss: 1.6670338362455368, metric: 44.97860622406006, lr: 9.999999747378752e-05
[23980] train loss: 1.3400977551937103, metric: 48.45973443984985, lr: 9.999999747378752e-05
[24000] train loss: 1.6760037541389465, metric: 46.655598640441895, lr: 9.999999747378752e-05
[24020] train loss: 1.3949646651744843, metric: 40.31272888183594, lr: 0.0009994393913075328
[24040] train loss: 0.5829575732350349, metric: 37.99998235702515, lr: 0.0009969500824809074
[24060] train loss: 0.7353077232837677, metric: 37.96953582763672, lr: 0.000992479850538075
[24080] train loss: 3.947590947151184, metric: 41.61739253997803, lr: 0.000986046390607953
[24100] train loss: 1.1637891083955765, metric: 42.11250591278076, lr: 0.0009776754304766655
[24120] train loss: 0.6866758912801743, metric: 44.4765510559082, lr: 0.0009674003813415766
[24140] train loss: 0.8389308005571365, metric: 37.8877534866333, lr: 0.0009552621049806476
[24160] train loss: 0.8514122739434242, metric: 40.557372093200684, lr: 0.0009413089719600976
[24180] train loss: 1.0819882526993752, metric: 41.400991916656494, lr: 0.0009255966870114207
[24200] train loss: 0.626174658536911, metric: 42.7427282333374, lr: 0.00090818788157776
[24220] train loss: 0.5407881289720535, metric: 32.937281131744385, lr: 0.0008891518809832633
[24240] train loss: 0.47150854766368866, metric: 32.032214641571045, lr: 0.0008685645880177617
[24260] train loss: 0.7165641188621521, metric: 32.56110620498657, lr: 0.0008465081336908042
[24280] train loss: 1.1081534698605537, metric: 36.89190864562988, lr: 0.0008230703533627093
[24300] train loss: 2.0026208609342575, metric: 32.412339210510254, lr: 0.0007983447285369039
[24320] train loss: 2.3445695601403713, metric: 34.407554626464844, lr: 0.0007724298629909754
[24340] train loss: 3.9638615772128105, metric: 33.42170810699463, lr: 0.0007454289589077234
[24360] train loss: 1.5876668244600296, metric: 29.199490070343018, lr: 0.0007174497004598379
[24380] train loss: 2.3702726922929287, metric: 32.47069334983826, lr: 0.00068860367173329
[24400] train loss: 0.5679895207285881, metric: 33.51911544799805, lr: 0.0006590057746507227
[24420] train loss: 0.49276119470596313, metric: 30.01693058013916, lr: 0.0006287740543484688
[24440] train loss: 0.6164072081446648, metric: 31.230961322784424, lr: 0.000598029000684619
[24460] train loss: 0.6548678576946259, metric: 30.455183029174805, lr: 0.0005668931407853961
[24480] train loss: 0.9675392098724842, metric: 32.34097480773926, lr: 0.0005354906315915287
[24500] train loss: 1.601307138800621, metric: 31.459636211395264, lr: 0.0005039466777816415
[24520] train loss: 2.359431877732277, metric: 28.56492519378662, lr: 0.0004723869787994772
[24540] train loss: 4.759638398885727, metric: 37.833539962768555, lr: 0.0004409373505041003
[24560] train loss: 4.694046474993229, metric: 37.91428852081299, lr: 0.0004097231721971184
[24580] train loss: 2.1394957304000854, metric: 55.58540058135986, lr: 0.000378868862753734
[24600] train loss: 0.6716190353035927, metric: 61.00446605682373, lr: 0.00034849741496145725
[24620] train loss: 0.5846980288624763, metric: 56.6287202835083, lr: 0.0003187299007549882
[24640] train loss: 0.38262730836868286, metric: 51.86498832702637, lr: 0.0002896849764510989
[24660] train loss: 0.43745560199022293, metric: 46.24981212615967, lr: 0.0002614784170873463
[24680] train loss: 0.5704208686947823, metric: 48.55107879638672, lr: 0.00023422270896844566
[24700] train loss: 0.48759155720472336, metric: 48.64044380187988, lr: 0.00020802643848583102
[24720] train loss: 0.5736234858632088, metric: 51.014098167419434, lr: 0.00018299407383892685
[24740] train loss: 0.5415847226977348, metric: 51.122901916503906, lr: 0.00015922538295853883
[24760] train loss: 0.45286130905151367, metric: 51.64035701751709, lr: 0.00013681512791663408
[24780] train loss: 0.4098816365003586, metric: 48.51269340515137, lr: 0.00011585262109292671
[24800] train loss: 0.4392135441303253, metric: 45.61660575866699, lr: 9.999999747378752e-05
[24820] train loss: 0.394303061068058, metric: 46.6400785446167, lr: 9.999999747378752e-05
[24840] train loss: 0.49910687282681465, metric: 42.54231357574463, lr: 9.999999747378752e-05
[24860] train loss: 0.6292747408151627, metric: 43.25296878814697, lr: 9.999999747378752e-05
[24880] train loss: 0.5500614792108536, metric: 41.90406036376953, lr: 9.999999747378752e-05
[24900] train loss: 0.9587943032383919, metric: 36.509613037109375, lr: 9.999999747378752e-05
[24920] train loss: 1.4285758882761002, metric: 37.4298095703125, lr: 9.999999747378752e-05
[24940] train loss: 1.2714797854423523, metric: 38.05334186553955, lr: 9.999999747378752e-05
[24960] train loss: 2.3911553882062435, metric: 39.09183120727539, lr: 9.999999747378752e-05
[24980] train loss: 3.8166138231754303, metric: 43.01481533050537, lr: 9.999999747378752e-05
[25000] train loss: 2.263660527765751, metric: 39.48652505874634, lr: 9.999999747378752e-05
[25020] train loss: 0.5694270357489586, metric: 44.91551208496094, lr: 0.0009994393913075328
[25040] train loss: 0.7186484038829803, metric: 56.46013069152832, lr: 0.0009969500824809074
[25060] train loss: 0.6812623888254166, metric: 57.14939785003662, lr: 0.000992479850538075
[25080] train loss: 0.4770171418786049, metric: 42.380064487457275, lr: 0.000986046390607953
[25100] train loss: 1.4001787453889847, metric: 33.867748737335205, lr: 0.0009776754304766655
[25120] train loss: 0.6218780726194382, metric: 31.582277297973633, lr: 0.0009674003813415766
[25140] train loss: 0.496605820953846, metric: 33.18643569946289, lr: 0.0009552621049806476
[25160] train loss: 0.40675443038344383, metric: 31.836276054382324, lr: 0.0009413089719600976
[25180] train loss: 0.34705449640750885, metric: 31.117376804351807, lr: 0.0009255966870114207
[25200] train loss: 0.3925692141056061, metric: 31.744863986968994, lr: 0.00090818788157776
[25220] train loss: 0.35996346920728683, metric: 30.81420612335205, lr: 0.0008891518809832633
[25240] train loss: 0.4659247249364853, metric: 31.05604362487793, lr: 0.0008685645880177617
[25260] train loss: 0.7824588492512703, metric: 33.10750865936279, lr: 0.0008465081336908042
[25280] train loss: 0.5782826580107212, metric: 31.944068908691406, lr: 0.0008230703533627093
[25300] train loss: 0.6090233139693737, metric: 34.31467342376709, lr: 0.0007983447285369039
[25320] train loss: 0.8773782923817635, metric: 37.5467643737793, lr: 0.0007724298629909754
[25340] train loss: 0.4118114300072193, metric: 32.88199043273926, lr: 0.0007454289589077234
[25360] train loss: 1.1515613496303558, metric: 38.455039978027344, lr: 0.0007174497004598379
[25380] train loss: 0.6802772954106331, metric: 48.60804843902588, lr: 0.00068860367173329
[25400] train loss: 0.484276682138443, metric: 44.67087268829346, lr: 0.0006590057746507227
[25420] train loss: 0.39985691383481026, metric: 37.683491706848145, lr: 0.0006287740543484688
[25440] train loss: 0.6982003450393677, metric: 35.53361129760742, lr: 0.000598029000684619
[25460] train loss: 0.4051829017698765, metric: 38.115699768066406, lr: 0.0005668931407853961
[25480] train loss: 0.4368181489408016, metric: 34.59576082229614, lr: 0.0005354906315915287
[25500] train loss: 0.8070321455597878, metric: 35.34743309020996, lr: 0.0005039466777816415
[25520] train loss: 0.978026881814003, metric: 41.70046520233154, lr: 0.0004723869787994772
[25540] train loss: 0.6777146682143211, metric: 39.24883842468262, lr: 0.0004409373505041003
[25560] train loss: 1.4868810921907425, metric: 35.89409875869751, lr: 0.0004097231721971184
[25580] train loss: 9.922131836414337, metric: 45.64992952346802, lr: 0.000378868862753734
[25600] train loss: 2.861033469438553, metric: 45.33919811248779, lr: 0.00034849741496145725
[25620] train loss: 0.6354968026280403, metric: 47.4580078125, lr: 0.0003187299007549882
[25640] train loss: 0.2994396686553955, metric: 47.091729164123535, lr: 0.0002896849764510989
[25660] train loss: 0.21802784875035286, metric: 44.77348232269287, lr: 0.0002614784170873463
[25680] train loss: 0.21333126723766327, metric: 46.27597904205322, lr: 0.00023422270896844566
[25700] train loss: 0.2642027512192726, metric: 43.86286735534668, lr: 0.00020802643848583102
[25720] train loss: 0.31595873087644577, metric: 43.36703062057495, lr: 0.00018299407383892685
[25740] train loss: 0.5148772783577442, metric: 42.762704849243164, lr: 0.00015922538295853883
[25760] train loss: 0.46901293098926544, metric: 44.94630813598633, lr: 0.00013681512791663408
[25780] train loss: 0.3905314914882183, metric: 45.65139389038086, lr: 0.00011585262109292671
[25800] train loss: 0.5439951792359352, metric: 44.76091003417969, lr: 9.999999747378752e-05
[25820] train loss: 0.30377237126231194, metric: 45.443366050720215, lr: 9.999999747378752e-05
[25840] train loss: 0.5242450535297394, metric: 45.301774978637695, lr: 9.999999747378752e-05
[25860] train loss: 0.6199086345732212, metric: 46.312010288238525, lr: 9.999999747378752e-05
[25880] train loss: 0.44806405529379845, metric: 50.24193859100342, lr: 9.999999747378752e-05
[25900] train loss: 0.6065199077129364, metric: 52.36314868927002, lr: 9.999999747378752e-05
[25920] train loss: 0.4456355944275856, metric: 55.96922969818115, lr: 9.999999747378752e-05
[25940] train loss: 0.6349572129547596, metric: 52.66830825805664, lr: 9.999999747378752e-05
[25960] train loss: 0.684405367821455, metric: 47.66731071472168, lr: 9.999999747378752e-05
[25980] train loss: 0.6838912554085255, metric: 47.49003219604492, lr: 9.999999747378752e-05
[26000] train loss: 1.2371982783079147, metric: 46.57883548736572, lr: 9.999999747378752e-05
[26020] train loss: 1.7384241446852684, metric: 49.1696400642395, lr: 0.0009994393913075328
[26040] train loss: 0.6996157169342041, metric: 50.4715518951416, lr: 0.0009969500824809074
[26060] train loss: 0.5992627814412117, metric: 56.854342460632324, lr: 0.000992479850538075
[26080] train loss: 0.6126349344849586, metric: 45.13531732559204, lr: 0.000986046390607953
[26100] train loss: 0.4154744856059551, metric: 45.68484449386597, lr: 0.0009776754304766655
[26120] train loss: 2.4331943094730377, metric: 26.06192398071289, lr: 0.0009674003813415766
[26140] train loss: 0.9204122796654701, metric: 28.057762145996094, lr: 0.0009552621049806476
[26160] train loss: 1.00501399487257, metric: 28.15832805633545, lr: 0.0009413089719600976
[26180] train loss: 2.566531628370285, metric: 25.119662761688232, lr: 0.0009255966870114207
[26200] train loss: 1.6730228811502457, metric: 36.11514711380005, lr: 0.00090818788157776
[26220] train loss: 1.447277083992958, metric: 32.581299781799316, lr: 0.0008891518809832633
[26240] train loss: 0.8410171717405319, metric: 33.070202350616455, lr: 0.0008685645880177617
[26260] train loss: 1.768551580607891, metric: 39.28612804412842, lr: 0.0008465081336908042
[26280] train loss: 1.2252607867121696, metric: 36.628567695617676, lr: 0.0008230703533627093
[26300] train loss: 0.8858842775225639, metric: 39.1238169670105, lr: 0.0007983447285369039
[26320] train loss: 1.1856525391340256, metric: 44.206252098083496, lr: 0.0007724298629909754
[26340] train loss: 1.7519940286874771, metric: 37.16495990753174, lr: 0.0007454289589077234
[26360] train loss: 0.8379426971077919, metric: 33.41587686538696, lr: 0.0007174497004598379
[26380] train loss: 0.8310238793492317, metric: 42.79184341430664, lr: 0.00068860367173329
[26400] train loss: 3.674080051481724, metric: 47.00824737548828, lr: 0.0006590057746507227
[26420] train loss: 1.426393836736679, metric: 44.22766590118408, lr: 0.0006287740543484688
[26440] train loss: 1.6856169924139977, metric: 41.84916877746582, lr: 0.000598029000684619
[26460] train loss: 1.093530111014843, metric: 39.39705181121826, lr: 0.0005668931407853961
[26480] train loss: 1.011037327349186, metric: 38.853179931640625, lr: 0.0005354906315915287
[26500] train loss: 1.5550620034337044, metric: 39.03030204772949, lr: 0.0005039466777816415
[26520] train loss: 0.6042197458446026, metric: 37.383878231048584, lr: 0.0004723869787994772
[26540] train loss: 0.6956948935985565, metric: 36.16718864440918, lr: 0.0004409373505041003
[26560] train loss: 0.6486909613013268, metric: 35.079026222229004, lr: 0.0004097231721971184
[26580] train loss: 0.5131759867072105, metric: 31.31972312927246, lr: 0.000378868862753734
[26600] train loss: 0.7733574211597443, metric: 40.07081604003906, lr: 0.00034849741496145725
[26620] train loss: 1.0254308730363846, metric: 50.55636978149414, lr: 0.0003187299007549882
[26640] train loss: 5.151594452559948, metric: 44.8690710067749, lr: 0.0002896849764510989
[26660] train loss: 6.448954537510872, metric: 43.355196475982666, lr: 0.0002614784170873463
[26680] train loss: 1.5029379576444626, metric: 37.96629524230957, lr: 0.00023422270896844566
[26700] train loss: 0.9342560842633247, metric: 37.372952461242676, lr: 0.00020802643848583102
[26720] train loss: 2.2825973853468895, metric: 36.62233638763428, lr: 0.00018299407383892685
[26740] train loss: 1.5344925858080387, metric: 33.07477569580078, lr: 0.00015922538295853883
[26760] train loss: 6.379477985203266, metric: 35.8020281791687, lr: 0.00013681512791663408
[26780] train loss: 0.6724179461598396, metric: 33.01940441131592, lr: 0.00011585262109292671
[26800] train loss: 0.8336509354412556, metric: 34.0338454246521, lr: 9.999999747378752e-05
[26820] train loss: 1.697383552789688, metric: 36.42510795593262, lr: 9.999999747378752e-05
[26840] train loss: 1.9810525700449944, metric: 42.04825782775879, lr: 9.999999747378752e-05
[26860] train loss: 2.617895271629095, metric: 37.9927339553833, lr: 9.999999747378752e-05
[26880] train loss: 0.7611084096133709, metric: 37.64671325683594, lr: 9.999999747378752e-05
[26900] train loss: 1.1246663331985474, metric: 31.94361639022827, lr: 9.999999747378752e-05
[26920] train loss: 6.716908365488052, metric: 38.207642555236816, lr: 9.999999747378752e-05
[26940] train loss: 7.393284723162651, metric: 46.22395706176758, lr: 9.999999747378752e-05
[26960] train loss: 15.99781684577465, metric: 43.98821449279785, lr: 9.999999747378752e-05
[26980] train loss: 1.474784292280674, metric: 34.94245004653931, lr: 9.999999747378752e-05
[27000] train loss: 0.8117901273071766, metric: 34.604976654052734, lr: 9.999999747378752e-05
[27020] train loss: 0.6995743364095688, metric: 33.59354257583618, lr: 0.0009994393913075328
[27040] train loss: 4.07187956571579, metric: 37.460280418395996, lr: 0.0009969500824809074
[27060] train loss: 18.124452777206898, metric: 47.40511512756348, lr: 0.000992479850538075
[27080] train loss: 4.0369202345609665, metric: 43.52284622192383, lr: 0.000986046390607953
[27100] train loss: 1.584482405334711, metric: 39.58294677734375, lr: 0.0009776754304766655
[27120] train loss: 0.9859080091118813, metric: 47.07919692993164, lr: 0.0009674003813415766
[27140] train loss: 4.794676974415779, metric: 47.060603618621826, lr: 0.0009552621049806476
[27160] train loss: 5.20474948734045, metric: 47.92443227767944, lr: 0.0009413089719600976
[27180] train loss: 4.646064713597298, metric: 56.73599052429199, lr: 0.0009255966870114207
[27200] train loss: 1.5190296471118927, metric: 55.81995964050293, lr: 0.00090818788157776
[27220] train loss: 1.8803832903504372, metric: 53.12576675415039, lr: 0.0008891518809832633
[27240] train loss: 1.3332534953951836, metric: 55.979949951171875, lr: 0.0008685645880177617
[27260] train loss: 0.9366994500160217, metric: 56.63247489929199, lr: 0.0008465081336908042
[27280] train loss: 1.0241472497582436, metric: 49.798563957214355, lr: 0.0008230703533627093
[27300] train loss: 1.250404067337513, metric: 52.02221870422363, lr: 0.0007983447285369039
[27320] train loss: 1.049102321267128, metric: 47.30300045013428, lr: 0.0007724298629909754
[27340] train loss: 0.6628267467021942, metric: 45.72972822189331, lr: 0.0007454289589077234
[27360] train loss: 0.6152130290865898, metric: 44.42774486541748, lr: 0.0007174497004598379
[27380] train loss: 0.38277118653059006, metric: 46.11424255371094, lr: 0.00068860367173329
[27400] train loss: 0.49619296193122864, metric: 49.72270393371582, lr: 0.0006590057746507227
[27420] train loss: 0.5708195604383945, metric: 48.26237678527832, lr: 0.0006287740543484688
[27440] train loss: 0.5922228917479515, metric: 52.81414222717285, lr: 0.000598029000684619
[27460] train loss: 1.251500803977251, metric: 53.540283203125, lr: 0.0005668931407853961
[27480] train loss: 4.58880877494812, metric: 56.05207443237305, lr: 0.0005354906315915287
[27500] train loss: 2.458924263715744, metric: 54.65005588531494, lr: 0.0005039466777816415
[27520] train loss: 0.9951762109994888, metric: 51.65828037261963, lr: 0.0004723869787994772
[27540] train loss: 0.5593523010611534, metric: 56.71382522583008, lr: 0.0004409373505041003
[27560] train loss: 0.5140918716788292, metric: 52.01075267791748, lr: 0.0004097231721971184
[27580] train loss: 0.5301816239953041, metric: 51.46855545043945, lr: 0.000378868862753734
[27600] train loss: 0.8372273445129395, metric: 49.37378215789795, lr: 0.00034849741496145725
[27620] train loss: 0.7246869839727879, metric: 51.6667423248291, lr: 0.0003187299007549882
[27640] train loss: 0.7049206867814064, metric: 49.301748275756836, lr: 0.0002896849764510989
[27660] train loss: 1.8493221700191498, metric: 37.637118339538574, lr: 0.0002614784170873463
[27680] train loss: 3.2965482771396637, metric: 35.360875606536865, lr: 0.00023422270896844566
[27700] train loss: 6.123094856739044, metric: 39.141557693481445, lr: 0.00020802643848583102
[27720] train loss: 1.6600432991981506, metric: 33.83820390701294, lr: 0.00018299407383892685
[27740] train loss: 3.961140960454941, metric: 41.38507604598999, lr: 0.00015922538295853883
[27760] train loss: 4.889016091823578, metric: 34.7090482711792, lr: 0.00013681512791663408
[27780] train loss: 1.670650452375412, metric: 38.140221118927, lr: 0.00011585262109292671
[27800] train loss: 1.777812898159027, metric: 38.91451358795166, lr: 9.999999747378752e-05
[27820] train loss: 2.0809646248817444, metric: 35.686670780181885, lr: 9.999999747378752e-05
[27840] train loss: 3.0805849879980087, metric: 35.87333059310913, lr: 9.999999747378752e-05
[27860] train loss: 3.0180433690547943, metric: 36.33989191055298, lr: 9.999999747378752e-05
[27880] train loss: 3.741582214832306, metric: 39.74980545043945, lr: 9.999999747378752e-05
[27900] train loss: 2.1817697286605835, metric: 40.85688495635986, lr: 9.999999747378752e-05
[27920] train loss: 2.64416666328907, metric: 38.70778751373291, lr: 9.999999747378752e-05
[27940] train loss: 4.848716095089912, metric: 37.527599811553955, lr: 9.999999747378752e-05
[27960] train loss: 3.257155977189541, metric: 37.1946816444397, lr: 9.999999747378752e-05
[27980] train loss: 1.987910307943821, metric: 37.84756326675415, lr: 9.999999747378752e-05
[28000] train loss: 1.445208102464676, metric: 37.58391809463501, lr: 9.999999747378752e-05
[28020] train loss: 0.8210433125495911, metric: 35.98785877227783, lr: 0.0009994393913075328
[28040] train loss: 0.9579677507281303, metric: 39.24474811553955, lr: 0.0009969500824809074
[28060] train loss: 1.531163640320301, metric: 34.96420335769653, lr: 0.000992479850538075
[28080] train loss: 1.2596058249473572, metric: 32.68939733505249, lr: 0.000986046390607953
[28100] train loss: 2.7146382182836533, metric: 35.18233585357666, lr: 0.0009776754304766655
[28120] train loss: 1.0924988016486168, metric: 30.041083335876465, lr: 0.0009674003813415766
[28140] train loss: 1.0601842552423477, metric: 40.21880340576172, lr: 0.0009552621049806476
[28160] train loss: 1.083421215415001, metric: 31.88822078704834, lr: 0.0009413089719600976
[28180] train loss: 7.53645658493042, metric: 34.5869824886322, lr: 0.0009255966870114207
[28200] train loss: 2.4338616132736206, metric: 45.62006378173828, lr: 0.00090818788157776
[28220] train loss: 2.643278419971466, metric: 39.107746601104736, lr: 0.0008891518809832633
[28240] train loss: 1.6988690793514252, metric: 36.42570161819458, lr: 0.0008685645880177617
[28260] train loss: 5.2358421087265015, metric: 43.47623157501221, lr: 0.0008465081336908042
[28280] train loss: 0.9901623427867889, metric: 54.16838455200195, lr: 0.0008230703533627093
[28300] train loss: 0.8453614115715027, metric: 49.023216247558594, lr: 0.0007983447285369039
[28320] train loss: 0.6824585795402527, metric: 44.53050518035889, lr: 0.0007724298629909754
[28340] train loss: 0.8372992128133774, metric: 41.72291278839111, lr: 0.0007454289589077234
[28360] train loss: 2.3269982635974884, metric: 41.62899446487427, lr: 0.0007174497004598379
[28380] train loss: 0.9822394251823425, metric: 35.36897897720337, lr: 0.00068860367173329
[28400] train loss: 1.5299992933869362, metric: 31.945727348327637, lr: 0.0006590057746507227
[28420] train loss: 1.0088011622428894, metric: 33.68220520019531, lr: 0.0006287740543484688
[28440] train loss: 0.5598849207162857, metric: 35.912360191345215, lr: 0.000598029000684619
[28460] train loss: 0.7706034705042839, metric: 34.6623969078064, lr: 0.0005668931407853961
[28480] train loss: 0.6080604121088982, metric: 39.59816646575928, lr: 0.0005354906315915287
[28500] train loss: 1.1694604232907295, metric: 38.42431926727295, lr: 0.0005039466777816415
[28520] train loss: 1.7580883353948593, metric: 38.55490159988403, lr: 0.0004723869787994772
[28540] train loss: 0.7188839390873909, metric: 39.27364110946655, lr: 0.0004409373505041003
[28560] train loss: 2.469731643795967, metric: 40.855863094329834, lr: 0.0004097231721971184
[28580] train loss: 1.8900718986988068, metric: 36.38770818710327, lr: 0.000378868862753734
[28600] train loss: 2.2710936665534973, metric: 38.755446434020996, lr: 0.00034849741496145725
[28620] train loss: 4.379461869597435, metric: 34.23287773132324, lr: 0.0003187299007549882
[28640] train loss: 4.829507976770401, metric: 44.38912010192871, lr: 0.0002896849764510989
[28660] train loss: 6.912419468164444, metric: 46.29044818878174, lr: 0.0002614784170873463
[28680] train loss: 3.7473531663417816, metric: 39.139163970947266, lr: 0.00023422270896844566
[28700] train loss: 1.7862470000982285, metric: 35.25663089752197, lr: 0.00020802643848583102
[28720] train loss: 1.4369482100009918, metric: 34.42385816574097, lr: 0.00018299407383892685
[28740] train loss: 1.0728080570697784, metric: 36.6130313873291, lr: 0.00015922538295853883
[28760] train loss: 0.9189526289701462, metric: 34.00142288208008, lr: 0.00013681512791663408
[28780] train loss: 0.7287535220384598, metric: 36.57466983795166, lr: 0.00011585262109292671
[28800] train loss: 0.8256762847304344, metric: 36.86416578292847, lr: 9.999999747378752e-05
[28820] train loss: 0.9697628021240234, metric: 33.8451247215271, lr: 9.999999747378752e-05
[28840] train loss: 0.9476185142993927, metric: 36.0749077796936, lr: 9.999999747378752e-05
[28860] train loss: 0.864835575222969, metric: 36.93113470077515, lr: 9.999999747378752e-05
[28880] train loss: 2.0355534702539444, metric: 38.60126972198486, lr: 9.999999747378752e-05
[28900] train loss: 1.567092701792717, metric: 42.52059459686279, lr: 9.999999747378752e-05
[28920] train loss: 7.505766570568085, metric: 45.96224498748779, lr: 9.999999747378752e-05
[28940] train loss: 3.5538912415504456, metric: 51.33147954940796, lr: 9.999999747378752e-05
[28960] train loss: 2.39969589561224, metric: 52.157212257385254, lr: 9.999999747378752e-05
[28980] train loss: 2.5300779044628143, metric: 47.046470642089844, lr: 9.999999747378752e-05
[29000] train loss: 2.2174475267529488, metric: 49.36462116241455, lr: 9.999999747378752e-05
[29020] train loss: 1.0509288161993027, metric: 50.043843269348145, lr: 0.0009994393913075328
[29040] train loss: 0.8706805631518364, metric: 56.39646053314209, lr: 0.0009969500824809074
[29060] train loss: 0.6145092993974686, metric: 56.694942474365234, lr: 0.000992479850538075
[29080] train loss: 1.2795822322368622, metric: 52.02781105041504, lr: 0.000986046390607953
[29100] train loss: 0.9552856013178825, metric: 45.2886266708374, lr: 0.0009776754304766655
[29120] train loss: 0.712895579636097, metric: 33.663737297058105, lr: 0.0009674003813415766
[29140] train loss: 0.8592214807868004, metric: 36.0421199798584, lr: 0.0009552621049806476
[29160] train loss: 0.8482511527836323, metric: 38.189454078674316, lr: 0.0009413089719600976
[29180] train loss: 0.5500256530940533, metric: 32.52732992172241, lr: 0.0009255966870114207
[29200] train loss: 0.45291101932525635, metric: 64.60864543914795, lr: 0.00090818788157776
[29220] train loss: 0.3636535629630089, metric: 51.5465784072876, lr: 0.0008891518809832633
[29240] train loss: 0.34772730991244316, metric: 52.384490966796875, lr: 0.0008685645880177617
[29260] train loss: 0.38334525376558304, metric: 52.56920528411865, lr: 0.0008465081336908042
[29280] train loss: 0.38034578412771225, metric: 50.759846687316895, lr: 0.0008230703533627093
[29300] train loss: 0.28167540580034256, metric: 51.03977966308594, lr: 0.0007983447285369039
[29320] train loss: 0.26624860242009163, metric: 49.667418479919434, lr: 0.0007724298629909754
[29340] train loss: 0.7499686852097511, metric: 49.6893949508667, lr: 0.0007454289589077234
[29360] train loss: 0.4977652467787266, metric: 48.08792972564697, lr: 0.0007174497004598379
[29380] train loss: 0.7121551595628262, metric: 48.773919105529785, lr: 0.00068860367173329
[29400] train loss: 0.6048231273889542, metric: 47.69642353057861, lr: 0.0006590057746507227
[29420] train loss: 0.8894698955118656, metric: 49.27157783508301, lr: 0.0006287740543484688
[29440] train loss: 0.9924461394548416, metric: 46.75129985809326, lr: 0.000598029000684619
[29460] train loss: 1.433301791548729, metric: 47.53567695617676, lr: 0.0005668931407853961
[29480] train loss: 0.9871037378907204, metric: 48.973989486694336, lr: 0.0005354906315915287
[29500] train loss: 0.4349938817322254, metric: 48.29085731506348, lr: 0.0005039466777816415
[29520] train loss: 0.5320508107542992, metric: 52.54003429412842, lr: 0.0004723869787994772
[29540] train loss: 0.3931427001953125, metric: 48.60002899169922, lr: 0.0004409373505041003
[29560] train loss: 1.1768216378986835, metric: 47.768296241760254, lr: 0.0004097231721971184
[29580] train loss: 0.9085779637098312, metric: 48.392181396484375, lr: 0.000378868862753734
[29600] train loss: 0.610587865114212, metric: 46.646780014038086, lr: 0.00034849741496145725
[29620] train loss: 0.7656040787696838, metric: 50.13060522079468, lr: 0.0003187299007549882
[29640] train loss: 0.961116686463356, metric: 50.6855993270874, lr: 0.0002896849764510989
[29660] train loss: 3.2997353225946426, metric: 46.65004062652588, lr: 0.0002614784170873463
[29680] train loss: 2.952375426888466, metric: 55.65358352661133, lr: 0.00023422270896844566
[29700] train loss: 2.3380557149648666, metric: 35.83615016937256, lr: 0.00020802643848583102
[29720] train loss: 1.4590104967355728, metric: 37.602885723114014, lr: 0.00018299407383892685
[29740] train loss: 1.6182909905910492, metric: 39.19822025299072, lr: 0.00015922538295853883
[29760] train loss: 0.7878197580575943, metric: 39.388808727264404, lr: 0.00013681512791663408
[29780] train loss: 0.925422877073288, metric: 40.486215114593506, lr: 0.00011585262109292671
[29800] train loss: 1.5001281201839447, metric: 42.467164039611816, lr: 9.999999747378752e-05
[29820] train loss: 1.7719658315181732, metric: 42.51901817321777, lr: 9.999999747378752e-05
[29840] train loss: 1.421593576669693, metric: 41.42713499069214, lr: 9.999999747378752e-05
[29860] train loss: 1.443505272269249, metric: 43.42596244812012, lr: 9.999999747378752e-05
[29880] train loss: 1.2781089693307877, metric: 37.33164882659912, lr: 9.999999747378752e-05
[29900] train loss: 0.9016614258289337, metric: 37.08671426773071, lr: 9.999999747378752e-05
[29920] train loss: 1.225670963525772, metric: 31.489756107330322, lr: 9.999999747378752e-05
[29940] train loss: 1.5049484372138977, metric: 35.134427070617676, lr: 9.999999747378752e-05
[29960] train loss: 0.7716445103287697, metric: 40.78819179534912, lr: 9.999999747378752e-05
[29980] train loss: 0.6782813146710396, metric: 42.66014003753662, lr: 9.999999747378752e-05
[30000] train loss: 0.7997221350669861, metric: 43.24900817871094, lr: 9.999999747378752e-05
[30020] train loss: 0.40188267081975937, metric: 35.71509552001953, lr: 0.0009994393913075328
[30040] train loss: 0.7570912465453148, metric: 31.537014961242676, lr: 0.0009969500824809074
[30060] train loss: 0.46628376096487045, metric: 30.736977100372314, lr: 0.000992479850538075
[30080] train loss: 0.6096379980444908, metric: 28.236751556396484, lr: 0.000986046390607953
[30100] train loss: 0.4877215027809143, metric: 30.06059980392456, lr: 0.0009776754304766655
[30120] train loss: 0.5338115394115448, metric: 31.19212770462036, lr: 0.0009674003813415766
[30140] train loss: 1.1888499781489372, metric: 27.62410068511963, lr: 0.0009552621049806476
[30160] train loss: 0.7724848762154579, metric: 26.63384771347046, lr: 0.0009413089719600976
[30180] train loss: 0.7531406059861183, metric: 31.752020359039307, lr: 0.0009255966870114207
[30200] train loss: 0.6216603443026543, metric: 31.274199962615967, lr: 0.00090818788157776
[30220] train loss: 1.7473469078540802, metric: 27.033594131469727, lr: 0.0008891518809832633
[30240] train loss: 2.1972586438059807, metric: 32.33671522140503, lr: 0.0008685645880177617
[30260] train loss: 7.594129756093025, metric: 34.50027894973755, lr: 0.0008465081336908042
[30280] train loss: 3.070542633533478, metric: 43.53113508224487, lr: 0.0008230703533627093
[30300] train loss: 0.9552524238824844, metric: 54.90087032318115, lr: 0.0007983447285369039
[30320] train loss: 0.7553375363349915, metric: 44.85767459869385, lr: 0.0007724298629909754
[30340] train loss: 0.6130880415439606, metric: 40.580573081970215, lr: 0.0007454289589077234
[30360] train loss: 0.5242631658911705, metric: 37.26959753036499, lr: 0.0007174497004598379
[30380] train loss: 0.5445931479334831, metric: 38.458441734313965, lr: 0.00068860367173329
[30400] train loss: 0.4854709506034851, metric: 36.664724349975586, lr: 0.0006590057746507227
[30420] train loss: 0.6892181411385536, metric: 36.47567844390869, lr: 0.0006287740543484688
[30440] train loss: 0.599441509693861, metric: 35.56558132171631, lr: 0.000598029000684619
[30460] train loss: 0.6511509642004967, metric: 38.493858337402344, lr: 0.0005668931407853961
[30480] train loss: 0.6761912032961845, metric: 35.44915771484375, lr: 0.0005354906315915287
[30500] train loss: 0.9045469760894775, metric: 31.47614812850952, lr: 0.0005039466777816415
[30520] train loss: 2.5199758112430573, metric: 38.290772438049316, lr: 0.0004723869787994772
[30540] train loss: 1.93910151720047, metric: 32.29601192474365, lr: 0.0004409373505041003
[30560] train loss: 0.7390209287405014, metric: 35.04810953140259, lr: 0.0004097231721971184
[30580] train loss: 1.5408935546875, metric: 36.80192756652832, lr: 0.000378868862753734
[30600] train loss: 1.3111825585365295, metric: 34.63971471786499, lr: 0.00034849741496145725
[30620] train loss: 0.9104601219296455, metric: 33.603564739227295, lr: 0.0003187299007549882
[30640] train loss: 0.8027336448431015, metric: 40.609426498413086, lr: 0.0002896849764510989
[30660] train loss: 1.4578337371349335, metric: 40.02112817764282, lr: 0.0002614784170873463
[30680] train loss: 1.2235987335443497, metric: 39.998263359069824, lr: 0.00023422270896844566
[30700] train loss: 1.1287982612848282, metric: 37.26614284515381, lr: 0.00020802643848583102
[30720] train loss: 2.805242881178856, metric: 39.64448165893555, lr: 0.00018299407383892685
[30740] train loss: 1.110513374209404, metric: 49.66105651855469, lr: 0.00015922538295853883
[30760] train loss: 0.6551571264863014, metric: 54.45272922515869, lr: 0.00013681512791663408
[30780] train loss: 0.7804079949855804, metric: 56.990920543670654, lr: 0.00011585262109292671
[30800] train loss: 0.8778360784053802, metric: 52.49134540557861, lr: 9.999999747378752e-05
[30820] train loss: 0.5947440266609192, metric: 54.98199939727783, lr: 9.999999747378752e-05
[30840] train loss: 0.4492495208978653, metric: 51.926281452178955, lr: 9.999999747378752e-05
[30860] train loss: 0.4428805187344551, metric: 51.18425369262695, lr: 9.999999747378752e-05
[30880] train loss: 0.5819357074797153, metric: 51.85441493988037, lr: 9.999999747378752e-05
[30900] train loss: 0.47710319980978966, metric: 53.13532257080078, lr: 9.999999747378752e-05
[30920] train loss: 0.33818867430090904, metric: 53.1932954788208, lr: 9.999999747378752e-05
[30940] train loss: 0.2504927068948746, metric: 53.98406410217285, lr: 9.999999747378752e-05
[30960] train loss: 0.24442075192928314, metric: 54.19871997833252, lr: 9.999999747378752e-05
[30980] train loss: 0.2656891979277134, metric: 54.149606704711914, lr: 9.999999747378752e-05
[31000] train loss: 0.32065072655677795, metric: 55.837371826171875, lr: 9.999999747378752e-05
[31020] train loss: 0.3945707269012928, metric: 57.645601749420166, lr: 0.0009994393913075328
[31040] train loss: 0.32053177431225777, metric: 60.522647857666016, lr: 0.0009969500824809074
[31060] train loss: 0.3541407100856304, metric: 61.47378921508789, lr: 0.000992479850538075
[31080] train loss: 0.273618470877409, metric: 56.44785499572754, lr: 0.000986046390607953
[31100] train loss: 0.3464301787316799, metric: 59.22363758087158, lr: 0.0009776754304766655
[31120] train loss: 0.26376793161034584, metric: 62.03147792816162, lr: 0.0009674003813415766
[31140] train loss: 0.2666451632976532, metric: 64.22976970672607, lr: 0.0009552621049806476
[31160] train loss: 0.3248063586652279, metric: 61.085726737976074, lr: 0.0009413089719600976
[31180] train loss: 0.494422797113657, metric: 63.59708309173584, lr: 0.0009255966870114207
[31200] train loss: 0.5470757856965065, metric: 59.563050270080566, lr: 0.00090818788157776
[31220] train loss: 0.3306765481829643, metric: 57.69813060760498, lr: 0.0008891518809832633
[31240] train loss: 3.532501682639122, metric: 53.62986469268799, lr: 0.0008685645880177617
[31260] train loss: 1.1783075034618378, metric: 37.67866611480713, lr: 0.0008465081336908042
[31280] train loss: 0.40910180658102036, metric: 44.475451946258545, lr: 0.0008230703533627093
[31300] train loss: 0.8986134119331837, metric: 43.03997325897217, lr: 0.0007983447285369039
[31320] train loss: 0.6691819950938225, metric: 50.56406879425049, lr: 0.0007724298629909754
[31340] train loss: 0.4317391403019428, metric: 36.9785852432251, lr: 0.0007454289589077234
[31360] train loss: 0.4621497169137001, metric: 38.035489559173584, lr: 0.0007174497004598379
[31380] train loss: 0.6196010932326317, metric: 34.50698375701904, lr: 0.00068860367173329
[31400] train loss: 0.3993196412920952, metric: 36.522873878479004, lr: 0.0006590057746507227
[31420] train loss: 0.45105747878551483, metric: 39.5328254699707, lr: 0.0006287740543484688
[31440] train loss: 0.8753597810864449, metric: 39.96451663970947, lr: 0.000598029000684619
[31460] train loss: 1.0135543942451477, metric: 46.33230972290039, lr: 0.0005668931407853961
[31480] train loss: 0.6221451982855797, metric: 43.655555725097656, lr: 0.0005354906315915287
[31500] train loss: 0.7364037819206715, metric: 40.93364095687866, lr: 0.0005039466777816415
[31520] train loss: 0.8830442279577255, metric: 39.41524934768677, lr: 0.0004723869787994772
[31540] train loss: 0.9443135522305965, metric: 39.39588451385498, lr: 0.0004409373505041003
[31560] train loss: 0.689710795879364, metric: 37.80956983566284, lr: 0.0004097231721971184
[31580] train loss: 0.5046961046755314, metric: 37.84746837615967, lr: 0.000378868862753734
[31600] train loss: 0.40715475380420685, metric: 43.563982009887695, lr: 0.00034849741496145725
[31620] train loss: 0.34555625170469284, metric: 39.35318946838379, lr: 0.0003187299007549882
[31640] train loss: 0.3408597633242607, metric: 36.5639214515686, lr: 0.0002896849764510989
[31660] train loss: 0.28943029791116714, metric: 39.67716932296753, lr: 0.0002614784170873463
[31680] train loss: 0.2242681421339512, metric: 44.60937976837158, lr: 0.00023422270896844566
[31700] train loss: 0.2885177992284298, metric: 44.52800178527832, lr: 0.00020802643848583102
[31720] train loss: 0.3451182655990124, metric: 45.31003713607788, lr: 0.00018299407383892685
[31740] train loss: 0.42039408162236214, metric: 43.848443031311035, lr: 0.00015922538295853883
[31760] train loss: 1.3920214101672173, metric: 34.67785167694092, lr: 0.00013681512791663408
[31780] train loss: 1.1355774477124214, metric: 35.73245358467102, lr: 0.00011585262109292671
[31800] train loss: 0.8575535044074059, metric: 36.81630849838257, lr: 9.999999747378752e-05
[31820] train loss: 0.9026636257767677, metric: 40.77946472167969, lr: 9.999999747378752e-05
[31840] train loss: 0.7681001648306847, metric: 40.85065412521362, lr: 9.999999747378752e-05
[31860] train loss: 2.317769207060337, metric: 46.61181926727295, lr: 9.999999747378752e-05
[31880] train loss: 1.1141558066010475, metric: 44.7290301322937, lr: 9.999999747378752e-05
[31900] train loss: 1.096422240138054, metric: 47.9564151763916, lr: 9.999999747378752e-05
[31920] train loss: 1.1025421023368835, metric: 48.254332542419434, lr: 9.999999747378752e-05
[31940] train loss: 0.878952257335186, metric: 47.31330680847168, lr: 9.999999747378752e-05
[31960] train loss: 1.1737509369850159, metric: 43.758216857910156, lr: 9.999999747378752e-05
[31980] train loss: 10.882814094424248, metric: 55.38980293273926, lr: 9.999999747378752e-05
[32000] train loss: 7.2939823269844055, metric: 56.80009746551514, lr: 9.999999747378752e-05
[32020] train loss: 1.55314239859581, metric: 53.89343070983887, lr: 0.0009994393913075328
[32040] train loss: 0.6715506985783577, metric: 48.062886238098145, lr: 0.0009969500824809074
[32060] train loss: 0.3494494929909706, metric: 43.12738227844238, lr: 0.000992479850538075
[32080] train loss: 1.0990038812160492, metric: 42.44044017791748, lr: 0.000986046390607953
[32100] train loss: 1.0303229540586472, metric: 45.627100467681885, lr: 0.0009776754304766655
[32120] train loss: 1.2857258841395378, metric: 50.52665901184082, lr: 0.0009674003813415766
[32140] train loss: 1.963793806731701, metric: 48.408246994018555, lr: 0.0009552621049806476
[32160] train loss: 0.5181172266602516, metric: 50.71883773803711, lr: 0.0009413089719600976
[32180] train loss: 0.4668230973184109, metric: 46.250929832458496, lr: 0.0009255966870114207
[32200] train loss: 0.4819648116827011, metric: 48.18312358856201, lr: 0.00090818788157776
[32220] train loss: 0.3942790701985359, metric: 46.11112594604492, lr: 0.0008891518809832633
[32240] train loss: 0.26053037494421005, metric: 46.61488723754883, lr: 0.0008685645880177617
[32260] train loss: 1.890600174665451, metric: 48.87648296356201, lr: 0.0008465081336908042
[32280] train loss: 0.5939325243234634, metric: 45.01516151428223, lr: 0.0008230703533627093
[32300] train loss: 0.7632679492235184, metric: 45.11696434020996, lr: 0.0007983447285369039
[32320] train loss: 0.4437427595257759, metric: 45.52462387084961, lr: 0.0007724298629909754
[32340] train loss: 0.48603200167417526, metric: 44.96858024597168, lr: 0.0007454289589077234
[32360] train loss: 0.277206864207983, metric: 44.56072759628296, lr: 0.0007174497004598379
[32380] train loss: 0.6421893462538719, metric: 40.70660662651062, lr: 0.00068860367173329
[32400] train loss: 0.8321082293987274, metric: 46.589412689208984, lr: 0.0006590057746507227
[32420] train loss: 0.5295390635728836, metric: 47.009936809539795, lr: 0.0006287740543484688
[32440] train loss: 0.44401781260967255, metric: 46.88735866546631, lr: 0.000598029000684619
[32460] train loss: 0.7025679647922516, metric: 44.21585488319397, lr: 0.0005668931407853961
[32480] train loss: 1.578216329216957, metric: 48.638976097106934, lr: 0.0005354906315915287
[32500] train loss: 2.749895729124546, metric: 50.42273807525635, lr: 0.0005039466777816415
[32520] train loss: 1.6307469010353088, metric: 53.80079936981201, lr: 0.0004723869787994772
[32540] train loss: 1.018686681985855, metric: 46.981911182403564, lr: 0.0004409373505041003
[32560] train loss: 0.5955932438373566, metric: 49.81646728515625, lr: 0.0004097231721971184
[32580] train loss: 1.1186660528182983, metric: 45.133058071136475, lr: 0.000378868862753734
[32600] train loss: 0.8418242931365967, metric: 42.66229963302612, lr: 0.00034849741496145725
[32620] train loss: 0.490340456366539, metric: 42.096420764923096, lr: 0.0003187299007549882
[32640] train loss: 0.5203568451106548, metric: 39.33851146697998, lr: 0.0002896849764510989
[32660] train loss: 0.4558744505047798, metric: 39.165263175964355, lr: 0.0002614784170873463
[32680] train loss: 0.854448601603508, metric: 41.2541708946228, lr: 0.00023422270896844566
[32700] train loss: 1.768301784992218, metric: 41.78582191467285, lr: 0.00020802643848583102
[32720] train loss: 1.224522404372692, metric: 50.353169441223145, lr: 0.00018299407383892685
[32740] train loss: 1.2509859129786491, metric: 48.25837516784668, lr: 0.00015922538295853883
[32760] train loss: 0.884718731045723, metric: 45.432475090026855, lr: 0.00013681512791663408
[32780] train loss: 9.13401910662651, metric: 49.00895595550537, lr: 0.00011585262109292671
[32800] train loss: 5.333790421485901, metric: 47.32100772857666, lr: 9.999999747378752e-05
[32820] train loss: 2.140190467238426, metric: 45.1213903427124, lr: 9.999999747378752e-05
[32840] train loss: 1.646507814526558, metric: 49.23306751251221, lr: 9.999999747378752e-05
[32860] train loss: 1.4349325150251389, metric: 52.86839199066162, lr: 9.999999747378752e-05
[32880] train loss: 1.7623834162950516, metric: 56.521446228027344, lr: 9.999999747378752e-05
[32900] train loss: 1.128941297531128, metric: 50.8023796081543, lr: 9.999999747378752e-05
[32920] train loss: 1.7752716839313507, metric: 46.41261100769043, lr: 9.999999747378752e-05
[32940] train loss: 1.9686478078365326, metric: 50.24322509765625, lr: 9.999999747378752e-05
[32960] train loss: 1.9627775251865387, metric: 49.70309352874756, lr: 9.999999747378752e-05
[32980] train loss: 2.6423101723194122, metric: 53.155213356018066, lr: 9.999999747378752e-05
[33000] train loss: 3.1075693666934967, metric: 56.30114221572876, lr: 9.999999747378752e-05
[33020] train loss: 1.7311903908848763, metric: 42.010719776153564, lr: 0.0009994393913075328
[33040] train loss: 1.1858724653720856, metric: 45.20068979263306, lr: 0.0009969500824809074
[33060] train loss: 1.0404739677906036, metric: 47.930434226989746, lr: 0.000992479850538075
[33080] train loss: 4.3533089607954025, metric: 47.24407148361206, lr: 0.000986046390607953
[33100] train loss: 0.8802935183048248, metric: 44.93773555755615, lr: 0.0009776754304766655
[33120] train loss: 0.6289981044828892, metric: 49.139596939086914, lr: 0.0009674003813415766
[33140] train loss: 0.5874198079109192, metric: 42.255849838256836, lr: 0.0009552621049806476
[33160] train loss: 0.5206029415130615, metric: 44.786864280700684, lr: 0.0009413089719600976
[33180] train loss: 0.8572613447904587, metric: 42.81959676742554, lr: 0.0009255966870114207
[33200] train loss: 0.8947164416313171, metric: 41.989718437194824, lr: 0.00090818788157776
[33220] train loss: 0.6285179369151592, metric: 40.71460819244385, lr: 0.0008891518809832633
[33240] train loss: 0.4743560068309307, metric: 41.72525119781494, lr: 0.0008685645880177617
[33260] train loss: 0.4802074581384659, metric: 42.64203882217407, lr: 0.0008465081336908042
[33280] train loss: 0.6639143973588943, metric: 42.244060754776, lr: 0.0008230703533627093
[33300] train loss: 8.421276830136776, metric: 59.64281368255615, lr: 0.0007983447285369039
[33320] train loss: 0.82673279941082, metric: 56.986510276794434, lr: 0.0007724298629909754
[33340] train loss: 0.7351837009191513, metric: 53.55221939086914, lr: 0.0007454289589077234
[33360] train loss: 1.416256070137024, metric: 58.7103853225708, lr: 0.0007174497004598379
[33380] train loss: 0.848450556397438, metric: 56.32921123504639, lr: 0.00068860367173329
[33400] train loss: 0.5794942229986191, metric: 54.1260929107666, lr: 0.0006590057746507227
[33420] train loss: 0.8512401878833771, metric: 53.06352233886719, lr: 0.0006287740543484688
[33440] train loss: 0.802475955337286, metric: 53.42802333831787, lr: 0.000598029000684619
[33460] train loss: 1.3719759695231915, metric: 52.26682472229004, lr: 0.0005668931407853961
[33480] train loss: 1.4347740858793259, metric: 51.61519145965576, lr: 0.0005354906315915287
[33500] train loss: 2.2818879187107086, metric: 49.65846252441406, lr: 0.0005039466777816415
[33520] train loss: 0.8633063063025475, metric: 48.94449996948242, lr: 0.0004723869787994772
[33540] train loss: 0.8754981309175491, metric: 52.0650520324707, lr: 0.0004409373505041003
[33560] train loss: 0.744750764220953, metric: 55.117547035217285, lr: 0.0004097231721971184
[33580] train loss: 0.49050605297088623, metric: 55.4741644859314, lr: 0.000378868862753734
[33600] train loss: 0.6481015756726265, metric: 53.95121669769287, lr: 0.00034849741496145725
[33620] train loss: 0.6031734347343445, metric: 53.09115982055664, lr: 0.0003187299007549882
[33640] train loss: 1.2961129695177078, metric: 54.76216793060303, lr: 0.0002896849764510989
[33660] train loss: 1.0496828630566597, metric: 58.178945541381836, lr: 0.0002614784170873463
[33680] train loss: 1.120168775320053, metric: 61.028987884521484, lr: 0.00023422270896844566
[33700] train loss: 4.446910806000233, metric: 59.571624755859375, lr: 0.00020802643848583102
[33720] train loss: 5.491740547120571, metric: 70.03557777404785, lr: 0.00018299407383892685
[33740] train loss: 4.693329393863678, metric: 73.36470413208008, lr: 0.00015922538295853883
[33760] train loss: 1.0960687324404716, metric: 67.30465888977051, lr: 0.00013681512791663408
[33780] train loss: 2.312185414135456, metric: 69.14588165283203, lr: 0.00011585262109292671
[33800] train loss: 15.103755921125412, metric: 59.955599784851074, lr: 9.999999747378752e-05
[33820] train loss: 4.643926709890366, metric: 44.51923656463623, lr: 9.999999747378752e-05
[33840] train loss: 10.657905176281929, metric: 51.47142219543457, lr: 9.999999747378752e-05
[33860] train loss: 6.152502223849297, metric: 48.893874168395996, lr: 9.999999747378752e-05
[33880] train loss: 6.830630272626877, metric: 45.5250358581543, lr: 9.999999747378752e-05
[33900] train loss: 4.036236882209778, metric: 51.82169055938721, lr: 9.999999747378752e-05
[33920] train loss: 2.6664641350507736, metric: 51.144179344177246, lr: 9.999999747378752e-05
[33940] train loss: 1.8029131516814232, metric: 57.018110275268555, lr: 9.999999747378752e-05
[33960] train loss: 2.5713072270154953, metric: 65.3417797088623, lr: 9.999999747378752e-05
[33980] train loss: 3.542943760752678, metric: 54.98542499542236, lr: 9.999999747378752e-05
[34000] train loss: 2.9532623812556267, metric: 52.16091251373291, lr: 9.999999747378752e-05
[34020] train loss: 1.585973009467125, metric: 60.00626850128174, lr: 0.0009994393913075328
[34040] train loss: 3.735680691897869, metric: 70.7036304473877, lr: 0.0009969500824809074
[34060] train loss: 1.3434951826930046, metric: 60.38856029510498, lr: 0.000992479850538075
[34080] train loss: 2.610803171992302, metric: 53.206252098083496, lr: 0.000986046390607953
[34100] train loss: 2.2164749205112457, metric: 93.00206565856934, lr: 0.0009776754304766655
[34120] train loss: 1.985884740948677, metric: 42.57112121582031, lr: 0.0009674003813415766
[34140] train loss: 1.5662814527750015, metric: 45.0003719329834, lr: 0.0009552621049806476
[34160] train loss: 0.9248617216944695, metric: 41.7705774307251, lr: 0.0009413089719600976
[34180] train loss: 0.8342274054884911, metric: 36.51332187652588, lr: 0.0009255966870114207
[34200] train loss: 1.9185362458229065, metric: 30.909558296203613, lr: 0.00090818788157776
[34220] train loss: 0.6744003519415855, metric: 29.665708541870117, lr: 0.0008891518809832633
[34240] train loss: 0.9551254957914352, metric: 29.326159477233887, lr: 0.0008685645880177617
[34260] train loss: 3.5846795737743378, metric: 35.52374076843262, lr: 0.0008465081336908042
[34280] train loss: 1.0963219478726387, metric: 32.711870193481445, lr: 0.0008230703533627093
[34300] train loss: 5.247508630156517, metric: 48.94841814041138, lr: 0.0007983447285369039
[34320] train loss: 1.393033355474472, metric: 43.59450721740723, lr: 0.0007724298629909754
[34340] train loss: 0.8362169414758682, metric: 44.18324375152588, lr: 0.0007454289589077234
[34360] train loss: 0.5065400376915932, metric: 42.094632148742676, lr: 0.0007174497004598379
[34380] train loss: 0.6650649085640907, metric: 39.78936243057251, lr: 0.00068860367173329
[34400] train loss: 0.6965582892298698, metric: 42.865628242492676, lr: 0.0006590057746507227
[34420] train loss: 1.5128654316067696, metric: 44.418020248413086, lr: 0.0006287740543484688
[34440] train loss: 1.5785623863339424, metric: 49.969308853149414, lr: 0.000598029000684619
[34460] train loss: 1.4396205395460129, metric: 41.23362922668457, lr: 0.0005668931407853961
[34480] train loss: 1.4390056654810905, metric: 37.402721881866455, lr: 0.0005354906315915287
[34500] train loss: 0.9588197767734528, metric: 39.53156042098999, lr: 0.0005039466777816415
[34520] train loss: 1.2255827188491821, metric: 41.95588207244873, lr: 0.0004723869787994772
[34540] train loss: 2.491741359233856, metric: 38.98045253753662, lr: 0.0004409373505041003
[34560] train loss: 5.531591646373272, metric: 43.741621017456055, lr: 0.0004097231721971184
[34580] train loss: 1.8513293042778969, metric: 37.47582769393921, lr: 0.000378868862753734
[34600] train loss: 1.1799322292208672, metric: 40.23086881637573, lr: 0.00034849741496145725
[34620] train loss: 0.732871875166893, metric: 40.37278652191162, lr: 0.0003187299007549882
[34640] train loss: 0.8867817670106888, metric: 39.59661340713501, lr: 0.0002896849764510989
[34660] train loss: 0.5633842945098877, metric: 34.24253034591675, lr: 0.0002614784170873463
[34680] train loss: 1.6421715095639229, metric: 36.98781681060791, lr: 0.00023422270896844566
[34700] train loss: 4.850126527249813, metric: 41.5704984664917, lr: 0.00020802643848583102
[34720] train loss: 1.7543782070279121, metric: 36.06607437133789, lr: 0.00018299407383892685
[34740] train loss: 1.849433809518814, metric: 37.33804130554199, lr: 0.00015922538295853883
[34760] train loss: 1.6651674211025238, metric: 41.366695404052734, lr: 0.00013681512791663408
[34780] train loss: 2.4607005268335342, metric: 44.939109802246094, lr: 0.00011585262109292671
[34800] train loss: 1.3726762980222702, metric: 46.70831775665283, lr: 9.999999747378752e-05
[34820] train loss: 4.857401326298714, metric: 49.462666034698486, lr: 9.999999747378752e-05
[34840] train loss: 2.472059026360512, metric: 49.87031841278076, lr: 9.999999747378752e-05
[34860] train loss: 3.749507337808609, metric: 53.42128562927246, lr: 9.999999747378752e-05
[34880] train loss: 3.307212248444557, metric: 54.72908115386963, lr: 9.999999747378752e-05
[34900] train loss: 1.252186618745327, metric: 54.16043519973755, lr: 9.999999747378752e-05
[34920] train loss: 2.2439151257276535, metric: 54.03912925720215, lr: 9.999999747378752e-05
[34940] train loss: 1.2292758747935295, metric: 55.411356925964355, lr: 9.999999747378752e-05
[34960] train loss: 0.8482246026396751, metric: 57.41125965118408, lr: 9.999999747378752e-05
[34980] train loss: 0.9174392521381378, metric: 58.635122299194336, lr: 9.999999747378752e-05
[35000] train loss: 1.2397446259856224, metric: 54.40455198287964, lr: 9.999999747378752e-05
[35020] train loss: 1.4557585194706917, metric: 53.58668231964111, lr: 0.0009994393913075328
[35040] train loss: 4.145830117166042, metric: 51.017977237701416, lr: 0.0009969500824809074
[35060] train loss: 1.7301369160413742, metric: 53.73376417160034, lr: 0.000992479850538075
[35080] train loss: 1.4147740229964256, metric: 52.66574192047119, lr: 0.000986046390607953
[35100] train loss: 2.1658723428845406, metric: 52.37592315673828, lr: 0.0009776754304766655
[35120] train loss: 1.576158232986927, metric: 46.52970886230469, lr: 0.0009674003813415766
[35140] train loss: 5.225217625498772, metric: 46.10147476196289, lr: 0.0009552621049806476
[35160] train loss: 1.1934518069028854, metric: 45.22813701629639, lr: 0.0009413089719600976
[35180] train loss: 0.8582836166024208, metric: 56.21739196777344, lr: 0.0009255966870114207
[35200] train loss: 1.0609356462955475, metric: 51.5880823135376, lr: 0.00090818788157776
[35220] train loss: 0.8303075097501278, metric: 44.577670097351074, lr: 0.0008891518809832633
[35240] train loss: 2.036259062588215, metric: 47.15006685256958, lr: 0.0008685645880177617
[35260] train loss: 1.8037680238485336, metric: 47.240821838378906, lr: 0.0008465081336908042
[35280] train loss: 2.139229141175747, metric: 51.14919090270996, lr: 0.0008230703533627093
[35300] train loss: 5.074011787772179, metric: 45.89024543762207, lr: 0.0007983447285369039
[35320] train loss: 1.0762844234704971, metric: 49.91723918914795, lr: 0.0007724298629909754
[35340] train loss: 2.529282569885254, metric: 39.551995277404785, lr: 0.0007454289589077234
[35360] train loss: 1.0236899107694626, metric: 33.12109613418579, lr: 0.0007174497004598379
[35380] train loss: 0.7529815584421158, metric: 29.73963212966919, lr: 0.00068860367173329
[35400] train loss: 0.9945536255836487, metric: 26.84316396713257, lr: 0.0006590057746507227
[35420] train loss: 0.9009358361363411, metric: 28.651822566986084, lr: 0.0006287740543484688
[35440] train loss: 0.7857354357838631, metric: 26.13344383239746, lr: 0.000598029000684619
[35460] train loss: 0.5800513289868832, metric: 30.45638370513916, lr: 0.0005668931407853961
[35480] train loss: 0.7045490853488445, metric: 34.86239671707153, lr: 0.0005354906315915287
[35500] train loss: 0.6464516147971153, metric: 30.719791889190674, lr: 0.0005039466777816415
[35520] train loss: 0.8868685141205788, metric: 31.876121520996094, lr: 0.0004723869787994772
[35540] train loss: 1.5975800901651382, metric: 27.645053386688232, lr: 0.0004409373505041003
[35560] train loss: 0.7099458798766136, metric: 29.57584524154663, lr: 0.0004097231721971184
[35580] train loss: 0.8160978481173515, metric: 29.797932147979736, lr: 0.000378868862753734
[35600] train loss: 1.002629965543747, metric: 28.14150094985962, lr: 0.00034849741496145725
[35620] train loss: 0.6390726491808891, metric: 30.62113094329834, lr: 0.0003187299007549882
[35640] train loss: 0.719583660364151, metric: 29.186501502990723, lr: 0.0002896849764510989
[35660] train loss: 0.6935767307877541, metric: 29.13024663925171, lr: 0.0002614784170873463
[35680] train loss: 0.49695633351802826, metric: 30.435451984405518, lr: 0.00023422270896844566
[35700] train loss: 1.1617299392819405, metric: 29.973987102508545, lr: 0.00020802643848583102
[35720] train loss: 0.8035624548792839, metric: 34.329171657562256, lr: 0.00018299407383892685
[35740] train loss: 1.2591369897127151, metric: 29.515830993652344, lr: 0.00015922538295853883
[35760] train loss: 1.6122321486473083, metric: 30.558631420135498, lr: 0.00013681512791663408
[35780] train loss: 1.2285357564687729, metric: 32.94396781921387, lr: 0.00011585262109292671
[35800] train loss: 1.4947906658053398, metric: 31.090811252593994, lr: 9.999999747378752e-05
[35820] train loss: 1.2819074764847755, metric: 28.1954026222229, lr: 9.999999747378752e-05
[35840] train loss: 1.610662505030632, metric: 28.875145435333252, lr: 9.999999747378752e-05
[35860] train loss: 2.994073808193207, metric: 45.03580617904663, lr: 9.999999747378752e-05
[35880] train loss: 8.841216117143631, metric: 52.42116641998291, lr: 9.999999747378752e-05
[35900] train loss: 2.7646192759275436, metric: 44.91977500915527, lr: 9.999999747378752e-05
[35920] train loss: 1.0063466578722, metric: 40.31663227081299, lr: 9.999999747378752e-05
[35940] train loss: 1.990479663014412, metric: 45.440706729888916, lr: 9.999999747378752e-05
[35960] train loss: 2.673270210623741, metric: 42.04010534286499, lr: 9.999999747378752e-05
[35980] train loss: 4.688969664275646, metric: 43.16289186477661, lr: 9.999999747378752e-05
[36000] train loss: 3.8140184804797173, metric: 42.68020677566528, lr: 9.999999747378752e-05
[36020] train loss: 2.7989810034632683, metric: 47.00036334991455, lr: 0.0009994393913075328
[36040] train loss: 4.957246825098991, metric: 43.580734729766846, lr: 0.0009969500824809074
[36060] train loss: 1.7836564406752586, metric: 46.3471097946167, lr: 0.000992479850538075
[36080] train loss: 1.9869998469948769, metric: 47.08946228027344, lr: 0.000986046390607953
[36100] train loss: 2.1025774851441383, metric: 49.04713821411133, lr: 0.0009776754304766655
[36120] train loss: 1.0992506369948387, metric: 46.31734561920166, lr: 0.0009674003813415766
[36140] train loss: 1.964924119412899, metric: 45.97990846633911, lr: 0.0009552621049806476
[36160] train loss: 4.325237073004246, metric: 45.03719615936279, lr: 0.0009413089719600976
[36180] train loss: 0.688880480825901, metric: 44.98855018615723, lr: 0.0009255966870114207
[36200] train loss: 0.5143162980675697, metric: 42.03127574920654, lr: 0.00090818788157776
[36220] train loss: 1.6129288524389267, metric: 46.99088954925537, lr: 0.0008891518809832633
[36240] train loss: 5.272715523838997, metric: 53.55347156524658, lr: 0.0008685645880177617
[36260] train loss: 6.337355464696884, metric: 41.56943416595459, lr: 0.0008465081336908042
[36280] train loss: 1.5005588829517365, metric: 38.43579864501953, lr: 0.0008230703533627093
[36300] train loss: 2.500555530190468, metric: 40.119303703308105, lr: 0.0007983447285369039
[36320] train loss: 5.169125854969025, metric: 40.918264865875244, lr: 0.0007724298629909754
[36340] train loss: 1.3601243197917938, metric: 38.73169660568237, lr: 0.0007454289589077234
[36360] train loss: 1.1650645434856415, metric: 57.46199178695679, lr: 0.0007174497004598379
[36380] train loss: 0.6282603666186333, metric: 60.087026596069336, lr: 0.00068860367173329
[36400] train loss: 0.39155373349785805, metric: 59.17164993286133, lr: 0.0006590057746507227
[36420] train loss: 0.790407620370388, metric: 55.625160217285156, lr: 0.0006287740543484688
[36440] train loss: 0.46017706394195557, metric: 54.11419153213501, lr: 0.000598029000684619
[36460] train loss: 0.4746418446302414, metric: 54.60432243347168, lr: 0.0005668931407853961
[36480] train loss: 0.5786496102809906, metric: 49.74967384338379, lr: 0.0005354906315915287
[36500] train loss: 1.0103572830557823, metric: 54.36946678161621, lr: 0.0005039466777816415
[36520] train loss: 0.7469749972224236, metric: 50.96690654754639, lr: 0.0004723869787994772
[36540] train loss: 1.0217836871743202, metric: 50.68246936798096, lr: 0.0004409373505041003
[36560] train loss: 0.7145839519798756, metric: 48.679492473602295, lr: 0.0004097231721971184
[36580] train loss: 0.3065302185714245, metric: 51.864795207977295, lr: 0.000378868862753734
[36600] train loss: 0.5180628262460232, metric: 52.6141939163208, lr: 0.00034849741496145725
[36620] train loss: 0.3681723400950432, metric: 49.551751136779785, lr: 0.0003187299007549882
[36640] train loss: 0.42277784645557404, metric: 50.72690486907959, lr: 0.0002896849764510989
[36660] train loss: 0.39571743458509445, metric: 51.1880841255188, lr: 0.0002614784170873463
[36680] train loss: 0.39489877223968506, metric: 51.30034828186035, lr: 0.00023422270896844566
[36700] train loss: 0.4478174038231373, metric: 53.270421504974365, lr: 0.00020802643848583102
[36720] train loss: 0.5597394593060017, metric: 51.363083839416504, lr: 0.00018299407383892685
[36740] train loss: 0.838352344930172, metric: 50.39041328430176, lr: 0.00015922538295853883
[36760] train loss: 0.7031912058591843, metric: 49.17369318008423, lr: 0.00013681512791663408
[36780] train loss: 0.5398939698934555, metric: 48.90704011917114, lr: 0.00011585262109292671
[36800] train loss: 1.0746019147336483, metric: 50.15111255645752, lr: 9.999999747378752e-05
[36820] train loss: 0.8294566422700882, metric: 48.9307279586792, lr: 9.999999747378752e-05
[36840] train loss: 0.666113156825304, metric: 48.626726150512695, lr: 9.999999747378752e-05
[36860] train loss: 0.46302295476198196, metric: 47.13678550720215, lr: 9.999999747378752e-05
[36880] train loss: 0.8342244625091553, metric: 43.89784812927246, lr: 9.999999747378752e-05
[36900] train loss: 0.9817249029874802, metric: 43.01373481750488, lr: 9.999999747378752e-05
[36920] train loss: 1.055215947329998, metric: 42.116302490234375, lr: 9.999999747378752e-05
[36940] train loss: 1.6704362258315086, metric: 43.30343437194824, lr: 9.999999747378752e-05
[36960] train loss: 2.087817996740341, metric: 42.56255912780762, lr: 9.999999747378752e-05
[36980] train loss: 2.1929977610707283, metric: 43.3635311126709, lr: 9.999999747378752e-05
[37000] train loss: 2.625934988260269, metric: 42.366737365722656, lr: 9.999999747378752e-05
[37020] train loss: 1.9666956216096878, metric: 48.05160331726074, lr: 0.0009994393913075328
[37040] train loss: 1.105523370206356, metric: 46.20960807800293, lr: 0.0009969500824809074
[37060] train loss: 0.630602266639471, metric: 42.79745578765869, lr: 0.000992479850538075
[37080] train loss: 0.4593150056898594, metric: 43.92746925354004, lr: 0.000986046390607953
[37100] train loss: 0.44868119806051254, metric: 49.392595291137695, lr: 0.0009776754304766655
[37120] train loss: 0.31417765840888023, metric: 42.98574447631836, lr: 0.0009674003813415766
[37140] train loss: 0.4864751771092415, metric: 43.6681547164917, lr: 0.0009552621049806476
[37160] train loss: 0.3822731524705887, metric: 40.08440399169922, lr: 0.0009413089719600976
[37180] train loss: 0.3918532729148865, metric: 41.27774906158447, lr: 0.0009255966870114207
[37200] train loss: 0.3885555639863014, metric: 37.62541627883911, lr: 0.00090818788157776
[37220] train loss: 0.9878940992057323, metric: 39.84383010864258, lr: 0.0008891518809832633
[37240] train loss: 1.4994176179170609, metric: 41.156405448913574, lr: 0.0008685645880177617
[37260] train loss: 3.230792410671711, metric: 50.63569927215576, lr: 0.0008465081336908042
[37280] train loss: 2.634900063276291, metric: 49.3714394569397, lr: 0.0008230703533627093
[37300] train loss: 0.8656021952629089, metric: 41.10720348358154, lr: 0.0007983447285369039
[37320] train loss: 5.381544589996338, metric: 51.36431407928467, lr: 0.0007724298629909754
[37340] train loss: 2.5147215500473976, metric: 44.5984525680542, lr: 0.0007454289589077234
[37360] train loss: 1.0657896623015404, metric: 43.70595169067383, lr: 0.0007174497004598379
[37380] train loss: 2.199841618537903, metric: 58.53308296203613, lr: 0.00068860367173329
[37400] train loss: 0.49499280750751495, metric: 63.858877182006836, lr: 0.0006590057746507227
[37420] train loss: 0.3982369154691696, metric: 62.81272029876709, lr: 0.0006287740543484688
[37440] train loss: 0.3990849666297436, metric: 59.41625690460205, lr: 0.000598029000684619
[37460] train loss: 0.5223386809229851, metric: 54.647040367126465, lr: 0.0005668931407853961
[37480] train loss: 0.3604953959584236, metric: 53.19701099395752, lr: 0.0005354906315915287
[37500] train loss: 0.382663257420063, metric: 50.68765163421631, lr: 0.0005039466777816415
[37520] train loss: 0.3217298500239849, metric: 53.98653602600098, lr: 0.0004723869787994772
[37540] train loss: 0.33207931369543076, metric: 55.197906494140625, lr: 0.0004409373505041003
[37560] train loss: 0.3553461767733097, metric: 57.70698928833008, lr: 0.0004097231721971184
[37580] train loss: 0.3784102685749531, metric: 55.4549560546875, lr: 0.000378868862753734
[37600] train loss: 0.6720327362418175, metric: 56.30147457122803, lr: 0.00034849741496145725
[37620] train loss: 0.5145398899912834, metric: 58.47892093658447, lr: 0.0003187299007549882
[37640] train loss: 0.699084997177124, metric: 56.398698806762695, lr: 0.0002896849764510989
[37660] train loss: 0.6236745789647102, metric: 58.489702224731445, lr: 0.0002614784170873463
[37680] train loss: 0.8776914775371552, metric: 56.705199241638184, lr: 0.00023422270896844566
[37700] train loss: 3.7688541188836098, metric: 57.59256362915039, lr: 0.00020802643848583102
[37720] train loss: 6.893091395497322, metric: 68.35215377807617, lr: 0.00018299407383892685
[37740] train loss: 3.266346350312233, metric: 64.06857299804688, lr: 0.00015922538295853883
[37760] train loss: 2.695016823709011, metric: 57.9345645904541, lr: 0.00013681512791663408
[37780] train loss: 2.2683466970920563, metric: 50.86512565612793, lr: 0.00011585262109292671
[37800] train loss: 2.529059588909149, metric: 49.787888526916504, lr: 9.999999747378752e-05
[37820] train loss: 2.483253300189972, metric: 51.93034267425537, lr: 9.999999747378752e-05
[37840] train loss: 3.0184613913297653, metric: 60.20379447937012, lr: 9.999999747378752e-05
[37860] train loss: 1.251129850745201, metric: 57.75424575805664, lr: 9.999999747378752e-05
[37880] train loss: 1.322378285229206, metric: 58.05138874053955, lr: 9.999999747378752e-05
[37900] train loss: 3.1100952327251434, metric: 70.32869720458984, lr: 9.999999747378752e-05
[37920] train loss: 1.4936518371105194, metric: 72.0259199142456, lr: 9.999999747378752e-05
[37940] train loss: 1.7918277084827423, metric: 70.75419044494629, lr: 9.999999747378752e-05
[37960] train loss: 1.8020054399967194, metric: 59.018436431884766, lr: 9.999999747378752e-05
[37980] train loss: 1.3568445444107056, metric: 64.26968955993652, lr: 9.999999747378752e-05
[38000] train loss: 3.263037383556366, metric: 60.408620834350586, lr: 9.999999747378752e-05
[38020] train loss: 0.7665730938315392, metric: 49.84122323989868, lr: 0.0009994393913075328
[38040] train loss: 1.5165136009454727, metric: 56.90977478027344, lr: 0.0009969500824809074
[38060] train loss: 0.8242302909493446, metric: 53.885037899017334, lr: 0.000992479850538075
[38080] train loss: 0.9864700138568878, metric: 52.47856140136719, lr: 0.000986046390607953
[38100] train loss: 0.8259052410721779, metric: 53.360671043395996, lr: 0.0009776754304766655
[38120] train loss: 1.146591641008854, metric: 49.303791999816895, lr: 0.0009674003813415766
[38140] train loss: 0.7987949624657631, metric: 51.719566345214844, lr: 0.0009552621049806476
[38160] train loss: 0.965927816927433, metric: 59.12836217880249, lr: 0.0009413089719600976
[38180] train loss: 0.4125047139823437, metric: 49.51338529586792, lr: 0.0009255966870114207
[38200] train loss: 0.5371656641364098, metric: 50.14126205444336, lr: 0.00090818788157776
[38220] train loss: 0.7867897227406502, metric: 47.90125322341919, lr: 0.0008891518809832633
[38240] train loss: 1.1988525316119194, metric: 51.64425182342529, lr: 0.0008685645880177617
[38260] train loss: 0.9751643911004066, metric: 46.477466106414795, lr: 0.0008465081336908042
[38280] train loss: 0.5799666941165924, metric: 48.12905740737915, lr: 0.0008230703533627093
[38300] train loss: 0.3778256066143513, metric: 47.346538066864014, lr: 0.0007983447285369039
[38320] train loss: 0.5274663046002388, metric: 44.938828468322754, lr: 0.0007724298629909754
[38340] train loss: 0.602381244301796, metric: 45.44246864318848, lr: 0.0007454289589077234
[38360] train loss: 0.6340074054896832, metric: 46.26606845855713, lr: 0.0007174497004598379
[38380] train loss: 0.5253150500357151, metric: 45.422531604766846, lr: 0.00068860367173329
[38400] train loss: 0.8531332314014435, metric: 47.102585315704346, lr: 0.0006590057746507227
[38420] train loss: 0.8422204777598381, metric: 39.452208518981934, lr: 0.0006287740543484688
[38440] train loss: 0.7309409454464912, metric: 39.34088897705078, lr: 0.000598029000684619
[38460] train loss: 0.7761799916625023, metric: 42.96936511993408, lr: 0.0005668931407853961
[38480] train loss: 0.42767196148633957, metric: 42.17937469482422, lr: 0.0005354906315915287
[38500] train loss: 0.8212958425283432, metric: 44.12843132019043, lr: 0.0005039466777816415
[38520] train loss: 0.4386787787079811, metric: 40.811859130859375, lr: 0.0004723869787994772
[38540] train loss: 0.6238441243767738, metric: 41.33819770812988, lr: 0.0004409373505041003
[38560] train loss: 0.501335509121418, metric: 42.41115379333496, lr: 0.0004097231721971184
[38580] train loss: 0.3792949840426445, metric: 40.15107297897339, lr: 0.000378868862753734
[38600] train loss: 1.055409349501133, metric: 43.731106758117676, lr: 0.00034849741496145725
[38620] train loss: 4.6922871842980385, metric: 43.59180545806885, lr: 0.0003187299007549882
[38640] train loss: 4.00800509005785, metric: 49.78140163421631, lr: 0.0002896849764510989
[38660] train loss: 0.8460426777601242, metric: 50.452863693237305, lr: 0.0002614784170873463
[38680] train loss: 0.6519913375377655, metric: 54.61753749847412, lr: 0.00023422270896844566
[38700] train loss: 0.4917612038552761, metric: 46.15012550354004, lr: 0.00020802643848583102
[38720] train loss: 0.4224412888288498, metric: 44.655123233795166, lr: 0.00018299407383892685
[38740] train loss: 0.584665272384882, metric: 43.47286605834961, lr: 0.00015922538295853883
[38760] train loss: 2.1581484526395798, metric: 44.679965019226074, lr: 0.00013681512791663408
[38780] train loss: 0.8853259272873402, metric: 45.061641693115234, lr: 0.00011585262109292671
[38800] train loss: 1.2638710848987103, metric: 42.96983814239502, lr: 9.999999747378752e-05
[38820] train loss: 0.8381487168371677, metric: 46.15452289581299, lr: 9.999999747378752e-05
[38840] train loss: 1.309814315289259, metric: 44.660104751586914, lr: 9.999999747378752e-05
[38860] train loss: 0.6738329641520977, metric: 44.76273441314697, lr: 9.999999747378752e-05
[38880] train loss: 0.5603058636188507, metric: 44.9704647064209, lr: 9.999999747378752e-05
[38900] train loss: 0.7989764660596848, metric: 44.63970470428467, lr: 9.999999747378752e-05
[38920] train loss: 2.462794452905655, metric: 53.03737926483154, lr: 9.999999747378752e-05
[38940] train loss: 1.1708598956465721, metric: 55.92368268966675, lr: 9.999999747378752e-05
[38960] train loss: 1.3091941103339195, metric: 52.888532638549805, lr: 9.999999747378752e-05
[38980] train loss: 0.8619680032134056, metric: 50.41280269622803, lr: 9.999999747378752e-05
[39000] train loss: 1.183985710144043, metric: 49.03405809402466, lr: 9.999999747378752e-05
[39020] train loss: 0.6330463737249374, metric: 54.543123722076416, lr: 0.0009994393913075328
[39040] train loss: 0.41224777698516846, metric: 47.21810436248779, lr: 0.0009969500824809074
[39060] train loss: 0.3252319246530533, metric: 52.44090747833252, lr: 0.000992479850538075
[39080] train loss: 0.4036563038825989, metric: 55.4871301651001, lr: 0.000986046390607953
[39100] train loss: 0.36894773691892624, metric: 60.37792491912842, lr: 0.0009776754304766655
[39120] train loss: 0.47539763152599335, metric: 54.612141132354736, lr: 0.0009674003813415766
[39140] train loss: 0.4974900744855404, metric: 54.388668060302734, lr: 0.0009552621049806476
[39160] train loss: 0.2766435891389847, metric: 53.80136728286743, lr: 0.0009413089719600976
[39180] train loss: 0.39681757241487503, metric: 54.401248931884766, lr: 0.0009255966870114207
[39200] train loss: 3.113055292516947, metric: 52.1873459815979, lr: 0.00090818788157776
[39220] train loss: 1.264618769288063, metric: 54.33377504348755, lr: 0.0008891518809832633
[39240] train loss: 1.0741354748606682, metric: 55.73476552963257, lr: 0.0008685645880177617
[39260] train loss: 0.9279961064457893, metric: 49.93984317779541, lr: 0.0008465081336908042
[39280] train loss: 1.1428614407777786, metric: 51.09201383590698, lr: 0.0008230703533627093
[39300] train loss: 1.8113227412104607, metric: 54.918639183044434, lr: 0.0007983447285369039
[39320] train loss: 1.2253533527255058, metric: 53.42810535430908, lr: 0.0007724298629909754
[39340] train loss: 0.6285050064325333, metric: 56.16835880279541, lr: 0.0007454289589077234
[39360] train loss: 0.9288680702447891, metric: 52.7275128364563, lr: 0.0007174497004598379
[39380] train loss: 1.379997693002224, metric: 56.044090270996094, lr: 0.00068860367173329
[39400] train loss: 1.1632051914930344, metric: 54.23472213745117, lr: 0.0006590057746507227
[39420] train loss: 0.8107439056038857, metric: 56.10452461242676, lr: 0.0006287740543484688
[39440] train loss: 0.6794378012418747, metric: 57.51016902923584, lr: 0.000598029000684619
[39460] train loss: 0.34612616896629333, metric: 56.809983253479004, lr: 0.0005668931407853961
[39480] train loss: 0.3299949876964092, metric: 55.34838676452637, lr: 0.0005354906315915287
[39500] train loss: 0.3914661779999733, metric: 55.86554765701294, lr: 0.0005039466777816415
[39520] train loss: 0.4023089110851288, metric: 55.933995723724365, lr: 0.0004723869787994772
[39540] train loss: 0.39288385957479477, metric: 54.59841966629028, lr: 0.0004409373505041003
[39560] train loss: 0.38922685757279396, metric: 52.27004814147949, lr: 0.0004097231721971184
[39580] train loss: 0.33848346397280693, metric: 54.637770652770996, lr: 0.000378868862753734
[39600] train loss: 0.34893401339650154, metric: 57.530306816101074, lr: 0.00034849741496145725
[39620] train loss: 0.3771422430872917, metric: 57.52643585205078, lr: 0.0003187299007549882
[39640] train loss: 0.38517269492149353, metric: 53.55037975311279, lr: 0.0002896849764510989
[39660] train loss: 0.4476631097495556, metric: 52.27605152130127, lr: 0.0002614784170873463
[39680] train loss: 0.5466734692454338, metric: 49.57772397994995, lr: 0.00023422270896844566
[39700] train loss: 0.5033377110958099, metric: 50.054954051971436, lr: 0.00020802643848583102
[39720] train loss: 0.5727799236774445, metric: 55.303707122802734, lr: 0.00018299407383892685
[39740] train loss: 0.4275324270129204, metric: 51.94889545440674, lr: 0.00015922538295853883
[39760] train loss: 0.5465093478560448, metric: 51.378490924835205, lr: 0.00013681512791663408
[39780] train loss: 0.40591929107904434, metric: 49.668840408325195, lr: 0.00011585262109292671
[39800] train loss: 0.450000561773777, metric: 50.07691240310669, lr: 9.999999747378752e-05
[39820] train loss: 0.36958659440279007, metric: 49.989996910095215, lr: 9.999999747378752e-05
[39840] train loss: 0.39709659665822983, metric: 47.152573585510254, lr: 9.999999747378752e-05
[39860] train loss: 0.314422894269228, metric: 47.34164094924927, lr: 9.999999747378752e-05
[39880] train loss: 0.3423476591706276, metric: 46.66823768615723, lr: 9.999999747378752e-05
[39900] train loss: 0.3404296338558197, metric: 48.79819202423096, lr: 9.999999747378752e-05
[39920] train loss: 0.38115112483501434, metric: 46.74371099472046, lr: 9.999999747378752e-05
[39940] train loss: 6.484142303466797, metric: 54.61853885650635, lr: 9.999999747378752e-05
[39960] train loss: 2.323596090078354, metric: 55.05095291137695, lr: 9.999999747378752e-05
[39980] train loss: 2.0749758780002594, metric: 57.6508092880249, lr: 9.999999747378752e-05
[40000] train loss: 1.1727789640426636, metric: 57.45323085784912, lr: 9.999999747378752e-05
[40020] train loss: 1.0635136514902115, metric: 55.220130920410156, lr: 0.0009994393913075328
[40040] train loss: 0.4651486352086067, metric: 61.15881061553955, lr: 0.0009969500824809074
[40060] train loss: 0.5732184126973152, metric: 57.52657413482666, lr: 0.000992479850538075
[40080] train loss: 0.6240559592843056, metric: 67.86123085021973, lr: 0.000986046390607953
[40100] train loss: 0.5756052881479263, metric: 61.48493957519531, lr: 0.0009776754304766655
[40120] train loss: 0.7112868502736092, metric: 62.348384857177734, lr: 0.0009674003813415766
[40140] train loss: 0.6630453541874886, metric: 67.89917659759521, lr: 0.0009552621049806476
[40160] train loss: 0.65446437895298, metric: 59.357194900512695, lr: 0.0009413089719600976
[40180] train loss: 0.6659695133566856, metric: 59.87121105194092, lr: 0.0009255966870114207
[40200] train loss: 0.30031583085656166, metric: 58.83143138885498, lr: 0.00090818788157776
[40220] train loss: 0.48350905627012253, metric: 56.12879180908203, lr: 0.0008891518809832633
[40240] train loss: 0.40043293684720993, metric: 57.1713809967041, lr: 0.0008685645880177617
[40260] train loss: 0.41343922913074493, metric: 61.36137104034424, lr: 0.0008465081336908042
[40280] train loss: 1.3550396040081978, metric: 60.92419147491455, lr: 0.0008230703533627093
[40300] train loss: 0.7230651527643204, metric: 59.222599029541016, lr: 0.0007983447285369039
[40320] train loss: 0.5419716835021973, metric: 63.10213565826416, lr: 0.0007724298629909754
[40340] train loss: 0.5337925553321838, metric: 61.88018989562988, lr: 0.0007454289589077234
[40360] train loss: 0.5063242614269257, metric: 65.39927005767822, lr: 0.0007174497004598379
[40380] train loss: 0.32315588742494583, metric: 65.28472137451172, lr: 0.00068860367173329
[40400] train loss: 0.31475790962576866, metric: 62.887224197387695, lr: 0.0006590057746507227
[40420] train loss: 0.4626282826066017, metric: 60.3248872756958, lr: 0.0006287740543484688
[40440] train loss: 0.5736970901489258, metric: 67.86672592163086, lr: 0.000598029000684619
[40460] train loss: 1.4890681505203247, metric: 50.25238800048828, lr: 0.0005668931407853961
[40480] train loss: 0.7076893299818039, metric: 48.11464309692383, lr: 0.0005354906315915287
[40500] train loss: 1.8388476073741913, metric: 52.16040325164795, lr: 0.0005039466777816415
[40520] train loss: 0.8456478044390678, metric: 51.99954319000244, lr: 0.0004723869787994772
[40540] train loss: 0.7410393878817558, metric: 52.33702278137207, lr: 0.0004409373505041003
[40560] train loss: 0.9023547917604446, metric: 56.03015327453613, lr: 0.0004097231721971184
[40580] train loss: 1.4705267399549484, metric: 49.49194526672363, lr: 0.000378868862753734
[40600] train loss: 2.3788517862558365, metric: 60.74674320220947, lr: 0.00034849741496145725
[40620] train loss: 1.1189764812588692, metric: 58.24898910522461, lr: 0.0003187299007549882
[40640] train loss: 0.5252904072403908, metric: 58.2965202331543, lr: 0.0002896849764510989
[40660] train loss: 0.5885277837514877, metric: 55.1486873626709, lr: 0.0002614784170873463
[40680] train loss: 0.4570177122950554, metric: 55.82054615020752, lr: 0.00023422270896844566
[40700] train loss: 0.46360014751553535, metric: 56.921420097351074, lr: 0.00020802643848583102
[40720] train loss: 0.4059312455356121, metric: 53.202778816223145, lr: 0.00018299407383892685
[40740] train loss: 0.3612086921930313, metric: 52.287522315979004, lr: 0.00015922538295853883
[40760] train loss: 0.3659561425447464, metric: 52.79185962677002, lr: 0.00013681512791663408
[40780] train loss: 0.29616308212280273, metric: 52.80703258514404, lr: 0.00011585262109292671
[40800] train loss: 0.29428617283701897, metric: 52.545278549194336, lr: 9.999999747378752e-05
[40820] train loss: 0.3399580083787441, metric: 54.52578926086426, lr: 9.999999747378752e-05
[40840] train loss: 0.3865620791912079, metric: 54.96019458770752, lr: 9.999999747378752e-05
[40860] train loss: 0.3442450240254402, metric: 54.110188484191895, lr: 9.999999747378752e-05
[40880] train loss: 0.36454688012599945, metric: 52.30162811279297, lr: 9.999999747378752e-05
[40900] train loss: 0.3599778637290001, metric: 54.04165172576904, lr: 9.999999747378752e-05
[40920] train loss: 0.3184242472052574, metric: 53.54004096984863, lr: 9.999999747378752e-05
[40940] train loss: 0.47394129261374474, metric: 54.61312437057495, lr: 9.999999747378752e-05
[40960] train loss: 0.9133562594652176, metric: 57.23802947998047, lr: 9.999999747378752e-05
[40980] train loss: 0.8244762569665909, metric: 49.69956064224243, lr: 9.999999747378752e-05
[41000] train loss: 0.7438600435853004, metric: 46.21696758270264, lr: 9.999999747378752e-05
[41020] train loss: 0.5381033942103386, metric: 45.91180229187012, lr: 0.0009994393913075328
[41040] train loss: 0.5804579854011536, metric: 46.0592098236084, lr: 0.0009969500824809074
[41060] train loss: 0.44183383136987686, metric: 46.244877338409424, lr: 0.000992479850538075
[41080] train loss: 0.4687815234065056, metric: 46.404738903045654, lr: 0.000986046390607953
[41100] train loss: 0.35172343254089355, metric: 48.82373046875, lr: 0.0009776754304766655
[41120] train loss: 0.5886330381035805, metric: 48.63033962249756, lr: 0.0009674003813415766
[41140] train loss: 0.35722804069519043, metric: 48.89478778839111, lr: 0.0009552621049806476
[41160] train loss: 0.37350407987833023, metric: 44.61278009414673, lr: 0.0009413089719600976
[41180] train loss: 0.5770492106676102, metric: 47.08481216430664, lr: 0.0009255966870114207
[41200] train loss: 0.33586328104138374, metric: 47.18938446044922, lr: 0.00090818788157776
[41220] train loss: 0.6441437266767025, metric: 46.28668403625488, lr: 0.0008891518809832633
[41240] train loss: 0.46063417941331863, metric: 42.73778009414673, lr: 0.0008685645880177617
[41260] train loss: 0.44076933339238167, metric: 45.744202613830566, lr: 0.0008465081336908042
[41280] train loss: 0.4137769229710102, metric: 41.60571002960205, lr: 0.0008230703533627093
[41300] train loss: 1.1505800299346447, metric: 42.132625579833984, lr: 0.0007983447285369039
[41320] train loss: 0.8199757039546967, metric: 43.82629203796387, lr: 0.0007724298629909754
[41340] train loss: 0.5595768876373768, metric: 43.45909833908081, lr: 0.0007454289589077234
[41360] train loss: 0.5013797953724861, metric: 39.97236156463623, lr: 0.0007174497004598379
[41380] train loss: 0.4195083789527416, metric: 40.798943519592285, lr: 0.00068860367173329
[41400] train loss: 0.703538328409195, metric: 39.458173751831055, lr: 0.0006590057746507227
[41420] train loss: 0.5412213131785393, metric: 37.86405849456787, lr: 0.0006287740543484688
[41440] train loss: 0.5961320139467716, metric: 42.02293539047241, lr: 0.000598029000684619
[41460] train loss: 5.159185476601124, metric: 38.21537160873413, lr: 0.0005668931407853961
[41480] train loss: 1.8285294026136398, metric: 41.93506145477295, lr: 0.0005354906315915287
[41500] train loss: 0.9372407495975494, metric: 33.356539249420166, lr: 0.0005039466777816415
[41520] train loss: 0.7613394781947136, metric: 35.055697441101074, lr: 0.0004723869787994772
[41540] train loss: 0.9914693459868431, metric: 35.32685708999634, lr: 0.0004409373505041003
[41560] train loss: 1.3496913388371468, metric: 34.43113327026367, lr: 0.0004097231721971184
[41580] train loss: 2.400189124047756, metric: 37.13718366622925, lr: 0.000378868862753734
[41600] train loss: 3.5672415122389793, metric: 34.55523443222046, lr: 0.00034849741496145725
[41620] train loss: 1.2684815376996994, metric: 37.538506507873535, lr: 0.0003187299007549882
[41640] train loss: 1.345938265323639, metric: 33.466708183288574, lr: 0.0002896849764510989
[41660] train loss: 0.6780108213424683, metric: 32.383952140808105, lr: 0.0002614784170873463
[41680] train loss: 0.7516237124800682, metric: 35.44631099700928, lr: 0.00023422270896844566
[41700] train loss: 0.5388946309685707, metric: 33.7221736907959, lr: 0.00020802643848583102
[41720] train loss: 0.4094771482050419, metric: 34.40332651138306, lr: 0.00018299407383892685
[41740] train loss: 1.143353410065174, metric: 35.3760461807251, lr: 0.00015922538295853883
[41760] train loss: 0.9413724653422832, metric: 36.792911529541016, lr: 0.00013681512791663408
[41780] train loss: 1.2286786884069443, metric: 38.82812261581421, lr: 0.00011585262109292671
[41800] train loss: 0.8843734413385391, metric: 36.750142097473145, lr: 9.999999747378752e-05
[41820] train loss: 0.8785495907068253, metric: 35.65698289871216, lr: 9.999999747378752e-05
[41840] train loss: 0.49385397881269455, metric: 31.040401458740234, lr: 9.999999747378752e-05
[41860] train loss: 0.5944308415055275, metric: 31.037636756896973, lr: 9.999999747378752e-05
[41880] train loss: 0.9658448770642281, metric: 33.05683755874634, lr: 9.999999747378752e-05
[41900] train loss: 0.9277250021696091, metric: 32.963279724121094, lr: 9.999999747378752e-05
[41920] train loss: 0.6334404498338699, metric: 34.01730489730835, lr: 9.999999747378752e-05
[41940] train loss: 1.865597739815712, metric: 37.59210395812988, lr: 9.999999747378752e-05
[41960] train loss: 0.7178093120455742, metric: 36.37434673309326, lr: 9.999999747378752e-05
[41980] train loss: 0.6617983803153038, metric: 36.20823669433594, lr: 9.999999747378752e-05
[42000] train loss: 2.24540838599205, metric: 36.2061128616333, lr: 9.999999747378752e-05
